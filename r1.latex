% Page setup
\documentclass[11pt]{memoir}
\setstocksize{9.69in}{7.44in}
\settrimmedsize{\stockheight}{\stockwidth}{*}
\setlrmarginsandblock{3.5cm}{2.5cm}{*}
\setulmarginsandblock{2cm}{3cm}{*}
\checkandfixthelayout 
\setheadfoot{\onelineskip}{2\onelineskip}

% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{parskip}    	
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}	

\usepackage{graphicx}					
\usepackage{amssymb}

%SetFonts
\usepackage[T1]{fontenc}
\usepackage{newpxtext,newpxmath}

%Images
\usepackage{graphicx}
% We will generate all images so they have a width 1\maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=1\maxwidth]{#1}}
\usepackage{rotating}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}
\captionsetup[figure]{labelfont={bf,it},textfont={bf,it}}
 \setfloatlocations{figure}{thpb}


% Links
\usepackage[hyphens]{url}
\usepackage[unicode=true]{hyperref}
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={},
            colorlinks=false,
            urlcolor=black,
            linkcolor=black,
            pdfborder={0 0 0}}

% Footers / Page Numbers            (FIX ME)
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
  \renewcommand{\headrulewidth}{0pt}
  \fancyfoot[LE, RO]{\thepage}
  \fancyfoot[C]{\textsl}

% Tables            
\usepackage{longtable,booktabs}
\usepackage[width=.8\textwidth]{caption}
% These lines are needed to make table captions work with longtable:
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{rotating}
 \setfloatlocations{table}{thpb}


% Code Sections
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstnewenvironment{code}{\lstset{basicstyle=\small\ttfamily}}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}


%Links as Notes
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
 \renewcommand{\footnotesize}{\fontsize{6.5pt}{8.5pt}\selectfont}


%Sections
\chapterstyle{veelo}
\setlength{\beforechapskip}{20pt}
\setsechook{\hangsecnum}
\setcounter{secnumdepth}{5}

\begin{document}

\frontmatter

\title{Risk-First Software Development: The Menagerie}
\author{Rob Moffat}

\begin{titlingpage}

\hspace{0.05\textwidth}

\centering

{\Huge\bfseries\textsc{Risk-First}}\\[2\baselineskip]

{\Huge\bfseries\textsc{Software Development}}\\[1\baselineskip]

{\Huge\bfseries\textsc{De-Risked }}\\[2\baselineskip]

{\Huge\textit{Volume 1: The Menagerie}}\\[4\baselineskip]

{\Oldincludegraphics[width=0.5\textwidth]{images/R1_logo_grue.png}}\\[4\baselineskip]

{\Huge\textsc{Rob Moffat}}


\end{titlingpage}

\hypertarget{risk-first-the-menagerie}{%
\section{Risk First: The Menagerie}\label{risk-first-the-menagerie}}

By Rob Moffat

Copyright Â© 2018 Kite9 Ltd.

All rights reserved. No part of this publication may be reproduced,
distributed, or transmitted in any form or by any means, including
photocopying, recording, or other electronic or mechanical methods,
without the prior written permission of the publisher, except in the
case of brief quotations embodied in critical reviews and certain other
noncommercial uses permitted by copyright law. For permission requests,
write to the publisher, addressed ``Attention: Permissions
Coordinator,'' at the address below.

ISBN: 9781717491855

\hypertarget{credits}{%
\subsection{Credits}\label{credits}}

tbd

Cover Images: Biodiversity Heritage Library. Biologia
Centrali-Americana. Insecta. Rhynchota. Hemiptera-Homoptera. Volume 1
(1881-1905)

Cover Design By P. Moffat (\texttt{peter@petermoffat.com})

Thanks to:

\hypertarget{books-in-the-series}{%
\subsection{Books In The Series}\label{books-in-the-series}}

\begin{itemize}
\tightlist
\item
  \textbf{Risk First: The Menagerie:} Book one of the
  \textbf{Risk-First} series argues the case for viewing \emph{all} of
  the activities on a software project through the lens of
  \emph{managing risk}. It introduces the menagerie of different risks
  you're likely to meet on a software project, naming and classifying
  them so that we can try to understand them better.
\item
  \textbf{Risk First: Tools and Practices:} Book two of the \textbf{Risk
  First} series explores the relationship between software project risks
  and the tools and practices we use to mitigate them. Due for
  publication in 2020.
\end{itemize}

\hypertarget{online}{%
\subsection{Online}\label{online}}

Material for the books is freely available to read, drawn from
\texttt{risk-first.org}.

\hypertarget{published-by}{%
\subsection{Published By}\label{published-by}}

\begin{verbatim}
Kite9 Ltd.
14 Manor Close
Colchester
CO6 4AR
\end{verbatim}

\newpage
\setcounter{tocdepth}{0}
\tableofcontents

\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

Welcome to Risk-First!

Let's cover some of the big questions up-front: The why, what, who, how
and where of \emph{The Menagerie}.

\hypertarget{why}{%
\section{Why}\label{why}}

\begin{quotation}

Scrum, Waterfall, Lean, Prince2: what do they all have in common?

\end{quotation}

I've started this because, on my career journey, I've noticed that the
way I do things doesn't seem to match up with the way the books
\emph{say} it should be done. And, I found this odd and wanted to
explore it further. Hopefully, you, the reader, will find something of
use in this.

I started with this observation: \emph{Development Teams} put a lot of
faith in methodology. Sometimes, this faith is often so strong it
borders on religion. (Which in itself is a concern.) For some, this is
Prince2. For others, it might be Lean or Agile.

\emph{Developers} put a lot of faith in \emph{particular tools} too.
Some developers are pro-or-anti-Java, others are pro-or-anti-XML. All of
them have their views coloured by their \emph{experiences} (or lack of)
with these tools. Was this because their past projects \emph{succeeded}
or \emph{failed} because of them?

As time went by, I came to see that the choice of methodology, process
or tool was contingent on the problem being solved, and the person
solving the problem. We don't face a shortage of tools in IT, or a
shortage of methodologies, or a shortage of practices. Essentially, that
all the tools and methodologies that the industry had supplied were
there to help \emph{minimize the risk of my project failing}.

This book considers that perspective: that building software is all
about \emph{managing risk}, and that these methodologies are
acknowledgements of this fact, and they differ because they have
\emph{different ideas} about which are the most important \emph{risks to
manage}.

\hypertarget{what-this-is}{%
\section{What This Is}\label{what-this-is}}

Hopefully, after reading this, you'll come away with:

\begin{itemize}
\tightlist
\item
  An appreciation of how risk underpins everything we do as developers,
  whether we want it to or not.
\item
  A framework for evaluating methodologies, tools and practices and
  choosing the right one for the task-at-hand.
\item
  A recontextualization of the software process as being an exercise in
  mitigating different kinds of risk.
\item
  The tools to help you decide when a methodology or tool is
  \emph{letting you down}, and the vocabulary to argue for when it's a
  good idea to deviate from it.
\end{itemize}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change too fast.)

\begin{quotation}

``I have this Pattern''

\sourceatright{\href{http://c2.com/ppr/wiki/WikiPagesAboutWhatArePatterns/HaveThisPattern.html}{\textemdash  Attributed to Ward Cunningham, \emph{Have This Pattern, C2 Wiki}}}
\end{quotation}

Does that diminish it? If you have visited the
\href{https://tvtropes.org}{TVTropes} website, you'll know that it's a
set of web-pages describing \emph{common patterns} of narrative,
production, character design etc. to do with fiction. For example:

\begin{quotation}

``Sometimes, at the end of a Dream Sequence or an All Just a Dream
episode, after the character in question has woken up and demonstrated
any {[}lesson{]} that the dream might have been communicating, there's
some small hint that it wasn't a dream after all, even though it quite
obviously was\ldots{} right?.''

\sourceatright{\href{https://tvtropes.org/pmwiki/pmwiki.php/Main/OrWasItADream}{\textemdash  Or Was It a Dream?, \emph{TVTropes}}}
\end{quotation}

Is it scientific? No.~Is it correct? Almost certainly. TVTropes is a set
of \emph{empirical patterns} for how stories on TV and other media work.
It's really useful, and a lot of fun. (Warning: it's also incredibly
addictive).

In the same way, ``\href{http://amzn.eu/d/3cOwTkH}{Design Patterns:
Elements of Reusable Object-Oriented Software}'', is a book detailing
patterns of \emph{structure} within Object-Oriented programming, such
as:

\begin{quotation}

``{[}The{]} Adapter {[}pattern{]} allows classes with incompatible
interfaces to work together by wrapping its own interface around that of
an already existing class\ldots{}''

\sourceatright{\href{https://en.wikipedia.org/wiki/Design_Patterns}{\textemdash  Design Patterns, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{patterns-for-practitioners}{%
\subsection{Patterns For
Practitioners}\label{patterns-for-practitioners}}

Design Patterns aimed to be a set of \emph{useful} patterns which
practitioners could use in their software to achieve certain goals. ``I
have this pattern'' was a phrase used to describe how they had seen a
certain set of constraints before, and how they had solved it in
software.

This book was a set of experts handing down their battle-tested
practices for other developers to use, and, whether you like patterns or
not, knowing them is an important part of being a software developer, as
you will see them used everywhere you go and probably use them yourself.

In the same way, Risk-First aims to be a set of \emph{Patterns for
Software Risk}. Hopefully after reading this book, you will see where
risk hides in software projects, and have a name for it when you see it.

\hypertarget{towards-a-periodic-table}{%
\subsection{Towards a ``Periodic
Table''}\label{towards-a-periodic-table}}

In the latter chapters of ``The Menagerie'' we try to assemble these
risk patterns into a cohesive whole. Projects fail because of risks, and
risks arise from predictable sources.

\hypertarget{what-this-is-not}{%
\subsection{What This is Not}\label{what-this-is-not}}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change too fast.)

Neither is this site isn't going to be an exhaustive guide of every
possible software development practice and methodology. That would just
be too long and tedious.

Neither is this really a practitioner's guide to using any particular
methodology: If you've come here to learn the best way to do
Retrospectives, then you're in the wrong place. There are plenty of
places you can find that information already. Where possible, this site
will link to or reference concepts on Wikipedia or the wider internet
for further reading on each subject.

\hypertarget{who}{%
\section{Who}\label{who}}

This work is intended to be read by people who work on software
projects, and especially those who are involved in managing software
projects.

If you work collaboratively with other people in a software process, you
should find Risk-First a useful lexicon of terms to help describe the
risks you face.

But here's a warning: This is going to be a depressing book to read. It
is book one of a two-book series, but in \textbf{Book One} you only get
to meet the bad guy.

While \textbf{Book Two} is all about \emph{how to succeed}, This book is
all about how projects \emph{fail}. In it, we're going to try and put
together a framework for understanding the risk of failure, in order
that we can reconstruct our understanding of our activities on a project
based on avoiding it.

So, if you are interested in \emph{avoiding your project failing}, this
is probably going to be useful knowledge.

\hypertarget{for-developers}{%
\subsection{For Developers}\label{for-developers}}

Risk-First is a tool you can deploy to immediately improve your ability
to plan your work.

Frequently, as developers we find software methodologies ``done to us''
from above. Risk-First is a toolkit to help \emph{take apart}
methodologies like Scrum, Lean and Prince2, and understand them.
Methodologies are \emph{bicycles}, rather than \emph{religions}. Rather
than simply \emph{believing}, we can take them apart and see how they
work.

\hypertarget{for-project-managers-and-team-leads}{%
\subsection{For Project Managers and Team
Leads}\label{for-project-managers-and-team-leads}}

All too often, Project Managers don't have a full grasp of the technical
details of their projects. And this is perfectly normal, as the
specialization belongs below them. However, projects fail because risks
materialize, and risks materialize because the devil is in those
details.

This seems like a lost cause, but there is hope: the ways in which risks
materialize on technical projects is the same every time. With
Risk-First we are attempting to name each of these types of risk, which
allows for a dialog with developers about which risks they face, and the
order they should be tackled.

Risk-First allows a project manager to pry open the black box of
development and talk with developers about their work, and how it will
affect the project. It is another tool in the (limited) arsenal of
techniques a project manager can bring to bear on the task of delivering
a successful project.

\hypertarget{how}{%
\section{How}\label{how}}

One of the original proponents of the Agile Manifesto, Kent Beck, begins
his book Extreme Programming by stating:

\begin{quotation}

``It's all about risk''

\sourceatright{\href{http://amzn.eu/d/gUQjnbF}{\textemdash  Kent Beck, \emph{Extreme Programming Explained}}}
\end{quotation}

This is a promising start. From there, he introduces his methodology,
Extreme Programming, and explains how you can adopt it in your team, the
features to observe and the characteristics of success and failure.
However, while \emph{Risk} has clearly driven the conception of Extreme
Programming, there is no clear model of software risk underpinning the
work, and the relationship between the practices he espouses and the
risks he is avoiding are hidden.

In this book, we are going to introduce a model of software project
risk. This means that in \textbf{Book Two} (Risk-First: Tools and
Practices), we can properly analyse Extreme Programming (and Scrum,
Waterfall, Lean and all the others) and \emph{understand} what drives
them. Since they are designed to deliver successful software projects,
they must be about mitigate risks, and we will uncover \emph{exactly
which risks are mitigated} and \emph{how they do it}.

\hypertarget{where}{%
\section{Where}\label{where}}

All of the material for this book is available Open Source on
\href{https://github.com}{github.com}, and at the
\href{https://risk-first.org}{risk-first.org} website. Please visit,
your feedback is appreciated.

There is no compulsion to buy a print or digital version of the book,
but we'd really appreciate the support. So, if you've read this and
enjoyed it, how about buying a copy for someone else to read?

\hypertarget{a-note-on-references}{%
\subsection{A Note on References}\label{a-note-on-references}}

Where possible, references are to the
\href{https://wikipedia.org}{Wikipedia} website. Wikipedia is not
perfect. There is a case for linking to the original articles and
papers, but by using Wikipedia references are free and easy for everyone
to access, and hopefully will exist for a long time into the future.

On to The Executive Summary

\hypertarget{executive-summary}{%
\chapter{Executive Summary}\label{executive-summary}}

\hypertarget{there-are-lots-of-ways-of-running-software-projects}{%
\section{1. There are Lots of Ways of Running Software
Projects}\label{there-are-lots-of-ways-of-running-software-projects}}

There are lots of different ways to look at a project. For example,
metrics such as ``number of open tickets'', ``story points'', ``code
coverage'' or ``release cadence'' give us a numerical feel for how
things are going and what needs to happen next. We also judge the health
of projects by the practices used on them - Continuous Integration, Unit
Testing or Pair Programming, for example.

Software methodologies, then, are collections of tools and practices:
``Agile'', ``Waterfall'', ``Lean'' or ``Phased Delivery'' (for example)
all suggest different approaches to running a project, and are
opinionated about the way they think projects should be done and the
tools that should be used.

None of these is necessarily more ``right'' than another- they are
suitable on different projects at different times.

A key question then is: \textbf{how do we select the right tools for the
job?}

\hypertarget{we-can-look-at-projects-in-terms-of-risks}{%
\section{2. We can Look at Projects in Terms of
Risks}\label{we-can-look-at-projects-in-terms-of-risks}}

One way to examine a project in-flight is by looking at the risks it
faces.

Commonly, tools such as RAID logs and RAG status reporting are used.
These techniques should be familiar to project managers and developers
everywhere.

However, the Risk-First view is that we can go much further: that each
item of work being done on the project is mitigating a particular risk.
Risk isn't something that just appears in a report, it actually drives
\emph{everything we do}.

For example:

\begin{itemize}
\tightlist
\item
  A story about improving the user login screen can be seen as reducing
  \emph{the risk of users not signing up}.
\item
  A task about improving the health indicators could be seen as
  mitigating \emph{the risk of the application failing and no-one
  reacting to it}.
\item
  Even a task as basic as implementing a new function in the application
  is mitigating \emph{the risk that users are dissatisfied and go
  elsewhere}.
\end{itemize}

\textbf{One assertion of Risk-First therefore, is that every action you
take on a project is to mitigate some risk.}

\hypertarget{we-can-break-down-risks-on-a-project-methodically}{%
\section{3. We Can Break Down Risks on a Project
Methodically}\label{we-can-break-down-risks-on-a-project-methodically}}

Although risk is usually complicated and messy, other industries have
found value in breaking down the types of risks that affect them and
addressing them individually.

For example:

\begin{itemize}
\tightlist
\item
  In manufacturing, \emph{tolerances} allow for calculating the
  likelihood of defects in production.
\item
  In finance, reserves are commonly set aside for the risks of
  stock-market crashes, and teams are structured around monitoring these
  different risks.
\item
  The insurance industry is founded on identifying particular risks and
  providing financial safety-nets for when they occur, such as death,
  injury, accident and so on.
\end{itemize}

Software risks are difficult to quantify, and mostly, the effort
involved in doing so \emph{exactly} would outweigh the benefit.
Nevertheless, there is value in spending time building
\emph{classifications of risk for software}. That's what Risk-First
does: describes the set of \emph{risk patterns} we see every day on
software projects.

With this in place, we can:

\begin{itemize}
\tightlist
\item
  Talk about the types of risks we face on our projects, using an
  appropriate language.
\item
  Expose Hidden Risks that we hadn't considered before.
\item
  Weigh the risks against each other, and decide which order to tackle
  them.
\end{itemize}

\hypertarget{we-can-analyse-tools-and-techniques-in-terms-of-how-they-mitigate-risk}{%
\section{4. We Can Analyse Tools and Techniques in Terms of how they
Mitigate
Risk}\label{we-can-analyse-tools-and-techniques-in-terms-of-how-they-mitigate-risk}}

If we accept the assertion above that \emph{all} the actions we take on
a project are about mitigating risks, then it stands to reason that the
tools and techniques available to us on a project are there for
mitigating different types of risks.

For example:

\begin{itemize}
\tightlist
\item
  If we do a Code Review, we are partly trying to mitigate the risks of
  bugs slipping through into production, and also mitigate the Key-Man
  Risk of knowledge not being widely-enough shared.
\item
  If we write Unit Tests, we're also mitigating the risk of bugs going
  to production, but we're also mitigating against future changes
  breaking our existing functionality.
\item
  If we enter into a contract with a supplier, we are mitigating the
  risk of the supplier vanishing and leaving us exposed. With the
  contract in place, we have legal recourse against this risk.
\end{itemize}

\textbf{Different tools are appropriate for mitigating different types
of risks.}

\hypertarget{different-methodologies-for-different-risk-profiles}{%
\section{5. Different Methodologies for Different Risk
Profiles}\label{different-methodologies-for-different-risk-profiles}}

In the same way that our tools and techniques are appropriate to dealing
with different risks, the same is true of the methodologies we use on
our projects. We can use a Risk-First approach to examine the different
methodologies, and see which risks they address.

For example:

\begin{itemize}
\tightlist
\item
  \textbf{Agile} methodologies prioritise mitigating the risk that
  requirements capture is complicated, error-prone and that requirements
  change easily.
\item
  \textbf{Waterfall} takes the view that coding effort is an expensive
  risk, and that we should build plans up-front to avoid it.
\item
  \textbf{Lean} takes the view that risk lies in incomplete work and
  wasted work, and aims to minimize that.
\end{itemize}

Although many developers have a methodology-of-choice, the argument here
is that there are tradeoffs with all of these choices. Methodologies are
like \emph{bicycles}, rather than \emph{religions}. Rather than simply
\emph{believing}, we can take them apart and see how they work.

\textbf{We can place methodologies within a framework, and show how
choice of methodology is contingent on the risks faced.}

\hypertarget{driving-development-with-a-risk-first-perspective}{%
\section{6. Driving Development With a Risk-First
Perspective}\label{driving-development-with-a-risk-first-perspective}}

We have described a model of risk within software projects, looking
something like this:

\begin{figure}
\centering
\includegraphics{images/generated/pattern_language-400dpi.png}
\caption{Methdologies, Risks, Practices}
\end{figure}

How do we take this further?

The first idea we explore is that of the Risk Landscape: Although the
software team can't remove risk from their project, they can take
actions that move them to a place in the Risk Landscape where the risks
on the project are more favourable than where they started.

From there, we examine basic risk archetypes you will encounter on the
software project, to build up a Taxonomy of Software Risk, and look at
which specific tools you can use to mitigate each kind of risk.

Then, we look at different software practices, and how they mitigate
various risks. Beyond this we examine the question: \emph{how can a
Risk-First approach inform the use of this technique?}

For example:

\begin{itemize}
\tightlist
\item
  If we are introducing a \textbf{Sign-Off} in our process, we have to
  balance the risks it \emph{mitigates} (coordination of effort, quality
  control, information sharing) with the risks it \emph{introduces}
  (delays and process bottlenecks).
\item
  If we have \textbf{Redundant Systems}, this mitigates the risk of a
  \emph{single point of failure}, but introduces risks around
  \emph{synchronizing data} and \emph{communication} between the
  systems.
\item
  If we introduce \textbf{Process}, this may make it easier to
  \emph{coordinate as a team} and \emph{measure performance} but may
  lead to bureaucracy, focusing on the wrong goals or over-rigid
  interfaces to those processes.
\end{itemize}

Risk-First aims to provide a framework in which we can \emph{analyse
these choices} and weigh up \emph{accepting} versus \emph{mitigating}
risks.

\textbf{Still interested? Then dive into reading the introduction.}

\mainmatter
\part{Introduction}

\hypertarget{a-simple-scenario}{%
\chapter{A Simple Scenario}\label{a-simple-scenario}}

First up, I'm going to introduce a simple model for thinking about risk.

\hypertarget{a-simple-scenario-1}{%
\section{A Simple Scenario}\label{a-simple-scenario-1}}

Lets for a moment forget about software completely, and think about
\emph{any endeavour at all} in life. It could be passing a test, mowing
the lawn or going on holiday. Choose something now. I'll discuss from
the point of view of ``cooking a meal for some friends'', but you can
play along with your own example.

\hypertarget{goal-in-mind}{%
\subsection{Goal In Mind}\label{goal-in-mind}}

Now, in this endeavour, we want to be successful. That is to say, we
have a Goal In Mind: we want our friends to go home satisfied after a
decent meal, and not to feel hungry. As a bonus, we might also want to
spend time talking with them before and during the meal. So, now to
achieve our Goal In Mind we \emph{probably} have to do some tasks.

Since our goal only exists \emph{in our head}, we can say it is part of
our Internal Model of the world. That is, the model we have of reality.
This model extends to \emph{predicting what will happen}.

If we do nothing, our friends will turn up and maybe there's nothing in
the house for them to eat. Or maybe, the thing that you're going to cook
is going to take hours and they'll have to sit around and wait for you
to cook it and they'll leave before it's ready. Maybe you'll be some
ingredients short, or maybe you're not confident of the steps to prepare
the meal and you're worried about messing it all up.

\hypertarget{attendant-risk}{%
\subsection{Attendant Risk}\label{attendant-risk}}

These \emph{nagging doubts} that are going through your head I'll call
the Attendant Risks: they're the ones that will occur to you as you
start to think about what will happen.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/goal_in_mind-400dpi.png}
\caption{Goal In Mind, with the risks you know about}
\end{figure}

When we go about preparing this wonderful evening, we can with these
risks and try to mitigate them: shop for the ingredients in advance,
prepare parts of the meal, maybe practice the cooking in advance. Or, we
can wing it, and sometimes we'll get lucky.

How much effort we expend on mitigating Attendant Risks depends on how
great we think they are: for example, if you know it's a 24-hour shop,
you'll probably not worry too much about getting the ingredients well in
advance (although, the shop \emph{could still be closed}).

\hypertarget{hidden-risks}{%
\subsection{Hidden Risks}\label{hidden-risks}}

There are also hidden Attendant Risks that you might not know about: if
you're poaching eggs for dinner, you might know that fresh eggs poach
best. These are the ``Unknown Unknowns'' of
\href{https://en.wikipedia.org/wiki/There_are_known_knowns}{Rumsfeld's
model}.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/hidden_risks-400dpi.png}
\caption{Goal In Mind, the risks you know about and the ones you don't}
\end{figure}

Different people will evaluate the risks differently. (That is, worry
about them more or less.) They'll also \emph{know} about different
risks. They might have cooked the recipe before, or organised lots more
dinner parties than you.

How we evaluate the risks, and which ones we know about depends on our
\textbf{knowledge} and \textbf{experience}, then. And that varies from
person to person (or team to team). Lets call this our Internal Model,
and it's something we build on and improve with experience (of
organising dinner parties, amongst everything else).

\hypertarget{model-meets-reality}{%
\subsection{Model Meets Reality}\label{model-meets-reality}}

As the dinner party gets closer, we make our preparations, and the
inadequacies of the Internal Model become apparent, and we learn what we
didn't know. The Hidden Risks reveal themselves; while other things we
were worried about may not materialise, things we thought would be minor
risks turn out to be greater.

Our model is forced into contact with reality, and the model changes. We
may be forced to take further, mitigating actions to deal with these new
risks, as shown in this diagram.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/model_vs_reality-400dpi.png}
\caption{How taking action affects Reality, and also changes your
internal model}
\end{figure}

If we had a good model, and took the right actions, we should see
positive outcomes. If we failed to mitigate risks, or took inappropriate
actions, we'll probably see negative outcomes.

\hypertarget{on-to-software}{%
\section{On To Software}\label{on-to-software}}

In this website, we're going to look at the risks in the software
process and how these are mitigated by the various methodologies you can
choose from.

Let's examine the scenario of a new software project, and expand on the
simple model being outlined above: instead of a single person, we are
likely to have a team, and our model will not just exist in our heads,
but in the code we write.

On to Development Process

\hypertarget{development-process}{%
\chapter{Development Process}\label{development-process}}

In the previous chapter we looked at a simple model for risks on any
given activity.

Now, let's look at the everyday process of developing \emph{a new
feature} on a software project, and see how our risk model informs it.

\hypertarget{an-example-process}{%
\section{An Example Process}\label{an-example-process}}

Let's ignore for now the specifics of what methodology is being used -
we'll come to that later. Let's say your team have settled for a process
something like the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Specification}: A new feature is requested somehow, and a
  business analyst works to specify it.
\item
  \textbf{Code And Unit Test}: A developer writes some code, and some
  unit tests.
\item
  \textbf{Integration}: They integrate their code into the code base.
\item
  \textbf{UAT}: They put the code into a User Acceptance Test (UAT)
  environment, and user(s) test it.
\end{enumerate}

\ldots{} All being well, the code is released to production.

Now, it might be waterfall, it might be agile, we're not going to commit
to specifics at this stage. It's probably not perfect, but let's just
assume that \emph{it works for this project} and everyone is reasonably
happy with it.

I'm not saying this is the \emph{right} process, or even a \emph{good}
process: you could add code review, a pilot, integration testing,
whatever. We're just doing some analysis of \emph{what process gives
us}.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_1-400dpi.png}
\caption{A Simple Development Process}
\end{figure}

What's happening here? Why these steps?

\hypertarget{minimizing-risks---overview}{%
\section{Minimizing Risks -
Overview}\label{minimizing-risks---overview}}

I am going to argue that this entire process is \emph{informed by
software risk}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We have \emph{a business analyst} who talks to users and fleshes out
  the details of the feature properly. This is to minimize the risk of
  \textbf{building the wrong thing}.
\item
  We \emph{write unit tests} to minimize the risk that our code
  \textbf{isn't doing what we expected, and that it matches the
  specifications}.
\item
  We \emph{integrate our code} to minimize the risk that it's
  \textbf{inconsistent with the other, existing code on the project}.
\item
  We have \emph{acceptance testing} and quality gates generally to
  \textbf{minimize the risk of breaking production}, somehow.
\end{enumerate}

We could skip all those steps above and just do this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Developer gets wind of new idea from user, logs onto production and
  changes some code directly.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_2-400dpi.png}
\caption{A Dangerous Development Process}
\end{figure}

We can all see this would be a disaster, but why?

Two reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  You're meeting reality all-in-one-go: all of these risks materialize
  at the same time, and you have to deal with them all at once.
\item
  Because of this, at the point you put code into the hands of your
  users, your Internal Model is at its least-developed. All the Hidden
  Risks now need to be dealt with at the same time, in production.
\end{enumerate}

\hypertarget{applying-the-model}{%
\section{Applying the Model}\label{applying-the-model}}

Let's look at how our process should act to prevent these risks
materializing by considering an unhappy path, one where at the outset,
we have lots of Hidden Risks ready to materialize. Let's say a
particularly vocal user rings up someone in the office and asks for new
\textbf{Feature X} to be added to the software. It's logged as a new
feature request, but:

\begin{itemize}
\tightlist
\item
  Unfortunately, this feature once programmed will break an existing
  \textbf{Feature Y}.
\item
  Implementing the feature will use some api in a library, which
  contains bugs and have to be coded around.
\item
  It's going to get misunderstood by the developer too, who is new on
  the project and doesn't understand how the software is used.
\item
  Actually, this functionality is mainly served by \textbf{Feature
  Z}\ldots{}
\item
  which is already there but hard to find.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_3-400dpi.png}
\caption{Development Process - Hidden Risks}
\end{figure}

This is a slightly contrived example, as you'll see. But let's follow
our feature through the process and see how it meets reality slowly, and
the hidden risks are discovered:

\hypertarget{specification}{%
\subsection{Specification}\label{specification}}

The first stage of the journey for the feature is that it meets the
Business Analyst (BA). The \emph{purpose} of the BA is to examine new
goals for the project and try to integrate them with \emph{reality as
they understands it}. A good BA might take a feature request and vet it
against the internal logic of the project, saying something like:

\begin{itemize}
\tightlist
\item
  ``This feature doesn't belong on the User screen, it belongs on the
  New Account screen''
\item
  ``90\% of this functionality is already present in the Document Merge
  Process''
\item
  ``We need a control on the form that allows the user to select between
  Internal and External projects''
\end{itemize}

In the process of doing this, the BA is turning the simple feature
request \emph{idea} into a more consistent, well-explained
\emph{specification} or \emph{requirement} which the developer can pick
up. But why is this a useful step in our simple methodology? From the
perspective of our Internal Model, we can say that the BA is responsible
for:

\begin{itemize}
\tightlist
\item
  Trying to surface Hidden Risks
\item
  Trying to evaluate Attendant Risk and make it clear to everyone on the
  project.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_ba-400dpi.png}
\caption{BA Specification: exposing hidden risks as soon as possible}
\end{figure}

In surfacing these risks, there is another outcome: while
\textbf{Feature X} might be flawed as originally presented, the BA can
``evolve'' it into a specification, and tie it down sufficiently to
reduce the risks. The BA does all this by simply \emph{thinking about
it}, \emph{talking to people} and \emph{writing stuff down}.

This process of evolving the feature request into a requirement is the
BAs job. From our Risk-First perspective, it is \emph{taking an idea and
making it meet reality}. Not the \emph{full reality} of production
(yet), but something more limited.

\hypertarget{code-and-unit-test}{%
\subsection{Code And Unit Test}\label{code-and-unit-test}}

The next stage for our feature, \textbf{Feature X} is that it gets coded
and some tests get written. Let's look at how our goal in mind meets a
new reality: this time it's the reality of a pre-existing codebase,
which has it's own internal logic.

As the developer begins coding the feature in the software, she will
start with an Internal Model of the software, and how the code fits into
it. But, in the process of implementing it, she is likely to learn about
the codebase, and her Internal Model will develop.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_code-400dpi.png}
\caption{Coding Process: exposing more hidden risks as you code}
\end{figure}

A couple of things about this diagram:

\begin{itemize}
\tightlist
\item
  In boxes, we are showing Risks, which exist within Internal Models,
  whereas:
\item
  Beneath them, we are showing actual \emph{physical artifacts} which
  exist in the real world.
\item
  \emph{Actions} might \emph{meet} reality, but they are \emph{changing
  reality} too, by producing these artifacts.
\end{itemize}

\hypertarget{integration}{%
\subsection{Integration}\label{integration}}

Integration is where we run \emph{all} the tests on the project, and
compile \emph{all} the code in a clean environment: the ``reality'' of
the development environment can vary from one developer's machine to
another.

So, this stage is about the developer's committed code meeting a new
reality: the clean build.

At this stage, we might discover the Hidden Risk that we'd break
\textbf{Feature Y}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_integration-400dpi.png}
\caption{Integration testing exposes hidden risks before you get to
production}
\end{figure}

\hypertarget{user-acceptance-test}{%
\subsection{User Acceptance Test}\label{user-acceptance-test}}

Is where our feature meets another reality: \emph{actual users}. I think
you can see how the process works by now. We're just flushing out yet
more Hidden Risks:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_uat-400dpi.png}
\caption{UAT - putting tame users in front of your software is better
than real ones, where the risk is higher}
\end{figure}

\begin{itemize}
\tightlist
\item
  Taking Action is the \emph{only} way to create change in the world.
\item
  It's also the only way we can \emph{learn} about the world, adding to
  our Internal Model. In this case, we discover the user's difficulty in
  finding the feature.
\end{itemize}

\hypertarget{observations}{%
\section{Observations}\label{observations}}

A couple of things:

\textbf{First}, the people setting up the development process
\emph{didn't know} about these \emph{exact} risks, but they knew the
\emph{shape that the risks take}. The process builds ``nets'' for the
different kinds of hidden risks without knowing exactly what they are.
Part of the purpose of this site is to help with this and try and
provide a taxonomy for different types of risks.

\textbf{Second}, are these really risks, or are they \emph{problems we
just didn't know about}? I am using the terms interchangeably, to a
certain extent. Even when you know you have a problem, it's still a risk
to your deadline until it's solved. So, when does a risk become a
problem? Is a problem still just a schedule-risk, or cost-risk? It's
pretty hard to draw a line and say exactly.

\textbf{Third}, the real take-away from this is that all these risks
exist because we don't know 100\% how reality is. Risk exists because we
don't (and can't) have a perfect view of the universe and how it'll
develop. Reality is reality, \emph{the risks just exist in our head}.

\textbf{Fourth}, hopefully you can see from the above that really
\emph{all this work is risk management}, and \emph{all work is testing
ideas against reality}.

In the next chapter, we're going to look at the concept of Meeting
Reality in a bit more depth.

\hypertarget{meeting-reality}{%
\chapter{Meeting Reality}\label{meeting-reality}}

In this chapter, we will look at how exposing your Internal Model to
reality is in itself a good risk management technique.

\hypertarget{revisiting-the-model}{%
\section{Revisiting the Model}\label{revisiting-the-model}}

In A Simple Scenario, we looked at a basic model for how
\textbf{Reality} and our Internal Model interacted with each other: we
take action based on out Internal Model, hoping to \textbf{change
Reality} with some positive outcome.

And, in Development Process we looked at how we can meet with reality in
\emph{different forms}: Analysis, Testing, Integration and so on, and
saw how the model could work in each stage of a project.

It should be no surprise to see that there is a \emph{recursive} nature
about this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \textbf{actions we take} each day have consequences: they
  \textbf{expose new Hidden Risks}, which inform our Internal Model, and
  at the same time, they change reality in some way (otherwise, what
  would be the point of doing them?)
\item
  The actions we take towards achieving a Goal In Mind each have their
  \emph{own} Goal In Mind. And because of this, when we take action, we
  have to consider and evaluate the Hidden Risks exposed by that action.
  That is, there are many ways to achieving a goal, and these different
  ways expose different Hidden Risks.
\end{enumerate}

So, let's see how this kind of recursion looks on our model. Note that
here, I am showing \emph{just one possible action}, in reality, you'll
have choices.

\includegraphics{images/generated/introduction/model_vs_reality_2-400dpi.png}
.

Hopefully, if you've read along so far, this model shouldn't be too hard
to understand. But, how is it helpful?

\hypertarget{navigating-the-risk-landscape}{%
\section{``Navigating the Risk
Landscape''}\label{navigating-the-risk-landscape}}

So, we often have multiple ways of achieving a Goal In Mind.

What's the best way?

I would argue that the best way is the one which accrues the \emph{least
risk} to get it done: each action you take in trying to achieve the
overall Goal In Mind will have it's Attendant Risks, and it's the
experience you bring to bear on these that will help you navigate
through them smoothly.

Ideally, when you take an action, you are trading off a big risk for a
smaller one. Take Unit Testing for example. Clearly, writing Unit Tests
adds to the amount of development work, so on it's own, it adds Schedule
Risk. However, if you write \emph{just enough} of the right Unit Tests,
you should be short-cutting the time spent finding issues in the User
Acceptance Testing (UAT) stage, so you're hopefully trading off a larger
Schedule Risk from UAT and adding a smaller risk to
\textbf{Development}.

You can think of taking actions as moving your project on a ``Risk
Landscape'': ideally, when you take an action, you move to some place
with worse risk to somewhere more favourable.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_landscape_1-400dpi.png}
\caption{Navigating The Risk Landscape}
\end{figure}

Sometimes, you can end up somewhere \emph{worse}: the actions you take
to solve a higher-level Attendant Risk will leave you with a worse
Attendant Risks. Almost certainly, this will have been a Hidden Risk
when you embarked on the action, otherwise you'd not have chosen it.

\hypertarget{an-example-automation}{%
\subsection{An Example: Automation}\label{an-example-automation}}

For example, \emph{automating processes} is very tempting: it
\emph{should} save time, and reduce the amount of boring, repetitive
work on a project. But sometimes, it turns into an industry in itself,
and consumes more effort than it's worth.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_landscape_2_automating-400dpi.png}
\caption{Hidden Risks of Automation}
\end{figure}

\hypertarget{another-quick-example-mongodb}{%
\subsection{Another Quick Example:
MongoDB}\label{another-quick-example-mongodb}}

On a recent project in a bank, we had a requirement to store a modest
amount of data and we needed to be able to retrieve it fast. The
developer chose to use \href{https://www.mongodb.com}{MongoDB} for this.
At the time, others pointed out that other teams in the bank had had
lots of difficulty deploying MongoDB internally, due to licensing issues
and other factors internal to the bank.

Other options were available, but the developer chose MongoDB because of
their \emph{existing familiarity} with it: therefore, they felt that the
Hidden Risks of MongoDB were \emph{lower} than the other options, and
disregarded the others' opinions.

The data storage Attendant Risk was mitigated easily with MongoDB.
However, the new Attendant Risk of licensing bureacracy eventually
proved too great, and MongoDB had to be abandoned after much investment
of time.

This is not a criticism of MongoDB: it's simply a demonstration that
sometimes, the cure is worse than the disease. Successful projects are
\emph{always} trying to \emph{reduce} Attendant Risks.

\hypertarget{the-cost-of-meeting-reality}{%
\section{The Cost Of Meeting
Reality}\label{the-cost-of-meeting-reality}}

Meeting reality is \emph{costly}, for example. Going to production can
look like this:

\begin{itemize}
\tightlist
\item
  Releasing software
\item
  Training users
\item
  Getting users to use your system
\item
  Gathering feedback
\end{itemize}

All of these steps take a lot of effort and time. But you don't have to
meet the whole of reality in one go - sometimes that is expensive. But
we can meet it in ``limited ways''.

In all, to de-risk, you should try and meet reality:

\begin{itemize}
\tightlist
\item
  \textbf{Sooner}, so you have time to mitigate the hidden risks it
  uncovers
\item
  \textbf{More Frequently}: so the hidden risks don't hit you all at
  once
\item
  \textbf{In Smaller Chunks}: so you're not over-burdened by hidden
  risks all in one go.
\item
  \textbf{With Feedback}: if you don't collect feedback from the
  experience of meeting reality, hidden risks \emph{stay hidden}.
\end{itemize}

In Development Process, we looked at the use of UAT in order to Meet
Reality earlier. By performing the UAT, we meet reality sooner. The
\emph{cost} of this is that we also expend precious time on that process
which adds risk to the schedule.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/meeting_reality_testing-400dpi.png}
\caption{Testing flushes out hidden risk, but increases Schedule Risk}
\end{figure}

\hypertarget{yagni}{%
\subsection{YAGNI}\label{yagni}}

As a flavour of what's to come, let's look at
\href{https://www.martinfowler.com/bliki/Yagni.html}{YAGNI}, an acronym
for You Aren't Gonna Need It. Martin Fowler says:

\begin{quote}
YAGNI originally is an acronym that stands for ``You Aren't Gonna Need
It''. It is a mantra from ExtremeProgramming that's often used generally
in agile software teams. It's a statement that some capability we
presume our software needs in the future should not be built now because
``you aren't gonna need it''.
\end{quote}

\begin{quote}
This principle was first discussed and fleshed out on
\href{http://wiki.c2.com/?YouArentGonnaNeedIt}{Ward's Wiki}
\end{quote}

The idea makes sense: if you take on extra work that you don't need,
\emph{of course} you'll be accreting Attendant Risks.

But, there is always the opposite opinion:
\href{http://wiki.c2.com/?YouAreGonnaNeedIt}{You \emph{Are} Gonna Need
It}. As a simple example, we often add log statements in our code as we
write it, though following YAGNI strictly says we shouldn't.

\hypertarget{which-is-right}{%
\subsubsection{Which is right?}\label{which-is-right}}

Now, we can say: do the work \emph{if it mitigates your Attendant
Risks}.

\begin{itemize}
\tightlist
\item
  Logging statements are \emph{good}, because otherwise, you're
  increasing the risk that in production, no one will be able to
  understand \emph{how the software went wrong}.
\item
  However, adding them takes time, which might introduce Schedule Risk.
\end{itemize}

So, it's a trade-off: continue adding logging statements so long as you
feel that overall, you're reducing risk.

\hypertarget{do-the-simplest-thing-that-could-possibly-work}{%
\subsection{Do The Simplest Thing That Could Possibly
Work}\label{do-the-simplest-thing-that-could-possibly-work}}

Another mantra from Kent Beck (originator of the
\href{https://en.wikipedia.org/wiki/Extreme_programming}{Extreme
Programming} methodology, is ``Do The Simplest Thing That Could Possibly
Work'', which is closely related to YAGNI and is about looking for
solutions which are simple. Our risk-centric view of this strategy would
be:

\begin{itemize}
\tightlist
\item
  Every action you take on a project has it's own Attendant Risks.
\item
  The bigger or more complex the action, the more Attendant Risk it'll
  have.
\item
  The reason you're taking action \emph{at all} is because you're trying
  to reduce risk elsewhere on the project
\item
  Therefore, the biggest payoff is whatever action \emph{works} to
  remove that risk, whilst simultaneously picking up the least amount of
  new Attendant Risk.
\end{itemize}

So, ``Do The Simplest Thing That Could Possibly Work'' is really a
helpful guideline for Navigating the Risk Landscape.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

So, here we've looked at Meeting Reality, which basically boils down to
taking actions to manage risk and seeing how it turns out:

\begin{itemize}
\tightlist
\item
  Each Action you take is a step on the Risk Landscape
\item
  Each Action exposes new Hidden Risks, changing your Internal Model.
\item
  Ideally, each action should reduce the overall Attendant Risk on the
  project (that is, puts it in a better place on the Risk Landscape
\end{itemize}

Could it be that \emph{everything} you do on a software project is risk
management? This is an idea explored in the next chapter.

\hypertarget{all-risk-management}{%
\chapter{All Risk Management}\label{all-risk-management}}

In this chapter, I am going to introduce the idea that everything you do
on a software project is Risk Management.

In the last chapter, we observed that all the activities in a simple
methodology had a part to play in exposing different risks. They worked
to manage risk prior to them creating bigger problems in production.

Here, we'll look at one of the tools in the Project Manager's tool-box,
the \href{http://pmtips.net/blog-new/raid-logs-introduction}{RAID Log},
and observe how risk-centric it is.

\hypertarget{raid-log}{%
\section{RAID Log}\label{raid-log}}

Many project managers will be familiar with the RAID Log. It's simply
four columns on a spreadsheet:

\begin{itemize}
\tightlist
\item
  Risks
\item
  Actions
\item
  Issues
\item
  Decisions
\end{itemize}

Let's try and put the following Attendant Risk into the RAID Log:

\begin{quote}
Debbie needs to visit the client to get them to choose the logo to use
on the product, otherwise we can't size the screen areas exactly.
\end{quote}

\begin{itemize}
\tightlist
\item
  So, is this an \textbf{action}? Certainly. There's definitely
  something for Debbie to do here.
\item
  Is it an \textbf{issue}? Yes, because it's holding up the screen-areas
  sizing thing.
\item
  Is it a \textbf{decision}? Well, clearly, it's a decision for someone.
\item
  Is it a \textbf{risk}? Probably: Debbie might go to the client and
  they \emph{still} don't make a decision. What then?
\end{itemize}

\hypertarget{lets-go-again}{%
\section{Let's Go Again}\label{lets-go-again}}

This is a completely made-up example, deliberately chosen to be hard to
categorize. Normally, items are more one thing than another. But often,
you'll have to make a choice between two categories, if not all four.

This hints at the fact that at some level it's All Risk:

\hypertarget{every-action-attempts-to-mitigate-risk}{%
\subsection{Every Action Attempts to Mitigate
Risk}\label{every-action-attempts-to-mitigate-risk}}

The reason you are \emph{taking} an action is to mitigate a risk. For
example:

\begin{itemize}
\tightlist
\item
  If you're coding up new features in the software, this is mitigating
  Feature Risk.
\item
  If you're getting a business sign-off for something, this is
  mitigating a Too Many Cooks-style \emph{stakeholder risk}.
\item
  If you're reading the specification, that's mitigating the type of
  ``Developer Misimplementation Risk'' we saw in the last chapter.
\end{itemize}

\hypertarget{every-action-carries-risk.}{%
\subsection{Every Action Carries
Risk.}\label{every-action-carries-risk.}}

\begin{itemize}
\tightlist
\item
  How do you know if the action will get completed?
\item
  Will it overrun, or be on time?
\item
  Will it lead to yet more actions?
\end{itemize}

Consider \emph{coding a feature} (as we did in the earlier Development
Process chapter). We saw here how the whole process of coding was an
exercise in learning what we didn't know about the world, uncovering
problems and improving our Internal Model. That is, flushing out the
Attendant Risk of the Goal In Mind.

And, as we saw in the Introduction, even something \emph{mundane} like
the Dinner Party had risks.

\hypertarget{an-issue-is-just-a-type-of-risk}{%
\subsection{An Issue is Just A Type of
Risk}\label{an-issue-is-just-a-type-of-risk}}

\begin{itemize}
\tightlist
\item
  Because issues need to be solved\ldots{}
\item
  And solving an issue is an action\ldots{}
\item
  Which, as we just saw also carry risk.
\end{itemize}

One retort to this might be to say: an issue is a problem I have now,
whereas a risk is a problem that \emph{might} occur. I am going to try
and \emph{break} that mind-set in the coming pages, but I'll just start
with this:

\begin{itemize}
\tightlist
\item
  Do you know \emph{exactly} how much damage this issue will do?
\item
  Can you be sure that the issue might not somehow go away?
\end{itemize}

\emph{Issues} then, just seem more ``definite'' and ``now'' than
\emph{risks}, right? This classification is arbitrary: they're all just
part of the same spectrum, so stop agonising over which column to put
them in.

\hypertarget{every-decision-is-a-risk.}{%
\subsection{Every Decision is a Risk.}\label{every-decision-is-a-risk.}}

\begin{itemize}
\tightlist
\item
  By the very nature of having to make a decision, there's the risk
  you'll decide wrongly.
\item
  And, there's the time it takes to make the decision.
\item
  And what's the risk if the decision doesn't get made?
\end{itemize}

\hypertarget{goals-are-risks-too}{%
\section{Goals Are Risks Too}\label{goals-are-risks-too}}

In the previous chapters, we've introduced something of a ``diagram
language'' of risk. Let's review it:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/all_risk_management_language-400dpi.png}
\caption{Risk-First Diagram Language}
\end{figure}

So we have:

\begin{itemize}
\tightlist
\item
  Risks, which exist within Internal Models.
\item
  Actions, which are operations we perform when we Meet Reality.
\item
  Artifacts, which are the results of Meeting Reality.
\end{itemize}

Goals live inside our Internal Model too. It turns out, that
functionally, Goals and Risks are equivalent. For example, The goal of
``Implementing Feature X'' is equivalent to mitigating ``Risk of Feature
X not being present''.

Let's try and back up that assertion with a few more examples:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.32\columnwidth}\raggedright
Goal\strut
\end{minipage} & \begin{minipage}[b]{0.62\columnwidth}\raggedright
Restated As A Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.32\columnwidth}\raggedright
Build a Wall\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
Mitigate the risk of something getting in / out\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.32\columnwidth}\raggedright
Land a man on the moon\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
Mitigate the risk of looking technically inferior during the cold
war\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.32\columnwidth}\raggedright
Move House\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
Mitigate the risks/problems of where you currently live\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

There is a certain ``interplay'' between the concepts of risks, actions
and goals. After all, on the Risk Landscape they correspond to the
starting point, a movement, and the destination. From a redundancy
perspective, any one of these can be determines by knowing the other
two.

Psychologically, humans are very goal-driven: they like to know where
they're going, and are good at organising around a goal. However, by
focusing on goals (``solutionizing'') it's easy to ignore alternatives.
By focusing on ``Risk-First'', we don't ignore the reasons we're doing
something.

\hypertarget{failure}{%
\section{Failure}\label{failure}}

So, when we talk about a project ``failing'', what do we mean?

Usually, we mean we've failed to achieve a goal, and since \emph{goals
are risks}, it is simply the scenario where we are overwhelmed by
Attendant Risks and give up.

\hypertarget{what-to-do}{%
\section{What To Do?}\label{what-to-do}}

It makes it much easier to tackle the RAID log if there's only one list:
all you do is pick either the \emph{most important} risk on the list, or
the \emph{most urgent}, or the risk you can make \emph{the biggest
impact on}, and deal with it.

In the next chapter, A Software Project Scenario we'll give an example
of this in action.

\hypertarget{software-project-scenario}{%
\chapter{Software Project Scenario}\label{software-project-scenario}}

Where do the risks of the project lie?

How do we decide what \emph{needs to be done today} on a software
project?

Let's look again at the simple risk framework from the introduction and
try to apply it at the level of the \emph{entire project}.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/model_vs_reality-400dpi.png}
\caption{Taking action changes reality, but it changes your perception
of the attendant risks too}
\end{figure}

\hypertarget{todays-action}{%
\section{Today's Action}\label{todays-action}}

How should we decide how to spend our time today?

What actions should we take? (In
\href{https://en.wikipedia.org/wiki/Scrum_(software_development)}{Scrum}
terminology, what is our \emph{Sprint Goal}?).

Let's say that we are working in a Startup, on a project building an
online service. As we discussed previously, we could call this a Goal,
but we could also restate it as mitigating Risk, which gives more
clarity about our intentions. For the startup, launching the Online
Service is about mitigating (Funding-Risk), in order to keep the startup
alive.

\hypertarget{attendant-risks}{%
\section{Attendant Risks}\label{attendant-risks}}

What are the Attendant Risks that come with that goal? Here are some to
get us started:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The users can't access the system
\item
  The data gets lost, stolen.
\item
  The data is wrong or corrupted
\item
  There are bugs that prevent the functionality working
\item
  The functionality isn't there that the user needs (Feature Risk).
\item
  Our Internal Model of the market is poor, and we could be building the
  wrong thing.
\end{enumerate}

I'm sure you can think of some more.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/software_project_scenario_action-400dpi.png}
\caption{Our Goal, With Attendant Risks}
\end{figure}

\hypertarget{evaluating-the-risks}{%
\section{Evaluating The Risks}\label{evaluating-the-risks}}

Next, we can look at each of these risks and consider the threat they
represent. The same Attendant Risks will be evaluated differently
depending on the \emph{nature of the project} and the mitigations you
already have in place. For example:

\begin{itemize}
\tightlist
\item
  If they \textbf{can't access it}, does that mean that they're stuck
  unable to get on the train? Or they can't listen to music?
\item
  If the \textbf{data is lost}, does this mean that no one can get on
  the plane? Or that the patients have to have their CAT scans done
  again? Or that people's private information is scattered around the
  Internet?
\item
  If the \textbf{data is wrong}, does that mean that the wrong people
  get sent their parcels? Do they receive the wrong orders? Do they end
  up going to the wrong courses?
\item
  If the \textbf{security is compromised} and all the data exposed, does
  that mean confidential details are shared on the Internet, or that
  they just need to create a new password?
\item
  If there is \textbf{missing functionality}, will they not buy the
  system? Will they use a competitor's product? Will they waste time
  doing things a harder or less optimal way?
\item
  If our \textbf{Internal Model is wrong}, then is there a chance we are
  building something for a non-existent market? Or annoying our
  customers? Or leaving an opportunity for competitors?
\end{itemize}

\hypertarget{a-single-attendant-risk-getting-hacked}{%
\subsection{A Single Attendant Risk: Getting
Hacked}\label{a-single-attendant-risk-getting-hacked}}

Let's consider a single risk: that the website gets hacked, and
sensitive data is stolen. How we evaluate this risk is going to depend
on a number of factors:

\begin{itemize}
\tightlist
\item
  How many users we have
\item
  The importance of the data
\item
  How much revenue will be lost
\item
  Risk of litigation
\item
  etc.
\end{itemize}

\hypertarget{ashley-maddison}{%
\subsubsection{Ashley Maddison}\label{ashley-maddison}}

In 2016, Ashley Maddison, a website specialising in aiding extra-marital
affairs,
\href{https://en.wikipedia.org/wiki/Ashley_Madison_data_breach}{suffered
a data breach}, revealing the personal details of all of their clients
on the Internet. The sensitive nature of their business contrasts
sharply with the reported sloppiness of their security arrangements.

Can our risk model explain what happened here?

\begin{itemize}
\tightlist
\item
  It's possible that for the developers in question, security concerns
  were a Hidden Risk: they were not aware of the dangers of being
  hacked.
\item
  It's possible that \emph{at the time of setting up the security
  arrangements}, stronger security was considered, but the evaluation of
  the risk was low: Perhaps, the risk of not shipping quickly was deemed
  greater. And so they ignored this concern.
\item
  It's also possible that \emph{for Ashley Maddison} the perceived
  impact of any data-breach was considered low. The impact is on the
  \emph{customers}, rather than the \emph{company}.
\item
  But, as the number of users of the sites increased, the risk increased
  too, but there was (apparently) no re-evaluation of the risk otherwise
  they would have addressed it. This was a costly \emph{failure to
  update the Internal Model}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/software_project_scenario_action_2-400dpi.png}
\caption{Attendant Risks of Improved Security}
\end{figure}

This story highlights a couple of important lessons. First, when
exposing a service on the Internet, it's now a good idea to \emph{look
for trouble}: you should go out and try and improve your Internal Model.
Thankfully, this is what sites like
\href{https://www.owasp.org/index.php/Top_10-2017_Top_10}{OWASP} are
for: they \emph{tell you about the Attendant Risks} and further, try to
provide some evaluation of them to guide your actions. Second, you
shouldn't expect an organisation with a morally-questionable business
model to have your best interests at heart.

\hypertarget{actions-are-dependent-on-risk-evaluation}{%
\section{Actions Are Dependent On Risk
Evaluation}\label{actions-are-dependent-on-risk-evaluation}}

So, \emph{evaluating risks against one another other} allows us to
determine what actions we should pursue on any given day, by answering
the question:

Which actions give us the biggest benefit in terms of mitigating
Attendant Risk?

For example, it's worth considering that if we're just starting this
project, risks 1-4 in our diagram above are \emph{negligible}. It makes
complete sense from a risk-evaluation perspective that we're only going
to spend time building functionality or improving our understanding of
the market.

\hypertarget{tacit-and-explicit-modelling}{%
\section{Tacit and Explicit
Modelling}\label{tacit-and-explicit-modelling}}

As we saw in the example of the Dinner Party, creating an internal model
is something \emph{we just do}: we have this functionality in our brains
already. When we scale this up to a whole project team, we can expect
the individuals on the project to continue to do this, but we might also
want to consider \emph{explicitly} creating a risk register for the
whole project.

In the next chapter, we're going to take a quick aside into looking at
some Risk Theory around this.

\hypertarget{risk-theory}{%
\chapter{Risk Theory}\label{risk-theory}}

Here, I am going to re-cap on some pre-existing knowledge about risk,
generally, in order to set the scene for the next chapter which heads
back to looking at risk on software projects.

\hypertarget{risk-registers}{%
\section{Risk Registers}\label{risk-registers}}

In the previous chapter Software Project Scenario we saw how you try to
look across the Attendant Risks of the project, in order to decide what
to do next.

A \href{https://en.wikipedia.org/wiki/Risk_register}{Risk Register} can
help with this. From Wikipedia:

\begin{quote}
A typical risk register contains:

\begin{itemize}
\tightlist
\item
  A risk category to group similar risks
\item
  The risk breakdown structure identification number
\item
  A brief description or name of the risk to make the risk easy to
  discuss
\item
  The impact (or consequence) if event actually occurs rated on an
  integer scale
\item
  The probability or likelihood of its occurrence rated on an integer
  scale
\item
  The Risk Score (or Risk Rating) is the multiplication of Probability
  and Impact and is often used to rank the risks.
\item
  Common mitigation steps (e.g.~within IT projects) are Identify,
  Analyse, Plan Response, Monitor and Control.
\end{itemize}
\end{quote}

This is Wikipedia's example:

\begin{figure}
\centering
\includegraphics{images/WikipediaRiskRegister2.png}
\caption{Wikipedia Risk Register}
\end{figure}

Some points about this description:

\hypertarget{this-is-a-bells-and-whistles-description}{%
\subsection{This is a Bells-and-Whistles
Description}\label{this-is-a-bells-and-whistles-description}}

Remember back to the Dinner Party example at the start: the Risk
Register happened \emph{entirely in your head}. There is a continuum all
the way from ``in your head'' to Wikipedia's Risk Register description.
Most of the time, it's going to be in your head, or in discussion with
the team, rather than written down.

Most of the value of the \textbf{Risk-First} approach is \emph{in
conversation}. Later, we'll have an example to show how this can work
out.

\hypertarget{probability-and-impact}{%
\subsection{Probability And Impact}\label{probability-and-impact}}

Sometimes, it's better to skip these, and just figure out a Risk Score.
This is because if you think about ``impact'', it implies a definite,
discrete event occurring, or not occurring, and asks you then to
consider the probability of that occurring.

\textbf{Risk-First} takes a view that risks are a continuous quantity,
more like \emph{money} or \emph{water}: by taking an action before
delivering a project you might add a degree of Schedule Risk, but
decrease the Operational Risk later on by a greater amount.

\hypertarget{graphical-analysis}{%
\section{Graphical Analysis}\label{graphical-analysis}}

The Wikipedia page also includes this wonderful diagram showing you
risks of a poorly run barbecue party:

\begin{figure}
\centering
\includegraphics{images/WikipediaRiskRegister1.png}
\caption{Wikipedia Risk Register}
\end{figure}

This type of graphic is \emph{helpful} in deciding what to do next,
although personally I prefer to graph the overall \textbf{Risk Score}
against the \textbf{Cost of Mitigation}: easily mitigated, but expensive
risks can therefore be dealt with first (hopefully).

\hypertarget{unknown-unknowns}{%
\section{Unknown Unknowns}\label{unknown-unknowns}}

In Wikipedia's example, this fictitious BBQ has high fire risk, so one
should begin mitigating there.

But, does this feel right? One of the criticisms of the Risk Register
approach is that of mistaking the map for the territory. That is,
mistakenly believing that what's on the Risk Register \emph{is all there
is}.

In the preceding discussions, I have been careful to point out the
existence of Hidden Risks for that very reason. Or, to put another way:

\begin{quote}
What we don't know is what usually gets us killed - Petyr Baelish,
\emph{Game of Thrones}
\end{quote}

Donald Rumsfeld's famous Known Knowns is also a helpful
conceptualisation.

\hypertarget{risk-and-uncertainty}{%
\section{Risk And Uncertainty}\label{risk-and-uncertainty}}

Arguably, this site uses the term `Risk' wrongly: most literature
suggests
\href{https://keydifferences.com/difference-between-risk-and-uncertainty.html}{risk
can be measured} whereas uncertainty represents things that cannot.

I am using \textbf{risk} everywhere because later we will talk about
specific risks (e.g.~Boundary Risk or Complexity Risk), and it doesn't
feel grammatically correct to talk about those as
\textbf{uncertainties}, especially given the pre-existing usage in
Banking of terms like
\href{https://en.wikipedia.org/wiki/Operational_risk}{Operational Risk}
or
\href{https://www.investopedia.com/terms/r/reputational-risk.asp}{Reputational
risk} which are also not really a-priori measurable.

\hypertarget{the-opposite-of-risk-management}{%
\section{The Opposite Of Risk
Management}\label{the-opposite-of-risk-management}}

Let's look at the classic description of Risk Management:

\begin{quote}
Risk Management is the process of thinking out corrective actions before
a problem occurs, while it's still an abstraction. The opposite of risk
management is crisis management, trying to figure out what to do about
the problem after it happens. - \href{http://amzn.eu/d/i0IDFA2}{Waltzing
With Bears, \emph{Tom De Marco \& Tim Lister}}
\end{quote}

This is not how \textbf{Risk-First} sees it:

First, we have the notion that Risks are discrete events, again. Some
risks \emph{are} (like gambling on a horse race), but most
\emph{aren't}. In the Dinner Party, for example, bad preparation is
going to mean a \emph{worse} time for everyone, but how good a time
you're having is a spectrum, it doesn't divide neatly into just ``good''
or ``bad''.

Second, the opposite of ``Risk Management'' (or trying to minimise the
``Down-side'') is either ``Upside Risk Management'', (trying to maximise
the good things happening), or it's trying to make as many bad things
happen as possible. Humans tend to be optimists (especially when there
are lots of Hidden Risks), hence our focus on Downside Risk. Sometimes
though, it's good to stand back and look at a scenario and think: am I
capturing all the Upside Risk here?

Finally, Crisis Management is \emph{still just Risk Management}: the
crisis (Earthquake, whatever) has \emph{happened}. You can't manage it
because it's in the past. All you can do is Risk Manage the future
(minimize further casualties and human suffering, for example).

Yes, it's fine to say ``we're in crisis'', but to assume there is a
different strategy for dealing with it is a mistake: this is the
\href{https://en.wikipedia.org/wiki/Sunk_costs}{Fallacy of Sunk Costs}.

\hypertarget{invariances-1-panic-invariance}{%
\section{Invariances \#1: Panic
Invariance}\label{invariances-1-panic-invariance}}

You would expect then, that any methods for managing software delivery
should be \emph{invariant} to the level of crisis in the project. If,
for example, a project proceeds using Scrum) for eight months, and then
the deadline looms and everyone agrees to throw Scrum out of the window
and start hacking, then \emph{this implies there is a problem with
Scrum}, and that it is not \emph{Panic Invariant}. In fact, many tools
like Scrum don't consider this:

\begin{itemize}
\tightlist
\item
  If there is a production outage during the working week, we don't wait
  for the next Sprint to fix it.
\item
  Although a 40-hour work-week \emph{is a great idea}, this goes out of
  the window if the databases all crash on a Saturday morning.
\end{itemize}

In these cases, we (hopefully calmly) \emph{evaluate the risks and take
action}.

I call this \textbf{Panic Invariance}: the methodology shouldn't need to
change given the amount of pressure or importance on the table.

\hypertarget{invariances-2-scale-invariance}{%
\section{Invariances \#2: Scale
Invariance}\label{invariances-2-scale-invariance}}

Another test of a methodology is that it shouldn't fall down when
applied at different \emph{scales}. Because, if it does, this implies
that there is something wrong with the methodology. The same is true of
physical laws: if they don't apply under all circumstances, then that
implies something is wrong. For example, Newton's Laws of Motion fail to
calculate the orbital period of Mercury, and this was an early win for
Einstein's Relativity.

Some methodologies are designed for certain scales: Extreme Programming
is designed for small, co-located teams. And, that's useful. But the
fact it doesn't scale tells us something about it: chiefly, that it
considers certain \emph{kinds} of risk, while ignoring others. At small
scales, that works ok, but at larger scales, the bigger risks increase
too fast for it to work.

So ideally, a methodology should be applicable at \emph{any} scale: - A
single class or function - A collection of functions, or a library - A
project team - A department - An entire organisation

If the methodology \emph{fails at a particular scale}, this tells you
something about the risks that the methodology isn't addressing. It's
fine to have methodologies that work at different scales, and on
different problems. One of the things that I am exploring with Risk
First is trying to place methodologies and practices within a framework
to say \emph{when} they are applicable.

\hypertarget{value-vs-speed}{%
\section{Value vs Speed}\label{value-vs-speed}}

\hypertarget{value}{%
\subsection{Value}\label{value}}

``Upside Risk'' isn't a commonly used term: industry tends to prefer
``value'', as in ``Is this a value-add project?''. There is plenty of
theory surrounding \textbf{Value}, such as Porter's
\href{https://en.wikipedia.org/wiki/Value_chain}{Value Chain} and
\href{https://en.wikipedia.org/wiki/Net_present_value}{Net Present
Value}. This is all fine so long as we remember:

\begin{itemize}
\tightlist
\item
  \textbf{The pay-off is risky}: Since the \textbf{Value} is created in
  the future, we can't be certain about it happening - we should never
  consider it a done-deal. \textbf{Future Value} is always at risk. In
  finance, for example, we account for this in our future cash-flows by
  discounting them according to the risk of default.
\item
  \textbf{The pay-off amount is risky}: Additionally, whereas in a
  financial transaction (like a loan, say), we might know the size of a
  future payment, in IT projects we can rarely be sure that they will
  deliver a certain return. On some fixed-contract projects this
  sometimes is not true: there may be a date when the
  payment-for-delivery gets made, but mostly we'll be expecting an
  uncertain pay-off.
\end{itemize}

\textbf{Risk-First} is a particular \emph{view} on reality. It's not the
only one. However, I am going to try and make the case that it's an
underutilized one that has much to offer us.

\hypertarget{speed}{%
\subsection{Speed}\label{speed}}

For example, in \href{http://a.co/d/ddWGTB2}{Rapid Development} by Steve
McConnell we have the following diagram:

\begin{figure}
\centering
\includegraphics{images/kite9/rapid_development_pillars.png}
\caption{Pillars, From Rapid Development By Steve McConnell}
\end{figure}

And, this is \emph{fine}, McConnell is structuring the process from the
perspective of \emph{delivering as quickly as possible}. However, here,
I want to turn this on it's head. Exploring Software Development from a
risk-first perspective is an under-explored technique, and I believe it
offers some useful insights. So the aim here is to present the case for
viewing software development like this:

\begin{figure}
\centering
\includegraphics{images/kite9/rapid_development_pillars2.png}
\caption{Pillars, re-arranged}
\end{figure}

As we will see, \emph{Speed} (or Schedule Risk as we will term it) is
one risk amongst others that need to be considered from a
risk-management perspective. There's no point in prioritising
\emph{speed} if the software fails in production due to unaddressed
Operational Risk, and irreparably damages trust in the product.

\hypertarget{eisenhowers-box}{%
\subsection{Eisenhower's Box}\label{eisenhowers-box}}

If we can view software delivery from the point of view of \emph{value},
then why can't we apply the same tools to Risk too? In order to do this,
let's review ``Eisenhower's Box'' model. This considers two variables:

\begin{itemize}
\tightlist
\item
  How valuable the work is (Importance)
\item
  How soon it is needed (Urgency)
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/pd/220px-MerrillCoveyMatrix.png}
\caption{A basic ``Eisenhower box'' to help evaluate urgency and
importance. Items may be placed at more precise points within each
quadrant. - \href{https://en.wikipedia.org/wiki/Time_management}{Time
Management, \emph{Wikipedia}}}
\end{figure}

Here, we're considering a synthesis of both \emph{time} and
\emph{value}. But Net Present Value allows us to discount value in the
future, which offers us a way to reconcile these two variables. In the
diagram, you can see two future payments, one of Â£100 due in one year,
one of Â£150 due in 10 years. By discounting at a given rate (here at 6\%
per year) we can compare their worth \emph{now}.

\begin{figure}
\centering
\includegraphics{images/numbers/npv.png}
\caption{Net Present Value Discounting}
\end{figure}

\hypertarget{net-present-risk}{%
\section{Net Present Risk}\label{net-present-risk}}

Can we do the same thing with risk? Let's introduce the concept of Net
Present Risk, or NPR:

\begin{quote}
Net Present Risk is the \emph{Importance} of a Future risk, discounted
to a common level of \emph{Urgency}.
\end{quote}

Let's look at a quick example to see how this could work out. Let's say
you had the following 3 risks:

\begin{itemize}
\tightlist
\item
  Risk \textbf{A}, which will cost you Â£50 in 5 year's time.
\item
  Risk \textbf{B}, which will cost you Â£70 in 8 year's time.
\item
  Risk \textbf{C}, which will cost you Â£120 in 18 year's time.
\end{itemize}

Which has the biggest NPR? Well, it depends on the discount rate that
you apply. Let's assume we are discounting at 6\% per year. A graph of
the discounted risks looks like this:

\begin{figure}
\centering
\includegraphics{images/numbers/npr1.png}
\caption{Net Present Risk, 6\% Discount Rate}
\end{figure}

On this basis, the biggest risk is \textbf{B}, at about Â£45. If we
\emph{reduce} the discount factor to 3\%, we get a different result:

\begin{figure}
\centering
\includegraphics{images/numbers/npr2.png}
\caption{Net Present Risk, 3\% Discount Rate}
\end{figure}

Now, risk \textbf{C} is bigger.

Because this is \emph{Net} Present Risk, we can also use it to make
decisions about whether or not to mitigate risks. Let's consider the
cost of mitigating each risk \emph{now}:

\begin{itemize}
\tightlist
\item
  Risk \textbf{A} costs Â£20 to mitigate
\item
  Risk \textbf{B} costs Â£50 to mitigate
\item
  Risk \textbf{C} costs Â£100 to mitigate
\end{itemize}

Which is the best deal?

Well, under the 6\% regime, only Risk \textbf{A} is worth mitigating,
because you spend Â£20 today to get rid of Â£40 of risk (today). The NPR
is positive at around Â£20, whereas for \textbf{B} and \textbf{C}
mitigations it's under water.

But, under a 3\% regime, risk \textbf{A} and \textbf{B} are \emph{both}
worth mitigating.

\hypertarget{discounting-the-future-to-zero}{%
\subsection{Discounting the Future To
Zero}\label{discounting-the-future-to-zero}}

I have worked in teams sometimes where the blinkers go down, and the
only thing that matters is \emph{now}. They may apply a rate of 60\%
per-day, which means that anything with a horizon over a week is
irrelevant. Regimes of such
\href{https://en.wikipedia.org/wiki/Hyperinflation}{hyper-inflation} are
a sure sign that something has \emph{really broken down} within a
project. Consider in this case a Discount Factor of 60\% per day, and
the following risks:

\begin{itemize}
\tightlist
\item
  Risk A: Â£80 cost, happening \emph{tomorrow}
\item
  Risk B: Â£500 cost, happening in \emph{5 days}.
\end{itemize}

Risk B is almost irrelevant under this regime, as this graph shows:

\begin{figure}
\centering
\includegraphics{images/numbers/npr3.png}
\caption{Net Present Risk, 60\% Discount Rate}
\end{figure}

Why do things like this happen? Often, the people involved are under
incredible job-stress: usually they are threatened with the sack on a
daily basis, and therefore feel they have to react. Publically-listed
companies also often apply short-term focus, because they only care
about the \emph{next annual report}, which limits their horizons and
ability to consider future risk.

Under these circumstances, we often see \emph{Pooh-Bear
Procrastination}:

\begin{quotation}

``Here is Edward Bear coming downstairs now, bump, bump, bump, on the
back of his head, behind Christopher Robin. It is, as far as he knows,
the only way of coming downstairs, but sometimes he feels that there
really is another way\ldots{}if only he could stop bumping for a moment
and think of it!''

\sourceatright{\href{http://amzn.eu/d/acJ5a2j}{\textemdash  A. A. Milne, \emph{Winne-the-Pooh}}}
\end{quotation}

\hypertarget{is-this-scientific}{%
\section{Is This Scientific?}\label{is-this-scientific}}

Enough with the numbers and the theory: \textbf{Risk-First} is an
attempt to provide a practical framework, rather than a scientifically
rigorous analysis. In fact, my view is that you should \emph{give up} on
trying to compute risk numerically. You \emph{can't} work out how long a
software project will take based purely on an analysis of (say)
\emph{function points}. (Whatever you define them to be).

\begin{itemize}
\tightlist
\item
  First, there isn't enough evidence for an approach like this. We
  \emph{can} look at collected data about IT projects, but techniques
  and tools advance rapidly.
\item
  Second, IT projects have too many confounding factors, such as
  experience of the teams, technologies used etc. That is, the risks
  faced by IT projects are \emph{too diverse} and \emph{hard to
  quantify} to allow for meaningful comparison from one to the next.
\item
  Third, as soon as you \emph{publish a date} it changes the
  expectations of the project (see Student Syndrome).
\item
  Fourth, metrics get first of all misused and then gamed.
\end{itemize}

Reality is messy. Dressing it up with numbers doesn't change that and
you risk fooling yourself. If this is the case, is there any hope at all
in what we're doing? I would argue yes: \emph{forget precision}. You
should, with experience be able to hold up two separate risks and answer
the question, ``is this one bigger than this one?''

\hypertarget{pay-off}{%
\section{Pay-Off}\label{pay-off}}

Because everything we're dealing with is Risk, we can't know in advance
how well any action we take will pay off. Taking Action is a lot like
placing a bet. But, if we can \emph{weigh separate risks in our hands}
we should be able to intuit what the Pay-Off of a given Action will be.

The fruits of this gambling are revealed when we meet reality, and we
can see whether our bets really paid off.

With that in mind, let's look at how we can meet reality as fast and
often as possible.

\hypertarget{cadence}{%
\chapter{Cadence}\label{cadence}}

Let's go back to the model again, introduced in Meeting Reality:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/model_vs_reality_2-400dpi.png}
\caption{Meeting Reality: reality is changed and so is your internal
model.}
\end{figure}

As you can see, it's an idealized \textbf{Feedback Loop}.

How \emph{fast} should we go round this loop? Is there a right answer?
The longer you leave your goal in mind, the longer it'll be before you
find out how it really stacks up against reality.

Testing your goals in mind against reality early and safely is how
you'll manage risk effectively, and to do this, you need to set up
\textbf{Feedback Loops}. e.g.

\begin{itemize}
\tightlist
\item
  \textbf{Bug Reports and Feature Requests} tell you how the users are
  getting on with the software.
\item
  Monitoring Tools and Logs allow you to find out how your software is
  doing in reality.
\item
  \textbf{Dog-Fooding} i.e using the software you write yourself might
  be faster than talking to users.
\item
  \href{https://en.wikipedia.org/wiki/Continuous_delivery}{Continuous
  Delivery} (CD) is about putting software into production as soon as
  it's written.
\item
  \textbf{Integration Testing} is a faster way of meeting \emph{some}
  reality than continually deploying code and re-testing it manually.
\item
  \textbf{Unit Testing} is a faster feedback loop than Integration
  Testing.
\item
  \textbf{Compilation} warns you about logical inconsistencies in your
  code.
\end{itemize}

.. and so on.

\hypertarget{time-reality-trade-off}{%
\subsection{Time / Reality Trade-Off}\label{time-reality-trade-off}}

This list is arranged so that at the top, we have the most visceral,
most \emph{real} feedback loop, but at the same time, the slowest.

At the bottom, a good IDE can inform you about errors in your Internal
Model in real time, by way of highlighting compilation errors . So, this
is the fastest loop, but it's the most \emph{limited} reality.

Imagine for a second that you had a special time-travelling machine.
With it, you could make a change to your software, and get back a report
from the future listing out all the issues people had faced using it
over its lifetime, instantly.

That'd be neat, eh? If you did have this, would there be any point at
all in a compiler? Probably not, right?

The whole \emph{reason} we have tools like compilers is because they
give us a short-cut way to get some limited experience of reality
\emph{faster} than would otherwise be possible. Because, cadence is
really important: the faster we test our ideas, the more quickly we'll
find out if they're correct or not.

\hypertarget{development-cycle-time}{%
\subsection{Development Cycle Time}\label{development-cycle-time}}

One thing that often astounds me is how developers can ignore the fast
feedback loops at the bottom of the list, because the ones nearer the
top \emph{will do}. In the worst cases, changing two lines of code,
running the build script, deploying and then manually testing out a
feature. And then repeating.

If you're doing it over and over, this is a terrible waste of time. And,
you get none of the benefit of a permanent suite of tests to run again
in the future.

The
\href{http://www.agilenutshell.com/episodes/41-testing-pyramid}{Testing
Pyramid} hints at this truth:

\begin{itemize}
\tightlist
\item
  \textbf{Unit Tests} have a \emph{fast feedback loop}, so have
  \emph{lots of them}.
\item
  \textbf{Integration Tests} have a slightly \emph{slower feedback
  loop}, so have \emph{few of them}. Use them when you can't write unit
  tests (at the application boundaries).
\item
  \textbf{Manual Tests} have a \emph{very slow feedback loop}, so have
  \emph{even fewer of them}. Use them as a last resort.
\end{itemize}

\hypertarget{production}{%
\subsection{Production}\label{production}}

You could take this chapter to mean that Continuous Delivery (CD) is
always and everywhere a good idea. I \emph{guess} that's not a bad
take-away, but it's clearly more nuanced than that.

Yes, CD will give you faster feedback loops, but even getting things
into production is not the whole story: the feedback loop isn't complete
until people have used the code, and reported back to the development
team.

The right answer is to use the fastest feedback loop possible,
\emph{which actually does give you feed back}.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/cadence-400dpi.png}
\caption{Different actions have different feedback loops}
\end{figure}

\hypertarget{re-cap}{%
\section{Re-cap}\label{re-cap}}

Let's look at the journey so far:

\begin{itemize}
\item
  In A Simple Scenario we looked at how risk pervades every goal we have
  in life, big or small. We saw that risk stems from the fact that our
  Internal Model of the world couldn't capture everything about reality,
  and so some things were down to chance.
\item
  In the Development Process we looked at how common software
  engineering conventions like Unit Testing, User Acceptance Testing and
  Integration could help us manage the risk of taking an idea to
  production, by \emph{gradually} introducing it to reality in stages.
\item
  Then, generalizing the lessons of the Development Process article, we
  examined the idea that Meeting Reality frequently helps flush out
  Hidden Risks and improve your Internal Model.
\item
  In It's All Risk Management we took a leap of faith: Could
  \emph{everything} we do just be risk management? And we looked at the
  RAID log and thought that maybe it could be.
\item
  Next, in A Software Project Scenario we looked at how you could treat
  the project-as-a-whole as a risk management exercise, and treat the
  goals from one day to the next as activities to mitigate risk.
\item
  Some Risk Theory was an aside, looking at some terminology and the
  useful concept of a Risk Register.
\item
  Finally, above, we looked at Cadence, and how feedback loops allow you
  Navigate the Risk Landscape more effectively, by showing you more
  quickly when you're going wrong.
\end{itemize}

What this has been building towards is supplying us with a vocabulary
with which to communicate to our team-mates about which Risks are
important to us, which actions we believe are the right ones, and which
tools we should use.

Let's have a look at an example of how this might work.

\hypertarget{de-risking}{%
\chapter{De Risking}\label{de-risking}}

As we saw in A Conversation, it's important not only to consider the
Attendant Risks you're trying to mitigate, but the ones you're likely to
pick up in the process. This means picking a careful path through the
Risk Landscape. This is the essence of \emph{De-Risking}.

\begin{quotation}

``To take steps to make (something) less risky or less likely to involve
a financial loss.''

\sourceatright{\href{https://en.oxforddictionaries.com/definition/de-risk}{\textemdash  De-Risk,\emph{OxfordDictionaries.com}}}
\end{quotation}

Some simple examples of this might be:

\begin{itemize}
\tightlist
\item
  Safety-nets and ropes de-risk climbing. But, the activity of climbing
  itself is otherwise much unchanged.
\item
  Backups and Source-Control de-risk the development process by reducing
  the impact of computer failure. Our process is changed \emph{slightly}
  by this imposition, but we're not massively inconvenienced.
\item
  tbd.
\item
  tbd.
\end{itemize}

Let's look at some common strategies for De-Risking. This is probably
not an exhaustive set, but it's a good starting point.

\hypertarget{mitigate}{%
\section{Mitigate}\label{mitigate}}

\textbf{Mitigating} the risk is taking steps towards minimising either
it's likelihood or impact (as we discussed in the Risk Theory chapter).
This is the main approach we will be looking at in Part 2. We'll break
down risk into its different types and look at the general mitigations
for each. The examples above of De-Risking were all mitigations.
(Safety-nets, for example, mitigate the impact of hitting the ground.)

\hypertarget{avoid}{%
\section{Avoid}\label{avoid}}

\textbf{Avoiding} a risk, means taking a route on the Risk Landscape
\emph{around} the risk. For example, if you are working in a team which
has no experience of relational databases, then \emph{storing data in
files} might be a way to avoid the Learning-Curve Risk associated with
this technology.

Of course, you may pick up other, more serious Attendant Risks as a
result: Relational Databases are software solutions to many kinds of
Coordination Risk problem.

\hypertarget{transfer}{%
\section{Transfer}\label{transfer}}

\textbf{Transferring} risk means \_making it someone else's problem. For
example, when I buy home insurance, the impact of my house burning down
is reduced. It hasn't gone away completely, but at least the financial
element of it is handled by the insurance company.

In part 2, we'll see how \textbf{Transfer} of risk is an essential
feature of Software as a Service. Inside organisations,
\textbf{Transfer} of risk can become a political game:

\begin{quotation}

``\ldots{} ownership results in `one throat to choke' for audit
functions {[}and{]} from ownership comes responsibility. A lot of the
political footwork in an enterprise revolves around trying to not own
technologies. Who wants to be responsible for Java usage across a
technology function of dozens of thousands of staff, any of whom might
be doing crazy stuff? You first, mate.''

\sourceatright{\href{https://zwischenzugs.com/2018/10/02/why-are-enterprises-so-slow/}{\textemdash  Why Are Enterprises So Slow?, \emph{zwischenzugs.com}}}
\end{quotation}

\hypertarget{ignore-accept}{%
\section{Ignore / Accept}\label{ignore-accept}}

\textbf{Accepting} a risk is to deal with it when it arises. One example
is the Key-Man Risk involved in having a super-star programmer on the
team. Although there would be fallout if they left, they are usually
mitigating more risk than they cause. Another example is using
particular software dependencies: I might build a mobile application
which requires a Facebook account to log in. This might give rise to the
risk that some people can't log in, but might simplify the software to
such an extent that it's worthwhile.

Whereas \textbf{Accepting} a risk seems to imply an eyes-wide-open
examination, \textbf{Ignoring} seems to imply that either the risk is so
insignificant it doesn't warrant evaluation, or so daunting that it
can't be stared down. Either way, \textbf{Ignoring} a risk amounts to
the same thing as \textbf{Accepting} it, since you're not doing anything
about it.

\textbf{Accepting} a risk has to occur \emph{before} we can
\textbf{Mitigate} it. As we've discussed previously, what we decide to
mitigate on a daily basis will depend on the evaluation of where we can
best mitigate Attendant Risk.

\hypertarget{a-nice-problem-to-have}{%
\subsection{A Nice Problem To Have}\label{a-nice-problem-to-have}}

\textbf{Ignoring} or \textbf{Accepting} risks is a lot less work than
\textbf{Mitigating} them, and sometimes it can feel negligent to just
add them to the backlog or risk-register. One useful test I have found
is whether ``This would be a nice problem to have''. For example:

\begin{quotation}

Running out of space in the database would be a nice problem to have,
because it would mean we have lots of users

\end{quotation}

\begin{quotation}

Users complaining about lacking function X would be a nice problem to
have, because it would mean they were using the system

\end{quotation}

Applying this kind of logic at the start of a project leads you towards
building a
\href{https://en.wikipedia.org/wiki/Minimum_viable_product}{Minimum
Viable Product}.

\hypertarget{learned-helplessness}{%
\subsection{Learned Helplessness}\label{learned-helplessness}}

Sometimes, risks just go away on their own.
\href{https://en.wikipedia.org/wiki/Learned_helplessness}{Learned
Helplessness} on the other hand, is where we \emph{could} do something
about the risk, but fail to see that as an option:

\begin{quotation}

``Learned helplessness is behaviour typical of animals, and in rare
cases humans, that occurs when the subject endures repeatedly painful or
otherwise aversive stimuli which it is unable to escape or avoid. After
such experience, the organism often fails to learn or accept''escape" or
``avoidance'' in new situations where such behavior would likely be
effective. "

\sourceatright{\href{https://en.wikipedia.org/wiki/Learned_helplessness}{\textemdash  Learned Helplessness, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{contain}{%
\section{Contain}\label{contain}}

\textbf{Containing} risks means setting aside sufficient time or money
to deal with them if they occur. This is an excellent approach for
Hidden Risk or entire sets of minor Attendant Risks.

Whenever a project-manager builds slack into a project plan, this is
\textbf{Containment}. In the chapter on Schedule Risk we are going to
look in detail at how this works.

\hypertarget{exploit}{%
\section{Exploit}\label{exploit}}

\textbf{Exploiting} as a strategy usually means taking advantage of the
upside of a risk. For example, ensuring enough stock is available to
mitigate the risk of a rush on sales over the Christmas period, or
ensuring your website has enough bandwidth to capture all the traffic
headed towards it after it's featured on television.

Going back to the example of home insurance, the Insurance company are
\textbf{exploiting} the risk of my house burning down by selling me
insurance. This is a common pattern: wherever there is risk, there is
likely to be a way to profit from it.

Later, in the chapter on Process Risk we'll be looking at how
\textbf{exploiting risk} can happen organically within a company.

\hypertarget{isnt-it-obvious}{%
\section{Isn't It Obvious?}\label{isnt-it-obvious}}

At this point, you might be wondering what all the fuss is about. This
stuff is all obvious! It's what we do anyway! Perhaps. Risk management
\emph{is} what we do anyway:

\begin{quotation}

``We've survived 200,000 years as humans. Don't you think there's a
reason why we survived? We're good at risk management.''

\sourceatright{\href{https://www.zerohedge.com/news/2018-03-13/taleb-best-thing-society-bankruptcy-goldman-sachs}{\textemdash  Nassim Nicholas Taleb, author of \emph{The Black Swan}}}
\end{quotation}

The problem is that although all this \emph{is} obvious, it appears to
have largely escaped codification within the literature, practices and
methodologies of software development. Further, while it is obvious,
there is a huge hole: Successful De-Risking depends heavily on
individual experience and talent.

If there are three take-aways from Risk-First, it is these:

\begin{itemize}
\tightlist
\item
  Concentrate on Risks, not Goals (goals are risks in disguise, anyway)
\item
  Every action you take is De-Risking \emph{something} (or should be)
\item
  tbd.
\end{itemize}

Risk-First has stressed the existence of Hidden Risk over and again, but
\emph{it's only hidden if you're not expecting it}. In part 2, we are
going to look at all the places where Hidden Risk lives.

\hypertarget{a-conversation}{%
\chapter{A Conversation}\label{a-conversation}}

After so much theory, it seems like it's time to look at how we can
apply these principles in the real world.

The following is based the summary of an issue from just a few weeks
ago. It's heavily edited and anonymized, and I've tried to add the
\textbf{Risk-First} vocabulary along the way, but otherwise, it's real.

Some background: \textbf{Synergy} is an online service with an
app-store, and \textbf{Eve} and \textbf{Bob} are developers working for
\textbf{Large Corporation LTD}, which wants to have an application
accepted into Synergy's app-store.

Synergy's release means that the app-store refresh will happen in a few
weeks, so this is something of a hard deadline: if we miss it, the next
release will be four months away.

\hypertarget{a-risk-conversation}{%
\section{A Risk Conversation}\label{a-risk-conversation}}

\textbf{Eve}: We've got a problem with the Synergy security review.

\textbf{Bob}: Tell me.

\textbf{Eve}: Well, you know Synergy did their review and asked us to
upgrade our Web Server to only allow TLS version 1.1 and greater?

\textbf{Bob}: Yes, I remember: We discussed it as a team and thought the
simplest thing would be to change the security settings on the Web
Server, but we all felt it was pretty risky. We decided that in order to
flush out Hidden Risk, we'd upgrade our entire production site to use it
\emph{now}, rather than wait for the app launch.

\textbf{Eve}: Right, and it \emph{did} flush out Hidden Risk: some
people using Windows 7, downloading Excel spreadsheets on the site,
couldn't download them: for some reason, that combination didn't support
anything greater than TLS version 1.0. So, we had to back it out.

\textbf{Bob}: Ok, well I guess it's good we found out \emph{now}. It
would have been a disaster to discover this after the go-live.

\textbf{Eve}: Yes. So, what's our next-best action to mitigate this?

\textbf{Bob}: Well, we could go back to Synergy and ask them for a
reprieve, but I think it'd be better to mitigate this risk now if we
can\ldots{} they'll definitely want it changed at some point.

\textbf{Eve}: How about we run two web-servers? One for the existing
content, and one for our new Synergy app? We'd have to get a new
external IP address, handle DNS setup, change the firewalls, and then
deploy a new version of the Web Server software on the production boxes.

\textbf{Bob}: This feels like there'd be a lot of Attendant Risk: and
all of this needs to be handled by the Networking Team, so we're picking
up a lot of Bureaucracy Risk. I'm also worried that there are too many
steps here, and we're going to discover loads of Hidden Risks as we go.

\textbf{Eve}: Well, you're correct on the first one. But, I've done this
before not that long ago for a Chinese project, so I know the process -
we shouldn't run into any new Hidden Risk.

\textbf{Bob}: OK, fair enough. But isn't there something simpler we can
do? Maybe some settings in the Web Server?

\textbf{Eve}: Well, if we were using Apache, yes, it would be easy to do
this. But, we're using Baroque Web Server, and it \emph{might} support
it, but the documentation isn't very clear.

\textbf{Bob}: OK, and upgrading it is a \emph{big} risk, right? We'd
have to migrate all of our configuration\ldots{}

\textbf{Eve}: Yes, let's not go there. But if we changing the settings
on Baroque, we have the Attendant Risk that it's not supported by the
software and we're back where we started. Also, if we isolate the
Synergy app stuff now, we can mess around with it at any point in
future, which is a big win in case there are other Hidden Risks with the
security changes that we don't know about yet.

\textbf{Bob}: OK, I can see that buys us something, but time is really
short and we have holidays coming up.

\textbf{Eve}: Yes. How about for now, we go with the isolated server,
and review next week? If it's working out, then great, we continue with
it. Otherwise, if we're not making progress next week, then it'll be
because our isolation solution is meeting more risk than we originally
thought. We can try the settings change in that case.

\textbf{Bob}: Fair enough, it sounds like we're managing the risk
properly, and because we can hand off a lot of this to the Networking
Team, we can get on with mitigating our biggest risk on the project, the
authentication problem, in the meantime.

\textbf{Eve}: Right. I'll check in with the Networking Team each day and
make sure it doesn't get forgotten.

\hypertarget{aftermath}{%
\section{Aftermath}\label{aftermath}}

Hopefully, this type of conversation will feel familiar. It should.
There's nothing ground-breaking at all in what we've covered so far;
it's more-or-less just Risk Management theory.

If you can now apply it in conversation, like we did above, then that's
one extra tool you have for delivering software.

So with the groundwork out of the way, let's get on to Part 2 and
investigate The Risk Landscape.

\part{Risk}

\hypertarget{risk-landscape}{%
\chapter{Risk Landscape}\label{risk-landscape}}

Risk is messy. It's not always easy to tease apart the different
components of risk and look at them individually. Let's look at a
high-profile recent example to see why.

\hypertarget{the-financial-crisis}{%
\section{The Financial Crisis}\label{the-financial-crisis}}

In the \href{https://en.wikipedia.org/wiki/Financial_services}{Financial
Services} industry, whole \emph{departments} exist to calculate things
like:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Market_risk}{Market Risk}: the
  risk that the amount some asset you hold/borrow/have loaned is going
  to change in value.
\item
  \href{https://en.wikipedia.org/wiki/Credit_risk}{Credit Risk}: the
  risk that someone who owes you a payment at a specific point in time
  might not pay it back.
\item
  \href{https://en.wikipedia.org/wiki/Liquidity_risk}{Liquidity Risk}:
  the risk that you can't find a market to sell/buy something, usually
  leading to a shortage of ready cash.
\end{itemize}

\ldots{} and so on. But, we don't need to know the details exactly to
understand this story.

They get expressed in ways like this:

\begin{quotation}

we have a 95\% chance that today we'll lose less than Â£100

\end{quotation}

In the financial crisis, though, these models of risk didn't turn out to
be much use. Although there are lots of conflicting explanations of what
happened, one way to look at it is this:

\begin{itemize}
\tightlist
\item
  Liquidity difficulties (i.e.~amount of cash you have for day-to-day
  running of the bank) caused some banks to not be able to cover their
  interest payments.
\item
  This caused credit defaults (the thing that Credit Risk measures were
  meant to guard against) even though the banks \emph{technically} were
  solvent.
\item
  That meant that, in time, banks got bailed out, share prices crashed
  and there was lots of
  \href{https://en.wikipedia.org/wiki/Quantitative_easing}{Quantitative
  Easing}.
\item
  All of which had massive impacts on the markets in ways that none of
  the Market Risk models foresaw.
\end{itemize}

All the Risks were
\href{https://www.investopedia.com/terms/c/correlation.asp}{correlated}.
That is, they were affected by the \emph{same underlying events}, or
\emph{each other}.

\hypertarget{the-risk-landscape-again}{%
\section{The Risk Landscape Again}\label{the-risk-landscape-again}}

It's like this with software risks, too, sadly.

In Meeting Reality, we looked at the concept of the Risk Landscape, and
how a software project tries to \emph{navigate} across this landscape,
testing the way as it goes, and trying to get to a position of
\emph{more favourable risk}.

It's tempting to think of our Risk Landscape as being like a
\href{https://en.wikipedia.org/wiki/Fitness_landscape}{Fitness
Landscape}. That is, you have a ``cost function'' which is your height
above the landscape, and you try and optimise by moving downhill in a
\href{https://en.wikipedia.org/wiki/Gradient_descent}{Gradient Descent}
fashion.

However, there's a problem with this: As we said in Risk Theory, we
don't have a cost function. We can only guess at what risks there are.
And, we have to go on our \emph{experience}. For this reason, I prefer
to think of the Risk Landscape as a terrain which contains \emph{fauna}
and \emph{obstacles} (or, specifically Boundaries).

I am going to try and show you some of the fauna of the Risk Landscape.
We know every project is different, so every Risk Landscape is also
different. But, just as I can tell you that the landscape outside your
window will probably will have some roads, trees, fields, forests,
buildings, and that the buildings are likely to be joined together by
roads, I can tell you some general things about risks too.

In fact, we're going to try and categorise the kinds of things we see on
this Risk Landscape. But, this isn't going to be perfect:

\begin{itemize}
\tightlist
\item
  One risk can ``blend'' into another just like sometimes a ``field'' is
  also a ``car-park'' or a building might contain some trees (but isn't
  a forest).
\item
  There is \emph{correlation} between different risks: one risk may
  cause another, or two risks may be due to the same underlying cause.
\item
  As we saw in Part 1, mitigating one risk can give rise to another, so
  risks are often \emph{inversely correlated}.
\end{itemize}

\hypertarget{why-should-we-categorise-the-risks}{%
\section{Why Should We Categorise The
Risks?}\label{why-should-we-categorise-the-risks}}

This is a ``spotters' guide'' to risks, not an in-depth encyclopedia.

If we were studying insects, this might be a guide giving you a
description and a picture of each insect, telling you where to find it
and what it does. That doesn't mean that this is \emph{all} there is to
know. Just as a scientist could spend her entire life studying a
particular species of bee, each of the risks we'll look at really has a
whole sub-discipline of Computer Science attached to it, which we can't
possibly hope to cover all of.

As software developers, we can't hope to know the detailed specifics of
the whole discipline of
\href{https://en.wikipedia.org/wiki/Complexity_theory}{Complexity
Theory}, or
\href{https://en.wikipedia.org/wiki/Concurrency_(computer_science)}{Concurrency
Theory}. But, we're still required to operate in a world where these
things exist. So, we may as well get used to them, and ensure that we
respect their primacy. We are operating in \emph{their} world, so we
need to know the rules.

\hypertarget{were-all-naturalists-now}{%
\section{We're all Naturalists Now}\label{were-all-naturalists-now}}

This is a new adventure. There's a long way to go. Just as naturalists
are able to head out and find new species of insects and plants, we
should expect to do the same. This is by no means a complete picture -
it's barely a sketch.

It's a big, crazy, evolving world of software. Help to fill in the
details. Report back what you find.

\hypertarget{our-tour-itinerary}{%
\section{Our Tour Itinerary}\label{our-tour-itinerary}}

Below is a table outlining the different risks we'll see. There
\emph{is} an order to this: the later risks are written assuming a
familiarity with the earlier ones. Hopefully, you'll stay to the end and
see everything, but you're free to choose your own tour if you want to.

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Feature Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you haven't built features the market needs, or they contain bugs,
or the market changes underneath you. \strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Communication Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks associated with getting messages heard and understood.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Complexity Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Your software is so complex it makes it hard to change, understand or
run.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Dependency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks of depending on other people, products, software, functions, etc.
This is a general look at dependencies, before diving into specifics
like\ldots{}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Scarcity Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks associated with having a dependency on time, money or some other
limited resource.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Software Dependency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you choose to depend on a software library, service or
function.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Process Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you depend on a business process, or human process to give you
something you need.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Boundary Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to making decisions that limit your choices later on.
Sometimes, you go the wrong way on the Risk Landscape and it's hard to
get back to where you want to be.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Agency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks that staff have their own Goals, which might not align with those
of the project or team.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to the fact that systems contain multiple agents, which need
to work together.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Map And Territory Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to the fact that people don't see the world as it really is.
(After all, they're working off different, imperfect Internal
Models.)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Operational Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Software is embedded in a system containing people, buildings, machines
and other services. Operational risk considers this wider picture of
risk associated with running a software service or business in the real
world.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

On each page we'll start by looking at the category of the risk \emph{in
general}, and then break this down into some specific sub-types. At the
end, in Staging and Classifying we'll have a recap about what we've seen
and make some guesses about how things fit together.

So, let's get started with Feature Risk.

\hypertarget{feature-risk}{%
\chapter{Feature Risk}\label{feature-risk}}

Feature Risk is the category of software risk to do with features that
have to be in your software. It is the risk that you face by \emph{not
having features that your clients need}.

In a way, Feature Risk is very fundamental: if there were \emph{no}
feature risk, the job would be done already, either by you, or by
another product, and the product would be perfect!

As a simple example, if your needs are served perfectly by Microsoft
Excel, then you don't have any Feature Risk. However, the day you find
Microsoft Excel wanting, and decide to build an Add-On is the day when
you first appreciate some Feature Risk.

Not considering Feature Risk means that you might be building the wrong
functionality, for the wrong audience or at the wrong time. And
eventually, this will come down to lost money, business, acclaim, or
whatever else reason you are doing your project for. So let's unpack
this concept into some of it's variations.

\hypertarget{feature-fit-risk}{%
\section{Feature Fit Risk}\label{feature-fit-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-fit-risk-400dpi.png}
\caption{Feature Risk}
\end{figure}

This is the one we've just discussed above: the feature that you (or
your clients) want to use in the software \emph{isn't there}. Now, as
usual, you could call this an issue, but we're calling it a Risk because
it's not clear exactly \emph{how many} people are affected, or how
badly.

\begin{itemize}
\tightlist
\item
  This might manifest itself as complete \emph{absence} of something you
  need, e.g ``Where is the word count?''
\item
  It could be that the implementation isn't complete enough, e.g ``why
  can't I add really long numbers in this calculator?''
\end{itemize}

\hypertarget{implementation-risk}{%
\section{Implementation Risk}\label{implementation-risk}}

Feature Risk also includes things that don't work as expected: That is
to say, \href{https://en.wikipedia.org/wiki/Software_bug}{bugs}.
Although the distinction between ``a missing feature'' and ``a broken
feature'' might be worth making in the development team, we can consider
these both the same kind of risk: \emph{the software doesn't do what the
user expects}.

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-implementation-risk-400dpi.png}
\caption{Implementation Risk}
\end{figure}

(At this point, it's worth pointing out that sometimes, \emph{the user
expects the wrong thing}. This is a different but related risk, which
could be down to Training or Documentation or simply Poor User Interface
and we'll look at that more in Communication Risk.)

\hypertarget{regression-risk}{%
\section{Regression Risk}\label{regression-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-regression-risk-400dpi.png}
\caption{Regression Risk}
\end{figure}

Regression Risk is basically risk of breaking existing features in your
software when you add new ones. As with the previous risks, the eventual
result is the same; customers don't have the features they expect. This
can become a problem as your code-base gains Complexity, as it becomes
impossible to keep a complete Internal Model of the whole thing.

Also, while delivering new features can delight your customers, breaking
existing ones will annoy them. This is something we'll come back to in
Reputation Risk.

\hypertarget{conceptual-integrity-risk}{%
\section{Conceptual Integrity Risk}\label{conceptual-integrity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/conceptual-integrity-risk-400dpi.png}
\caption{Conceptual Integrity Risk}
\end{figure}

Sometimes, users \emph{swear blind} that they need some feature or
other, but it runs at odds with the design of the system, and plain
\emph{doesn't make sense}. Often, the development team can spot this
kind of conceptual failure as soon as it enters the Backlog. Usually,
it's in coding that this becomes apparent.

Sometimes, it can go for a lot longer. I once worked on some software
that was built as a score-board within a chat application. However,
after we'd added much-asked-for commenting and reply features to our
score-board, we realised we'd implemented a chat application
\emph{within a chat application}, and had wasted our time enormously.

\href{https://en.wikipedia.org/wiki/Feature_phone}{Feature Phones} are a
real-life example: although it \emph{seemed} like the market wanted more
and more features added to their phones,
\href{https://en.wikipedia.org/wiki/IPhone}{Apple's iPhone} was able to
steal huge market share by presenting a much more enjoyable, more
coherent user experience, despite being more expensive and having fewer
features. Feature Phones had been drowning in increasing Conceptual
Integrity Risk without realising it.

Which leads to Greenspun's 10th Rule:

\begin{quotation}

``Any sufficiently complicated C or Fortran program contains an ad-hoc,
informally-specified, bug-ridden, slow implementation of half of Common
Lisp.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Greenspun's_tenth_rule}{\textemdash  Greenspun's 10th Rule, \emph{Wikipedia}}}
\end{quotation}

This is a particularly pernicious kind of Feature Risk which can only be
mitigated by good Design. Human needs are fractal in nature: the more
you examine them, the more differences you can find. The aim of a
product is to capture some needs at a \emph{general} level: you can't
hope to ``please all of the people all of the time''.

Conceptual Integrity Risk is the risk that chasing after features leaves
the product making no sense, and therefore pleasing no-one.

\hypertarget{feature-access-risk}{%
\section{Feature Access Risk}\label{feature-access-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-access-risk-400dpi.png}
\caption{Feature Access Risk}
\end{figure}

Sometimes, features can work for some people and not others: this could
be down to
\href{https://en.wikipedia.org/wiki/Accessibility}{Accessibility}
issues, language barriers or localisation.

You could argue that the choice of \emph{platform} is also going to
limit access: writing code for XBox-only leaves PlayStation owners out
in the cold. This is \emph{largely} Feature Access Risk, though
Dependency Risk is related here.

In Marketing, minimising Feature Access Risk is all about
\href{https://en.wikipedia.org/wiki/Market_segmentation}{Segmentation}:
trying to work out \emph{who} your product appeals to, and tailoring it
to that particular market, but for technologists, increasing Feature
Access means increasing complexity: you have to deliver the software on
more platforms, localised in more languages, with different
configurations of features at different price-points. Mitigating Feature
Access Risk therefore means increased effort and complexity (which we'll
come to later).

\hypertarget{market-risk}{%
\subsection{Market Risk}\label{market-risk}}

Feature Access Risk is related, of course, to Market Risk, which I
introduced on the Risk Landscape page as being the value that the market
places on a particular asset. Since the product you are building is your
asset, it makes sense that you'll face Market Risk on it:

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/market-risk-400dpi.png}
\caption{Market Risk}
\end{figure}

\begin{quotation}

``Market risk is the risk of losses in positions arising from movements
in market prices.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Market_risk}{\textemdash  Market Risk, \emph{Wikipedia}}}
\end{quotation}

I face market risk when I own (i.e.~have a \emph{position} in) some
\href{http://apple.com}{Apple} stock. Apple's's stock price will decline
if a competitor brings out an amazing product, or if fashions change and
people don't want their products any more.

In the same way, \emph{you} have Market Risk on the product or service
you are building: the \emph{market} decides what it is prepared to pay
for this, and it tends to be outside your control.

\hypertarget{feature-drift-risk}{%
\section{Feature Drift Risk}\label{feature-drift-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-drift-risk-400dpi.png}
\caption{Feature Drift Risk}
\end{figure}

\textbf{Feature Drift} is the tendency that the features people need
\emph{change over time}. For example, at one point in time, supporting
IE6 was right up there for website developers, but it's not really
relevant anymore. Although that change took \emph{many} years to
materialize, other changes are more rapid.

The point is: Requirements captured \emph{today} might not make it to
\emph{tomorrow}, especially in the fast-paced world of IT. This is
partly because the market \emph{evolves} and becomes more discerning.
This happens in several ways:

\begin{itemize}
\tightlist
\item
  Features present in competitor's versions of the software become
  \emph{the baseline}, and they're expected to be available in your
  version.
\item
  Certain ways of interacting become the norm (e.g.
  \href{https://en.wikipedia.org/wiki/QWERTY}{querty} keyboards, or the
  control layout in cars: these don't change with time).
\item
  Features decline in usefulness: \emph{Printing} is less important now
  than it was, for example.
\end{itemize}

As we will see later in Boundary Risk, Feature Drift Risk is often a
source of Complexity Risk, since you often need to add new features,
while not dismantling old features as some users still need them.

Feature Drift Risk is \emph{not the same thing} as \textbf{Requirements
Drift}, which is the tendency projects have to expand in scope as they
go along. There are lots of reasons they do that, a key one being the
Hidden Risks uncovered on the project as it progresses.

\hypertarget{fashion}{%
\subsection{Fashion}\label{fashion}}

Fashion plays a big part in IT, as this
\href{https://designers.hubspot.com/blog/the-history-of-web-design-infographic}{infographic
on website design shows}. True, web-sites have got easier to use as time
has gone by, and users now expect this. Also, bandwidth is greater now,
which means we can afford more media and code on the client side.
However, \emph{fashion} has a part to play in this.

By being \emph{fashionable}, web-sites are communicating: \emph{this is
a new thing}, \emph{this is relevant}, \emph{this is not terrible}: all
of which is mitigating a Communication Risk. Users are all-too-aware
that the Internet is awash with terrible, abandon-ware sites that are
going to waste their time. How can you communicate that you're not one
of them to your users?

\hypertarget{delight}{%
\section{Delight}\label{delight}}

If this breakdown of Feature Risk seems reductive, then try not to think
of it that way: the aim \emph{of course} should be to delight users, and
turn them into fans. That's a laudable Goal, but should be treated in
the usual Risk-First way: \emph{pick the biggest risk you can mitigate
next}.

Consider Feature Risk from both the down-side and the up-side:

\begin{itemize}
\tightlist
\item
  What are we missing?
\item
  How can we be \emph{even better}?
\end{itemize}

Hopefully, this has given you some ideas about what Feature Risk
involves. Hopefully, you might be able to identify a few more specific
varieties. But, it's time to move on and look in more detail at
Complexity Risk and how it affects what we build.

\hypertarget{analysis}{%
\section{Analysis}\label{analysis}}

At this point, it would be easy to stop and say, look, here are a bunch
of Feature Risk issues that you could face. But, it turns out that we're
going to be relying heavily on Feature Risk as we go on in order to
build our understanding of other risks, so it's probably worth spending
a bit of time up front to classify what we've found.

The Feature Risks identified here basically exist in a 3-dimensional
space:

\begin{itemize}
\tightlist
\item
  \textbf{Fit}: How well the features fit for a particular client.
\item
  \textbf{Audience}: The range of clients (the \emph{market}) that may
  be able to use this feature.
\item
  \textbf{Evolution}: The way the fit and the audience changes and
  evolves as time goes by.
\end{itemize}

\hypertarget{fit}{%
\subsection{Fit}\label{fit}}

\begin{quotation}

``This preservation, during the battle for life, of varieties which
possess any advantage in structure, constitution, or instinct, I have
called Natural Selection; and Mr.~Herbert Spencer has well expressed the
same idea by the Survival of the Fittest''

\sourceatright{\href{https://en.wikipedia.org/wiki/Survival_of_the_fittest}{\textemdash  Charles Darwin (Survival of the Fittest), \emph{Wikipedia}}.}
\end{quotation}

Darwin's conception of fitness was not one of athletic prowess, but how
well an organism worked within the landscape, with the goal of
reproducing itself.

Feature Fit Risk, Conceptual Integrity Risk and Implementation Risk all
hint at different aspects of this ``fitness''. We can conceive of them
as the gaps between the following entities:

\begin{itemize}
\tightlist
\item
  Perceived Need: What the user \emph{thinks} they want
\item
  Expectation: What the user \emph{expects}
\item
  Reality: What they actually \emph{get}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/all_feature_risk_1.png}
\caption{Feature Risks Assembled: Fit Risks}
\end{figure}

For further reading, you can check out
\href{http://en.wikipedia.org/SERVQUAL}{The Service Quality Model},
whcih this model is derived from. This model analyses the types of
\emph{quality gaps} in services, and how consumer expectations and
perceptions of a service arise. In the Staging And Classifying chapter,
we'll come back and build on this model further.

\hypertarget{fit-and-audience}{%
\subsection{Fit and Audience}\label{fit-and-audience}}

Two risks, Feature Access Risk and Market Risk considers \emph{Fit} for
a whole \emph{Audience} of users. They are different: just as it's
possible to have a small audience, but a large revenue, it's possible to
have a product which has low Feature Access Risk (i.e lots of users can
access it without difficulty) but high Market Risk (i.e.~the market is
highly volatile or capricious in it's demands). \emph{Online services}
often suffer from this Market Risk roller-coaster, being one moment
highly valued and the next irrelevant.

\hypertarget{fit-audience-and-evolution}{%
\subsection{Fit, Audience and
Evolution}\label{fit-audience-and-evolution}}

Two risks further consider how the \textbf{Fit} and \textbf{Audience}
\emph{change}: Regression Risk and Feature Drift Risk. We call this
\emph{evolution} in the sense that:

\begin{itemize}
\tightlist
\item
  Our product's features \emph{evolve} with time, and changes made by
  the development team.
\item
  Our audience changes and evolves as it is exposed to our product and
  competing products.
\item
  The world as a whole is an evolving system within which our product
  exists.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/all_feature_risk_2.png}
\caption{Feature Risks Assembled: Audience and Evolution}
\end{figure}

\hypertarget{applying-feature-risk}{%
\section{Applying Feature Risk}\label{applying-feature-risk}}

Consider Feature Risk carefully next time you are grooming the backlog:

\begin{itemize}
\tightlist
\item
  Can you judge which tasks mitigate the most Feature Risk?
\item
  Are you delivering features that are valuable to a large audience? How
  well do you understand your audience? How does the size of the
  audience for a task impact it's importance in the backlog?
\item
  Does the audience \emph{know} that the features exist? How do you
  communicate feature availability to them?
\item
  How does writing a specification mitigate Fit Risk? For what other
  reasons are you writing specifications?
\end{itemize}

In the next chapter, we are going to unpack this third point further.
Somewhere between ``what the customer wants'' and ``what you give them''
is a \emph{dialog}. In using a software product, users are engaging in a
\emph{dialog} with its features. If the features don't exist, hopefully
they will engage in a dialog with the development team to get them
added.

These dialogs are prone to risk, and this is the subject of the next
chapter, Communication-Risk.

\hypertarget{complexity-risk}{%
\chapter{Complexity Risk}\label{complexity-risk}}

Complexity Risk are the risks to your project due to its underlying
``complexity''. Over the next few chapters, we'll break down exactly
what we mean by complexity, looking at Dependency Risk and Boundary Risk
as two particular sub-types of Complexity Risk. However, in this
chapter, we're going to be specifically focusing on \emph{code you
write}: the size of your code-base, the number of modules, the
interconnectedness of the modules and how well-factored the code is.

You could think of this chapter, then, as \textbf{Codebase Risk}: We'll
look at three separate measures of codebase complexity and talk about
Technical Debt, and look at places in which \textbf{Codebase Risk} is at
it's greatest.

\hypertarget{kolmogorov-complexity}{%
\section{Kolmogorov Complexity}\label{kolmogorov-complexity}}

The standard Computer-Science definition of complexity, is
\href{https://en.wikipedia.org/wiki/Kolmogorov_complexity}{Kolmogorov
Complexity}. This is:

\begin{quote}
``\ldots{}is the length of the shortest computer program (in a
predetermined programming language) that produces the object as
output.'' - Kolmogorov Complexity, Wikipedia
\end{quote}

This is a fairly handy definition for us, as it means that to in writing
software to solve a problem, there is a lower bound on the size of the
software we write. In practice, this is pretty much impossible to
quantify. But that doesn't really matter: the techniques for
\emph{moving in that direction} are all that we are interested in, and
this basically amounts to compression.

Let's say we wanted to write a JavaScript program to output this string:

\begin{verbatim}
abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd
\end{verbatim}

We might choose this representation:

\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return} \StringTok{"abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd"}\NormalTok{ (}\DecValTok{45}\NormalTok{)}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

The numbers in brackets indicate how many symbols each line contains, so
in total, this code block contains \textbf{53 symbols}, if you count
\texttt{function}, \texttt{out} and \texttt{return} as one symbol each.

But, if we write it like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                    (}\DecValTok{11}\NormalTok{)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return}\NormalTok{ ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{        (}\DecValTok{16}\NormalTok{)}
\NormalTok{        ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{;}\NormalTok{                               (}\DecValTok{6}\NormalTok{ )}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

With this version, we now have \textbf{41 symbols} (\textbf{ABCD} is a
single symbol, because we could have called it anything). And with this
version:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                    (}\DecValTok{11}\NormalTok{)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                            (}\DecValTok{7}\NormalTok{ )}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\ldots{} we have \textbf{26 symbols}.

\hypertarget{abstraction}{%
\subsection{Abstraction}\label{abstraction}}

What's happening here is that we're \emph{exploiting a pattern}: we
noticed that \texttt{ABCD} occurs several times, so we defined it a
single time and then used it over and over, like a stamp. Separating the
\emph{definition} of something from the \emph{use} of something as we've
done here is called ``abstraction''. We're going to come across it over
and over again in this part of the book, and not just in terms of
computer programs.

By applying techniques such as Abstraction, we can improve in the
direction of the Kolmogorov limit. And, by allowing ourselves to say
that \emph{symbols} (like \texttt{out} and \texttt{ABCD}) are worth one
complexity point, we've allowed that we can be descriptive in our
\texttt{function} name and \texttt{const}. Naming things is an important
part of abstraction, because to use something, you have to be able to
refer to it.

\hypertarget{trade-off}{%
\subsection{Trade-Off}\label{trade-off}}

But we could go further down into
\href{https://en.wikipedia.org/wiki/Code_golf}{Code Golf} territory.
This javascript program plays
\href{https://en.wikipedia.org/wiki/Fizz_buzz}{FizzBuzz} up to 100, but
is less readable than you might hope:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{<}\DecValTok{100}\OperatorTok{;}\NormalTok{)}\VariableTok{document}\NormalTok{.}\AttributeTok{write}\NormalTok{(((}\OperatorTok{++}\NormalTok{i}\OperatorTok{%}\DecValTok{3}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Fizz'}\NormalTok{)}\OperatorTok{+}
\NormalTok{(i}\OperatorTok{%}\DecValTok{5}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Buzz'}\NormalTok{)}\OperatorTok{||}\NormalTok{i)}\OperatorTok{+}\StringTok{"<br>"}\NormalTok{)                           (}\DecValTok{62}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So there is at some point a trade-off to be made between Complexity Risk
and Communication Risk. This is a topic we'll address more in that
chapter. But for now, it should be said that Communication Risk is about
\emph{misunderstanding}: The more complex a piece of software is, the
more difficulty users will have understanding it, and the more
difficulty developers will have changing it.

\hypertarget{connectivity}{%
\section{Connectivity}\label{connectivity}}

A second, useful measure of complexity comes from graph theory, and that
is the connectivity of a graph:

\begin{quotation}

``\ldots{}the minimum number of elements (nodes or edges) that need to
be removed to disconnect the remaining nodes from each other''

\sourceatright{\href{https://en.wikipedia.org/wiki/Connectivity_(graph_theory}{\textemdash  Connectivity, \emph{Wikipedia}})}
\end{quotation}

To see this in action, have a look at the below graph:

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/connectivity_1-400dpi.png}
\caption{Graph 1}
\end{figure}

It has 10 vertices, labelled \textbf{a} to \textbf{j}, and it has 15
edges (or links) connecting the vertices together. If any single edge
were removed from this diagram, the 10 vertices would still be linked
together. Because of this, we can say that the graph is
\emph{2-connected}. That is, to disconnect any single vertex, you'd have
to remove \emph{at least} two edges.

As a slight aside, let's consider the \textbf{Kolmogorov Complexity} of
this graph, by inventing a mini-language to describe graphs. It could
look something like this:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<}\NormalTok{item}\OperatorTok{>} \OperatorTok{:}\NormalTok{ [}\OperatorTok{<}\NormalTok{item}\OperatorTok{>,}\NormalTok{]}\OperatorTok{*} \OperatorTok{<}\NormalTok{item}\OperatorTok{>}\NormalTok{    # Indicates that the item}
\NormalTok{                              # before the colon}
\NormalTok{                              # has a connection to all}
\NormalTok{                              # the items after the colon}
\end{Highlighting}
\end{Shaded}

So our graph could be defined like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ b}\OperatorTok{,}\NormalTok{c}\OperatorTok{,}\NormalTok{d}
\NormalTok{b}\OperatorTok{:}\NormalTok{ c}\OperatorTok{,}\NormalTok{f}\OperatorTok{,}\NormalTok{e}
\NormalTok{c}\OperatorTok{:}\NormalTok{ f}\OperatorTok{,}\NormalTok{d}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}\OperatorTok{,}\NormalTok{j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{g}\OperatorTok{:}\NormalTok{ j}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{i}\OperatorTok{:}\NormalTok{ j}
\NormalTok{                                                      (}\DecValTok{39}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's remove some of those extra links:

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/connectivity_2-400dpi.png}
\caption{Graph 2}
\end{figure}

In this graph, I've removed 6 of the edges. Now, we're in a situation
where if any single edge is removed, the graph becomes
\emph{unconnected}. That is, it's broken into distinct chunks. So, it's
\emph{1-connected}.

The second graph is clearly simpler than the first. And, we can show
this by looking at the \textbf{Kolgomorov Complexity} in our little
language:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{g}
\NormalTok{b}\OperatorTok{:}\NormalTok{ f}
\NormalTok{c}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{f}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{                                                      (}\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Connectivity} is also \textbf{Complexity}. Heavily connected
programs/graphs are much harder to work with than less-connected ones.
Even \emph{laying out} the first graph sensibly is a harder task than
the second (the second is a doddle). But the reason programs with
greater connectivity are harder to work with is that changing one module
potentially impacts many others.

\hypertarget{hierarchies-and-modularisation}{%
\section{Hierarchies and
Modularisation}\label{hierarchies-and-modularisation}}

In the second, simplified graph, I've arranged it as a hierarchy, which
I can do now that it's only 1-connected. For 10 vertices, we need 9
edges to connect everything up. It's always:

\begin{verbatim}
  edges = vertices - 1
\end{verbatim}

Note that I could pick any hierarchy here: I don't have to start at
\textbf{c} (although it has the nice property that it has two roughly
even sub-trees attached to it).

How does this help us? Imagine if \textbf{a} - \textbf{j} were modules
of a software system, and the edges of the graph showed communications
between the different sub-systems. In the first graph, we're in a worse
position: who's in charge? What deals with what? Can I isolate a
component and change it safely? What happens if one component
disappears? But, in the second graph, it's easier to reason about,
because of the reduced number of connections and the new heirarchy of
organisation.

On the down-side, perhaps our messages have farther to go now: in the
original \textbf{i} could send a message straight to \textbf{j}, but now
we have to go all the way via \textbf{c}. But this is the basis of
\href{https://en.wikipedia.org/wiki/Modular_programming}{Modularisation}
and \href{https://en.wikipedia.org/wiki/Hierarchy}{Hierarchy}.

As a tool to battle complexity, we don't just see this in software, but
everywhere in our lives. Society, business, nature and even our bodies:

\begin{itemize}
\tightlist
\item
  \textbf{Organelles} - such as
  \href{https://en.wikipedia.org/wiki/Mitochondrion}{Mitochondria}.
\item
  \textbf{Cells} - such as blood cells, nerve cells, skin cells in the
  \href{https://en.wikipedia.org/wiki/List_of_distinct_cell_types_in_the_adult_human_body}{Human
  Body}.
\item
  \textbf{Organs} - like hearts livers, brains etc.
\item
  \textbf{Organisms} - like you and me.
\end{itemize}

The great complexity-reducing mechanism of modularisation is that
\emph{you only have to consider your local environment}. Elements of the
program that are ``far away'' in the hierarchy can be relied on not to
affect you. This is somewhat akin to the \textbf{Principal Of Locality}:

\begin{quotation}

``Spatial locality refers to the use of data elements within relatively
close storage locations.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Locality_of_reference}{\textemdash  Locality Of Reference, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{cyclomatic-complexity}{%
\section{Cyclomatic Complexity}\label{cyclomatic-complexity}}

A variation on this graph connectivity metric is our third measure of
complexity,
\href{https://en.wikipedia.org/wiki/Cyclomatic_complexity}{Cyclomatic
Complexity}. This is:

\begin{verbatim}
Cyclomatic Complexity = edges â vertices + 2P,
\end{verbatim}

Where \textbf{P} is the number of \textbf{Connected Components}
(i.e.~distinct parts of the graph that aren't connected to one another
by any edges).

So, our first graph had a \textbf{Cyclomatic Complexity} of 7.
\texttt{(15\ -\ 10\ +\ 2)}, while our second was 1.
\texttt{(9\ -\ 10\ +\ 2)}.

Cyclomatic complexity is all about the number of different routes
through the program. The more branches a program has, the greater it's
cyclomatic complexity. Hence, this is a useful metric in Testing and
\href{https://en.wikipedia.org/wiki/Code_coverage}{Code Coverage}: the
more branches you have, the more tests you'll need to exercise them all.

\hypertarget{more-abstraction}{%
\section{More Abstraction}\label{more-abstraction}}

Although we ended up with our second graph having a \textbf{Cyclomatic
Complexity} of 1 (the minimum), we can go further through abstraction,
because this representation isn't minimal from a \textbf{Kolmogorov
Complexity} point-of-view. For example, we might observe that there are
further similarities in the graph that we can ``draw out'':

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/connectivity_3-400dpi.png}
\caption{Complexity 3}
\end{figure}

Here, we've spotted that the structure of subgraphs \textbf{P1} and
\textbf{P2} are the same: we can have the same functions there to
assemble those. Noticing and exploiting patterns of repetition is one of
the fundamental tools we have in the fight against Complexity Risk.

So, we've looked at some measures of software structure complexity, in
order that we can say ``this is more complex than this''. However, we've
not really said why complexity entails Risk. So let's address that now
by looking at two analogies, Mass and Technical Debt.

\hypertarget{complexity-as-mass}{%
\section{Complexity As Mass}\label{complexity-as-mass}}

The first way to look at complexity is as \textbf{Mass} or
\textbf{Inertia} : a software project with more complexity has greater
\textbf{Inertia} or \textbf{Mass} than one with less complexity.

Newton's Second Law states:

\begin{quotation}

``F = \emph{m}\textbf{a}, ( Force = Mass x Acceleration )''

\sourceatright{\href{https://en.wikipedia.org/wiki/Newtons_laws_of_motion}{\textemdash  Netwon's Laws Of Motion, \emph{Wikipedia}}}
\end{quotation}

That is, in order to move your project \emph{somewhere new}, and make it
do new things, you need to give it a push, and the more \textbf{Mass} it
has, the more \textbf{Force} you'll need to move (accelerate) it.

\textbf{Inertia} and \textbf{Mass} are equivalent concepts in physics:

\begin{quotation}

``mass is the quantitative or numerical measure of a body's inertia,
that is of its resistance to being accelerated''.

\sourceatright{\href{https://en.wikipedia.org/wiki/Inertia\#Mass_and_inertia}{\textemdash  Inertia, \emph{Wikipedia}}}
\end{quotation}

You could stop here and say that the more lines of code a project
contains, the higher it's mass. And, that makes sense, because in order
to get it to do something new, you're likely to need to change more
lines.

But there is actually some underlying sense in which \emph{this is
real}, as discussed in this
\href{https://www.youtube.com/user/1veritasium}{Veritasium} video. To
paraphrase:

\begin{quotation}

``Most of your mass you owe due to E=mcÂ², you owe to the fact that your
mass is packed with energy, because of the \textbf{interactions} between
these quarks and gluon fluctuations in the gluon field\ldots{} what we
think of as ordinarily empty space\ldots{} that turns out to be the
thing that gives us most of our mass.''

\sourceatright{\href{https://www.youtube.com/watch?annotation_id=annotation_3771848421&feature=iv&src_vid=Xo232kyTsO0&v=Ztc6QPNUqls}{\textemdash  Your Mass is NOT From the Higgs Boson, \emph{Veritasium}}}
\end{quotation}

I'm not an expert in physics, \emph{at all}, and so there is every
chance that I am pushing this analogy too hard. But, substituting quarks
and gluons for pieces of software we can (in a very handwaving-y way)
say that more complex software has more \textbf{interactions} going on,
and therefore has more mass than simple software.

The reason I am labouring this analogy is to try and make the point that
Complexity Risk is really fundamental:

\begin{itemize}
\tightlist
\item
  Feature Risk: like \textbf{money}.
\item
  Schedule Risk: like \textbf{time}.
\item
  Complexity Risk: like \textbf{mass}.
\end{itemize}

At a basic level, Complexity Risk heavily impacts on Schedule Risk: more
complexity means you need more force to get things done, which takes
longer.

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/complexity-risk-400dpi.png}
\caption{Complexity Risk and it's mitigations}
\end{figure}

\hypertarget{technical-debt}{%
\section{Technical Debt}\label{technical-debt}}

The most common way we talk about unnecessary complexity in software is
as Technical Debt:

\begin{quotation}

``Shipping first time code is like going into debt. A little debt speeds
development so long as it is paid back promptly with a rewrite\ldots{}
The danger occurs when the debt is not repaid. Every minute spent on
not-quite-right code counts as interest on that debt. Entire engineering
organisations can be brought to a stand-still under the debt load of an
unconsolidated implementation, object-oriented or otherwise.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Technical_debt}{Ward Cunningham, 1992}}
\end{quotation}

Building a perfect first-time solution is a waste, because perfection
takes a long time. You're taking on more attendant Schedule Risk than
necessary and Meeting Reality more slowly than you could.

A quick-and-dirty, over-complex implementation mitigates the same
Feature Risk and allows you to Meet Reality faster.

But, having mitigated the Feature Risk, you are now carrying more
Complexity Risk than you necessarily need, and it's time to think about
how to \href{https://en.wikipedia.org/wiki/Code_refactoring}{Refactor}
the software to reduce this risk again.

\hypertarget{kitchen-analogy}{%
\section{Kitchen Analogy}\label{kitchen-analogy}}

It's often hard to make the case for minimising Technical Debt: it often
feels that there are more important priorities, especially when
technical debt can be ``swept under the carpet'' and forgotten about
until later. (See Discounting The Future.)

One helpful analogy I have found is to imagine your code-base is a
kitchen. After preparing a meal (i.e.~delivering the first
implementation), \emph{you need to tidy up the kitchen}. This is just
something everyone does as a matter of \emph{basic sanitation}.

Now of course, you could carry on with the messy kitchen. When tomorrow
comes and you need to make another meal, you find yourself needing to
wash up saucepans as you go, or working around the mess by using
different surfaces to chop on.

It's not long before someone comes down with food poisoning.

We wouldn't tolerate this behaviour in a restaurant kitchen, so why put
up with it in a software project?

\hypertarget{feature-creep}{%
\section{Feature Creep}\label{feature-creep}}

In Brooks' essay ``No Silver Bullet - Essence and Accident in Software
Engineering'', a distinction is made between:

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{Essence}: \emph{the difficulties inherent in the nature of the
  software.}
\item
  \textbf{Accident}: \emph{those difficulties that attend its production
  but are not inherent.} -
  \href{https://en.wikipedia.org/wiki/No_Silver_Bullet}{Fred Brooks,
  \emph{No Silver Bullet}}
\end{itemize}
\end{quote}

The problem with this definition is that we are accepting features of
our software as \emph{essential}.

The \textbf{Risk-First} approach is that if you want to mitigate some
Feature Risk then you have to pick up Complexity Risk as a result. But,
that's a \emph{choice you get to make}.

Therefore, \href{https://en.wikipedia.org/wiki/Feature_creep}{Feature
Creep} (or
\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}) is a failure to observe this basic equation: instead of
considering this trade off, you're building every feature possible. This
has an impact on Complexity Risk, which in turn impacts Communication
Risk and also Schedule Risk.

Sometimes, feature-creep happens because either managers feel they need
to keep their staff busy, or the staff decide on their own that they
need to keep themselves busy. But now, we can see that basically this
boils down to bad risk management.

\begin{quotation}

``Perfection is Achieved Not When There Is Nothing More to Add, But When
There Is Nothing Left to Take Away''

\sourceatright{\href{http://www.quotationspage.com/quote/26979.html}{Antoine de Saint-Exupery}}
\end{quotation}

\hypertarget{dead-end-risk}{%
\section{Dead-End Risk}\label{dead-end-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/dead-end-risk-400dpi.png}
\caption{Dead-End Risk}
\end{figure}

Dead-End Risk is where you build functionality that you \emph{think} is
useful, only to find out later that actually, it was a dead-end, and is
superseded by something else.

For example, let's say that the Accounting sub-system needed password
protection (so you built this). Then the team realised that you needed a
way to \emph{change the password} (so you built that). Then, that you
needed to have more than one user of the Accounting system so they would
all need passwords (OK, fine).

Finally, the team realises that actually logging-in would be something
that all the sub-systems would need, and that it had already been
implemented more thoroughly by the Approvals sub-system.

At this point, you realise you're in a \textbf{Dead End}:

\begin{itemize}
\tightlist
\item
  \textbf{Option 1}: You carry on making minor incremental improvements
  to the accounting password system (carrying the extra Complexity Risk
  of the duplicated functionality).
\item
  \textbf{Option 2}: You rip out the accounting password system, and
  merge in the Approvals system, surfacing new, hidden Complexity Risk
  in the process, due to the difficulty in migrating users from the old
  to new way of working.
\item
  \textbf{Option 3}: You start again, trying to take into account both
  sets of requirements at the same time, again, possibly surfacing new
  hidden Complexity Risk due to the combined approach.
\end{itemize}

Sometimes, the path from your starting point to your goal on the Risk
Landscape will take you to dead ends: places where the only way towards
your destination is to lose something, and do it again another way.

This is because you surface new Hidden Risk along the way. And the
source of a lot of this hidden risk will be unexpected Complexity Risk
in the solutions you choose. This happens a lot.

\hypertarget{source-control}{%
\subsection{Source Control}\label{source-control}}

\href{https://en.wikipedia.org/wiki/Version_control}{Version Control
Systems} like \href{https://en.wikipedia.org/wiki/Git}{Git} are a useful
mitigation of Dead-End Risk, because it means you can \emph{go back} to
the point where you made the bad decision and go a different way.
Additionally, they provide you with backups against the often
inadvertent Dead-End Risk of someone wiping the hard-disk.

\hypertarget{the-re-write}{%
\subsection{The Re-Write}\label{the-re-write}}

\textbf{Option 3}, Rewriting code or a whole project can seem like a way
to mitigate Complexity Risk, but it usually doesn't work out too well.
As Joel Spolsky says:

\begin{quote}
There's a subtle reason that programmers always want to throw away the
code and start over. The reason is that they think the old code is a
mess. And here is the interesting observation: they are probably wrong.
The reason that they think the old code is a mess is because of a
cardinal, fundamental law of programming: \emph{It's harder to read code
than to write it.} -
\href{https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/}{Things
You Should Never Do, Part 1, \emph{Joel Spolsky}}
\end{quote}

The problem that Joel is outlining here is that the developer mistakes
hard-to-understand code for unnecessary Complexity Risk. Also, perhaps
there is Agency Risk because the developer is doing something that is
more useful to him than the project. We're going to return to this
problem in again Communication Risk.

\hypertarget{where-complexity-hides}{%
\section{Where Complexity Hides}\label{where-complexity-hides}}

Complexity isn't spread evenly within a software project. Some problems,
some areas, have more than their fair share of issues. We're going to
cover a few of these now, but be warned, this is not a complete list by
any means:

\begin{itemize}
\tightlist
\item
  Memory Management
\item
  Protocols / Types
\item
  Algorithmic (Space and Time) Complexity
\item
  Concurrency / Mutability
\item
  Networks / Security
\end{itemize}

\hypertarget{memory-management}{%
\subsection{Memory Management}\label{memory-management}}

Memory Management is another place where Complexity Risk hides:

\begin{quotation}

``Memory leaks are a common error in programming, especially when using
languages that have no built in automatic garbage collection, such as C
and C++.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Memory_leak}{\textemdash  Memory Leak, \emph{Wikipedia}}}
\end{quotation}

\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{Garbage
Collectors} (as found in Javascript or Java) offer you the deal that
they will mitigate the Complexity Risk of you having to manage your own
memory, but in return perhaps give you fewer guarantees about the
\emph{performance} of your software. Again, there are times when you
can't accommodate this Operational Risk, but these are rare and usually
only affect a small portion of an entire software-system.

\hypertarget{protocols-and-types}{%
\subsection{Protocols And Types}\label{protocols-and-types}}

Whenever two components of a software system need to interact, they have
to establish a protocol for doing so. There are lots of different ways
this can work, but the simplest example I can think of is where some
component \textbf{a} calls some function \textbf{b}. e.g:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c) }\OperatorTok{\{}
    \ControlFlowTok{return} \StringTok{"whatever"} \CommentTok{// do something here.}
\OperatorTok{\}}

\KeywordTok{function} \AttributeTok{a}\NormalTok{() }\OperatorTok{\{}
    \KeywordTok{var}\NormalTok{ bOut }\OperatorTok{=} \AttributeTok{b}\NormalTok{(}\StringTok{"one"}\OperatorTok{,} \StringTok{"two"}\OperatorTok{,} \StringTok{"three"}\NormalTok{)}\OperatorTok{;}
    \ControlFlowTok{return} \StringTok{"something "}\OperatorTok{+}\NormalTok{bOut}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

If component \textbf{b} then changes in some backwards-incompatible way,
say:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{,}\NormalTok{ d }\CommentTok{/* new parameter */}\NormalTok{) }\OperatorTok{\{}
    \ControlFlowTok{return} \StringTok{"whatever"} \CommentTok{// do something here.}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then, we can say that the protocol has changed. This problem is so
common, so endemic to computing that we've had compilers that check
function arguments \href{https://en.wikipedia.org/wiki/Compiler}{since
the 1960's}. The point being is that it's totally possible for the
compiler to warn you about when a protocol within the program has
changed.

The same is basically true of
\href{https://en.wikipedia.org/wiki/Data_type}{Data Types}: whenever we
change the \textbf{Data Type}, we need to correct the usages of that
type. Note above, I've given the \texttt{JavaScript} example, but I'm
going to switch to \texttt{TypeScript} now:

\begin{verbatim}
interface BInput {
    a: string,
    b: string,
    c: string,
    d: string
}

function b(in: BInput): string {
    return "whatever" // do something here.
}
\end{verbatim}

Now, of course, there is a tradeoff: we \emph{mitigate} Complexity Risk,
because we define the protocols / types \emph{once only} in the program,
and ensure that usages all match the specification. But the tradeoff is
(as we can see in the \texttt{TypeScript} code) more
\emph{finger-typing}, which some people argue counts as Schedule Risk.

Nevertheless, compilers and type-checking are so prevalent in software
that clearly, you have to accept that in most cases, the trade-off has
been worth it: Even languages like \href{https://clojure.org}{Clojure}
have been retro-fitted with
\href{https://github.com/clojure/core.typed/wiki/User-Guide}{type
checkers}.

We're going to head into much more detail on this in the chapter on
Protocol Risk.

\hypertarget{space-and-time-complexity}{%
\subsection{Space and Time Complexity}\label{space-and-time-complexity}}

So far, we've looked at a couple of definitions of complexity in terms
of the codebase itself. However, in Computer Science there is a whole
branch of complexity theory devoted to how the software \emph{runs},
namely \href{https://en.wikipedia.org/wiki/Big_O_notation}{Big O
Complexity}.

Once running, an algorithm or data structure will consume space or
runtime dependent on it's characteristics. As with Garbage Collectors),
these characteristics can introduce Performance Risk which can easily
catch out the unwary. By and large, using off-the-shelf data structures
and algorithms helps, but you still need to know their performance
characteristics.

The \href{http://bigocheatsheet.com}{Big O Cheat Sheet} is a wonderful
resource to investigate this further.

\hypertarget{concurrency-mutability}{%
\subsection{Concurrency / Mutability}\label{concurrency-mutability}}

Although modern languages include plenty of concurrency primitives,
(such as the
\href{https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/package-summary.html}{java.util.concurrent}
libraries), concurrency is \emph{still} hard to get right.

\href{https://en.wikipedia.org/wiki/Race_condition}{Race conditions} and
\href{https://en.wikipedia.org/wiki/Deadlock}{Deadlocks} \emph{thrive}
in over-complicated concurrency designs: complexity issues are magnified
by concurrency concerns, and are also hard to test and debug.

Recently, languages such as Clojure have introduced
\href{https://en.wikipedia.org/wiki/Persistent_data_structure}{persistent
collections} to alleviate concurrency issues. The basic premise is that
any time you want to \emph{change} the contents of a collection, you get
given back a \emph{new collection}. So, any collection instance is
immutable once created. The tradeoff is again attendant Performance Risk
to mitigate Complexity Risk.

An important lesson here is that choice of language can reduce
complexity: and we'll come back to this in Software Dependency Risk.

\hypertarget{networking-security}{%
\subsection{Networking / Security}\label{networking-security}}

There are plenty of Complexity Risk perils in \emph{anything} to do with
networked code, chief amongst them being error handling and (again)
protocol evolution.

In the case of security considerations, exploits \emph{thrive} on the
complexity of your code, and the weaknesses that occur because of it. In
particular, Schneier's Law says, never implement your own cryptographic
scheme:

\begin{quotation}

``Anyone, from the most clueless amateur to the best cryptographer, can
create an algorithm that he himself can't break. It's not even hard.
What is hard is creating an algorithm that no one else can break, even
after years of analysis.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Bruce_Schneier\#Cryptography}{Bruce Schneier, 1998} }
\end{quotation}

Luckily, most good languages include cryptographic libraries that you
can include to mitigate these Complexity Risks from your own code-base.

This is a strong argument for the use of libraries. But, when should you
use a library and when should you implement yourself? This is again
covered in the chapter on Software Dependency Risk.

\hypertarget{big-ball-of-mud}{%
\subsection{Big Ball Of Mud}\label{big-ball-of-mud}}

Although Type-Systems help for avoiding Communication Risk in the small,
when software systems grow large it becomes hard to communicate their
intent and keep their degree of connectivity low.

\begin{quotation}

``A big ball of mud is a software system that lacks a perceivable
architecture. Although undesirable from a software engineering point of
view, such systems are common in practice due to business pressures,
developer turnover and code entropy.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Big_ball_of_mud}{\textemdash  Big Ball Of Mud, \emph{Wikipedia}}}
\end{quotation}

costs associated with complexity risk

CHANGE is also more risky why?

https://en.wikipedia.org/wiki/Big\_ball\_of\_mud

\hypertarget{communication-risk}{%
\chapter{Communication Risk}\label{communication-risk}}

Communication Risk is the risk of communication between entities
\emph{going wrong}, due to loss or misunderstanding. Consider this: if
we all had identical knowledge, there would be no need to do any
communicating at all, and therefore and also no Communication Risk.

But, people are not all-knowing oracles. We rely on our \emph{senses} to
improve our Internal Models of the world. There is Communication Risk
here - we might overlook something vital (like an on-coming truck) or
mistake something someone says (like ``Don't cut the green wire'').

Communication Risk isn't just for people; it affects computer systems
too.

\hypertarget{a-model-of-communication}{%
\section{A Model Of Communication}\label{a-model-of-communication}}

In 1948, Claude Shannon proposed this definition of communication:

\begin{quotation}

``The fundamental problem of communication is that of reproducing at one
point, either exactly or approximately, a message selected at another
point.''

\sourceatright{\href{https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication}{\textemdash  A Mathematical Theory Of Communication, \emph{Claude Shannon}}  <!-- tweet-end -->}
\end{quotation}

And from this same paper, we get the following (slightly adapted) model.

\begin{figure}
\centering
\includegraphics{images/generated/communication_1-400dpi.png}
\caption{Shannon's Communication Model}
\end{figure}

We move from top-left (``I want to send a message to someone'') to
bottom left, clockwise, where we hope the message has been understood
and believed. (I've added this last box to Shannon's original diagram.)

One of the chief concerns in Shannon's paper is the step between
\textbf{Transmission} and \textbf{Reception}. He creates a theory of
information (measured in \textbf{bits}), the upper-bounds of information
that can be communicated over a channel and ways in which Communication
Risk between these processes can be mitigated by clever
\textbf{Encoding} and \textbf{Decoding} steps.

But it's not just transmission. Communication Risk exists at each of
these steps. Let's imagine a short exchange where someone,
\textbf{Alice} is trying to send a message to \textbf{Bob}:

\begin{itemize}
\tightlist
\item
  \textbf{Alice} might be \textbf{motivated} to send a message to tell
  \textbf{Bob} something, only to find out that \emph{he already knew
  it}, or it wasn't useful information for them.
\item
  In the \textbf{composition} stage, \textbf{Alice} might mess up the
  \emph{intent} of the message: instead of ``Please buy chips'' she
  might say, ``Please buy chops''.
\item
  In the \textbf{encoding} stage, \textbf{Alice} might not speak clearly
  enough to be understood, and\ldots{}
\item
  In the \textbf{transmission} stage, \textbf{Alice} might not say it
  loudly enough for \textbf{Bob} to\ldots{}
\item
  \textbf{receive} the message clearly (maybe there is background
  noise).
\item
  Having heard \textbf{Alice} say something, can \textbf{Bob}
  \textbf{decode} what was said into a meaningful sentence?
\item
  Then, assuming that, will they \textbf{interpret} correctly which type
  of chips (or chops) \textbf{Alice} was talking about? Does ``Please
  buy chips'' convey all the information they need?
\item
  Finally, assuming \emph{everything else}, will \textbf{Bob} believe
  the message? Will they \textbf{reconcile} the information into their
  Internal Model and act on it? Perhaps not, if \textbf{Bob} thinks that
  there are chips at home already.
\end{itemize}

\hypertarget{approach-to-communication-risk}{%
\section{Approach To Communication
Risk}\label{approach-to-communication-risk}}

There is a symmetry about the steps going on in Shannon's diagram, and
we're going to exploit this in order to break down Communication Risk
into it's main types.

\begin{figure}
\centering
\includegraphics{images/generated/communication_2-400dpi.png}
\caption{Communication Risk 2}
\end{figure}

To get inside Communication Risk, we need to understand
\textbf{Communication} itself, whether between \emph{machines},
\emph{people} or \emph{products}: we'll look at each in turn. In order
to do that, we're going to examine four basic concepts in each of these
settings:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Communication_channel}{Channels},
  the medium via which the communication is happening.
\item
  \href{https://en.wikipedia.org/wiki/Communication_protocol}{Protocols}
  - the systems of rules that allow two or more entities of a
  communications system to transmit information.
\item
  \href{https://en.wikipedia.org/wiki/Message}{Messages}: The
  information we want to convey.
\item
  Internal Models: the sources and destinations for the messages.
  Updating internal models (whether in our heads or machines) is the
  reason why we're communicating.
\end{itemize}

And, as we look at these four areas, we'll consider the Attendant Risks
of each.

\hypertarget{channels}{%
\section{Channels}\label{channels}}

There are lots of different types of media for communicating (e.g.~TV,
Radio, DVD, Talking, Posters, Books, Phones, The Internet, etc. ) and
they all have different characteristics. When we communicate via a given
medium, it's called a \emph{channel}.

The channel \emph{characteristics} depend on the medium, then. Some
obvious ones are cost, utilisation, number of people reached, simplex or
duplex (parties can transmit and receive at the same time), persistence
(a play vs a book, say), latency (how long messages take to arrive) and
bandwidth (the amount of information that can be transmitted in a period
of time).

Channel characteristics are important: in a high-bandwidth, low-latency
situation, \textbf{Alice} and \textbf{Bob} can \emph{check} with each
other that the meaning was transferred correctly. They can discuss what
to buy, they can agree that \textbf{Alice} wasn't lying or playing a
joke.

The channel characteristics also imply suitability for certain
\emph{kinds} of messages. A documentary might be a great way of
explaining some economic concept, whereas an opera might not be.

\hypertarget{channel-risk}{%
\section{Channel Risk}\label{channel-risk}}

Shannon discusses that no channel is perfect: there is always the
\textbf{risk of noise} corrupting the signal. A key outcome from
Shannon's paper is that there is a tradeoff: within the capacity of the
channel (the \textbf{Bandwidth}), you can either send lots of
information with \emph{higher} risk that it is wrong, or less
information with \emph{lower} risk of errors. And, rather like the
Kolgomorov complexity result, the more \emph{randomness} in the signal,
the less compressible it is, and therefore the more \emph{bits} it will
take to transmit.

\begin{figure}
\centering
\includegraphics{images/generated/channel-risk-400dpi.png}
\caption{Communication Channel Risk}
\end{figure}

But channel risk goes wider than just this mathematical example:
messages might be delayed or delivered in the wrong order, or not be
acknowledged when they do arrive. Sometimes, a channel is just an
inappropriate way of communicating. When you work in a different
time-zone to someone else on your team, there is \emph{automatic}
Channel Risk, because instantaneous communication is only available for
a few hours' a day.

When channels are \textbf{poor-quality}, less communication occurs.
People will try to communicate just the most important information. But,
it's often impossible to know a-priori what constitutes ``important''.
This is why Extreme Programming recommends the practice of
\href{https://en.wikipedia.org/wiki/Pair_programming}{Pair Programming}
and siting all the developers together: although you don't know whether
useful communication will happen, you are mitigating Channel Risk by
ensuring high-quality communication channels are in place.

At other times, channels can contain so much information that we can't
hope to receive all the messages. In these cases, we don't even observe
the whole channel, just parts of it. For example, you might have a few
YouTube channels that you subscribe to, but hundreds of hours of video
are being posted on YouTube every second, so there is no way you can
keep up with all of it.

\begin{figure}
\centering
\includegraphics{images/generated/communication_channel_risks-400dpi.png}
\caption{Communication Channels}
\end{figure}

\hypertarget{marketing-communications}{%
\subsubsection{Marketing
Communications}\label{marketing-communications}}

When we are talking about a product or a brand, mitigating Channel Risk
is the domain of
\href{https://en.wikipedia.org/wiki/Marketing_communications}{Marketing
Communications}. How do you ensure that the information about your
(useful) project makes it to the right people? How do you address the
right channels?

This works both ways. Let's looks at some of the \textbf{Channel Risks}
from the point of view of a hypothetical software tool, \textbf{D},
which would really useful in my software:

\begin{itemize}
\tightlist
\item
  The concept that there is such a thing as \textbf{D} which solves my
  problem isn't something I'd even considered.
\item
  I'd like to use something like \textbf{D}, but how do I find it?
\item
  There are multiple implementations of \textbf{D}, which is the best
  one for the task?
\item
  I know \textbf{D}, but I can't figure out how to solve my problem in
  it.
\item
  I've chosen \textbf{D}, I now need to persuade my team that \textbf{D}
  is the correct solution\ldots{}
\item
  \ldots{} and then they also need to understand \textbf{D} to do their
  job too.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/communication_marketing-400dpi.png}
\caption{Communication Marketing}
\end{figure}

Internal Models don't magically get populated with the information they
need: they fill up gradually, as shown in this diagram. Popular products
and ideas \emph{spread}, by word-of-mouth or other means. Part of the
job of being a good technologist is to keep track of new \textbf{Ideas},
\textbf{Concepts} and \textbf{Options}, so as to use them as
Dependencies when needed.

\hypertarget{protocols}{%
\section{Protocols}\label{protocols}}

In this chapter, I want to examine the concept of Communication
Protocols and how they relate to Abstraction.

So, to do this, let's look in a bit of detail at how web pages are
loaded. When considering this, we need to broaden our terminology.
Although so far we've talked about \textbf{Senders} and
\textbf{Receivers}, we now need to talk from the point of view of
who-depends-on-who. If you're \emph{depended on}, then you're a
``Server'', whereas if you require communication with something else,
you're a ``Client''. Thus, clients depend on servers in order to load
pages.

This is going to involve (at least) six separate protocols, the top-most
one being the
\href{https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol}{HTTP
Protocol}. As far as the HTTP Protocol is concerned, a \emph{client}
makes an \texttt{HTTP\ Request} at a specific URL and the
\texttt{HTTP\ Response} is returned in a predictable format that the
browser can understand.

Let's have a quick look at how that works with a \texttt{curl} command,
which allows me to load a web page from the command line. We're going to
try and load Google's preferences page, and see what happens. If I type:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>} \ExtensionTok{curl}\NormalTok{ -v http://google.com/preferences}
\end{Highlighting}
\end{Shaded}

\hypertarget{dns---domain-name-system}{%
\subsection{1. DNS - Domain Name
System}\label{dns---domain-name-system}}

Then, the first thing that happens is this:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{*}\NormalTok{ Rebuilt URL to: http://google.com/}
\ExtensionTok{*}\NormalTok{   Trying 216.58.204.78...}
\end{Highlighting}
\end{Shaded}

At this point, curl has used
\href{https://en.wikipedia.org/wiki/Domain_Name_System}{DNS} to
\emph{resolve} the address ``google.com'' to an IP address. This is some
Abstraction: instead of using the machine's
\href{https://en.wikipedia.org/wiki/IP_address}{IP Address} on the
network, \texttt{216.58.204.78}, I can use a human-readable address,
\texttt{google.com}. The address \texttt{google.com} doesn't necessarily
resolve to that same address each time: \emph{They have multiple IP
addresses for \texttt{google.com}}. But, for the rest of the
\texttt{curl} request, I'm now set to just use this one.

\hypertarget{ip---internet-protocol}{%
\subsection{2. IP - Internet Protocol}\label{ip---internet-protocol}}

But this hints at what is beneath the abstraction: although I'm loading
a web-page, the communication to the Google server happens by
\href{https://en.wikipedia.org/wiki/Internet_Protocol}{IP Protocol} -
it's a bunch of discrete ``packets'' (streams of binary digits). You can
think of a packet as being like a real-world parcel or letter.

Each packet consists of two things:

\begin{itemize}
\tightlist
\item
  An address, which tells the network components (such as routers and
  gateways) where to send the packet, much like you'd write the address
  on the outside of a parcel.
\item
  The \emph{payload}, the stream of bytes for processing at the
  destination. Like the contents of the parcel.
\end{itemize}

But, even this concept of ``packets'' is an Abstraction. Although all
the components of the network interoperate with this protocol, we might
be using Wired Ethernet, or WiFi, 4G or \emph{something else}.

\hypertarget{wifi-protocol}{%
\subsection{3. 802.11 - WiFi Protocol}\label{wifi-protocol}}

I ran this at home, using WiFi, which uses
\href{https://en.wikipedia.org/wiki/IEEE_802.11}{IEEE 802.11 Protocol},
which allows my laptop to communicate with the router wirelessly, again
using an agreed, standard protocol. But even \emph{this} isn't the
bottom, because this is actually probably specifying something like
\href{https://en.wikipedia.org/wiki/MIMO-OFDM}{MIMO-OFDM}, giving
specifications about frequencies of microwave radiation, antennas,
multiplexing, error-correction codes and so on. And WiFi is just the
first hop: after the WiFi receiver, there will be protocols for
delivering the packets via the telephony system.

\hypertarget{tcp---transmission-control-protocol}{%
\subsection{4. TCP - Transmission Control
Protocol}\label{tcp---transmission-control-protocol}}

Anyway, the next thing that happens is this:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{*}\NormalTok{ TCP_NODELAY set}
\ExtensionTok{*}\NormalTok{ Connected to google.com (216.58.204.78) }\ExtensionTok{port}\NormalTok{ 80 (#0)}
\end{Highlighting}
\end{Shaded}

The second obvious Abstraction going on here is that \texttt{curl} now
believes it has a
\href{https://en.wikipedia.org/wiki/Transmission_Control_Protocol}{TCP}
connection. The TCP connection abstraction gives us the surety that the
packets get delivered in the right order, and retried if they go
missing. Effectively it \emph{guarantees} these things, or that it will
have a connection failure if it can't keep it's guarantee.

But, this is a fiction - TCP is built on the IP protocol, packets of
data on the network. So there are lots of packets floating around which
say ``this connection is still alive'' and ``I'm message 5 in the
sequence'' and so on in order to maintain this fiction. But that means
that the HTTP protocol can forget about this complexity and work with
the fiction of a connection.

\hypertarget{http---hypertext-transfer-protocol}{%
\subsection{5. HTTP - Hypertext Transfer
Protocol}\label{http---hypertext-transfer-protocol}}

Next, we see this:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>} \ExtensionTok{GET}\NormalTok{ /preferences HTTP/1.1     (1)}
\OperatorTok{>} \ExtensionTok{Host}\NormalTok{: google.com              (2)}
\OperatorTok{>} \ExtensionTok{User-Agent}\NormalTok{: curl/7.54.0       (3)}
\OperatorTok{>} \ExtensionTok{Accept}\NormalTok{: */*                   (4)}
\OperatorTok{>}                               \KeywordTok{(}\ExtensionTok{5}\KeywordTok{)}
\end{Highlighting}
\end{Shaded}

This is now the HTTP protocol proper, and these 5 lines are sending
information \emph{over the connection} to the Google server.

\begin{itemize}
\tightlist
\item
  \texttt{(1)} says what version of HTTP we are using, and the path
  we're loading (\texttt{/preferences} in this case).
\item
  \texttt{(2)} to \texttt{(4)} are \emph{headers}. They are name-value
  pairs, separated with a colon. The HTTP protocol specifies a bunch of
  these names, and later versions of the protocol might introduce newer
  ones.
\item
  \texttt{(5)} is an empty line, which indicates that we're done with
  the headers, please give us the response. And it does:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<} \ExtensionTok{HTTP/1.1}\NormalTok{ 301 Moved Permanently}
\OperatorTok{<} \ExtensionTok{Location}\NormalTok{: http://www.google.com/preferences}
\OperatorTok{<} \ExtensionTok{Content-Type}\NormalTok{: text/html}\KeywordTok{;} \VariableTok{charset=}\NormalTok{UTF-8}
\OperatorTok{<} \ExtensionTok{Date}\NormalTok{: Sun, 08 Apr 2018 10:24:34 GMT}
\OperatorTok{<} \ExtensionTok{Expires}\NormalTok{: Tue, 08 May 2018 10:24:34 GMT}
\OperatorTok{<} \ExtensionTok{Cache-Control}\NormalTok{: public, max-age=2592000}
\OperatorTok{<} \ExtensionTok{Server}\NormalTok{: gws}
\OperatorTok{<} \ExtensionTok{Content-Length}\NormalTok{: 230}
\OperatorTok{<} \ExtensionTok{X-XSS-Protection}\NormalTok{: 1}\KeywordTok{;} \VariableTok{mode=}\NormalTok{block}
\OperatorTok{<} \ExtensionTok{X-Frame-Options}\NormalTok{: SAMEORIGIN}
\OperatorTok{<}
\OperatorTok{<}\ExtensionTok{HTML}\OperatorTok{><}\NormalTok{HEAD}\OperatorTok{><}\NormalTok{meta http-equiv=}\StringTok{"content-type"}
\VariableTok{content=}\StringTok{"text/html;charset=utf-8"}\OperatorTok{>}
\OperatorTok{<}\ExtensionTok{TITLE}\OperatorTok{>}\NormalTok{301 Moved}\OperatorTok{<}\NormalTok{/TITLE}\OperatorTok{><}\NormalTok{/HEAD}\OperatorTok{><}\NormalTok{BODY}\OperatorTok{>}
\OperatorTok{<}\ExtensionTok{H1}\OperatorTok{>}\NormalTok{301 Moved}\OperatorTok{<}\NormalTok{/H1}\OperatorTok{>}
\ExtensionTok{The}\NormalTok{ document has moved}
\OperatorTok{<}\NormalTok{/}\ExtensionTok{BODY}\OperatorTok{><}\NormalTok{/HTML}\OperatorTok{>}
\ExtensionTok{*}\NormalTok{ Connection }\CommentTok{#0 to host google.com left intact}
\end{Highlighting}
\end{Shaded}

There's a lot going on here, but we can break it down really easily into
3 chunks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The first line is the
  \href{https://en.wikipedia.org/wiki/List_of_HTTP_status_codes}{HTTP
  Status Code}. \texttt{301} is a code meaning that the page has moved.
\item
  The next 9 lines are HTTP headers again (name-value pairs). The
  \texttt{Location:} directive tells us where the page has moved to.
  Instead of trying \texttt{http://google.com/preferences}, we should
  have used:
\end{enumerate}

\begin{quote}
\texttt{http://www.google.com/preferences}.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The lines starting \texttt{\textless{}HTML\textgreater{}} are now some
  HTML to display on the screen to tell the user that the page has
  moved.
\end{enumerate}

\hypertarget{html---hypertext-mark-up-language}{%
\subsection{6. HTML - Hypertext Mark-Up
Language}\label{html---hypertext-mark-up-language}}

Although \href{https://en.wikipedia.org/wiki/HTML}{HTML} is a language,
a language is also a protocol. (After all, language is what we use to
encode our ideas for transmission as speech.) In the example we gave,
this was a very simple page telling the client that it's looking in the
wrong place. In most browsers, you don't get to see this: the browser
will understand the meaning of the \texttt{301} error and redirect you
to the location.

Let's look at all the protocols we saw here:

\begin{figure}
\centering
\includegraphics{images/generated/communication_protocols-400dpi.png}
\caption{Protocol Stack}
\end{figure}

Each protocol ``passes on'' to the next one in the chain. On the left,
we have the representation most suitable for the \emph{messages}: HTTP
is designed for browsers to use to ask for and receive web pages. As we
move right, we are converting the message more and more into a form
suitable for the Channel: in this case, microwave transmission.

By having a stack of protocols, we are able to apply
\href{https://en.wikipedia.org/wiki/Separation_of_concerns}{Separation
Of Concerns}, each protocol handling just a few concerns:

\begin{itemize}
\tightlist
\item
  \texttt{HTML} Abstraction: A language for describing the contents of a
  web-page.
\item
  \texttt{HTTP} Abstraction: Name-Value pairs, agreed on by both
  \texttt{curl} and Google, URLs and error codes.
\item
  \texttt{DNS} Abstraction: Names of servers to IP Addresses.
\item
  \texttt{TCP} Abstraction: The concept of a ``connection'' with
  guarantees about ordering and delivery.
\item
  \texttt{IP} Abstraction: ``Packets'' with addresses and payloads.
\item
  \texttt{WiFi} Abstraction: ``Networks'', 802.11 flavours.
\item
  Transmitters, Antennas, error correction codes, etc.
\end{itemize}

\texttt{HTTP} ``stands on the shoulders of giants''. Not only does it
get to use pre-existing protocols like \texttt{TCP} and \texttt{DNS} to
make it's life easier, it got \texttt{802.11} ``for free'' when this
came along and plugged into the existing \texttt{IP} protocol. This is
the key value of abstraction: you get to piggy-back on \emph{existing}
patterns, and use them yourself.

The protocol mediates between the message and the channel. Where this
goes wrong, we have Protocol Risk. This is a really common issue for IT
systems, but also sometimes for human communication too.

\hypertarget{protocol-risk}{%
\section{Protocol Risk}\label{protocol-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/protocol-risk-400dpi.png}
\caption{Protocol Risk}
\end{figure}

Generally, any time where you have different parts of a system
communicating with each other, and one part can change incompatibly with
another you have Protocol Risk.

Locally, (within our own project), where we have control, we can
mitigate this risk using compile-time checking (as discussed already in
Complexity Risk), which essentially forces all clients and servers to
agree on protocol. But, the wider the group that you are communicating
with, the less control you have and the more chance there is of Protocol
Risk.

Let's look at some types of Protocol Risk:

\hypertarget{protocol-incompatibility-risk}{%
\subsection{Protocol Incompatibility
Risk}\label{protocol-incompatibility-risk}}

The people you find it \emph{easiest} to communicate with are your
friends and family, those closest to you. That's because you're all
familiar with the same protocols. Someone from a foreign country,
speaking a different language and having a different culture, will
essentially have a completely incompatible protocol for spoken
communication to you.

Within software, there are also competing, incompatible protocols for
the same things, which is maddening when your protocol isn't supported.
Although the world seems to be standardizing, there used to be
\emph{hundreds} of different image formats. Photographs often use
\href{https://en.wikipedia.org/wiki/TIFF}{TIFF},
\href{https://en.wikipedia.org/wiki/Raw_image_format}{RAW} or
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG}, whilst we also have
\href{https://en.wikipedia.org/wiki/Scalable_Vector_Graphics}{SVG} for
vector graphics, \href{https://en.wikipedia.org/wiki/GIF}{GIF} for
images and animations and
\href{https://en.wikipedia.org/wiki/Portable_Network_Graphics}{PNG} for
other bitmap graphics.

\hypertarget{protocol-versioning-risk}{%
\subsection{Protocol Versioning Risk}\label{protocol-versioning-risk}}

Even when systems are talking the same protocol, there can be problems.
When we have multiple, different systems owned by different parties, on
their own upgrade cycles, we have \textbf{Protocol Versioning Risk}: the
risk that either client or server could start talking in a version of
the protocol that the other side hasn't learnt yet. There are various
mitigating strategies for this. We'll look at two now: \textbf{Backwards
Compatibility} and \textbf{Forwards Compatibility}.

\hypertarget{protocol-complexity}{%
\subsection{Protocol Complexity}\label{protocol-complexity}}

tbd. abstraction - virtue between two vices. Postel's law.

\hypertarget{backward-compatibility}{%
\subsubsection{Backward Compatibility}\label{backward-compatibility}}

Backwards Compatibility mitigates Protocol Versioning Risk. Quite
simply, this means, supporting the old format until it falls out of use.
If a server is pushing for a change in protocol it either must ensure
that it is Backwards Compatible with the clients it is communicating
with, or make sure they are upgraded concurrently. When building
\href{https://en.wikipedia.org/wiki/Web_service}{web services}, for
example, it's common practice to version all APIs so that you can manage
the migration. Something like this:

\begin{itemize}
\tightlist
\item
  Server publishes \texttt{/api/v1/something}.
\item
  Clients use \texttt{/api/v1/something}.
\item
  Server publishes \texttt{/api/v2/something}.
\item
  Clients start using \texttt{/api/v2/something}.
\item
  Clients (eventually) stop using \texttt{/api/v2/something}.
\item
  Server retires \texttt{/api/v2/something} API.
\end{itemize}

\hypertarget{forward-compatibility}{%
\subsubsection{Forward Compatibility}\label{forward-compatibility}}

\texttt{HTML} and \texttt{HTTP} provide ``graceful failure'' to mitigate
Protocol Risk: while its expected that all clients can parse the syntax
of \texttt{HTML} and \texttt{HTTP}, it's not necessary for them to be
able to handle all of the tags, attributes and rules they see. The
specification for both these standards is that if you don't understand
something, ignore it. Designing with this in mind means that old clients
can always at least cope with new features, but it's not always
possible.

\texttt{JavaScript} \emph{can't} support this: because the meaning of
the next instruction will often depend on the result of the previous
one.

Does human language support this? To some extent! New words are added to
our languages all the time. When we come across a new word, we can
either ignore it, guess the meaning, ask or look it up. In this way,
human language has \textbf{Forward Compatibility} features built in.

\hypertarget{protocol-implementation-risk}{%
\subsection{Protocol Implementation
Risk}\label{protocol-implementation-risk}}

A second aspect of Protocol Risk exists in heterogeneous computing
environments, where protocols have been independently implemented based
on standards. For example, there are now so many different browsers, all
supporting different levels of \texttt{HTTP}, \texttt{HTML} and
\texttt{JavaScript} that it becomes impossible to test comprehensively
over all the different versions. To mitigate as much Protocol Risk as
possible, generally we run tests in a subset of browsers, and use a
lowest-common-denominator approach to choosing protocol and language
features.

\begin{figure}
\centering
\includegraphics{images/generated/communication_protocol_risks-400dpi.png}
\caption{Communication Protocols Risks}
\end{figure}

\hypertarget{messages}{%
\section{Messages}\label{messages}}

\begin{figure}
\centering
\includegraphics{images/generated/message-risk-400dpi.png}
\caption{Message Risk}
\end{figure}

Although Shannon's Communication Theory is about transmitting
\textbf{Messages}, messages are really encoded \textbf{Ideas} and
\textbf{Concepts}, from an \textbf{Internal Model}.

\hypertarget{internal-model-assumption-risk}{%
\subsection{Internal Model Assumption
Risk}\label{internal-model-assumption-risk}}

When we construct messages in a conversation, we have to make judgements
about what the other person already knows. When talking to children,
it's often hard work because they \emph{assume} that you have knowledge
of everything they do. This is called
\href{https://en.wikipedia.org/wiki/Theory_of_mind}{Theory Of Mind}: the
appreciation that your knowledge is different to other people's, and
adjusting you messages accordingly.

When teaching, this is called
\href{https://en.wikipedia.org/wiki/Curse_of_knowledge}{The Curse Of
Knowledge}: teachers have difficulty understanding students' problems
\emph{because they already understand the subject}. For example, if I
want to tell you about a new
\href{https://en.wikipedia.org/wiki/JDBC_driver}{JDBC Driver}, this
pre-assumes that you know what JDBC is: the message has a dependency on
prior knowledge.

\hypertarget{message-dependency-risk}{%
\subsection{Message Dependency Risk}\label{message-dependency-risk}}

A second, related problem is actually Dependency Risk, which is covered
more thoroughly in the next chapter. Often, messages assume that you
have followed everything up to that point already, otherwise again, your
Internal Model will not be rich enough to understand the new messages.

This happens when messages get missed, or delivered out of order. In the
past, TV shows were only aired once a week at a particular time. So
writers were constrained plot-wise by not knowing whether their audience
would have seen the previous week's episode. Therefore, often the state
of the show would ``reset'' week-to-week, allowing you to watch it in
\emph{any} order.

The same \textbf{Message Dependency Risk} exists for computer software:
if there is replication going on between instances of an application,
and one of the instances misses some messages, you end up with a
``\href{https://en.wikipedia.org/wiki/Split-brain_(computing)}{Split
Brain}'' scenario, where later messages can't be processed because they
refer to an application state that doesn't exist. For example, a message
saying:

\begin{verbatim}
Update user 53's surname to 'Jones'
\end{verbatim}

only makes sense if the application has previously had the message

\begin{verbatim}
Create user 53 with surname 'Smith'
\end{verbatim}

\hypertarget{misinterpretation-risk}{%
\subsection{Misinterpretation Risk}\label{misinterpretation-risk}}

People don't rely on rigorous implementations of abstractions like
computers do; we make do with fuzzy definitions of concepts and ideas.
We rely on Abstraction to move between the name of a thing and the
\emph{idea of a thing}.

While machines only process \emph{information}, people's brains run on
concepts and ideas. For people, abstraction is critical: nothing exists
unless we have a name for it. Our world is just atoms, but we don't
think like this. \emph{The name is the thing}.

\begin{quotation}

``The famous pipe. How people reproached me for it! And yet, could you
stuff my pipe? No, it's just a representation, is it not? So if I had
written on my picture ``This is a pipe'', I'd have been lying!''

\sourceatright{\href{https://en.wikipedia.org/wiki/The_Treachery_of_Images}{\textemdash  Rene Magritte, of \emph{The Treachery of Images}}}
\end{quotation}

This brings about Misinterpretation Risk: names are not \emph{precise},
and concepts mean different things to different people. We can't be sure
that people have the same meaning for concepts that we have.

\hypertarget{invisibility-risk}{%
\subsection{Invisibility Risk}\label{invisibility-risk}}

Another cost of Abstraction is Invisibility Risk. While abstraction is a
massively powerful technique, (as we saw above in the chapter on
Protocols, it allows things like the Internet to happen) it lets the
function of a thing hide behind the layers of abstraction and become
invisible.

\hypertarget{invisibility-risk-in-software}{%
\subsubsection{Invisibility Risk In
Software}\label{invisibility-risk-in-software}}

As soon as you create a function, you are doing abstraction. You are
saying: ``I now have this operation. The details, I won't mention again,
but from now on, it's called \textbf{f}'' And suddenly, ``\textbf{f}''
hides. It is working invisibly. Things go on in \textbf{f} that people
don't necessarily need to understand. There may be some documentation,
or tacit knowledge around what \textbf{f} is, and what it does, but it's
not necessarily right. Referring to \textbf{f} is a much simpler job
than understanding \textbf{f}.

We try to mitigate this via (for the most part) documentation, but this
is a terrible deal: because we can't understand the original,
(un-abstracted) implementation, we now need to write some simpler
documentation, which \emph{explains} the abstraction, in terms of
further abstractions, and this is where things start to get murky.

Invisibility Risk is mainly Hidden Risk. (Mostly, \emph{you don't know
what you don't know}.) But you can carelessly \emph{hide things from
yourself} with software:

\begin{itemize}
\tightlist
\item
  Adding a thread to an application that doesn't report whether it's
  worked, failed, or is running out of control and consuming all the
  cycles of the CPU.
\item
  Redundancy can increase reliability, but only if you know when servers
  fail, and fix them quickly. Otherwise, you only see problems when the
  last server fails.
\item
  When building a web-service, can you assume that it's working for the
  users in the way you want it to?
\end{itemize}

When you build a software service, or even implement a thread, ask
yourself: ``How will I know next week that this is working properly?''
If the answer involves manual work and investigation, then your
implementation has just cost you in Invisibility Risk.

\hypertarget{invisibility-risk-in-conversation}{%
\subsubsection{Invisibility Risk In
Conversation}\label{invisibility-risk-in-conversation}}

Invisibility Risk is risk due to information not sent. But because
humans don't need a complete understanding of a concept to use it, we
can cope with some Invisibility Risk in communication, and this saves us
time when we're talking. It would be \emph{painful} to have
conversations if, say, the other person needed to understand everything
about how cars worked in order to discuss cars.

For people, Abstraction is a tool that we can use to refer to other
concepts, without necessarily knowing how the concepts work. This
divorcing of ``what'' from ``how'' is the essence of abstraction and is
what makes language useful.

The debt of Invisibility Risk comes due when you realise that \emph{not}
being given the details \emph{prevents} you from reasoning about it
effectively. Let's think about this in the context of a project status
meeting, for example:

\begin{itemize}
\tightlist
\item
  Can you be sure that the status update contains all the details you
  need to know?
\item
  Is the person giving the update wrong or lying?
\item
  Do you know enough about the details of what's being discussed in
  order to make informed decisions about how the project is going?
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/communication_message_risks-400dpi.png}
\caption{Message Risk}
\end{figure}

\hypertarget{internal-models}{%
\section{Internal Models}\label{internal-models}}

So finally, we are coming to the root of the problem: communication is
about transferring ideas and concepts from one Internal Model to
another.

The communication process so far has been fraught with risks, but we
have a few more to come.

\hypertarget{trust-belief-risk}{%
\subsection{Trust \& Belief Risk}\label{trust-belief-risk}}

Although protocols can sometimes handle security features of
communication (such as
\href{https://en.wikipedia.org/wiki/Authentication}{Authentication} and
preventing
\href{https://en.wikipedia.org/wiki/Man-in-the-middle_attack}{man-in-the-middle
attacks}), trust goes further than this, it is the flip-side of Agency
Risk, which we will look at later: can you be sure that the other party
in the communication is acting in your best interests?

Even if the receiver trusts the communicator, they may not believe the
message. Let's look at some reasons for that:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/World_view}{Weltanschauung (World
  View)}: The ethics, values and beliefs in the receiver's Internal
  Model may be incompatible to those from the sender.
\item
  \href{https://en.wikipedia.org/wiki/Relativism}{Relativism} is the
  concept that there are no universal truths. Every truth is from a
  frame of reference. For example, what constitutes \emph{offensive
  language} is dependent on the listener.
\item
  \href{https://en.wikipedia.org/wiki/Psycholinguistics}{Psycholinguistics}
  is the study of humans aquire languages. There are different languages
  and dialects, (and \emph{industry dialects}), and we all understand
  language in different ways, take different meanings and apply
  different contexts to the messages.
\end{itemize}

From the point-of-view of Marketing Communications choosing the right
message is part of the battle. You are trying to communicate your idea
in such a way as to mitigate Trust \& Belief Risk.

\hypertarget{learning-curve-risk}{%
\subsection{Learning-Curve Risk}\label{learning-curve-risk}}

If the messages we are receiving force us to update our Internal Model
too much, we can suffer from the problem of ``too steep a
\href{https://en.wikipedia.org/wiki/Learning_curve}{Learning Curve}'' or
``\href{https://en.wikipedia.org/wiki/Information_overload}{Information
Overload}'', where the messages force us to adapt our Internal Model too
quickly for our brains to keep up.

Commonly, the easiest option is just to ignore the information channel
completely in these cases.

\hypertarget{reading-code}{%
\subsection{Reading Code}\label{reading-code}}

It's often been said that code is \emph{harder to read than to write}:

\begin{quotation}

If you ask a software developer what they spend their time doing,
they'll tell you that they spend most of their time writing code.
However, if you actually observe what software developers spend their
time doing, you'll find that they spend most of their time trying to
understand code.

\end{quotation}

By now it should be clear that it's going to be \emph{both} quite hard
to read and write: the protocol of code is actually designed for the
purpose of machines communicating, not primarily for people to
understand. Making code human readable is a secondary concern to making
it machine readable.

But now we should be able to see the reasons it's harder to read than
write too:

\begin{itemize}
\tightlist
\item
  When reading code, you are having to shift your Internal Model to
  wherever the code is, accepting decisions that you might not agree
  with and accepting counter-intuitive logical leaps. i.e.~Learning
  Curve Risk. \emph{(cf.
  \href{https://en.wikipedia.org/wiki/Principle_of_least_astonishment}{Principle
  of Least Surprise})}
\item
  There is no Feedback Loop between your Internal Model and the Reality
  of the code, opening you up to Misinterpretation Risk. When you write
  code, your compiler and tests give you this.
\item
  While reading code \emph{takes less time} than writing it, this also
  means the Learning Curve is steeper.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/communication_internal_model_risks-400dpi.png}
\caption{Internal Model Risks}
\end{figure}

\hypertarget{communication-risk-wrap-up}{%
\section{Communication Risk Wrap Up}\label{communication-risk-wrap-up}}

So, here's a summary of where we've arrived with our model of
communication risk:

\begin{figure}
\centering
\includegraphics{images/generated/communication_3-400dpi.png}
\caption{Communication 2}
\end{figure}

tbd, So next it's time to look at Complexity Risk.

this seems complex tbd.

\hypertarget{dependency-risk}{%
\chapter{Dependency Risk}\label{dependency-risk}}

Dependency Risk is the risk you take on whenever you have a dependency
on something (or someone) else. One simple example could be that the
software service you write might depend on a server to run on. If the
server goes down, the service goes down too. In turn, the server depends
on electricity from a supplier, as well as a network connection from a
provider. If either of these dependencies aren't met, the service is out
of commission.

Dependencies can be on \emph{events}, \emph{people}, \emph{teams},
\emph{processes}, \emph{software}, \emph{services}, \emph{money}: pretty
much \emph{any resource}. Dependencies add risk to any project because
the reliability of the project itself is now a function involving the
reliability of the dependency.

In order to avoid repetition, and also to break down this large topic,
we're going to look at this over 6 chapters:

\begin{itemize}
\tightlist
\item
  In this first chapter will look at dependencies \emph{in general}, and
  apply our existing risk categorizations to understand Dependency Risk.
\item
  Next, we'll look at Scarcity Risk, because time and money are scarce
  resources in every project.
\item
  We'll cover Deadline Risk, and discuss the purpose of Events and
  Deadlines, and how they enable us to co-ordinate around dependency
  use.
\item
  Then, we'll move on to look specifically at Software Dependency Risk,
  covering using libraries, software services and building on top of the
  work of others.
\item
  After, we'll take a look at Process Risk, which is still Dependency
  Risk, but we'll be considering more organisational factors and how
  bureaucracy comes into the picture.
\item
  Next, we'll take a closer look at Boundary Risk and Dead-End Risk.
  These are the risks you face in choosing the wrong things to depend
  on.
\item
  Finally, we'll wrap up this analysis with a look at some of the
  specific problems around working with other people or businesses in
  Agency Risk.
\end{itemize}

\hypertarget{why-have-dependencies}{%
\section{Why Have Dependencies?}\label{why-have-dependencies}}

Luckily for us, the things we depend on in life are, for the most part,
abundant: water to drink, air to breathe, light, heat and most of the
time, food for energy.

This isn't even lucky though: life has adapted to build dependencies on
things that it can \emph{rely} on.

Although life exists at the bottom of the ocean around
\href{https://en.wikipedia.org/wiki/Hydrothermal_vent}{hydrothermal
vents}, it is a very different kind of life to us, and has a different
set of dependencies given it's circumstances.

This tells us a lot about Dependency Risk right here:

\begin{itemize}
\tightlist
\item
  On the one hand, depending on something else is very often helpful,
  and quite often essential. (For example, all animals that \emph{move}
  seem to depend on oxygen).
\item
  However, as soon as you have dependencies, you need to take into
  account of their \emph{reliability}. (Living near a river or stream
  gives you access to fresh water, for example).
\item
  Successful organisms \emph{adapt} to the dependencies available to
  them (like the thermal vent creatures).
\item
  There is likely to be \emph{competition} for a dependency when it is
  scarce (think of droughts and famine).
\end{itemize}

So, dependencies are a trade-off. They give with one hand and take with
the other. Our modern lives are full of dependency (just think of the
chains of dependency needed for putting a packet of biscuits on a
supermarket shelf, for example), but we accept this extra complexity
because it makes life \emph{easier}.

tbd. diagram, mitigating feature risk with a dependency?

\hypertarget{simple-made-easy}{%
\section{Simple Made Easy}\label{simple-made-easy}}

In Rich Hickey's talk,
\href{https://www.infoq.com/presentations/Simple-Made-Easy}{Simple Made
Easy} he discusses the difference between \emph{simple} software systems
and \emph{easy} (to use) ones, heavily stressing the virtues of simple
over easy. It's an incredible talk and well worth watching.

But. Living systems are not simple. Not anymore. They evolved in the
direction of increasing complexity because life was \emph{easier} that
way. In the ``simpler'' direction, life is first \emph{harder} and then
\emph{impossible}, and then an evolutionary dead-end.

Depending on things makes \emph{your job easier}. It's just
\href{https://en.wikipedia.org/wiki/Division_of_labour}{division of
labour} and dependency hierarchies, as we saw in Hierarchies and
Modularisation.

Our economic system and our software systems exhibit the same
tendency-towards-complexity. For example, the television in my house now
is \emph{vastly more complicated} than the one in my home when I was a
child. But, it contains much more functionality and consumes much less
power and space.

\hypertarget{reliability-risk}{%
\section{Reliability Risk}\label{reliability-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/reliability-risk-400dpi.png}
\caption{Reliability Risk}
\end{figure}

Deadline Risk is really a kind of reliability issue: if you can
understand which parties are unreliable, you have a much better handle
on your Deadline Risk.

Luckily, there is quite a lot of existing science around reliability.
For example:

\begin{itemize}
\tightlist
\item
  If a component \textbf{A} depends on component \textbf{B}, unless
  there is some extra redundancy around \textbf{B}, then \textbf{A}
  \emph{can't} be more reliable than \textbf{B}.
\item
  Is \textbf{A} or \textbf{B} a
  \href{https://en.wikipedia.org/wiki/Single_point_of_failure}{Single
  Point Of Failure} in a system?
\item
  Are there bugs in \textbf{B} that are going to prevent it working
  correctly in all circumstances?
\end{itemize}

This kind of stuff is encapsulated in the science of
\href{https://en.wikipedia.org/wiki/Reliability_engineering}{Reliability
Engineering}. For example,
\href{https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis}{Failure
mode and effects analysis (FEMA)}:

\begin{quotation}

``\ldots{}was one of the first highly structured, systematic techniques
for failure analysis. It was developed by reliability engineers in the
late 1950s to study problems that might arise from malfunctions of
military systems.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis}{\textemdash  FEMA, \emph{Wikipedia}}}
\end{quotation}

This was applied on NASA missions, and then more recently in the 1970's
to car design following the
\href{https://en.wikipedia.org/wiki/Ford_Pinto\#Design_flaws_and_ensuing_lawsuits}{Ford
Pinto exploding car} affair.

\hypertarget{communication-risk-1}{%
\section{Communication Risk}\label{communication-risk-1}}

\begin{figure}
\centering
\includegraphics{images/generated/communication-risk-400dpi.png}
\caption{Communication Risk}
\end{figure}

We've already looked at communication risk in a lot of depth, and we're
going to go deeper still in Software Dependency Risk, but let's look at
some general issues around communicating dependencies. In the
Communication Risk chapter we looked at Marketing Communications and
talked about the levels of awareness that you could have with
dependencies. i.e.

\begin{itemize}
\tightlist
\item
  The concept that there is such a thing as \textbf{D} which solves my
  problem isn't something I'd even considered.
\item
  I'd like to use something like \textbf{D}, but how do I find it?
\item
  There are multiple implementations of \textbf{D}, which is the best
  one for the task?
\item
  I know \textbf{D}, but I can't figure out how to solve my problem in
  it.
\end{itemize}

Let's apply this to our Bus scenario:

\begin{itemize}
\tightlist
\item
  Am I aware that there is public transport in my area?
\item
  How do I find out about the different options?
\item
  How do I choose between buses, taxis, cars etc.
\item
  How do I understand the timetable, and apply it to my problem?
\end{itemize}

\hypertarget{silo-mentality}{%
\subsection{Silo Mentality}\label{silo-mentality}}

Finding out about bus schedules is easy. But in a large company,
Communication Risk and especially Invisibility Risk are huge problems.
This tends to get called
``\href{https://en.wikipedia.org/wiki/Information_silo\#Silo_mentality}{Silo
Mentality}'', that is, ignoring what else is going on in other divisions
of the company or
\href{https://en.wikipedia.org/wiki/Not_invented_here}{``not invented
here''} syndrome:

\begin{quotation}

``In management the term silo mentality often refers to information
silos in organisations. Silo mentality is caused by divergent goals of
different organisational units.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Information_silo\#Silo_mentality}{\textemdash  Silo Mentality, \emph{Wikipedia}}}
\end{quotation}

Ironically, \emph{more communication} might not be the answer - if
channels are provided to discover functionality in other teams you can
still run into Trust Risk (why should I believe in the quality of this
dependency?) Or Channel Risk in terms of too low a signal-to-noise
ratio, or desperate self-promotion.

Silo Mentality is exacerbated by the problems you would face in
\emph{budgeting} if suddenly all the divisions in an organisation
started providing dependencies for each other. This starts to require a
change to organisational structure towards being a set of individual
businesses marketing services to one another, rather than a
division-based one. We'll look more closely at these kind of
organisational issues in the Coordination Risk chapter.

\hypertarget{complexity-risk-1}{%
\section{Complexity Risk}\label{complexity-risk-1}}

Dependencies are usually a mitigation for Complexity Risk, and we'll
investigate that in much more detail in Software Dependency Risk. The
reason for this is that a dependency gives you an abstraction: you no
longer need to know \emph{how} to do something, (that's the job of the
dependency), you just need to interact with the dependency properly to
get the job done. Buses are \emph{perfect} for people who can't drive,
after all.

But this means that all of the issues of abstractions that we covered in
Communication Risk apply:

\begin{itemize}
\tightlist
\item
  There is Invisibility Risk because you probably don't have a full view
  of what the dependency is doing. Nowadays, bus stops have a digital
  ``arrivals'' board which gives you details of when the bus will
  arrive, and shops publish their opening hours online. But, abstraction
  always means the loss of some detail.
\item
  There is Misinterpretation Risk, because often the dependency might
  mistake your instructions. This is endemic in software, where it's
  nearly impossible to describe exactly what you want up-front.
\end{itemize}

\hypertarget{fit-risk}{%
\section{Fit Risk}\label{fit-risk}}

Sometimes, the bus will take you to lots of in-between places you
\emph{didn't} want to go. This is Fit Risk and we saw this already in
the chapter on Feature Risk. There, we considered two problems:

\begin{itemize}
\tightlist
\item
  The feature (or now, dependency) doesn't provide all the functionality
  you need. This was Fit Risk. An example might be the supermarket not
  stocking everything you wanted.
\item
  The feature / dependency provides far too much, and you have to accept
  more complexity than you need. This was Conceptual Integrity Risk. An
  example of this might be the supermarket being \emph{too big}, and you
  spend a lot longer navigating it than you wanted to.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/dependency-risk-fit.png}
\caption{Feature Fit: A Two-Dimensional Problem (at least)}
\end{figure}

\hypertarget{dead-end-risk-and-boundary-risk}{%
\section{Dead-End Risk and Boundary
Risk}\label{dead-end-risk-and-boundary-risk}}

When you choose something to depend on, you can't be certain that it's
going to work out in your favour. Sometimes, the path from your starting
point to your goal on the Risk Landscape will take you to dead ends:
places where the only way towards your destination is to lose something,
and do it again another way. This is Dead End Risk, which we looked at
before.

Boundary Risk is another feature of the Risk Landscape: when you make a
decision to use one dependency over another, you are picking a path on
the risk landscape that \emph{precludes} other choices. After all,
there's not really much cost in a Dead End if you've not had to follow a
path to get to it.

We're also going to look at Boundary Risk in more detail later, but I
want to introduce it here. Here are some examples:

\begin{itemize}
\tightlist
\item
  If I choose to program some software in Java, I will find it hard to
  integrate libraries from other languages. The dependencies available
  to Java software are different to those in Javascript, or C\#. Having
  gone down a Java route, there are \emph{higher risks} associated with
  choosing incompatible technologies. Yes, I can pick dependencies that
  use C\# (still), but I am now facing greater complexity risk than if
  I'd just chosen to do everything in C\# in the first place.
\item
  If I choose one database over another, I am \emph{limited to the
  features of that database}. This is not the same as a dead-end: I can
  probably build what I want to build, but the solution will be
  ``bounded'' by the dependency choices I make. One of the reasons we
  have standards like
  \href{https://en.wikipedia.org/wiki/Java_Database_Connectivity}{Java
  Database Connectivity (JDBC)} is to mitigate Dead End Risk around
  databases, so that we can move to a different database later.
\item
  If I choose to buy a bus ticket, I've made a decision not to travel by
  train, even though later on it might turn out that the train was a
  better option. Buying the bus ticket is Boundary Risk: I may be able
  to get a refund, but having chosen the dependency I've set down a path
  on the risk landscape.
\end{itemize}

\hypertarget{managing-dependency-risk}{%
\section{Managing Dependency Risk}\label{managing-dependency-risk}}

Arguably, managing Dependency Risk is \emph{what Project Managers do}.
Their job is to meet the Goal by organising the available dependencies
into some kind of useful order.

There are \emph{some} tools for managing dependency risk:
\href{https://en.wikipedia.org/wiki/Gantt_chart}{Gantt Charts} for
example, arrange work according to the capacity of the resources
(i.e.~dependencies) available, but also the \emph{dependencies between
the tasks}. If task \textbf{B} requires the outputs of task \textbf{A},
then clearly task \textbf{A} comes first and task \textbf{B} starts
after it finishes. We'll look at this more in Process Risk.

We'll look in more detail at project management in the \emph{practices}
part, later. But now let's get into the specifics with Scarcity Risk.

\hypertarget{scarcity-risk}{%
\chapter{Scarcity Risk}\label{scarcity-risk}}

Any resource that you depend on can suffer from \emph{scarcity},

Schedule Risk is the term for risks you face because of \emph{lack of
time}.

You could also call this ``Chronological Risk'' or just ``Time Risk'' if
you wanted to.

\begin{figure}
\centering
\includegraphics{images/generated/schedule-risk-400dpi.png}
\caption{Schedule Risk}
\end{figure}

Schedule Risk is very pervasive, and really underlies \emph{everything}
we do. People \emph{want} things, but they \emph{want them at a certain
time}. We need to eat and drink every day, for example. We might value
having a great meal, but not if we have to wait three weeks for it.

And let's go completely philosophical for a second: Were you to attain
immortality, you'd probably not feel the need to buy \emph{anything}.
You'd clearly have no \emph{needs}, and anything you wanted, you could
create yourself within your infinite time-budget. Rocks don't need
money, after all.

Let's look at some specific kinds of Schedule Risk.

\hypertarget{scarcity-risk-1}{%
\section{Scarcity Risk}\label{scarcity-risk-1}}

\begin{figure}
\centering
\includegraphics{images/generated/scarcity-risk-400dpi.png}
\caption{Scarcity Risk}
\end{figure}

Let's get back to the bus (which, hopefully, is still working). What if,
when it arrives, it's already full of passengers? Let's term this,
Scarcity Risk - the chance that a dependency is over-subscribed and you
can't use it the way you want. This is clearly an issue for nearly every
kind of dependency: buses, supermarkets, concerts, teams, services and
people.

You could also call this \emph{availability risk} or \emph{capacity
risk} of the resource. Here are a selection of mitigations:

\begin{itemize}
\tightlist
\item
  \textbf{Buffers}: Smoothing out peaks and troughs in utilisation.
\item
  \textbf{Reservation Systems}: giving clients information \emph{ahead}
  of the dependency usage about whether the resource will be available
  to them.
\item
  \textbf{Graceful degradation}: Ensuring \emph{some} service in the
  event of over-subscription. It would be no use allowing people to cram
  onto the bus until it can't move.
\item
  \textbf{Demand Management}: Having different prices during busy
  periods helps to reduce demand. Having ``first class'' seats means
  that higher-paying clients can get service even when the train is
  full. \href{https://www.uber.com}{Uber} adjust prices in real-time by
  so-called
  \href{https://www.uber.com/en-GB/drive/partner-app/how-surge-works/}{Surge
  Pricing}. This is basically turning Scarcity Risk into a Market Risk
  problem.
\item
  \textbf{Queues}: Again, these provide a ``fair'' way of dealing with
  scarcity by exposing some mechanism for prioritising use of the
  resource. Buses operate a first-come-first-served system, whereas
  emergency departments in hospitals triage according to need.
\item
  \textbf{Pools}: Reserving parts of a resource for particular
  customers.
\item
  \textbf{Horizontal Scaling}: allowing a scarce resource to flexibly
  scale according to how much demand there is. (For example, putting on
  extra buses when the trains are on strike, or opening extra check-outs
  at the supermarket.)
\end{itemize}

Much like Reliability Risk, there is science for it:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Queueing_theory}{Queue Theory} is
  all about building mathematical models of buffers, queues, pools and
  so forth.
\item
  \href{https://en.wikipedia.org/wiki/Logistics}{Logistics} is the
  practical organisation of the flows of materials and goods around
  things like \href{https://en.wikipedia.org/wiki/Supply_chain}{Supply
  Chains}.
\item
  And \href{https://en.wikipedia.org/wiki/Project_management}{Project
  Management} is in large part about ensuring the right resources are
  available at the right times. We'll be taking a closer look at that in
  Risk-First Part 3 chapters on Prioritisation and the
  \href{https://en.wikipedia.org/wiki/Project_Management_Body_of_Knowledge}{Project
  Management Body Of Knowledge}.
\end{itemize}

\hypertarget{schedule-risk}{%
\section{Schedule Risk}\label{schedule-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/schedule-risk-400dpi.png}
\caption{Schedule Risk}
\end{figure}

By agreeing a \emph{time} and \emph{place} for something to happen,
you're introducing Deadline Risk. Miss the deadline, and you miss the
bus, or the start of the meeting or get fined for not filling your tax
return on time.

As discussed above, \emph{schedules} (such as bus timetables) exist so
that \emph{two or more parties can coordinate}, and Deadline Risk is on
\emph{all} of the parties. While there's a risk I am late, there's also
a risk the bus is late. I might miss the start of a concert, or the band
might keep everyone waiting.

Each party can mitigate Deadline Risk with \emph{slack}. That is,
ensuring that the exact time of the event isn't critical to your plans:

\begin{itemize}
\tightlist
\item
  Don't build into your plans a \emph{need} to start shopping at 9am.
\item
  Arrive at the bus-stop \emph{early}.
\end{itemize}

The amount of slack you build into the schedule is likely dependent on
the level of risk you face: I tend to arrive a few minutes early for a
bus, because the risk is \emph{low} (there'll be another bus along
soon), however I try to arrive over an hour early for a flight, because
I can't simply get on the next flight straight away, and I've already
paid for it, so the risk is \emph{high}.

Deadline Risk becomes very hard to manage when you have to coordinate
actions with lots of tightly-constrained events. So what else can give?
We can reduce the number of \emph{parties} involved in the event, which
reduces risk, or, we can make sure all the parties are in the same
\emph{place} to begin with.

\hypertarget{opportunity-risk}{%
\section{Opportunity Risk}\label{opportunity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/opportunity-risk-400dpi.png}
\caption{Opportunity Risk}
\end{figure}

Opportunity Risk is really the concern that whatever we do, we have to
do it \emph{in time}. If we wait too long, we'll miss the
\href{https://en.wikipedia.org/wiki/Window_of_opportunity}{Window Of
Opportunity} for our product or service.

Any product idea is necessarily of it's time: the Goal In Mind will be
based on observations from a particular Internal Model, reflecting a
view on reality at a specific \emph{point in time}.

How long will that remain true for? This is your \emph{opportunity}: it
exists apart from any deadlines you set yourself, or funding options.
It's purely, ``how long will this idea be worth doing?''

With any luck, decisions around \emph{funding} your project will be tied
into this, but it's not always the case. It's very easy to under-shoot
or overshoot the market completely and miss the window of opportunity.

\hypertarget{the-ipad}{%
\subsection{The iPad}\label{the-ipad}}

For example, let's look at the
\href{https://en.wikipedia.org/wiki/History_of_tablet_computers}{iPad},
which was introduced in 2010 and was hugely successful.

This was not the first tablet computer. Apple had already tried to
introduce the \href{https://en.wikipedia.org/wiki/Apple_Newton}{Newton}
in 1989, and Microsoft had released the
\href{https://en.wikipedia.org/wiki/Microsoft_Tablet_PC}{Tablet PC} in
1999. But somehow, they both missed the Window Of Opportunity. Possibly,
the window existed because Apple had changed changed the market with
their release of the iPhone, which left people open to the idea of a
tablet being ``just a bigger iPhone''.

But maybe now, the iPad's window is closing? We have more \emph{wearable
computers} like the
\href{https://en.wikipedia.org/wiki/Apple_Watch}{Apple Watch}, and
voice-controlled devices like
\href{https://en.wikipedia.org/wiki/Amazon_Alexa}{Alexa} or
\href{https://en.wikipedia.org/wiki/Siri}{Siri}. Peak iPad was in 2014,
according to
\href{https://www.statista.com/statistics/269915/global-apple-ipad-sales-since-q3-2010/}{this
graph}.

So, it seems Apple timed the iPad to hit the peak of the Window of
Opportunity.

But, even if you time the Window Of Opportunity correctly, you might
still have the rug pulled from under your feet due to a different kind
of Schedule Risk, such as\ldots{}

\hypertarget{funding-risk}{%
\section{Funding Risk}\label{funding-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/funding-risk-400dpi.png}
\caption{Funding Risk}
\end{figure}

On a lot of software projects, you are ``handed down'' deadlines from
above, and told to deliver by a certain date or face the consequences.
But sometimes you're given a budget instead, which really just adds
another layer of abstraction to the Schedule Risk: That is, do I have
enough funds to cover the team for as long as I need them?

This grants you some leeway as now you have two variables to play with:
the \emph{size} of the team, and \emph{how long} you can run it for. The
larger the team, the shorter the time you can afford to pay for it.

In startup circles, this ``amount of time you can afford it'' is called
the \href{https://en.wiktionary.org/wiki/runway}{``Runway''}: you have
to get the product to ``take-off'' before the runway ends. So you could
term this component as ``Runway Risk''.

Startups often spend a lot of time courting investors in order to get
funding and mitigate this type of Schedule Risk. But, this activity
usually comes at the expense of Opportunity Risk and Feature Risk, as
usually the same people are trying to raise funds as build the project
itself.

\hypertarget{staff-risk}{%
\section{Staff Risk}\label{staff-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/staff-risk-400dpi.png}
\caption{Staff Risk}
\end{figure}

If a startup has a ``Runway'', then the chances are that the founders
and staff do too, as this article
\href{https://www.entrepreneur.com/article/223135}{explores}. It
identifies the following risks:

\begin{itemize}
\tightlist
\item
  Company Cash: The \textbf{Runway} of the startup itself
\item
  Founder Cash: The \textbf{Runway} for a founder, before they run out
  of money and can't afford their rent.
\item
  Team Cash: The \textbf{Runway} for team members, who may not have the
  same appetite for risk as the founders do.
\end{itemize}

You need to consider how long your staff are going to be around,
especially if you have
\href{https://en.wikipedia.org/wiki/Key_person_insurance\#Key_person_definition}{Key
Man Risk} on some of them. People like to have new challenges, or move
on to live in new places, or simply get bored. The longer your project
goes on for, the more Staff Risk you will have to endure, and you can't
rely on getting the best staff for failing projects.

In the chapter on Coordination-Risk we'll look in more detail at the
non-temporal components of Staff Risk.

\hypertarget{red-queen-risk}{%
\section{Red-Queen Risk}\label{red-queen-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/red-queen-risk-400dpi.png}
\caption{Red Queen Risk}
\end{figure}

A more specific formulation of Schedule Risk is Red Queen Risk, which is
that whatever you build at the start of the project will go slowly
more-and-more out of date as the project goes on.

This is named after the Red Queen quote from Alice in Wonderland:

\begin{quote}
``My dear, here we must run as fast as we can, just to stay in place.
And if you wish to go anywhere you must run twice as fast as that.'' -
\href{https://www.goodreads.com/quotes/458856-my-dear-here-we-must-run-as-fast-as-we}{Lewis
Carroll, \emph{Alice in Wonderland}}
\end{quote}

The problem with software projects is that tools and techniques change
\emph{really fast}. In 2011, 3DRealms released Duke Nukem Forever after
\href{https://en.wikipedia.org/wiki/Duke_Nukem_Forever}{15 years in
development}, to negative reviews:

\begin{quotation}

\ldots{} most of the criticism directed towards the game's long loading
times, clunky controls, offensive humor, and overall aging and dated
design.

\end{quotation}

Now, they didn't \emph{deliberately} take 15 years to build this game
(lots of things went wrong). But, the longer it took, the more their
existing design and code-base were a liability rather than an asset.

Personally, I have suffered the pain on project teams where we've had to
cope with legacy code and databases because the cost of changing them
was too high. And any team who is stuck using
\href{https://en.wikipedia.org/wiki/Visual_Basic}{Visual Basic 6.0} is
here. It's possible to ignore Red Queen Risk for a time, but this is
just another form of Technical Debt which eventually comes due.

\hypertarget{schedule-risk-and-feature-risk}{%
\section{Schedule Risk and Feature
Risk}\label{schedule-risk-and-feature-risk}}

In the chapter on Feature Risk we looked at Market Risk, the idea that
the value of your product is itself at risk from the morÃ©s of the
market, share prices being the obvious example of that effect. In
Finance, we measure this using \emph{money}, and we can put together
probability models based on how much money you might make or lose.

With Schedule Risk, the underlying measure is \emph{time}:

\begin{itemize}
\tightlist
\item
  ``If I implement feature X, I'm picking up something like 5 days of
  Schedule Risk.''
\item
  ``If John goes travelling that's going to hit us with lots of Schedule
  Risk while we train up Anne.''
\end{itemize}

\ldots{} and so on. Clearly, in the same way as you don't know exactly
how much money you might lose or gain on the stock-exchange, you can't
put precise numbers on Schedule Risk either.

Schedule Risk, then, is \emph{fundamental} to every dependency. But now
it's time to get into the \emph{specifics}, and look at Software
Dependencies.

\hypertarget{deadline-risk}{%
\chapter{Deadline Risk}\label{deadline-risk}}

Events as mitigation for coordination risk. diagram.

\hypertarget{deadline-risk-1}{%
\section{Deadline Risk}\label{deadline-risk-1}}

\begin{figure}
\centering
\includegraphics{images/generated/deadline-risk-400dpi.png}
\caption{Deadline Risk}
\end{figure}

Often when running a software project, you're given a team of people and
told to get something delivered by a certain date. i.e.~you have an
artificially-imposed Deadline on delivery.

What happens if you miss the deadline? It could be:

\begin{itemize}
\tightlist
\item
  The funding on the project runs out, and it gets cancelled.
\item
  You have to go back to a budgeting committee, and get more money.
\item
  The team gets replaced, because of lack of faith.
\end{itemize}

.. or something else.

Deadlines can be set by an authority in order to \emph{sharpen focus}
and reduce Coordination Risk. This is how we arrive at tools like
\href{https://en.wikipedia.org/wiki/SMART_criteria}{SMART Objectives}
and \href{https://en.wikipedia.org/wiki/Performance_indicator}{KPI's
(Key Performance Indicators)}. Time scales change the way we evaluate
goals, and the solutions we choose.

In JFK's quote:

\begin{quotation}

First, I believe that this nation should commit itself to achieving the
goal, before this decade is out, of landing a man on the moon and
returning him safely to the Earth.

\end{quotation}

The 9-year timespan came from an authority figure (the president) and
helped a huge team of people coordinate their efforts and arrive at a
solution that would work within a given time-frame.

Compare with this quote:

\begin{quote}
``I love deadlines. I love the whooshing noise they make as they go
by.'' - \href{https://en.wikipedia.org/wiki/Douglas_Adams}{Douglas
Adams}
\end{quote}

As a successful author, Douglas Adams \emph{didn't really care} about
the deadlines his publisher's gave him. The Deadline Risk was minimal
for him, because the publisher wouldn't be able to give his project to
someone else to complete.

Sometimes, deadlines are set in order to \emph{coordinate work between
teams}. The classic example being in a battle, to coordinate attacks.
When our deadlines are for this purpose, we're heading towards
Coordination Risk territory.

\hypertarget{student-syndrome}{%
\subsection{Student Syndrome}\label{student-syndrome}}

\href{https://en.wikipedia.org/wiki/Student_syndrome}{Student Syndrome}
is, according to Wikipedia:

\begin{quotation}

Student syndrome refers to planned procrastination, when, for example, a
student will only start to apply themselves to an assignment at the last
possible moment before its deadline.

\end{quotation}

Arguably, there is good psychological, evolutionary and risk-based
reasoning behind procrastination: the further in the future the Deadline
Risk is, the more we discount it. If we're only ever mitigating our
\emph{biggest risks}, then deadlines in the future don't matter so much,
do they? And, putting efforts into mitigating future risks that
\emph{might not arise} is wasted effort.

Or at least, that's the argument. If you're Discounting the Future To
Zero then you'll be pulling all-nighters in order to deliver any
assignment.

So, the problem with Student Syndrome is that the \emph{very mitigation}
for Schedule Risk (allowing more time) is an Attendant Risk that
\emph{causes} Schedule Risk: you'll work towards the new, generous
deadline more slowly, and you'll end up revealing Hidden Risk
\emph{later} than you would have with the original, pressing deadline
\ldots{} and you end up being late because of them.

We'll look at mitigations for this in Part 3's chapter on
Prioritisation.

\hypertarget{event-dependencies}{%
\section{Event Dependencies}\label{event-dependencies}}

Let's start with dependencies on \emph{events}.

We rely on events occuring all the time in our lives, and so this is a
good place to start in our analysis of Dependency Risk generally. And,
as we will see, all the risks that apply to events pretty much apply to
all the other kinds of dependencies we'll look at.

Arguably, the event dependencies are the simplest to express, too:
usually, a \emph{time} and a \emph{place}. For example: - ``I can't
start shopping until the supermarket opens at 9am'', or - ``I must catch
my bus to work at 7:30am''.

In the first example, you can't \emph{start} something until a
particular event happens. In the latter example, you must \emph{be
ready} for an event at a particular time.

\hypertarget{events-mitigate-risk}{%
\subsection{Events Mitigate Risk\ldots{}}\label{events-mitigate-risk}}

Having an event occur in a fixed time and place is mitigating risk:

\begin{itemize}
\tightlist
\item
  By taking the bus, we are mitigating our own Schedule Risk: we're
  (hopefully) reducing the amount of time we're going to spend on the
  activity of getting to work.
\item
  Events are a mitigation for Coordination Risk: A bus needn't
  necessarily \emph{have} a fixed timetable: it could wait for each
  passenger until they turned up, and then go. (A bit like ride-sharing
  works). This would be a total disaster from a Coordination Risk
  perspective, as one person could cause everyone else to be really
  really late. Having a fixed time for doing something mitigates
  Coordination Risk by turning it into Schedule Risk. Agreeing a date
  for a product launch, for example, allows lots of teams to coordinate
  their activities.
\item
  It's not entirely necessary to even take the bus: you could walk, or
  go by another form of transport. But, effectively, this just swaps one
  dependency for another: if you walk, this might well take longer and
  use more energy, so you're just picking up Schedule Risk in another
  way. If you drive, you have a dependency on your car instead. So,
  there is often an \emph{opportunity cost} with dependencies. Using the
  bus might be a cheap way to travel. You're therefore imposing less
  Dependency Risk on a different scarce resource - your money.
\end{itemize}

\hypertarget{but-events-lead-to-attendant-risk}{%
\subsection{But, Events Lead To Attendant
Risk}\label{but-events-lead-to-attendant-risk}}

By \emph{deciding to use the bus} we've Taken Action.

\begin{figure}
\centering
\includegraphics{images/kite9/dependency-risk-event.png}
\caption{Action Diagram showing risks mitigated by having an
\emph{event}}
\end{figure}

However, as we saw in A Simple Scenario, this means we pick up Attendant
Risks.

So, we're going to look at Dependency Risk for our toy events (bus,
supermarket) from 7 different perspectives, many of which we've already
touched on in the other chapters.

\begin{itemize}
\tightlist
\item
  Scarcity Risk
\item
  Schedule Risk
\item
  Reliability Risk
\item
  Communication Risk
\item
  Complexity Risk
\item
  Feature Fit Risk
\item
  Dead-End Risk and Boundary Risk
\end{itemize}

(Although you might be able to think of a few more.)

Let's look at each of these in turn.

\hypertarget{software-dependency-risk}{%
\chapter{Software Dependency Risk}\label{software-dependency-risk}}

In this chapter, we're going to look specifically at \emph{Software}
dependencies, although many of the concerns we'll raise here apply
equally to all the other types of dependency we outlined in Dependency
Risk.

\hypertarget{kolmogorov-complexity-cheating}{%
\section{Kolmogorov Complexity:
Cheating}\label{kolmogorov-complexity-cheating}}

In the earlier chapter on Complexity Risk we tackled Kolmogorov
Complexity, and the idea that your codebase had some kind of minimal
level of complexity based on the output it was trying to create. This is
a neat idea, but in a way, we cheated. Let's look at how.

We were trying to figure out the shortest (Javascript) program to
generate this output:

\begin{verbatim}
abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd
\end{verbatim}

And we came up with this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                         (}\DecValTok{11}\NormalTok{ symbols)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                           (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                 (}\DecValTok{7}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

Which had \textbf{26} symbols in it.

Now, here's the cheat: The \texttt{repeat()} function was built into
Javascript in 2015 in
\href{http://www.ecma-international.org/ecma-262/6.0/}{ECMAScript 6.0}.
If we'd had to program it ourselves, we might have added this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{repeat}\NormalTok{(s}\OperatorTok{,}\NormalTok{n) }\OperatorTok{\{}\NormalTok{                     (}\DecValTok{10}\NormalTok{ symbols)}
    \KeywordTok{var}\NormalTok{ a}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{                              (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{while}\NormalTok{(}\VariableTok{a}\NormalTok{.}\AttributeTok{length}\OperatorTok{<}\NormalTok{n)}\OperatorTok{\{}\NormalTok{                     (}\DecValTok{9}\NormalTok{ symbols)}
        \VariableTok{a}\NormalTok{.}\AttributeTok{push}\NormalTok{(s)                          (}\DecValTok{6}\NormalTok{ symbols)}
    \OperatorTok{\}}\NormalTok{                                      (}\DecValTok{1}\NormalTok{ symbol)}
    \ControlFlowTok{return} \VariableTok{a}\NormalTok{.}\AttributeTok{join}\NormalTok{(}\StringTok{''}\NormalTok{)}\OperatorTok{;}\NormalTok{                     (}\DecValTok{10}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

\ldots{} which would be an extra \textbf{44} symbols (in total
\textbf{70}), and push us completely over the original string encoding
of \textbf{53} symbols. So, \emph{encoding language is important}.

Conversely, if ECMAScript 6.0 had introduced a function called
\texttt{abcdRepeater(n)} we'd have been able to do this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                           (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \AttributeTok{abcdRepeater}\NormalTok{(}\DecValTok{10}\NormalTok{)                (}\DecValTok{6}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

.. and re-encode to \textbf{14} symbols. Now, clearly there are some
problems with all this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clearly, \emph{language matters}: the Kolmogorov complexity is
  dependent on the language, and the features the language has built in.
\item
  The exact Kolmogorov complexity is uncomputable anyway (it's the
  \emph{theoretical} minimum program length). It's just a fairly
  abstract idea, so we shouldn't get too hung up on this. There is no
  function to be able to say, ``what's the Kolmogorov complexity of
  string X''
\item
  What is this new library function we've created? Is
  \texttt{abcdRepeater} going to be part of \emph{every} Javascript? If
  so, then we've shifted Codebase Risk away from ourselves, but we've
  pushed Communication Risk and Dependency Risk onto every \emph{other}
  user of Javascript. (Why these? Because \texttt{abcdRepeater} will be
  clogging up the documentation and other people will rely on it to
  function correctly.)
\item
  Are there equivalent functions for every single other string? If so,
  then compilation is no longer a tractable problem: is
  \texttt{return\ abcdRepeater(10)} correct code? Well, now we have a
  massive library of different \texttt{XXXRepeater} functions to compile
  against to see if it is\ldots{} So, what we \emph{lose} in Kolmogorov
  Complexity we gain in Runtime Complexity.
\item
  Language design, then, is about \emph{ergonomics}. After you have
  passed the relatively low bar of providing
  \href{https://en.wikipedia.org/wiki/Turing_completeness}{Turing
  Completeness}, the key is to provide \emph{useful} features that
  enable problems to be solved, without over-burdening the user with
  features they \emph{don't} need. And in fact, all software is about
  this.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-ergonomics.png}
\caption{Software Dependency Ergonomics: finding the sweet spot between
too many features and too few}
\end{figure}

\hypertarget{ergonomics-examined}{%
\section{Ergonomics Examined}\label{ergonomics-examined}}

Have a look at some physical tools, like a hammer, or spanner. To look
at them, they are probably \emph{simple} objects, obvious, strong and
dependable. Their entire behaviour is encapsulated in their form. Now,
if you have a drill or sander to hand, look at the design of this too.
If it's well-designed, then from the outside it is simple, perhaps with
only one or two controls. Inside, it is complex and contains a motor,
perhaps a transformer, and is maybe made of a hundred different
components.

But outside, the form is simple, and designed for humans to use. This is
\emph{\href{https://en.wikipedia.org/wiki/Human_factors_and_ergonomics}{ergonomics}}:

\begin{quotation}

``Human factors and ergonomics (commonly referred to as Human Factors),
is the application of psychological and physiological principles to the
(engineering and) design of products, processes, and systems. The goal
of human factors is to reduce human error, increase productivity, and
enhance safety and comfort with a specific focus on the interaction
between the human and the thing of interest.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Human_factors_and_ergonomics}{\textemdash  Human Factors and Ergonomics, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{interfaces}{%
\subsection{Interfaces}\label{interfaces}}

The interface of a tool is the part we touch and interact with. By
striving for simplicity, the interface reduces Communication Risk.

The interface of a system expands when you ask it to do a wide variety
of things. An easy-to-use drill does one thing well: it turns drill-bits
at useful levels of torque for drilling holes and sinking screws. But if
you wanted it to also operate as a lathe, a sander or a strimmer (all
basically mechanical things going round) you would have to sacrifice the
ergonomic simplicity for a more complex interface, probably including
adapters, extensions, handles and so on.

So, we now have split complexity into two: - The inner complexity of the
tool (how it works internally, it's own Kolmogorov Complexity). - The
complexity of the instructions that we need to write to make the tool
work (the interface Kolmogorov Complexity).

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-complexity.png}
\caption{Types of Complexity For a Software Dependency}
\end{figure}

\hypertarget{software-tools}{%
\subsection{Software Tools}\label{software-tools}}

In the same way as with a hand-tool, the bulk of the complexity of a
software tool is hidden behind it's interface. But, the more complex the
\emph{purpose} of the tool, the more complex the interface will be.

Software is not constrained by \emph{physical} ergonomics in the same
way as a tool is. But ideally, it should have conceptual ergonomics:
ideally, complexity is hidden away from the user behind the
\href{https://en.wikipedia.org/wiki/Application_programming_interface}{Application
Programming Interface (API)}. This is the familiar concept of
Abstraction we've already looked at.

That is, the tool should be as simple to use and understand as possible.
This is the Principal Of Least Astonishment:

\begin{itemize}
\tightlist
\item
  \textbf{The abstractions should map easily to how the user expects the
  tool to work.} For example, I \emph{expect} the trigger on a drill to
  start the drill turning.
\item
  \textbf{The abstractions should leverage existing idioms and
  knowledge.} In a new car, I \emph{expect} to know what the symbols on
  the dashboard mean, because I've driven other cars.
\item
  \textbf{The abstractions provide me with only the functions I need.}
  Because everything else is confusing and gets in the way.
\end{itemize}

The way to win, then, is to allow a language to be extensible as-needed
with features written by third parties. By supplying mechanisms for
extension a language can provide insurances against the Boundary Risk of
adopting it.

\hypertarget{types-of-software-dependencies}{%
\section{Types Of Software
Dependencies}\label{types-of-software-dependencies}}

There are lots of ways you can depend on software. Here though, we're
going to focus on just three main types: 1. \textbf{Code Your Own}:
write some code ourselves to meet the dependency. 2. \textbf{Software
Libraries}: importing code from the Internet, and using it in our
project. Often, libraries are Open Source (this is what we'll consider
here). 3. \textbf{Software as a Service}: calling a service on the
Internet, (probably via \texttt{http}) This is often known as
\href{https://en.wikipedia.org/wiki/Software_as_a_service}{SaaS, or
Software as a Service}.

All 3 approaches involve a different risk-profile. Let's look at each in
turn, from the perspective of which risks get mitigated, and which risks
are accentuated.

\hypertarget{code-your-own}{%
\subsection{1. Code Your Own}\label{code-your-own}}

Initially, writing our own code was the only game in town: when I
started programming, you had a user guide, BASIC and that was pretty
much it. Tool support was very thin-on-the-ground. Programs and
libraries could be distributed as code snippets \emph{in magazines}
which could be transcribed and run, and added to your program. This
spirit lives on somewhat in StackOverflow and JSFiddle, where you are
expected to ``adopt'' others' code into your own project.

One of the hidden risks of embarking on a code-your-own approach is that
the features you need are \emph{not} apparent from the outset. What
might appear to be a trivial implementation of some piece of
functionality can often turn into it's own industry as more and more
hidden Feature Risk is uncovered.

For example, as we discussed in our earlier treatment of Dead-End Risk,
building log-in screens \emph{seemed like a good idea}. However, this
gets out-of-hand fast when you need: - A password reset screen - To
email the reset links to the user - An email verification screen - A
lost account screen - Reminders to complete the sign up process -
\ldots{} and so on.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-code-your-own.png}
\caption{Code-Your-Own mitigates immediate feature risk, but at the
expense of schedule risk, complexity risk and communication risk. There
is also a hidden risk of features you don't yet know you need.}
\end{figure}

\hypertarget{unwritten-software}{%
\subsection{Unwritten Software}\label{unwritten-software}}

Sometimes, you will pick up a dependency on \emph{unwritten software}.
This commonly happens when work is divided amongst team members, or
teams.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-unwritten-1.png}
\caption{Sometimes, a module you're writing will depend on unwritten
code}
\end{figure}

If a component \textbf{A} of our project \emph{depends} on \textbf{B}
for some kind of processing, you might not be able to complete
\textbf{A} before writing \textbf{B}. This makes \emph{scheduling} the
project harder, and if component \textbf{A} is a risky part of the
project, then the chances are you'll want to mitigate risk there first.

But it also hugely increases Communication Risk because now you're being
asked to communicate with a dependency that doesn't really exist yet,
\emph{let alone} have any documentation.

There are a couple of ways to do this:

\begin{itemize}
\tightlist
\item
  \textbf{Standards}: If component \textbf{B} is a database, a queue,
  mail gateway or something else with a standard interface, then you're
  in luck. Write \textbf{A} to those standards, and find a cheap, simple
  implementation to test with. This gives you time to sort out exactly
  what implementation of \textbf{B} you're going for. This is not a
  great long-term solution, because obviously, you're not using the
  \emph{real} dependency- you might get surprised when the behaviour of
  the real component is subtly different. But it can reduce Schedule
  Risk in the short-term.
\item
  \textbf{Coding To Interfaces}: If standards aren't an option, but the
  surface area of \textbf{B} that \textbf{A} uses is quite small and
  obvious, you can write a small interface for it, and work behind that,
  using a \href{https://en.wikipedia.org/wiki/Mock_object}{Mock} for
  \textbf{B} while you're waiting for finished component. Write the
  interface to cover only what \textbf{A} \emph{needs}, rather than
  everything that \textbf{B} \emph{does} in order to minimise the risk
  of \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{Leaky
  Abstractions}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-unwritten-2.png}
\caption{Coding to a standard on an interface breaks the dependency on
unwritten software}
\end{figure}

\hypertarget{conways-law}{%
\subsection{Conway's Law}\label{conways-law}}

If the dependency is being written by another person, another team or in
another country, communication risks pile up. When this happens, you
will want to minimise \emph{as much as possible} the interface
complexity, since the more complex the interface, the worse the
Communication Risk will be. The tendency then is to make the interfaces
between teams or people \emph{as simple as possible}, modularising along
these organisational boundaries.

In essence, this is
\href{https://en.wikipedia.org/wiki/Conways_law}{Conway's Law}:

\begin{quotation}

organisations which design systems \ldots{} are constrained to produce
designs which are copies of the communication structures of these
organisations.

\end{quotation}

\hypertarget{software-libraries}{%
\subsection{2. Software Libraries}\label{software-libraries}}

By choosing a particular software library, we are making a move on the
Risk Landscape in the hope of moving to place with more favourable
risks. Typically, using library code offers a Schedule Risk and
Complexity Risk Silver Bullet. But, in return we expect to pick up: -
Communication Risk: because we now have to learn how to communicate with
this new dependency. - Boundary Risk - because now are limited to using
the functionality provided by this dependency. We have chosen it over
alternatives and changing to something else would be more work and
therefore costly.

But, it's quite possible that we could wind up in a worse place than we
started out, by using a library that's out-of-date, riddled with bugs or
badly supported. i.e.~Full of new, hidden Feature Risk.

It's \emph{really easy} to make bad decisions about which tools to use
because the tools don't (generally) advertise their deficiencies. After
all, they don't generally know how \emph{you} will want to use them.

\hypertarget{software-libraries---hidden-risks}{%
\subsection{Software Libraries - Hidden
Risks}\label{software-libraries---hidden-risks}}

Currently, choosing software dependencies looks like a ``bounded
rationality''-type process:

\begin{quotation}

``Bounded rationality is the idea that when individuals make decisions,
their rationality is limited by the tractability of the decision
problem, the cognitive limitations of their minds, and the time
available to make the decision.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Bounded_rationality}{\textemdash  Bounded Rationality, \emph{Wikipedia}}}
\end{quotation}

Unfortunately, we know that most decisions \emph{don't} really get made
this way. We have things like
\href{https://en.wikipedia.org/wiki/Confirmation_bias}{Confirmation
Bias} (looking for evidence to support a decision you've already made)
and \href{https://en.wikipedia.org/wiki/Cognitive_inertia}{Cognitive
Inertia} (ignoring evidence that would require you to change your mind)
to contend with.

But, leaving that aside, let's try to build a model of what this
decision making process \emph{should} involve. Luckily, other authors
have already considered the problem of choosing good software libraries,
so let's start there.

In the table below, I am summarising three different sources (linked at
the end of the chapter), which give descriptions of which factors to
look for when choosing open-source libraries.

\begin{figure}
\centering
\Oldincludegraphics[width=1\maxwidth]{images/generated/software_dependency_table_1_large-400dpi.png}
\caption{Software Dependencies}
\end{figure}

Some take-aways:

\begin{itemize}
\tightlist
\item
  Feature Risk is a big concern. How can you be sure that the project
  will do what you want it to do ahead of schedule? Will it contain bugs
  or missing features? By looking at factors like \emph{release
  frequency} and \emph{size of the community} you get a good feel for
  this which is difficult to fake.
\item
  Boundary Risk is also very important. You are going to have to
  \emph{live} with your choices for the duration of the project, so it's
  worth spending the effort to either ensure that you're not going to
  regret the decision, or that you can change direction later.
\item
  Third is Communication Risk: how well does the project deal with it's
  users? If a project is ``famous'', then it has communicated its
  usefulness to a wide, appreciative audience. Avoiding Communication
  Risk is also a good reason to pick \emph{tools you are already
  familiar with}.
\end{itemize}

\hypertarget{complexity-risk-2}{%
\subsection{Complexity Risk?}\label{complexity-risk-2}}

One thing that none of the sources consider (at least from the outset)
is the Complexity Risk of using a solution: - Does it drag in lots of
extra dependencies that seem unnecessary for the job in hand? If so, you
could end up in
\href{https://en.wikipedia.org/wiki/Dependency_hell}{Dependency Hell},
with multiple, conflicting versions of libraries in the project. - Do
you already have a dependency providing this functionality? So many
times, I've worked on projects that import a \emph{new} dependency when
some existing (perhaps transitive) dependency has \emph{already brought
in the functionality}. For example, there are plenty of libraries for
\href{https://en.wikipedia.org/wiki/JSON}{JSON} marshaling, but if I'm
also using a web framework the chances are it already has a dependency
on one already. - Does it contain lots of functionality that isn't
relevant to the task you want it to accomplish? e.g.~Using Java when a
shell script would do (on a non-Java project)

To give an extreme example of this, I once worked on an application
which used \href{https://en.wikipedia.org/wiki/Hazelcast}{Hazlecast} to
cache log-in session tokens for a 3rd party data-source. But, the app is
only used once every month, and session IDs can be obtained in
milliseconds. So\ldots{} why cache them? Although Hazlecast is an
excellent choice for in-memory caching across multiple JVMs, it is a
complex piece of software (after all, it does lots of stuff). By doing
this, you have introduced extra dependency risk, cache invalidation
risks, networking risks, synchronisation risks and so on, for actually
no benefit at all\ldots{} Unless, it's about CV Building.

Sometimes, the amount of complexity \emph{goes up} when you use a
dependency for \emph{good reason}. For example, in Java, you can use
Java Database Connectivity (JDBC) to interface with various types of
database. \href{https://en.wikipedia.org/wiki/Spring_Framework}{Spring
Framework} (a popular Java library) provides a thing called a
\texttt{JDBCTemplate}. This actually makes your code \emph{more}
complex, and can prove very difficult to debug. However, it prevents
some security issues, handles resource disposal and makes database
access more efficient. None of those are essential to interfacing with
the database, but not using them is Technical Debt that can bite you
later on.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-library.png}
\caption{Software Libraries Risk Tradeoff}
\end{figure}

\hypertarget{software-as-a-service}{%
\subsection{3. Software as a Service}\label{software-as-a-service}}

Businesses opt for Software as a Service (SaaS) because: - It vastly
reduces the Complexity Risk they face in their organisations.
e.g.~managing the software or making changes to it. - Payment is usually
based on \emph{usage}, mitigating Schedule Risk. e.g.~Instead of having
to pay for in-house software administrators, they can leave this
function to the experts. - Potentially, you out-source the Operational
Risk to a third party. e.g.~ensuring availability, making sure data is
secure and so on.

SaaS is now a very convenient way to provide \emph{commercial} software.
Popular examples of SaaS might be
\href{https://en.wikipedia.org/wiki/Salesforce.com}{SalesForce}, or
\href{https://en.wikipedia.org/wiki/Gmail}{GMail}. Both of which follow
the commonly-used
\href{https://en.wikipedia.org/wiki/Freemium}{Freemium} model, where the
basic service is provided free, but upgrading to a paid account gives
extra benefits.

By providing the software on their own servers, the commercial
organisation has a defence against \emph{piracy}, as well as being able
to control the Complexity Risk of the their environment (e.g.~not having
to support \emph{every} version of the software that's ever been
released).

Let's again recap the risks raised in some of the available literature:

\begin{figure}
\centering
\Oldincludegraphics[width=1\maxwidth]{images/generated/software_dependency_table_2_large-400dpi.png}
\caption{Software As A Service Dependencies}
\end{figure}

Some take-aways:

\begin{itemize}
\tightlist
\item
  Clearly, Operational Risk is now a big concern. By depending on a
  third-party organisation you are tying yourself to its success or
  failure in a much bigger way than just by using a piece of open-source
  software. What happens to data security, both in the data centre and
  over the Internet?
\item
  With Feature Risk you now have to contend with the fact that the
  software will be upgraded \emph{outside your control}, and you may
  have limited control over which features get added or changed.
\item
  Boundary Risk is a also a different proposition: you are tied to the
  software provider by \emph{a contract}. If the service changes in the
  future, or isn't to your liking, you can't simply fork the code (like
  you could with an open source project).
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-saas.png}
\caption{Risk Tradeoff From Using \_Software as a Service (SaaS)}
\end{figure}

\hypertarget{a-matrix-of-options}{%
\section{A Matrix of Options}\label{a-matrix-of-options}}

We've looked at just 3 different ways of providing a software
dependency: SaaS, Libraries and code-your-own.

But these are not the only ways to do it, and there's clearly no one
\emph{right} way. Although here we have looked just at ``Commercial
SaaS'' and ``Free Open Source'', in reality, these are just points in a
two-dimensional space involving \emph{Pricing} and \emph{Hosting}.

Let's expand this view slightly and look at where different pieces of
software sit on these axes:

\begin{sidewaysfigure}
\centering
\includegraphics{images/generated/software_dependency_table_3_sideways-400dpi.png}
\caption{Software Dependencies, Pricing, Delivery Matrix Risk Profiles}
\end{sidewaysfigure}

\begin{itemize}
\tightlist
\item
  Where there is value in the
  \href{https://en.wikipedia.org/wiki/Network_effect}{Network Effect},
  it's often a sign that the software will be free, or open source:
  programming languages and Linux are the obvious examples of this. Bugs
  are easier to find when there are lots of eyes looking, and learning
  the skill to use the software has less Boundary Risk if you know
  you'll be able to use it at any point in the future.
\item
  At the other end of the spectrum, clients will happily pay for
  software if it clearly \textbf{reduces complexity}. Take
  \href{https://en.wikipedia.org/wiki/Amazon_Web_Services}{Amazon Web
  Services (AWS)}. The essential trade here is that you substitute the
  complexity of hosting and maintaining various pieces of software, in
  exchange for monthly payments (Funding Risk for you). Since the AWS
  \emph{interfaces} are specific to Amazon, there is significant
  Boundary Risk in choosing this option.
\item
  In the middle there are lots of \textbf{substitute options} and
  therefore high competition. Because of this, prices are pushed towards
  zero, and and therefore often advertising is used to monetarise the
  product. \href{https://en.wikipedia.org/wiki/Angry_Birds}{Angry Birds}
  is a classic example: initially, it had demo and paid versions,
  however
  \href{https://en.wikipedia.org/wiki/Rovio_Entertainment}{Rovio}
  discovered there was much more money to be made through advertising
  than from the
  \href{https://www.deconstructoroffun.com/blog/2017/6/11/how-angry-birds-2-multiplied-quadrupled-revenue-in-a-year}{paid-for
  app}.
\end{itemize}

\hypertarget{managing-risks}{%
\subsection{Managing Risks}\label{managing-risks}}

So far, we've considered only how the different approaches to Software
Dependencies change the landscape of risks we face to mitigate some
Feature Risk or other.

But with Software Dependencies we can construct dependency networks to
give us all kinds of features and mitigate all kinds of risk. That is,
\emph{the features we are looking for are to mitigate some kind of
risk}.

For example, I might start using
\href{https://en.wikipedia.org/wiki/WhatsApp}{WhatsApp} for example,
because I want to be able to send my friends photos and text messages.
However, it's likely that those same features are going to allow us to
mitigate Communication Risk and Coordination Risk when we're next trying
to meet up.

Let's look at some:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.40\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.55\columnwidth}\raggedright
Examples of Software Mitigating That Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Calendar tools, Bug Tracking, Distributed Databases\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Map-And-Territory-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
The Internet, generally. Excel, Google, ``Big Data'', Reporting
tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Schedule-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Planning Software, Project Management Software\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Communication-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Email, Chat tools, CRM tools like SalesForce, Forums, Twitter,
Protocols\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Process-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Reporting tools, online forms, process tracking tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Agency-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Auditing tools, transaction logs, Time-Sheet software, HR Software\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Operational-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Support tools like ZenDesk, Grafana, InfluxDB, Geneos\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Feature-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Every piece of software you use!\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{back-to-ergonomics}{%
\section{Back To Ergonomics}\label{back-to-ergonomics}}

What's clear from this analysis is that software dependencies don't
\emph{conquer} any risk - the moves they make on the Risk Landscape are
\emph{subtle}. Whether or not you end up in a more favourable position
risk-wise is going to depend heavily on the quality of the execution and
the skill of the implementor.

In particular, \emph{choosing} dependencies can be extremely difficult.
As we discussed above, the usefulness of any tool depends on its fit for
purpose, it's \emph{ergonomics within a given context}. It's all too
easy to pick a good tool for the wrong job:

\begin{quotation}

``I suppose it is tempting, if the only tool you have is a hammer, to
treat everything as if it were a nail.''

\sourceatright{\href{https://en.wiktionary.org/wiki/if_all_you_have_is_a_hammer,_everything_looks_like_a_nail}{\textemdash  Abraham Maslow, \emph{Toward a Psychology of Being}} <!-- tweet-end -->}
\end{quotation}

With software dependencies, we often have to live with the decisions we
make for a long time. In my experience, given the Boundary Risks
associated with getting this wrong, not enough time is spent really
thinking about this in advance.

Let's take a closer look at this problem in the next chapter, Boundary
Risk.

\begin{longtable}[]{@{}l@{}}
\toprule
Sources\tabularnewline
\midrule
\endhead
\href{https://www.software.ac.uk/resources/guides/defending-your-code-against-dependency-problems}{sd1
- Defending your code against dependency problems}\tabularnewline
\href{https://stackoverflow.com/questions/2960371/how-to-choose-an-open-source-library}{sd2
- How to choose an open source library}\tabularnewline
\href{https://www.forbes.com/sites/forbestechcouncil/2017/07/20/open-source-to-use-or-not-to-use-and-how-to-choose/2/\#39e67e445a8c}{sd3
- Open Source - To use or not to use}\tabularnewline
\href{https://www.zdnet.com/article/saas-checklist-nine-factors-to-consider-when-selecting-a-vendor/}{sd4
- SaaS Checklist - Nine Factors to Consider}\tabularnewline
\href{http://sandhill.com/article/how-to-evaluate-saas-vendors-five-key-considerations/}{sd5
- How to Evaluate SaaS Vendors}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{process-risk}{%
\chapter{Process Risk}\label{process-risk}}

Process Risk, as we will see, is the risk you take on whenever you
embark on completing a \emph{process}.

\begin{quotation}

``\textbf{Process:} A process is a set of activities that interact to
achieve a result.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Process}{\textemdash  Process, \emph{Wikipedia}}}
\end{quotation}

In the software development world (and the business world generally)
processes commonly involve \emph{forms}: If you're filling out a form
(whether on paper or on a computer) then you're involved in a process of
some sort, whether an ``Account Registration'' process, ``Loan
Application'' process or ``Consumer Satisfaction Survey'' process. But
sometimes, they involve events occurring: a
\href{https://en.wikipedia.org/wiki/Software_build}{build process} might
start after you commit some code, for example.

\hypertarget{the-purpose-of-process}{%
\section{The Purpose Of Process}\label{the-purpose-of-process}}

Process exists to mitigate other kinds of risk, and for this reason,
we'll be looking at them again in Part 3: Practices, where we'll look at
how you can design processes to mitigate risks on your own project.

Until we get there, let's look at some examples of how process can
mitigate other risks:

\begin{itemize}
\tightlist
\item
  Coordination Risk: You can often use process to help people
  coordinate. For example, a
  \href{https://en.wikipedia.org/wiki/Production_line}{Production Line}
  is a process where work being done by one person is pushed to the next
  person when it's done. A meeting booking process ensures that people
  will all attend a meeting together at the same place and time, and
  that a room is available for it.
\item
  Dependency Risk: You can use processes to make dependencies explicit
  and mitigate dependency risk. For example, a process for hiring a car
  will make sure there is a car available at the time you need it.
  Alternatively, if we're processing a loan application, we might need
  evidence of income or bank statements. We can push this Dependency
  Risk onto the person asking for the loan, by making it part of the
  process and not accepting the application until this has been
  provided.
\item
  Complexity Risk: Working \emph{within a process} can reduce the amount
  of Complexity you have to deal with. We accept that processes are
  going to slow us down, but we appreciate the reduction in risk this
  brings. (They allow us to trade Complexity for Schedule risk). For
  example, setting up a server might be complex, but filling in a form
  to do the job might simplify things. Clearly, the complexity hasn't
  gone away, but it's hidden within the process. Process therefore can
  provide Abstraction. mcdonalds. tbd
\item
  Operational Risk: Operational Risk encompasses the risk of people
  \emph{not doing their job properly}. But, by having a process, (and
  asking, did this person follow the process?) you can draw a
  distinction between a process failure and a personnel failure. For
  example, making a loan to a money launderer \emph{could} be a failure
  of the loan agent. But, if they followed the \emph{process}, it's a
  failure of the Process itself.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-introduction.png}
\caption{Introducing process can mitigate many risks for a team, but
there are attendant process risks created.}
\end{figure}

These are all examples of Risk Mitigation for the \emph{owners} of the
process. The \emph{consumers} of the process end up picking up most of
the Process Risks. Let's see how this comes about.

\hypertarget{evolution-of-business-process}{%
\section{Evolution Of Business
Process}\label{evolution-of-business-process}}

Before we get to examining what constitutes Process Risks, let's
consider how processes \emph{form}. Specifically, we're going to look at
\href{https://en.wikipedia.org/wiki/Business_process}{Business Process}:

\begin{quotation}

``\textbf{Business Process} or \textbf{Business Method} is a collection
of related, structured activities or tasks that in a specific sequence
produces a service or product (serves a particular business goal) for a
particular customer or customers.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Business_process}{\textemdash  Business Process, \emph{Wikipedia}}}
\end{quotation}

Business Processes often arise in response to an unmet need within an
organisation. And, as we said above, they are usually there to mitigate
other risks. Let's look at an example life-cycle of how that can happen.

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-0.png}
\caption{Step 0: Clients \texttt{C} need \texttt{A} to do their jobs}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  Let's say, there exists a group of people inside a company \texttt{C},
  which need a certain something \texttt{A} in order to get their jobs
  done. It might be a producing a resource, or dealing with some source
  of complexity, or whatever.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-1.png}
\caption{Step 1: Person B doing A for company C}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Person \texttt{B} in a company starts producing \texttt{A} \emph{as a
  service to others}. This is really useful! It makes the the lives of
  clients in \texttt{C} much easier as they have an easier path to
  \texttt{A} than before. \texttt{B} gets busy keeping \texttt{C} happy.
  No one cares. But then, \texttt{B} goes on holiday. \texttt{A} doesn't
  get done, and people now care: the Dependency Risk is suddenly
  apparent.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-2.png}
\caption{Step 2: Team T is created to do A for Company C}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Either, \texttt{B} co-opts other people to help, gets given a team
  (\texttt{T}), or someone else forms a team \texttt{T} containing
  \texttt{B} to get the job done ``properly''.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{T} is responsible for doing \texttt{A}, but it needs to supply
  the company with \texttt{A} reliably and responsibly, otherwise there
  will be trouble, so they try and please all of their clients as far as
  possible.
\item
  This is a good deal for their clients within \texttt{C}, but because
  there is a lot of variation in what the clients ask for, \texttt{T}
  end up absorbing a lot of Complexity Risk and are overworked.
\item
  This is attendant Schedule Risk: They either need to streamline what
  they are doing, or get a larger budget, because all this extra
  Complexity impacts their ability to reliably deliver \texttt{A}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-3.png}
\caption{Team T protects itself from complexity with a process, P}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{T} organises bureaucratically, so that there is a controlled
  process (\texttt{P}) by which \texttt{A} can be accessed. Like a cell,
  they have arranged a protective barrier around themselves, the
  strength of which depends on the power conferred to them by control of
  \texttt{A}.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{P} probably involves filling in a form (or following some
  other Protocol).
\item
  \texttt{T} can now deal with requests on a first-come-first-served
  basis and deal with them all in the same way: Complexity Risks are now
  the problem of the form-filler in \texttt{C}.
\item
  \texttt{T} has mitigated Schedule Risk issues by drawing a line around
  the amount of Complexity Risk they are willing to take on.
\item
  \texttt{C} now has Process Risk: will their requirements for
  \texttt{A} be met by \texttt{T}? They have to submit to the process to
  find out\ldots{}
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-4.png}
\caption{Team T protects itself from Coordination issues with sign-offs
or other barriers}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  But it's hard to make sure the right clients get access to \texttt{A}
  at the right times, and it's necessary to synchronise access across
  company \texttt{C}. (A Coordination Risk issue.)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{T} reacts and sets up sign-off, authorisation or monetary
  barriers around \texttt{A}, moving the Coordination Risk issue out of
  their team.
\item
  But, for \texttt{C}, this \emph{again} increases the Process Risk
  involved in using \texttt{A}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-5.png}
\caption{Team T increases bureaucratic load, and pushes Process Risk
onto C}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  But, there are abuses of \texttt{A}: people either misuse it, or use
  it too much. (These are Operational Risks).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{T} reacts by \emph{increasing} the amount of \emph{process} to
  use \texttt{A}, mitigating Operational Risk within their team,
  but\ldots{}
\item
  This corresponds to greater Process Risk for clients in company
  \texttt{C}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-6.png}
\caption{Person D acts as a middleman for customers needing some variant
of \texttt{A}}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Person \texttt{D}, who has experience working with team \texttt{T}
  acts as a middleman for customers requiring some variant of \texttt{A}
  for a subset of \texttt{C}. They are able to help navigate the
  bureaucratic process (handle with Process Risk). The cycle potentially
  starts again: will \texttt{D} end up becoming a new team, with a new
  process?
\end{enumerate}

In this example, you can see how the organisation evolves to mitigate
risk around the use (and misuse) of \texttt{A}: First, Complexity Risk,
then Coordination Risk, then Dependency Risk and finally, the Process
Risk was created to mitigate everything else. This is an example of
\emph{Process following Strategy}:

\begin{quote}
In this conception, you can see how the structure of an organisation
(the teams and processes within it, the hierarchy of control) will
`evolve' from the resources of the organisation and the strategy it
pursues. Processes evolve to meet the needs of the organisation." -
\href{http://www.mintzberg.org/books/strategy-safari}{Minzberg,
\emph{Strategy Safari}}
\end{quote}

\hypertarget{an-example---release-process}{%
\section{An Example - Release
Process}\label{an-example---release-process}}

For many years I have worked in the Finance Industry, and it's given me
time to observe how, across an entire industry, process can evolve, both
in response to regulatory pressure but also because of organisational
maturity, and mitigating risks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initially, I could release software by logging onto the production
  accounts with a password that everyone knew, and deploy software or
  change data in the database.
\item
  The first issue with this is bad actors: How could you know that the
  numbers weren't being altered in the databases? Production auditing
  came in so that at least you could tell \emph{who was changing what},
  in order to point the blame later.
\item
  But, there was still plenty of scope for deliberate or accidental
  damage. I personally managed to wipe production data on one occasion
  by mistaking it for a development environment. Eventually, passwords
  were taken out of the hands of developers and you needed approval to
  ``break glass'' to get onto production.
\item
  Change Requests were introduced. This is another approval process
  which asks you to describe what you want to change in production, and
  why you want to change it. In most places, this was quite an onerous
  process, so the unintended consequence was that release cadence was
  reduced.
\item
  The change request software is generally awful, making the job of
  raising change requests tedious and time-consuming. Therefore,
  developers would \emph{automate} the processes for release, sometimes
  including the process to write the change request. This allowed them
  to improve release cadence, at the expense of owning more code.
\item
  Auditors didn't like the fact that this automation existed, because
  effectively, that meant that developers could get access to production
  with the press of a button, effectively taking you back to step 1. So
  auditing of Change Requests had to happen.
\end{enumerate}

\ldots{} and so on.

\hypertarget{process-risks}{%
\section{Process Risks}\label{process-risks}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/process-risk-400dpi.png}
\caption{Process Risk}
\end{figure}

\textbf{Process Risk}, then, is a type of Dependency Risk, where you are
relying on a process. In a way, it's no different from any other kind of
Dependency Risk. But Process Risk manifests itself in fairly predictable
ways:

\begin{itemize}
\tightlist
\item
  Reliability Risk: If \emph{people} are part of the process, there's
  the chance that they forget to follow the process itself, and miss
  steps or forget your request completely. The reliability is related to
  the amount of Complexity Risk the process is covering.
\item
  Invisibility Risk: Usually, processes (like other dependencies) trade
  Complexity Risk for visibility: it's often not possible to see how far
  along a process is to completion. Sometimes, you can do this to an
  extent. For example, when I send a package for delivery, I can see
  roughly how far it's got on the tracking website. But, this is still
  less-than-complete information, and is a representation of reality.
\item
  Fit Risk: You have to be careful to match the process to the outcome
  you want. Sometimes, it's easy to waste time on the wrong process.
\item
  Dead-End Risk: Even if you have the right process, initiating a
  process has no guarantee that your efforts won't be wasted and you'll
  be back where you started from. The chances of this happening increase
  as you get further from the standard use-case for the process, and the
  sunk cost increases with the length of time the process takes to
  report back.
\item
  Agency Risk: Due to Parkinson's Law, see below.
\item
  Operational Risk: Where processes fail, this is often called
  Operational Risk, which we'll address further in it's own chapter.
\item
  Credit Risk: Where you pay for something to be done, but then end up
  without the outcome you want. Let's look at that in more detail.
\end{itemize}

\hypertarget{processes-and-invisibility-risk}{%
\subsection{Processes And Invisibility
Risk}\label{processes-and-invisibility-risk}}

Processes tend to work well for the common cases, because \emph{practice
makes perfect}. but they are really tested when unusual situations
occur. Expanding processes to deal with edge-cases incurs Complexity
Risk, so often it's better to try and have clear boundaries of what is
``in'' and ``out'' of the process' domain.

Sometimes, processes are \emph{not} used commonly. How can we rely on
them anyway? Usually, the answer is to build in extra feedback loops
anyway:

\begin{itemize}
\tightlist
\item
  Testing that backups work, even when no backup is needed.
\item
  Running through a disaster recovery scenario at the weekend.
\item
  Increasing the release cadence, so that we practice the release
  process more.
\end{itemize}

The feedback loops allow us to perform Retrospectives and Reviews to
improve our processes.

\hypertarget{bureaucracy-risk}{%
\subsection{Bureaucracy Risk}\label{bureaucracy-risk}}

Where we've talked about process evolution above, the actors involved
have been acting in good faith: they are working to mitigate risk in the
organisation. The Process Risk that accretes along the way is an
\emph{unintended consequence}: There is no guarantee that the process
that arises will be humane and intuitive. Many organisational processes
end up being baroque or Kafka-esque, forcing unintuitive behaviour on
their users. This is partly because process design is \emph{hard}, and
it's difficult to anticipate all the various ways a process will be used
ahead-of-time. So, some of Bureaucracy Risk is due to Complexity.

But \href{https://en.wikipedia.org/wiki/Parkinsons_law}{Parkinson's Law}
takes this one step further: the human actors shaping the organisation
will abuse their positions of power in order to further their own
careers (this is Agency Risk, which we will come to in a future
chapter):

\begin{quotation}

``Parkinson's law is the adage that''work expands so as to fill the time
available for its completion``. It is sometimes applied to the growth of
bureaucracy in an organisation\ldots{} He explains this growth by two
forces: (1) `An official wants to multiply subordinates, not rivals' and
(2) `Officials make work for each other.'\,''

\sourceatright{\href{https://en.wikipedia.org/wiki/Parkinsons_law}{\textemdash  Parkinson's Law, \emph{Wikipedia}}  }
\end{quotation}

This implies that there is a tendency for organisations to end up with
\emph{needless levels of Bureaucratic Risk}.

\hypertarget{credit-risk}{%
\subsection{Credit Risk}\label{credit-risk}}

Where the process you depend on is being run by a third-party
organisation, (or that party depends on you) you are looking at Credit
Risk (also known as Counterparty Risk):

\begin{quotation}

``A credit risk is the risk of default on a debt that may arise from a
borrower failing to make required payments\ldots{} For example\ldots{} A
business or consumer does not pay a trade invoice when due {[}or{]} A
business does not pay an employee's earned wages when due''

\sourceatright{\href{https://en.wikipedia.org/wiki/Credit_risk}{\textemdash  Credit Risk, \emph{Wikipedia}}}
\end{quotation}

Money is \emph{changing hands} between you and the supplier of the
process, and often, the money doesn't transfer \emph{at the same time}
as the process is performed. Let's look at an example: Instead of
hosting my website on a server in my office, I could choose to host my
software project with an online provider. I am trading Complexity Risk
for Credit Risk, because now, I have to care that the supplier is
solvent.

There's a couple of ways this could go wrong: They may \emph{take my
payment}, but then turn off my account. Or, they could go bankrupt, and
leave me with the costs of moving to another provider (this is also
Dead-End Risk).

Mechanisms like
\href{https://en.wikipedia.org/wiki/Insurance_policy}{insurance},
\href{https://en.wikipedia.org/wiki/Contract}{contracts} and
\href{https://en.wikipedia.org/wiki/Guarantee}{guarantees} help mitigate
this risk at the cost of complexity and expense.

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/credit-risk-400dpi.png}
\caption{Credit Risk}
\end{figure}

\hypertarget{sign-offs}{%
\subsection{Sign-Offs}\label{sign-offs}}

Often, Processes will include sign-off steps. The Sign-Off is an
interesting mechanism: - By signing off on something for the business,
people are usually in some part staking their reputation on something
being right. - Therefore, you would expect that sign-off involves a lot
of Agency Risk: people don't want to expose themselves in
career-limiting ways. - Therefore, the bigger the risk they are being
asked to swallow, the more cumbersome and protracted the sign off
process.

Often, Sign Offs boil down to a balance of risk for the signer: on the
one hand, \emph{personal, career risk} from signing off, on the other,
the risk of upsetting the rest of the staff waiting for the sign-off,
and the Dead End Risk of all the effort gone into getting the sign off
if they don't.

This is a nasty situation, but there are a couple of ways to de-risk
this: - break Sign Offs down into bite-size chunks of risk that are
acceptable to those doing the sign-off. - Agree far-in-advance the
sign-off criteria. As discussed in Risk Theory, people have a habit of
heavily discounting future risk, and it's much easier to get agreement
on the \emph{criteria} than it is to get the sign-off.

\hypertarget{software-processes}{%
\subsection{Software Processes}\label{software-processes}}

tbd

tbd. processes as a response to legal environment.

\hypertarget{boundary-risk}{%
\chapter{Boundary Risk}\label{boundary-risk}}

In the previous few chapters on Dependency Risk we've touched on
Boundary Risk several times, but now it's time to tackle it head-on and
discuss this important type of risk.

In terms of the Risk Landscape, Boundary Risk is exactly as it says: a
\emph{boundary}, \emph{wall} or other kind of obstacle in your way to
making a move you want to make. This changes the nature of the Risk
Landscape, and introduces a maze-like component to it. It also means
that we have to make \emph{decisions} about which way to go, knowing
that our future paths are constrained by the decisions we make.

\begin{figure}
\centering
\includegraphics{images/generated/risks/boundary/boundary-risk-400dpi.png}
\caption{Boundary Risk}
\end{figure}

And, as we discussed in Complexity Risk, there is always the chance we
end up at a Dead End, and we've done work that we need to throw away. In
this case, we'll have to head back and make a different decision.

\hypertarget{emergence-through-choice}{%
\section{Emergence Through Choice}\label{emergence-through-choice}}

Boundary Risk is an emergent risk, which exists at the intersection of
Complexity Risk, Dependency Risk and Communication Risk. Because of
that, it's going to take a bit of time to pick it apart and understand
it, so we're going to build up to this in stages.

Let's start with an obvious example: Musical Instruments. Let's say you
want to learn to play some music. There are a \emph{multitude} of
options available to you, and you might choose an \emph{uncommon}
instrument like a
\href{https://en.wikipedia.org/wiki/Balalaika}{Balalaika} or a
\href{https://en.wikipedia.org/wiki/Theremin}{Theremin}, or you might
choose a \emph{common} one like a piano or guitar. In any case, once you
start learning this instrument, you have picked up the three risks
above:

\begin{itemize}
\tightlist
\item
  Dependency Risk You have a \emph{physical} Dependency on it in order
  to play music, so get to the music shop and buy one.
\item
  Communication Risk: You have to \emph{communicate} with the instrument
  in order to get it to make the sounds you want. And you have Learning
  Curve Risk in order to be able to do that.
\item
  Complexity Risk: As \emph{a music playing system}, you now have an
  extra component (the instrument), with all the attendant complexity of
  looking after that instrument, tuning it, and so on.
\end{itemize}

Those risks are true for \emph{any} instrument you choose. However, if
you choose the \emph{uncommon} instrument like the Balalaika, you have
\emph{worse} Boundary Risk, because the \emph{ecosystem} for the
balalaika is smaller. It might be hard to find a tutor, or a band
needing a balalaika. You're unlikely to find one in a friend's house
(compared to the piano, say).

Even choosing the Piano has Boundary Risk. By spending your time
learning to play the piano, you're mitigating Communication Risk issues,
but \emph{mostly}, your skills won't be transferable to playing the
guitar. Your decision to choose one instrument over another cements the
Boundary Risk: you're following a path on the Risk Landscape and
changing to a different path is \emph{expensive}.

Also, it stands to reason that making \emph{any} choice is better than
making \emph{no} choice, because you can't try and learn \emph{all} the
instruments. Doing that, you'd make no meaningful progress on any of
them.

\hypertarget{boundary-risk-for-software-dependencies}{%
\section{Boundary Risk For Software
Dependencies}\label{boundary-risk-for-software-dependencies}}

Let's look at a software example now.

As discussed in Software Dependency Risk, if we are going to use a
software tool as a dependency, we have to accept the complexity of it's
Interface, and learn the protocol of that interface. If you want to work
with it, you have to use it's protocol, it won't come to you.

Let's take a look at a hypothetical system structure, in the
accompanying diagram. In this design, we have are transforming data from
the \texttt{input} to the \texttt{output}. But how should we do it?

\begin{itemize}
\tightlist
\item
  We could go via \texttt{a}, using the Protocols of \texttt{a}, and
  having a dependency on \texttt{a}.
\item
  We could go via \texttt{b}, using the Protocols of \texttt{b}, and
  having a dependency on \texttt{b}.
\item
  We could choose the middle route, and avoid the dependency, but
  potentially pick up lots more Complexity Risk and Schedule Risk.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/boundary-risk-ps.png}
\caption{Our System receives data from the \texttt{input}, translates it
and sends it to the \texttt{output}. But which dependency should we use
for the translation, if any?}
\end{figure}

This is a basic \textbf{Translation} job from \texttt{input} to
\texttt{output}. Since we are talking about \textbf{Translation}, we are
clearly talking about Communication Risk again: our task in
\textbf{Integrating} all of these components is \emph{to get them to
talk to each other}.

From a Cyclomatic Complexity point of view, this is a very simple
structure, with low Complexity. But the choice of approach presents us
with Boundary Risk, because we don't know that we'll be able to make
them \emph{talk to each other} properly:

\begin{itemize}
\tightlist
\item
  Maybe \texttt{a} outputs dates in a strange calendar format that we
  won't understand.
\item
  Maybe \texttt{b} works on some streaming API basis, that is
  incompatible with the input protocol.
\item
  Maybe \texttt{a} runs on Windows, whereas our code runs on Linux.
\end{itemize}

\ldots{} and so on.

\hypertarget{boundary-risk-pinned-down}{%
\section{Boundary Risk Pinned Down}\label{boundary-risk-pinned-down}}

Wherever we integrate dependencies with complex Protocols, we
potentially have Boundary Risk. The more complex the systems being
integrated, the higher the risk. When we choose software tools or
libraries to help us build our systems, we are trading Complexity Risk
for Boundary Risk. It is:

\begin{itemize}
\tightlist
\item
  The \emph{sunk cost} of the Learning Curve we've overcome to integrate
  the dependency, when it fails to live up to expectations.
\item
  The likelihood of, and costs of changing in the future.
\item
  The rarity of alternatives (or, conversely, the risk of Lock In).
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-library.png}
\caption{The tradeoff for using a library}
\end{figure}

As we saw in Software Dependency Risk, Boundary Risk is a big factor in
choosing libraries and services. However, it can apply to any kind of
dependency:

\begin{itemize}
\tightlist
\item
  If you're depending on a Process or Organisation, they might change
  their products or quality, making the effort you put into the
  relationship worthless.
\item
  If you're depending on Staff, they might leave, meaning your efforts
  on training them don't pay back as well as you hoped.
\item
  If you're depending on an Event occurring at a particular time, you
  might have a lot of work to reorganise your life if it changes time or
  place.
\end{itemize}

\hypertarget{avoiding-boundary-risk-now}{%
\section{Avoiding Boundary Risk
Now\ldots{}}\label{avoiding-boundary-risk-now}}

Because of Boundary Risk's relationship to Learning Curve Risk, we can
avoid accreting it by choose the \emph{simplest} and \emph{fewest}
dependencies for any job. Let's look at some examples:

\begin{itemize}
\tightlist
\item
  \texttt{mkdirp} is an \href{https://www.npmjs.com}{npm} module
  defining a single function. This function takes a single string
  parameter and recursively creating directories. Because the protocol
  is so simple, there is almost no Boundary Risk.
\item
  Using a database with a JDBC driver comes with \emph{some} Boundary
  Risk: but the boundary is specified by a standard. Although the
  standard doesn't cover every aspect of the behaviour of the database,
  it does minimise risk, because if you are familiar with one JDBC
  driver, you'll be familiar with them all, and swapping one for another
  is relatively easy.
\item
  Using a framework like \href{https://spring.io}{Spring},
  \href{https://redux.js.org}{Redux} or
  \href{https://angularjs.org}{Angular} comes with higher Boundary Risk:
  you are expected to yield to the framework's way of behaving
  throughout your application. You cannot separate the concern easily,
  and swapping out the framework for another is likely to leave you with
  a whole new set of assumptions and interfaces to deal with.
\end{itemize}

\hypertarget{and-in-the-future}{%
\section{\ldots{} And In The Future}\label{and-in-the-future}}

Unless your project \emph{ends}, you can never be completely sure that
Boundary Risk \emph{isn't} going to stop you making a move you want. For
example:

\begin{itemize}
\tightlist
\item
  \texttt{mkdirp} might not work on a new device's Operating System,
  forcing you to swap it out.
\item
  You might discover that the database you chose satisfied all the
  features you needed at the start of the project, but came up short
  when the requirements changed later on.
\item
  The front-end framework you chose might go out-of-fashion, and it
  might be hard to find developers interested in working on the project
  because of it.
\end{itemize}

This third point is perhaps the most interesting aspect of Boundary
Risk: how can we ensure that the decisions we make now are future-proof?
In order to investigate this further, let's look at three things:
Plugins, Ecosystems and Evolution (again).

\hypertarget{plugins-ecosystems-and-evolution}{%
\section{Plugins, Ecosystems and
Evolution}\label{plugins-ecosystems-and-evolution}}

On the face of it,
\href{https://en.wikipedia.org/wiki/WordPress}{WordPress} and
\href{https://en.wikipedia.org/wiki/Drupal}{Drupal} \emph{should} be
very similar:

\begin{itemize}
\tightlist
\item
  They are both
  \href{https://en.wikipedia.org/wiki/Content_management_system}{Content
  Management Systems}
\item
  They both use a
  \href{https://en.wikipedia.org/wiki/LAMP_(software_bundle)}{LAMP
  (Linux, Apache, MySql, PHP) Stack}
\item
  They were both started around the same time (2001 for Drupal, 2003 for
  WordPress)
\item
  They are both Open-Source, and have a wide variety of
  \href{https://en.wikipedia.org/wiki/Plug-in_(computing)}{Plugins}.
  That is, ways for other programmers to extend the functionality in new
  directions.
\end{itemize}

In practice, they are very different. This could be put down to
different \emph{design goals}: it seems that WordPress was focused much
more on usability, and an easy learning curve, whereas Drupal supported
plugins for building things with complex data formats. It could also be
down to the \emph{design decisions}: although they both support
\href{https://en.wikipedia.org/wiki/Plug-in_\%28computing\%29}{Plugins},
they do it in very different ways.

(Side note: I wasn't short of go-to examples for this. I could have
picked on \href{https://en.wikipedia.org/wiki/TeamCity}{Team City} and
\href{https://en.wikipedia.org/wiki/Jenkins_(software)}{Jenkins} here
(\href{https://en.wikipedia.org/wiki/Continuous_integration}{Continuous
Integration} tools), or
\href{https://en.wikipedia.org/wiki/Apache_Maven}{Maven} and
\href{https://en.wikipedia.org/wiki/Gradle}{Gradle} (build tools). All
of these support plugins), and the \emph{choice} of plugins is dependent
on which I've chosen, despite the fact that the platforms are solving
pretty much the same problems. )

\hypertarget{ecosystems-and-systems}{%
\subsection{Ecosystems and Systems}\label{ecosystems-and-systems}}

The quality, and choice of plugins for a given platform, along with
factors such as community and online documentation is often called its
\href{https://en.wikipedia.org/wiki/Software_ecosystem}{ecosystem}:

\begin{quotation}

``as a set of businesses functioning as a unit and interacting with a
shared market for software and services, together with relationships
among them''

\sourceatright{\href{https://en.wikipedia.org/wiki/Software_ecosystem}{\textemdash  Software Ecosystem, \emph{Wikipedia}}}
\end{quotation}

You can think of the ecosystem as being like the footprint of a town or
a city, consisting of the buildings, transport network and the people
that live there. Within the city, and because of the transport network
and the amenities available, it's easy to make rapid, useful moves on
the Risk Landscape. In a software ecosystem it's the same: the ecosystem
has gathered together to provide a way to mitigate various different
Feature Risks in a common way.

tbd: talk about complexity within the boundary. (increased convenience?)

Ecosystem size is one key determinant of Boundary Risk: a \emph{large}
ecosystem has a large boundary circumference. Boundary Risk is lower
because your moves on the Risk Landscape are unlikely to collide with
it. The boundary \emph{got large} because other developers before you
hit the boundary and did the work building the software equivalents of
bridges and roads and pushing it back so that the boundary didn't get in
their way.

In a small ecosystem, you are much more likely to come into contact with
the edges of the boundary. \emph{You} will have to be the developer that
pushes back the frontier and builds the roads for the others. This is
hard work.

\hypertarget{evolution}{%
\subsection{Evolution}\label{evolution}}

In the real world, there is a tendency for \emph{big cities to get
bigger}. The more people that live there, the more services they
provide, and therefore, the more immigrants they attract. And, it's the
same in the software world. In both cases, this is due to the Network
Effect:

\begin{quotation}

``A network effect (also called network externality or demand-side
economies of scale) is the positive effect described in economics and
business that an additional user of a good or service has on the value
of that product to others. When a network effect is present, the value
of a product or service increases according to the number of others
using it.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Network_effect}{\textemdash  Network Effect, \emph{Wikipedia}}}
\end{quotation}

You can see the same effect in the adoption rates of WordPress and
Drupal, shown in the chart below. Note: this is over \emph{all sites on
the internet}, so Drupal accounts for hundreds of thousands of sites. In
2018, WordPress is approximately 32\% of all web-sites. For Drupal it's
2\%.

\begin{figure}
\centering
\includegraphics{images/wordpress-drupal-chart.png}
\caption{WordPress vs Drupal adoption over 8 years, according to
\href{https://w3techs.com/technologies/history_overview/content_management/all/y}{w3techs.com}}
\end{figure}

Did WordPress gain this march because it was better than Drupal? That's
arguable. That it's this way round could be \emph{entirely accidental},
and a result of Network Effect.

And maybe, they aren't comparable: Given the same problems, the people
in each ecosystem have approached them and solved them in different
ways. And, this has impacted the `shape' of the abstractions, and the
protocols you use in each. Complexity \emph{emerges}, and the ecosystem
gets more complex and opinionated, much like the way in which the
network of a city will evolve over time in an unpredictable way.

But, by now, if they \emph{are} to be compared side-by-side, WordPress
\emph{should be better} due to the sheer number of people in this
ecosystem who are\ldots{}

\begin{itemize}
\tightlist
\item
  Creating web sites.
\item
  Using those sites.
\item
  Submitting bug requests.
\item
  Fixing bugs.
\item
  Writing documentation.
\item
  Building plugins.
\item
  Creating features.
\item
  Improving the core platform.
\end{itemize}

But, there are two further factors to consider\ldots{}

\hypertarget{the-peter-principle}{%
\subsubsection{1. The Peter Principle}\label{the-peter-principle}}

When a tool or platform is popular, it is under pressure to increase in
complexity. This is because people are attracted to something useful,
and want to extend it to new purposes. This is known as \emph{The Peter
Principle}:

\begin{quotation}

``The Peter principle is a concept in management developed by Laurence
J. Peter, which observes that people in a hierarchy tend to rise to
their `level of incompetence'.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Peter_principle}{\textemdash  The Peter Principle, \emph{Wikipedia}}}
\end{quotation}

Although designed for \emph{people}, it can just as easily be applied to
any other dependency you can think of. Let's look at
\href{https://en.wikipedia.org/wiki/Java_(software_platform)}{Java} as
an example of this.

Java is a very popular platform. Let's look at how the number of public
classes (a good proxy for the boundary) has increased with each release:

\begin{figure}
\centering
\includegraphics{images/java_classes_by_version.png}
\caption{Java Public Classes By Version (3-9)}
\end{figure}

Why does this happen?

\begin{itemize}
\tightlist
\item
  More and more people are using Java for more and more things. It's
  popularity begets more popularity.
\item
  Human needs are \emph{fractal} in complexity. You can always find ways
  to make a dependency \emph{better} (For some meaning of better).
\item
  There is Feature Drift Risk: our requirements evolve with time.
  \href{https://en.wikipedia.org/wiki/Android_software_development}{Android
  Apps} weren't even a thing when Java 3 came out, for example, yet they
  are all written in Java now, and Java has had to keep up.
\end{itemize}

\hypertarget{backward-compatibility-1}{%
\subsubsection{2. Backward
Compatibility}\label{backward-compatibility-1}}

As we saw in Software Dependency Risk, The art of good design is to
afford the greatest increase in functionality with the smallest increase
in complexity possible, and this usually means
\href{https://en.wikipedia.org/wiki/Refactoring}{Refactoring}. But, this
is at odds with Backward Compatibility.

Each new version has a greater functional scope than the one before
(pushing back Boundary Risk), making the platform more attractive to
build solutions in. But this increases the Complexity Risk as there is
more functionality to deal with.

\hypertarget{focus-vs-over-reach}{%
\subsection{Focus vs Over-Reach}\label{focus-vs-over-reach}}

\begin{figure}
\centering
\includegraphics{images/kite9/boundary-risk-peter-principle.png}
\caption{The Peter Principle: Backward Compatibility + Extension leads
to complexity and learning curve risk}
\end{figure}

You can see in the diagram the Peter Principle at play: as more
responsibility is given to a dependency, the more complex it gets, and
the greater the learning curve to work with it. Large ecosystems like
Java react to Learning Curve Risk by having copious amounts of
literature to read or buy to help, but it is still off-putting.

Because Complexity is Mass, large ecosystems can't respond quickly to
Feature Drift. This means that when the world changes, \emph{new}
systems will come along to plug the gaps.

This implies a trade-off: - Sometimes it's better to accept the Boundary
Risk innate in a smaller system than try to work within the bigger, more
complex system.

example:

In the late 80's and 90's there was a massive push towards
\emph{building functionality in the database}.
\href{https://en.wikipedia.org/wiki/Relational_database}{Relational
Database Management Systems (RDBMSs)} were all-in-one solutions,
expensive platforms that you purchased and built \emph{everything}
inside. However, this dream didn't last:

why? (need some research here).

This tbd

tbd. diagram here.

\hypertarget{beating-boundary-risk-with-standards}{%
\section{Beating Boundary Risk With
Standards}\label{beating-boundary-risk-with-standards}}

Sometimes, technology comes along that allows us to cross boundaries,
like a \emph{bridge} or a \emph{road}. This has the effect of making it
easy to to go from one self-contained ecosystem to another. Going back
to WordPress, a simple example might be the
\href{https://en-gb.wordpress.org/plugins/google-analytics-dashboard-for-wp/}{Analytics
Dashboard} which provides
\href{https://en.wikipedia.org/wiki/Google_Marketing_Platform}{Google
Analytics} functionality inside WordPress.

I find, a lot of code I write is of this nature: trying to write the
\emph{glue code} to join together two different \emph{ecosystems}.

Standards allow us to achieve the same thing, in one of two ways:

\begin{itemize}
\tightlist
\item
  \textbf{Mode 1: Abstract over the ecosystems.} Provide a
  \emph{standard} protocol (a \emph{lingua franca}) which can be
  converted down into the protocol of any of a number of competing
  ecosystems.
\item
  \textbf{Mode 2: Force adoption.} All of the ecosystems start using the
  standard for fear of being left out in the cold. Sometimes, a
  standards body is involved, but other times a ``de facto'' standard
  emerges that everyone adopts.
\end{itemize}

Let's look at some examples:

\begin{itemize}
\item
  \href{https://en.wikipedia.org/wiki/ASCII}{ASCII}: fixed the
  different-character-sets boundary risk by being a standard that others
  could adopt. Before everyone agreed on ASCII, copying data from one
  computer system to another was a massive pain, and would involve some
  kind of translation.
  \href{https://en.wikipedia.org/wiki/Unicode}{Unicode} continues this
  work. (\textbf{Mode 1})
\item
  \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C}: The
  C programming language provided a way to get the same programs
  compiled against different CPU instruction sets, therefore providing
  some \emph{portability} to code. The problem was, each different
  operating system would still have it's own libraries, and so to
  support multiple operating systems, you'd have to write code against
  multiple different libraries. (\textbf{Mode 2})
\item
  \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}
  took what C did and went one step further, providing interoperability
  at the library level. Java code could run anywhere where Java was
  installed. (\textbf{Mode 2})
\item
  Internet Protocol: As we saw in Communication Risk, the Internet
  Protocol (IP) is the \emph{lingua franca} of the modern Internet.
  However, at one period of time, there were many competing standards.
  and IP was the ecosystem that ``won'', and was subsequently
  standardized by the
  \href{https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force}{IETF}.
  (\textbf{Mode 1})
\end{itemize}

\hypertarget{complex-boundaries}{%
\section{Complex Boundaries}\label{complex-boundaries}}

As shown in the above diagram, mitigating
\protect\hyperlink{boundary-risk}{Boundary Risk} involves taking on
complexity. The more Protocol Complexity there is to bridge the two
ecosystems, the more Complex the bridge will necessarily be.

\begin{sidewaystable} 

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.18\columnwidth}\raggedright
Protocol Risk From A\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Protocol Risk From B\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Resulting Bridge Complexity\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\raggedright
Example\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Simple\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Changing from one date format to another.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Status Dashboard, tbd\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Object-Relational Mapping (ORM) Tools, (see below)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High + Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Moderate, Versioned\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Simple Phone App, e.g.~note-taker or calculator\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Modern browser (see below)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Very Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Google Search, Scala (see below)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\end{sidewaystable} 

From examining the {[}Protocol Risk{]}{[}br1{]} at each end of the
bridge you are creating, you can get a rough idea of how complex the
endeavour will be:

\begin{itemize}
\tightlist
\item
  If it's low-risk at both ends, you're probably going to be able to
  knock it out easily. Like translating a date, or converting one file
  format to another.
\item
  Where one of the protocols is \emph{evolving}, you're definitely going
  to need to keep releasing new versions. The functionality of a
  \texttt{Calculator} app on my phone remains the same, but new versions
  have to be released as the phone APIs change, screens change
  resolution and so on.
\item
  tbd
\end{itemize}

Where boundaries

tbd Trying to create a complex, fractal surface. User requirements are
fractal in nature.

\hypertarget{object-relational-mapping}{%
\subsection{Object-Relational Mapping}\label{object-relational-mapping}}

For example,
\href{https://en.wikipedia.org/wiki/Object-relational_mapping}{Object
Relational Mapping (ORM)} has long been a problem in software. This is
Boundary-Crossing software trying to bridge the gap between Relational
Databases and
\href{https://en.wikipedia.org/wiki/Object-oriented_programming}{Object-Oriented
Languages} like Java). Building a \emph{general} library that does this
and is useful tbd said:

\begin{quote}
`Object/Relational Mapping is the Vietnam of Computer Science' -
\href{http://blogs.tedneward.com/post/the-vietnam-of-computer-science/}{Ted
Neward}
\end{quote}

This is a particularly difficult problem because the two ecosystems are
so \emph{rich} and \emph{complex} in the functionality they expose. But
what are the alternatives?

\begin{itemize}
\tightlist
\item
  Either back to building functionality within the database again, using
  stored procedures
\item
  Building \href{https://en.wikipedia.org/wiki/Object_database}{Object
  Databases}. It's interesting that neither of these really worked out.
\item
  Custom-building the bridge between the systems, one database call
  at-a-time in your own software.
\end{itemize}

This is tbd hobson's choice, there is strong debate about whether ORM is
a worse trade of mitigated Boundary Risk for attendant Complexity Risk
or not, and clearly will depend on your circumstances.

\hypertarget{scala}{%
\subsection{Scala}\label{scala}}

Mapping between complex boundaries is especially difficult if the
Boundaries are evolving and changing as you go. This means in ecosystems
that are changing rapidly, you are unlikely to be able to create lasting
bridges between them. Given that Java) is an old, large and complex
ecosystem, you would imagine that it would have a slow-enough rate of
change that abstracting technologies can be built on top of it safely.

Indeed, we see that happening with
\href{https://en.wikipedia.org/wiki/Clojure}{Clojure} and
\href{https://en.wikipedia.org/wiki/Kotlin_(programming_language)}{Kotlin},
two successful languages built on top of the
\href{https://en.wikipedia.org/wiki/Java_virtual_machine}{Java Virtual
Machine (JVM)} and offering compatibility with it.

\href{https://en.wikipedia.org/wiki/Scala_(programming_language)}{Scala}
is arguably the first mainstream language that tried to do the same
thing: it is trying to build a
\href{https://en.wikipedia.org/wiki/Functional_programming}{Functional
Programming} paradigm on top of the JVM, which traditionally has an
Object Oriented paradigm.

The problem faced by Scala is that Java didn't stay still: as soon as
they demonstrated some really useful features in Scala
(i.e.~stream-based processing), Java moved to include this new
functionality too. If they hadn't, the developer community would have
slowly drifted away and used Scala instead.

So, in a sense, Scala is a \emph{success story}: they were able to force
change to Java. But, once Java had changed, Scala was in the difficult
position of having two sets of competing features in the platform: the
existing Scala streams, and the new Java streams.

Clojure can interoperability with Java because on one side, the boundary
is simple: lisp is a simple language which lends itself to
re-implementation within other platforms. Therefore, the complexity of
the bridge is \emph{simple}: all that needs to be provided is a way to
call methods from Java to Clojure.

Scala and Java have a complex relationship because Scala creates it's
own complex boundary: it is syntactically and functionally a broad
language with lots of features. And so is Java. Mapping from one to the
other is therefore

for interoperability here. Why is one so different from the other?

\hypertarget{browsers}{%
\subsection{Browsers}\label{browsers}}

Web browsers are another surprisingly complex boundary. They have to
understand the following protocols:

\begin{itemize}
\tightlist
\item
  HTTP for loading resources (as we already reviewed in Communication
  Risk
\item
  HTML Pages, for describing the content of web pages.
\item
  Various image formats
\item
  \href{https://en.wikipedia.org/wiki/JavaScript}{JavaScript} for
  web-page \emph{interactivity}
\item
  \href{https://en.wikipedia.org/wiki/Cascading_Style_Sheets}{CSS} for
  web-page styling, animation and so on.
\item
  \ldots{} and several others.
\end{itemize}

Handling any one of these protocols alone is a massive endeavour, so
browsers are built on top of Software Libraries which handle each
concern, for example, Networking Libraries,
\href{https://en.wikipedia.org/wiki/Parsing\#Computer_languages}{Parsers}
and so on.

One way of looking at the browser is that it is a \emph{function}, where
those elements listed above are the \emph{inputs} to the function, and
the output is \emph{what is displayed on the screen}, as shown in the
image below.

tbd. browser as a function

There are three specific problems that make this a really complex
boundary:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  All of the standards above are \emph{evolving and improving}. And,
  although \href{https://en.wikipedia.org/wiki/HTML5}{HTML5} (say) is a
  reasonably well-specified standard, in reality, web pages tend not to
  adhere exactly to the letter of it. People make mistakes in the HTML
  they write, and it's up to the browser to try and figure out what they
  \emph{meant} to write, rather than what they did write. This makes the
  \emph{input} to the function extremely complex.
\item
  Similarly, the \emph{output} of the function is not well defined
  either, and relies a lot on people's \emph{subjective aesthetic
  judgement}. For example, if you insert a
  \texttt{\textless{}table\textgreater{}} into an HTML page, the
  specification doesn't say anything about exactly how big the table
  should be, the size of it's borders, the spacing of the content and so
  on. At least, initially, \emph{none} of this was covered by the HTML
  Specification. The CSS specification is over time clearing this up,
  but it's not \emph{exactly nailed down}, which means\ldots{}
\item
  That because there are various different browsers
  (\href{https://en.wikipedia.org/wiki/Google_Chrome}{Chrome},
  \href{https://en.wikipedia.org/wiki/Safari_(web_browser)}{Safari},
  \href{https://en.wikipedia.org/wiki/Internet_Explorer}{Internet
  Explorer},
  \href{https://en.wikipedia.org/wiki/Microsoft_Edge}{Microsoft Edge},
  \href{https://en.wikipedia.org/wiki/Firefox}{Firefox} etc.) and each
  browser has multiple different versions, released over a period of
  many years, you cannot, as a web-page developer know, \emph{a priori}
  what your web-page will look like to a user.
\end{enumerate}

As developers trying to build software to be delivered over the
Internet, this is therefore a source of common Boundary Risk. If you
were trying to build software to work in \emph{all browsers} and
\emph{all versions}, this problem would be nearly insurmountable. So, in
order to tackle this risk, we do the following:

\begin{itemize}
\tightlist
\item
  We pick a small (but commonly used) subset of browsers, and use
  features from the specifications that we know commonly work in that
  subset.
\item
  We test across the subset. Again, testing is \emph{harder than it
  should be}, because of problem 2 above, that the expected output is
  not exactly defined. This generally means you have to get humans to
  apply their \emph{subjective aesthetic judgement}, rather than getting
  machines to do it.
\item
  There is considerable pressure on browser developers to ensure
  consistency of behaviour across the implementations. If all the
  browsers work the same, then we don't face the Boundary Risk of having
  to choose just one to make our software work in. However, it's not
  always been like this\ldots{}
\end{itemize}

\hypertarget{vendor-lock-in}{%
\section{Vendor Lock-In}\label{vendor-lock-in}}

In the late 1990s, faced with the emergence of the nascent World Wide
Web, and the
\href{https://en.wikipedia.org/wiki/Netscape_Navigator}{Netscape
Navigator} browser,
\href{https://en.wikipedia.org/wiki/Microsoft}{Microsoft} adoped a
strategy known as
\href{https://en.wikipedia.org/wiki/Embrace_and_extend}{Embrace and
Extend}. The idea of this was to subvert the HTML standard to their own
ends by \emph{embracing} the standard and creating their own browser
Internet Explorer and then \emph{extending} it with as much
functionality as possible, which would then \emph{not work} in Netscape
Navigator. They then embarked on a campaign to try and get everyone to
``upgrade'' to Internet Explorer. In this way, they hoped to ``own'' the
Internet, or at least, the software of the browser, which they saw as
analogous to being the ``operating system'' of the Internet, and
therefore a threat to their own operating system,
\href{https://en.wikipedia.org/wiki/Microsoft_Windows}{Windows}.

There are two questions we need to ask about this, from the
point-of-view of understanding Boundary Risk:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Why was this a successful strategy?
\item
  Why did they stop doing this?
\end{enumerate}

Let's look at the first question then. Yes, it was a successful
strategy. In the 1990s, browser functionality was rudimentary.
Developers were \emph{desperate} for more features, and for more control
over what appeared on their web-pages. And, Internet Explorer was a free
download (or, bundled with Windows). By shunning other browsers and
coding just for IE, developers pushed Boundary Risk to the consumers of
the web pages and in return mitigated Feature Fit Risk: they were able
to get more of the functionality they wanted in the browser.

It's worth pointing out, \emph{this was not a new strategy}:

\begin{itemize}
\tightlist
\item
  Processor Chip manufacturers had done something similar in the tbds:
  by providing features (instructions) on their processors that other
  vendors didn't have, they made their processors more attractive to
  system integrators. However, since the instructions were different on
  different chips, this created Boundary Risk for the integrators. Intel
  and Microsoft were able to use this fact to build a big ecosystem
  around Windows running on Intel chips (so called, WinTel).
\item
  We have two main \emph{mobile} ecosystems:
  \href{https://en.wikipedia.org/wiki/IOS}{Apple's iOS} and
  \href{https://en.wikipedia.org/wiki/Android_(operating_system)}{Google's
  Android}, which are both \emph{very} different and complex ecosystems
  with large, complex boundaries. They are both innovating as fast as
  possible to keep users happy with their features. Tools like
  \href{https://en.wikipedia.org/wiki/Xamarin}{Xamarin} exist which
  allow you to build
\item
  Currently, Amazon Web Services (AWS) are competing with
  \href{https://en.wikipedia.org/wiki/Microsoft_Azure}{Microsoft Azure}
  and \href{https://en.wikipedia.org/wiki/Google_Cloud_Platform}{Google
  Cloud Platform} over building tools for
  \href{https://en.wikipedia.org/wiki/Platform_as_a_service}{Platform as
  a Service (PaaS)} (running software in the cloud). They are both
  racing to build new functionality, but at the same time it's hard to
  move from one vendor to another as there is no standardisation on the
  tools.
\item
  As we saw above, Database vendors tried to do the same thing with
  features in the database. Oracle particularly makes money over
  differentiating itself from competitors by providing features that
  other vendors don't have. Tom tbd provides a compelling argument for
  using these features thus:
\end{itemize}

\begin{quote}
tbd.
\end{quote}

The next question, is why did Microsoft \emph{stop} pursuing this
strategy? It seems that the answer is because they were made to. tbd.

\hypertarget{everyday-boundary-risks}{%
\section{Everyday Boundary Risks}\label{everyday-boundary-risks}}

Boundary Risk occurs all the time. Let's look at some ways:

\begin{itemize}
\tightlist
\item
  \textbf{Configuration}: When software has to be deployed onto a
  server, there has to be configuration (usually on the command line, or
  via configuration property files) in order to bridge the boundary
  between the \emph{environment it's running in} and the \emph{software
  being run}. Often, this is setting up file locations, security keys
  and passwords, and telling it where to find other files and services.
\item
  \textbf{Integration Testing}: Building a unit test is easy. You are
  generally testing some code you have written, aided with a testing
  framework. Your code and the framework are both written in the same
  language, which means low boundary risk. But, to \emph{integration
  test} you need to step outside this boundary and so it becomes much
  harder. This is true whether you are integrating with other systems
  (providing or supplying them with data) or parts of your own system
  (say testing the client-side and server parts together).
\item
  \textbf{User Interface Testing}: If you are supplying a
  user-interface, then the interface with the user is already a complex,
  under-specified risky protocol. Although tools exist to automate UI
  testing (such as
  \href{https://en.wikipedia.org/wiki/Selenium_(software)}{Selenium},
  these rarely satisfactorily mitigate this protocol risk: can you be
  sure that the screen hasn't got strange glitches, that the mouse moves
  correctly, that the proportions on the screen are correct on all
  browsers?
\item
  \textbf{Jobs}: When you pick a new technology to learn and add to your
  CV, it's worth keeping in mind how useful this will be to you in the
  future. It's career-limiting to be stuck in a dying ecosystem and need
  to retrain.
\item
  \textbf{Teams}: if you're given license to build a new product within
  an existing team, are you creating Boundary Risk by using tools that
  the team aren't familiar with?
\item
  \textbf{Organisations}: Getting teams or departments to work with each
  other often involves breaking down Boundary Risk. Often the
  departments use different tool-sets or processes, and have different
  goals making the translation harder. tbd
\end{itemize}

\hypertarget{boundary-risk-and-change}{%
\subsection{Boundary Risk and Change}\label{boundary-risk-and-change}}

You can't always be sure that a dependency now will always have the same
guarantees in the future:

\begin{itemize}
\tightlist
\item
  \textbf{Ownership changes} Microsoft buys
  \href{https://en.wikipedia.org/wiki/GitHub}{GitHub}. What will happen
  to the ecosystem around GitHub now?
\item
  \textbf{Licensing changes}. (e.g. \href{http://oracle.com}{Oracle}
  buys \textbf{Tangosol} who make
  \href{https://en.wikipedia.org/wiki/Oracle_Coherence}{Coherence} for
  example). Having done this, they increase the licensing costs of
  Tangosol to huge levels, milking the
  \href{https://en.wikipedia.org/wiki/Cash_cow}{Cash Cow} of the
  installed user-base, but ensuring no-one else is likely to use it.
\item
  \textbf{Better alternatives become available}: As a real example of
  this, I began a project in 2016 using
  \href{https://en.wikipedia.org/wiki/Apache_Solr}{Apache Solr}.
  However, in 2018, I would probably use
  \href{https://en.wikipedia.org/wiki/Elasticsearch}{ElasticSearch}. In
  the past, I've built web-sites using Drupal and then later converted
  them to use WordPress.
\end{itemize}

\hypertarget{patterns-in-boundary-risk}{%
\section{Patterns In Boundary Risk}\label{patterns-in-boundary-risk}}

In Feature Risk, we saw that the features people need change over time.
Let's get more specific about this:

\begin{itemize}
\tightlist
\item
  Human need is \href{https://en.wikipedia.org/wiki/Fractal}{Fractal}.
  This means that over time, software products have evolved to more
  closely map to human needs. Software that would have delighted us ten
  years ago lacks the sophistication we expect today.
\item
  Software and hardware are both is improving with time, due to
  evolution and the ability to support greater and greater levels of
  complexity.
\item
  Abstractions build too. As we saw in Process Risk, we
  \emph{encapsulate} earlier abstractions in order to build later ones.
\end{itemize}

If all this is true, the only thing we can expect in the future is that
the lifespan of any ecosystem will follow an arc through creation,
adoption, growth, use and finally either be abstracted over or
abandoned.

tbd diagram.

Although our discipline is a young one, we should probably expect to see
``Software Archaeology'' in the same way as we see it for biological
organisms. Already we can see the dead-ends in the software evolutionary
tree: COBOL and BASIC languages, CASE systems. Languages like FORTH live
on in PostScript, SQL is still embedded in everything

Boundary risk is \emph{inside} and \emph{outside}

\hypertarget{agency-risk}{%
\chapter{Agency Risk}\label{agency-risk}}

Coordinating a team is difficult enough when everyone on the team has a
single Goal. But, people have their own goals, too. Sometimes, the goals
harmlessly co-exist with the team's goal, but other times they don't.

This is Agency Risk. This term comes from finance and refers to the
situation where you (the ``principal'') entrust your money to someone
(the ``agent'') in order to invest it, but they don't necessarily have
your best interests at heart. They may instead elect to invest the money
in ways that help them, or outright steal it.

\begin{quotation}

``This dilemma exists in circumstances where agents are motivated to act
in their own best interests, which are contrary to those of their
principals, and is an example of moral hazard.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Principalâagent_problem}{\textemdash  Principal-Agent Problem, \emph{Wikipedia}}}
\end{quotation}

The less visibility you have of the agent's activities, the bigger the
risk. However, the whole \emph{point} of giving the money to the agent
was that you would have to spend less time and effort managing it.

\begin{figure}
\centering
\includegraphics{images/kite9/agency-risk-monitoring.png}
\caption{Mitigating Agency Risk Through Monitoring}
\end{figure}

Agency Risk clearly includes the behaviour of
\href{https://en.wiktionary.org/wiki/bad_actor}{Bad Actors}. But, this
is a very strict definition of Agency Risk. In software development,
we're not lending each other money, but we are being paid by the project
sponsor, so they are assuming Agency Risk by employing us.

As we saw in the previous chapter on Process Risk, Agency Risk doesn't
just apply to people: it can apply to \emph{running software} or
\emph{whole teams}.

Let's look at some examples of borderline Agency Risk situations, in
order to sketch out where the domain of this risk lies.

\hypertarget{personal-lives}{%
\section{Personal Lives}\label{personal-lives}}

We can't (shouldn't) expect people on a project to sacrifice their
personal lives for the success of the project, right? Except that
\href{https://en.wikipedia.org/wiki/Video_game_developer\#\%22Crunch_time\%22}{``Crunch
Time''} is exactly how some software companies work:

\begin{quotation}

``Game development\ldots{} requires long working hours and dedication
from their employees. Some video game developers (such as Electronic
Arts) have been accused of the excessive invocation of''crunch
time``.''Crunch time" is the point at which the team is thought to be
failing to achieve milestones needed to launch a game on schedule. "

\sourceatright{\href{https://en.wikipedia.org/wiki/Video_game_developer\#"Crunch_time"}{\textemdash  Crunch Time, \emph{Wikipedia}}}
\end{quotation}

People taking time off, going to funerals, looking after sick relatives
and so on are all Agency Risk, but they should be \emph{accepted} on the
project. They are a necessary Attendant Risk of having \emph{staff}
rather than \emph{slaves}.

\hypertarget{the-hero}{%
\section{The Hero}\label{the-hero}}

\begin{quotation}

``The one who stays later than the others is a hero.''

\sourceatright{\href{http://wiki.c2.com/?HeroCulture}{\textemdash  Hero Culture, \emph{Ward's Wiki}} <!-- tweet-end -->}
\end{quotation}

Conversely, Heroes put in more hours and try to rescue projects
single-handedly, often cutting corners like team communication and
process in order to get there.

Sometimes, projects don't get done without heroes. But other times, the
hero has an alternative agenda than just getting the project done:

\begin{itemize}
\tightlist
\item
  A need for control, and for their own vision.
\item
  A preference to work alone.
\item
  A desire for recognition and acclaim from colleagues.
\item
  For the job security of being a
  \href{https://en.wikipedia.org/wiki/Key_person_insurance}{Key Man}.
\end{itemize}

A team \emph{can} make use of heroism, but it's a double-edged sword.
The hero can becomes a bottleneck to work getting done, and because want
to solve all the problems themselves, they under-communicate.

\hypertarget{consultancies}{%
\section{Consultancies}\label{consultancies}}

When you work with an external consultancy, there is \emph{always} more
Agency Risk than with a direct employee. This is because as well as your
goals and the employee's goals, there is also the consultancy's goals.

This is a good argument for not using consultancies, but sometimes the
technical expertise they bring can outweigh this risk.

Also, try to look for \emph{hungry} consultancies: if you being a happy
client is valuable to them, they will work at a discount (either working
cheaper, harder or longer or more carefully) as a result.

\hypertarget{cv-building}{%
\section{CV Building}\label{cv-building}}

This is when someone decides that the project needs a dose of ``Some
Technology X'', but in actual fact, this is either completely unhelpful
to the project (incurring large amounts of Complexity Risk), or merely
less useful than something else.

It's very easy to spot CV building: look for choices of technology that
are incongruently complex compared to the problem they solve, and then
challenge by suggesting a simpler alternative.

\hypertarget{career-risk}{%
\section{Career Risk}\label{career-risk}}

\hypertarget{devil-makes-work}{%
\section{Devil Makes Work}\label{devil-makes-work}}

Heroes can be useful, but \emph{underused} project members are a
nightmare. The problem is, people who are not fully occupied begin to
worry that actually, the team would be better off without them, and then
wonder if their jobs are at risk.

The solution to this is ``busy-work'': finding tasks that, at first
sight, look useful, and then delivering them in an over-elaborate way
(Gold Plating)) that'll keep them occupied. This will leave you with
more Complexity Risk than you had in the first place.

Even if they don't worry about their jobs, doing this is a way to stave
off \emph{boredom}.

\hypertarget{pet-projects}{%
\section{Pet Projects}\label{pet-projects}}

\begin{quote}
A project, activity or goal pursued as a personal favourite, rather than
because it is generally accepted as necessary or important. -
\href{https://en.wiktionary.org/wiki/pet_project}{Pet Project,
\emph{Wiktionary}}
\end{quote}

Sometimes, budget-holders have projects they value more than others
without reference to the value placed on them by the business. Perhaps
the project has a goal that aligns closely with the budget holder's
passions, or its related to work they were previously responsible for.

Working on a pet project usually means you get lots of attention (and
more than enough budget), but due to Map and Territory Risk, it can fall
apart very quickly under scrutiny.

\hypertarget{morale-risk}{%
\section{Morale Risk}\label{morale-risk}}

\begin{quote}
Morale, also known as Esprit de Corps is the capacity of a group's
members to retain belief in an institution or goal, particularly in the
face of opposition or hardship -
\href{https://en.wikipedia.org/wiki/Morale}{Morale, \emph{Wikipedia}}
\end{quote}

Sometimes, the morale of the team or individuals within it dips, leading
to lack of motivation. Morale Risk is a kind of Agency Risk because it
really means that a team member or the whole team isn't committed to the
Goal, may decide their efforts are best spent elsewhere. Morale Risk
might be caused by:

\begin{itemize}
\tightlist
\item
  External factors: Perhaps the employees' dog has died, or they're
  simply tired of the industry, or are not feeling challenged.
\item
  If the team don't believe a goal is achievable, they won't commit
  their full effort to it. This might be due to to a difference in the
  evaluation of the risks on the project between the team members and
  the leader.
\item
  If the goal isn't considered sufficiently worthy, or the team isn't
  sufficiently valued.
\item
  In military science, a second meaning of morale is how well supplied
  and equipped a unit is. This would also seem like a useful reference
  point for IT projects. If teams are under-staffed or under-equipped,
  this will impact on motivation too.
\end{itemize}

\hypertarget{hubris-ego}{%
\section{Hubris \& Ego}\label{hubris-ego}}

It seems strange that humans are over-confident. You would have thought
that evolution would drive out this trait but apparently it's not so:

\begin{quotation}

``Now, new computer simulations show that a false sense of optimism,
whether when deciding to go to war or investing in a new stock, can
often improve your chances of winning.''

\sourceatright{\href{https://news.nationalgeographic.com/news/2011/09/110914-optimism-narcissism-overconfidence-hubris-evolution-science-nature/}{\textemdash  Evolution of Narcissism, \emph{National Geographic}}}
\end{quotation}

In any case, humans have lots of self-destructive tendencies that
\emph{haven't} been evolved away, and we get by.

Development is a craft, and ideally, we'd like developers to take pride
in their work. Too little pride means lack of care, but too much pride
is \emph{hubris}, and the belief that you are better than you really
are. Who does hubris benefit? Certainly not the team, and not the goal,
because hubris blinds the team to hidden risks that they really should
have seen.

Although over-confidence might be a useful trait when bargaining with
other humans, the thesis of everything so far is that Meeting Reality
will punish your over-confidence again and again.

Perhaps it's a little unfair to draw out one human characteristic for
attention. After all, we are riddled with biases. There is probably an
interesting article to be written about the effects of different biases
on the software development and project management processes. (This task
is left as an exercise for the reader.)

\hypertarget{software-processes-and-teams}{%
\section{Software Processes And
Teams}\label{software-processes-and-teams}}

Agency Risk doesn't just refer to people - it refers to anything which
has agency over it's actions.

\begin{quotation}

``Agency is the capacity of an actor to act in a given
environment\ldots{} Agency may either be classified as unconscious,
involuntary behaviour, or purposeful, goal directed activity
(intentional action).''

\sourceatright{\href{https://en.wikipedia.org/wiki/Agency_(philosophy}{\textemdash  Agency, \emph{Wikipedia}}) }
\end{quotation}

There is significant Agency Risk in running software \emph{at all}.
Since computer systems follow rules we set for them, we shouldn't be
surprised when those rules have exceptions that lead to disaster. For
example:

\begin{itemize}
\tightlist
\item
  A process continually writing log files until the disks fill up,
  crashing the system.
\item
  Bugs causing data to get corrupted, causing financial loss.
\item
  Malware infecting a system, and sending your passwords and data to
  undesirables.
\end{itemize}

Agency Risk also covers \emph{whole teams} too. It's perfectly possible
that a team within an organisation develops Goals that don't align with
those of the overall organisation. For example:

\begin{itemize}
\tightlist
\item
  A team introduces excessive Bureaucracy in order to avoid work it
  doesn't like.
\item
  A team gets obsessed with a particular technology, or their own
  internal process improvement, at the expense of delivering business
  value.
\item
  A marginalised team forces their services on other teams in the name
  of ``consistency''. (This can happen a lot with ``Architecture'',
  ``Branding'' and ``Testing'' teams, sometimes for the better,
  sometimes for the worse.)
\end{itemize}

\hypertarget{security}{%
\section{Security}\label{security}}

\hypertarget{security-1}{%
\subsection{Security}\label{security-1}}

Intersecting both the internal and external environments are security
concerns.

Interestingly, security is handled in very similar ways at all sorts of
levels:

\begin{itemize}
\tightlist
\item
  \textbf{Walls}: defences \emph{around} the complex system, to protect
  it's parts from the external environment.
\item
  \textbf{Doors}: ways to get \emph{in} and \emph{out} of the complex
  system, possibly with \emph{locks}.
\item
  \textbf{Guards}: to make sure only the right things go in and out.
  (i.e.~to try and keep out \emph{Bad Actors}).
\item
  \textbf{Police}: to defend from \emph{within} the system, against
  Agency Risk and \emph{invaders}.
\item
  \textbf{Subterfuge}: Hiding, camouflage, disguises, pretending to be
  something else. tbd
\end{itemize}

These work various levels in our own bodies: our \emph{cells} have
\emph{cell walls} around them, and \emph{cell membranes} that act as the
guards to allow things in and out. Our \emph{bodies} have \emph{skin} to
keep the world out, and we have \emph{mouths}, \emph{eyes}, \emph{pores}
and so on to allow things in and out. We have an \emph{immune system} to
act as the police.

Our societies work in similar ways: in medieval times, a city would have
walls, guards and doors to keep out intruders. Nowadays, we have customs
control, borders and passports.

We're waking up to the realisation that our software systems need to
work the same way: we have Firewalls to protect our organisations, we
lock down \emph{ports} on servers to ensure there are the minimum number
of doors to guard and we \emph{police} the servers ourselves with
monitoring tools and anti-virus software.

\begin{verbatim}
- Security Risk
  - Hacking
  - Denial Of Service
  - Security, Trust and Complexity
  - oWASp
\end{verbatim}

tbd, How much do compilers do for you? Now, they prevent many kinds of
security error. Libraries too.

Security risk thrives on complexity. As does Agency Risk generally.

\hypertarget{its-about-goals}{%
\section{It's About Goals}\label{its-about-goals}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/agency/agency-risk-400dpi.png}
\caption{Agency Risk}
\end{figure}

We've looked here at some illustrative examples of Agency Risk. But as
we stated at the beginning, Agency Risk at any level comes down to
differences of Goals between the different agents, whether they are
\emph{people}, \emph{teams} or \emph{software}.

So, having looked at agents \emph{individually}, it's time to look more
closely at Goals, and the Attendant Risks when aligning them amongst
multiple agents.

On to Coordination Risk\ldots{}

\hypertarget{coordination-risk}{%
\chapter{Coordination Risk}\label{coordination-risk}}

Coordination Risk is the risk that, a group of people (or processes),
maybe with a similar Goal In Mind they can fail to coordinate on a way
to meet this goal and end up making things worse. Coordination Risk is
embodied in the phrase ``Too Many Cooks Spoil The Broth'': more people,
opinions or agents often make results worse.

As in Agency Risk, we are going to use the term \emph{agent}, which
refers to anything with
\href{https://github.com/risk-first/website/wiki/Agency-Risk\#software-processes-and-teams}{agency}
in a system to decide it's own fate. That is, an agent has an Internal
Model, and can take actions based on it. Here, we're going to work on
the assumption that the agents \emph{are} working towards a common Goal,
even though in reality it's not always the case, as we saw in the
chapter on Agency Risk.

In this chapter, we'll first build up A Model Of Coordination Risk and
what exactly coordination means and why we do it. Then, we'll look at
some classic Problems of Coordination. Then, we're going to consider
agency at several different levels (because of Scale Invariance) . We'll
look at: - Team Decision Making, - Living Organisms, - Larger
Organisations and the staff within them, - and Software Processes.

\ldots{} and we'll consider how Coordination Risk is a problem at each
scale.

But for now, let's crack on and examine where Coordination Risk comes
from.

\hypertarget{a-model-of-coordination-risk}{%
\section{A Model Of Coordination
Risk}\label{a-model-of-coordination-risk}}

Earlier, in Dependency Risk, we looked at various resources (time,
money, people, events etc) and showed how we could Depend On Them,
taking on risk. Here, however, we're looking at the situation where
there is \emph{competition for those dependencies}, that is, Scarcity
Risk: other parties want to use them in a different way.

\hypertarget{competition}{%
\subsection{Competition}\label{competition}}

The basic problem of Coordination Risk, then, is \emph{competition}.
Sometimes, competition is desireable (such as in sports and in markets),
but sometimes competition is a waste and cooperation would be more
efficient. Without coordination, we would deliberately or accidentally
compete for the same Dependencies, which is wasteful.

Why is this wasteful?

One argument could come from
\href{https://en.wikipedia.org/wiki/Diminishing_returns}{Diminishing
Returns}, which says that the earlier units of a resource (say,
chocolate bars) give you more benefit than later ones.

We can see this in the graph below. Let's say A and B compete over a
resource, of which there are 5 units available. For every extra A takes,
B loses one. The X axis shows A's consumption of the resource, so the
biggest benefit to A is in the consumption of the first unit.

\begin{figure}
\centering
\includegraphics{images/sharing.png}
\caption{Sharing Resources. 5 units are available, and the X axis shows
A's consumption of the resource. B gets whatever remains. Total benefit
is maximised somewhere in the middle}
\end{figure}

As you can see, by \emph{sharing}, it's possible that the \emph{total
benefit} is greater than it can be for either individual. But sharing
requires coordination. Further, the more competitors involved, the
\emph{worse} a winner-take-all outcome is for total benefit.

Just two things are needed for competition to occur:

\begin{itemize}
\tightlist
\item
  Individual agents, trying to achieve Goals.
\item
  Scarce Resources, which the agents want to use as Dependencies.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-2.png}
\caption{A model of competition: scarce resources, and individual agents
competing for them.}
\end{figure}

\hypertarget{coordination-via-communication}{%
\subsection{Coordination via
Communication}\label{coordination-via-communication}}

The only way that the agents can move away from competition towards
coordination is via Communication, and this is where their coordination
problems begin.

You might think, therefore, that this is just another type of
Communication Risk problem, and that's often a part of it, but even with
synchronized Internal Models, coordination risk can occur. Imagine the
example of people all trying to madly leave a burning building. They all
have the same information (the building is on fire). If they coordinate,
and leave in an orderly fashion, they might all get out. If they don't,
and there's a scramble for the door, more people might die.

But commonly, Coordination Risk occurs where people have different ideas
about how to achieve a goal, and they have different ideas because they
have different evaluations of the Attendant Risk. As we saw in the
chapter on Communication Risk, we can only hope to synchronize Internal
Models if there are high-bandwidth Channels available for communication.

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/coordination-risk-400dpi.png}
\caption{Coordination Risk - Mitigated by Communication}
\end{figure}

\hypertarget{problems-of-coordination}{%
\section{Problems Of Coordination}\label{problems-of-coordination}}

Let's unpack this idea, and review some classic problems of
coordination, none of which can be addressed without good communication:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Merging Data}. If you are familiar with the source code
  control system, Git, you will know that this is a \emph{distributed}
  version control system. That means that two or more people can propose
  changes to the same files without knowing about each other. This means
  that at some later time, Git then has to merge (or reconcile) these
  changes together. Git is very good at doing this automatically, but
  sometimes, different people can independently change the same lines of
  code and these will have to be merged manually. In this case, a human
  arbitrator ``resolves'' the difference, either by combining the two
  changes or picking a winner.
\item
  \textbf{Consensus}. Making group decisions (as in elections) is often
  decided by votes. But having a vote is a coordination issue, and
  requires that everyone has been told the rules:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Where will the vote be held?
\item
  How long do you provide for the vote?
\item
  What do you do about absentees?
\item
  What if people change their minds in the light of new information?
\item
  How do you ensure everyone has enough information to make a good
  decision?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  \textbf{Factions}. Sometimes, it's hard to coordinate large groups at
  the same time, and ``factions'' can occur. That the world isn't a
  single big country is probably partly a testament to this: countries
  are frequently separated by geographic features that prevent the easy
  flow of communication (and force). We can also see this in distributed
  systems, with the ``split brain'') problem. This is where a network of
  processes becomes disconnected (usually due to a network failure
  between data centers), and you end up with two, smaller networks with
  different knowledge. We'll address in more depth later.
\item
  \href{https://en.wikipedia.org/wiki/Resource_allocation}{Resource
  Allocation}: Ensuring that the right people are doing the right work,
  or the right resources are given to the right people is a coordination
  issue. On a grand scale, we have Logistics, and
  \href{https://en.wikipedia.org/wiki/Economic_system}{Economic
  Systems}. On a small scale, the office's \emph{room booking system}
  solves the coordination issue of who gets a meeting room using a
  first-come-first-served booking algorithm.
\item
  Deadlock: Deadlock refers to a situation where, in an environment
  where multiple parallel processes are running, the processing stops
  and no-one can make progress because the resources each process needs
  are being reserved by another process. This is a specific issue in
  Resource Allocation, but it's one we're familiar with in the computer
  science industry. Compare with
  \href{https://en.wikipedia.org/wiki/Gridlock}{Gridlock}, where traffic
  can't move because other traffic is occupying the space it wants to
  move to already.
\item
  Race Conditions: A race condition is where we can't be sure of the
  result of a calculation, because it is dependent on the ordering of
  events within a system. For example, two separate threads writing the
  same memory at the same time (one ignoring and over-writing the work
  of the other) is a race.
\item
  \textbf{Contention}: Where there is Scarcity Risk for a Dependency, we
  might want to make sure that everyone gets fair use of it, by taking
  turns, booking, queueing and so on. As we saw in Scarcity Risk,
  sometimes, this is handled for us by the Dependency itself. However if
  it isn't, it's the \emph{users} of the dependency who'll need to
  coordinate to use the resource fairly, again, by communicating with
  each other.
\end{enumerate}

\hypertarget{team-decision-making}{%
\section{Team Decision Making}\label{team-decision-making}}

Within a team, Coordination Risk is at it's core about resolving
Internal Model conflicts in order that everyone can agree on a Goal In
Mind and cooperate on getting it done. Therefore, Coordination Risk is
worse on projects with more members, and worse in organizations with
more staff.

If you are engaged in a solo project, do you suffer from Coordination
Risk at all? Maybe: sometimes, you can feel ``conflicted'' about the
best way to solve a problem. And weirdly, usually \emph{not thinking
about it} helps. Sleeping too. (Rich Hickey calls this
``\href{https://www.youtube.com/watch?v=f84n5oFoZBc}{Hammock Driven
Development}''). This is probably because, unbeknownst to you, your
subconscious is furiously communicating internally, trying to resolve
these conflicts itself, and will let you know when it's come to a
resolution.

\href{https://en.wikipedia.org/wiki/Vroom-Yetton_decision_model}{Vroom
and Yetton} introduced a model of group decision making which delineated
five different styles of decision making within a team. These are
summarised in the table below (\textbf{AI, AII, CI, CII, GII}). To this,
I have added a sixth (\textbf{UI}), which is the \emph{uncoordinated}
option, where everyone competes. In the accompanying diagrams I have
adopted the following convention: - Thin lines with arrow-heads show a
flow of \emph{information}, either one-way or two-way. - Thick lines
show a flow of \emph{opinion}. - Boxes with corners are \emph{decision
makers}, whereas curved corners don't have a part in the decision.

\begin{figure}
\centering
\includegraphics{images/kite9/vroom-yetton.png}
\caption{Vroom And Yetton Decision Making Styles. ``d'' indicates
authority in making a decision. Thin lines with arrow-heads show
information flow, whilst thick lines show \emph{opinions} being passed
around.}
\end{figure}

\begin{sidewaystable} 

\begin{longtable}[]{@{}llllll@{}}
\toprule
\begin{minipage}[b]{0.07\columnwidth}\raggedright
Type\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedright
People Involved In Decision\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedright
Opinions\strut
\end{minipage} & \begin{minipage}[b]{0.24\columnwidth}\raggedright
Channels Of Communication\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{UI}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
0\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Competition\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
\emph{No Coordination}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{AI}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textbf{s} (One message to each \textbf{subordinate})\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Maximum Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Autocratic, top-down\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{AII}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
2 x \textbf{s} (Messages from/to each \textbf{subordinate})\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Autocratic, with information flow up.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{CI}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textgreater{} 2 x \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Individual Consultations\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{CII}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textgreater{} \textbf{s}2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Group Consultation\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{GII}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textgreater{} \textbf{s}2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Maximum Communication Risk, Schedule Risk\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Group Consultation with voting\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\end{sidewaystable} 

At the top, you have the \emph{least} consultative styles, and at the
bottom, the \emph{most}. At the top, decisions are made with just the
leader's Internal Model but moving down, the Internal Models of the rest
of the team are increasingly brought into play.

The decisions at the top are faster, but don't do much for mitigating
\textbf{Coordination Risk}. The ones below take longer, (incurring
Schedule Risk) but mitigate more \textbf{Coordination Risk}. Group
decision-making inevitably involves everyone \emph{learning}, and
improving their Internal Models.

The trick is to be able to tell which approach is suitable at which
time. Everyone is expected to make decisions \emph{within their realm of
expertise}: you can't have developers continually calling meetings to
discuss whether they should be using an
\href{https://en.wikipedia.org/wiki/Abstract_factory_pattern}{Abstract
Factory} or a
\href{https://en.wikipedia.org/wiki/Factory_method_pattern}{Factory
Method}, this would waste time. The critical question is therefore,
``what's the biggest risk?'' - Is the Coordination Risk greater? Are we
going to suffer Dead End Risk if the decision is made wrongly? What if
people don't agree with it? Poor leadership has an impact on Morale too.
- Is the Schedule Risk greater? If you have a 1-hour meeting with eight
people to decide a decision, that's \emph{one man day} gone right there:
group decision making is \emph{expensive}.

Hopefully, this model shows how \emph{organisation} can reduce
Coordination Risk. But, to make this work, we need more
\emph{communication}, and this has attendant complexity and time costs.
So, we can draw this diagram of our move on the Risk Landscape:

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-1.png}
\caption{Coordination Risk traded for Complexity Risk, Schedule Risk and
Communication Risk}
\end{figure}

\hypertarget{staff-as-agents}{%
\subsection{Staff As Agents}\label{staff-as-agents}}

Staff in a team have a dual nature: they are \textbf{Agents} and
\textbf{Resources} at the same time. The team depends on staff for their
resource of \emph{labour}, but they're also part of the decision making
process of the team, because they have agency over their own actions.

Part of Coordination Risk is about trying to mitigate differences in
Internal Models. So it's worth considering how varied people's models
can be: - Different skill levels - Different experiences - Expertise in
different areas - Preferences - Personalities

The job of harmonzing this on a project would seem to fall to the team
leader, but actually people are self-organising to some extent. This
process is called
\href{https://en.wikipedia.org/wiki/Tuckmans_stages_of_group_development}{Team
Development}:

\begin{quotation}

``The forming--storming--norming--performing model of group development
was first proposed by Bruce Tuckman in 1965, who said that these phases
are all necessary and inevitable in order for the team to grow, face up
to challenges, tackle problems, find solutions, plan work, and deliver
results.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Tuckmans_stages_of_group_development}{\textemdash  Tuckman's Stages Of Group Development, \emph{Wikipedia}}}
\end{quotation}

Specifically, this describes a process whereby a new group will form and
then be required to work together. In the process, they will have many
\emph{disputes}. Ideally, the group will resolve these disputes
internally and emerge as a \emph{Team}, with a common Goal In Mind.

They can be encouraged with orthogonal practices such as
\href{https://en.wikipedia.org/wiki/Team_building}{team-building
exercises} (generally, submitting everyone to extreme experiences in
order to bond them together). With enough communication bandwidth and
detente, a motivated team will self-organise code reviews, information
exchange and improve their practices.

As decribed above, the job of Coordination is Resource Allocation, and
so the skills of staff can potentially be looked at as resources to
allocate. This means handling Coordination Risk issues like:

\begin{itemize}
\tightlist
\item
  People leaving, taking their Internal Models and expertise with them
  Key Man Risk.
\item
  People requiring external training, to understand new tools and
  techniques Learning-Curve Risk.
\item
  People being protective about their knowledge in order to protect
  their jobs Agency Risk.
\item
  Where there are mixed ability levels, senior developers not helping
  juniors as it ``slows them down''.
\item
  People not getting on and not helping each other.
\end{itemize}

\begin{quotation}

``As a rough rule, three programmers organised into a team can do only
twice the work of a single programmer of the same ability - because of
time spent on coordination problems.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Gerald_Weinberg}{Gerald Wienberg, The Psychology of Computer Programming} }
\end{quotation}

\hypertarget{in-living-organisms}{%
\section{In Living Organisms}\label{in-living-organisms}}

Vroom and Yetton's organisational style isn't relevant to just teams of
people. We can see it in the natural world too. Although \emph{the
majority} of cellular life on earth (by weight) is
\href{http://www.stephenjaygould.org/library/gould_bacteria.html}{single
celled organisms}, the existence of \emph{humans} (to pick a single
example) demonstrates that sometimes it's better to try to mitigate
Coordination Risk and work as a team, accepting the Complexity Risk and
Communication Risk this entails. As soon as cells start working
together, they either need to pass \emph{resources} between them, or
\emph{control} and \emph{feedback}.

For example, in the human body, we have various
\href{https://en.wikipedia.org/wiki/List_of_systems_of_the_human_body}{systems}:

\begin{itemize}
\tightlist
\item
  The
  \href{https://en.wikipedia.org/wiki/Respiratory_system}{Respiratory
  System} which is responsible for ensuring that
  \href{https://en.wikipedia.org/wiki/Red_blood_cell}{Red Blood Cells}
  are replenished with Oxygen, as well as disposing of Carbon Dioxide.
\item
  The
  \href{https://en.wikipedia.org/wiki/Human_digestive_system}{Digestive
  System} which is responsible for extracting nutrition from food and
  putting them in our
  \href{https://en.wikipedia.org/wiki/Blood_plasma}{Blood Plasma}.
\item
  The
  \href{https://en.wikipedia.org/wiki/Circulatory_system}{Circulatory
  System} which is responsible for moving blood cells to all the rest of
  the body.
\item
  The \href{https://en.wikipedia.org/wiki/Nervous_system}{Nervous
  System} which is responsible for collecting information from all the
  parts of the body, dealing with it in the
  \href{https://en.wikipedia.org/wiki/Brain}{Brain} and issuing
  commands.
\item
  The \href{https://en.wikipedia.org/wiki/Motor_system}{Motor System}
  which contains muscles and bones, and allows us to move about.
\end{itemize}

\ldots{} and many others. Each of these systems contains organs, which
contain tissues, which contain cells of different types. (Even cells are
complex systems containing multiple different, communicating
sub-systems.) There is huge Complexity Risk here: the entire organism
fails if one of these systems fail (they are Single Points Of Failure,
although we can get by despite the failure of one lung or one leg say).

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-organism.png}
\caption{Hierarchy of Function in the Human Body}
\end{figure}

\href{https://www.quora.com/What-is-the-most-complex-object-in-the-universe}{Some
argue} that the human nervous system is the most complex known artifact
in the universe: there is huge attendant Communication Risk to running
the human body. But, given the success of humanity as a species, you
must conclude that these steps on the evolutionary Risk Landscape have
benefitted us in our ecological niche.

The key observation from looking at biology is this: most of the cells
in the human body \emph{don't get a vote}. Muscles in the motor system
have an \textbf{AI} or \textbf{AII} relationship with the brain - they
do what they are told, but there are often nerves to report pain back.
The only place where \textbf{CII} or \textbf{GII} \emph{could} occur is
in our brains, when we try to make a decision and weigh up the pros and
cons.

This means that there is a deal: \emph{most} of the cells in our body
accede control of their destiny to ``the system''. Living within the
system of the human body is a better option than going it alone.
Occasionally, due to mutation, we can end up with
\href{https://en.wikipedia.org/wiki/Cancer}{Cancer}, which is where one
cell genetically ``forgets'' its purpose in the whole system and goes
back to selfish individual self-replication (\textbf{UI}). We have
\href{https://en.wikipedia.org/wiki/White_blood_cell}{White Blood Cells}
in the body to shut down this kind of behaviour and try to kill the
rogue cells. In the same way, society has a police force to stop
undesireable behaviour amongst its citizens.

\hypertarget{large-organisations}{%
\section{Large Organisations}\label{large-organisations}}

Working in a large organisation often feels like being a cell in a
larger organism. Just as cells live and die, but the organism goes on,
in the same way, workers come and go from a large company but the
organisation goes on. By working in an organisation, we give up
self-control and competition and accept \textbf{AI} and \textbf{AII}
power structures above us, but we trust that there is symbiotic value
creation on both sides of the employment deal.

\emph{Less} consultative decision making styles are more appropriate
then when we don't have the luxury of high-bandwidth channels for
discussion, or when the number of parties rises above a room-full of
people. As you can see from the table above, for \textbf{CII} and
\textbf{GII} decision-making styles, the amount of communication
increases non-linearly with the number of participants, so we need
something simpler. As we saw in the Complexity Risk chapter, hierarchies
are an excellent way of economizing on number of different communication
channels, and we use these frequently when there are lots of parties to
coordinate.

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-organisation-temp.png}
\caption{Hierarchy of Function in an Organisation}
\end{figure}

In large organisations, teams are created and leaders chosen for those
teams precisely to mitigate Communication Risk. We're all familiar with
this: control of the team is ceded to the leader, who takes on the role
of `handing down' direction from above, but also `reporting up' issues
that cannot be resolved within the team. In Vroom and Yetton's model,
this is moving from a \textbf{GII} or \textbf{CII} to an \textbf{AI} or
\textbf{AII} style of leadership.

As shown in the diagram above, we end up with a hierarchy of groups,
each having it's own decision-making style. The team leader at the
bottom level is a \emph{decision maker} within his team, but moving up,
doesn't have decision making power in the next team up.. and so on.

Sometimes, parts of an organisation are encouraged \emph{not} to
coordinate, but to compete. In the diagram above, we have an
\href{https://en.wikipedia.org/wiki/Multi-divisional_form}{M-Form}
organisation, composed of \emph{competing divisions}.

Clearly, this is just a \emph{model}, it's not set in stone and decision
making styles usually change from day-to-day and decision to decision.
The same is not true in our software - \emph{rules are rules}.

\hypertarget{in-software-processes}{%
\section{In Software Processes}\label{in-software-processes}}

It should be pretty clear that we are applying the Scale Invariance rule
to Coordination Risk: all of the problems we've described as affecting
teams, also affect software, although the scale and terrain are
different. Software processes have limited \emph{agency} - in most cases
they follow fixed rules set down by the programmers, rather than
self-organising like people can (so far).

As before, in order to face Coordination Risk in software, we need
multiple agents all working together. Coordination Risks (such as race
conditions or deadlock) only really occurs where \emph{more than one
thing is happening at a time}. This means we are considering \emph{at
least} multi-threaded software and anything above that (multiple CPUs,
servers, data-centres and so on).

\hypertarget{cap-theorem}{%
\subsection{CAP Theorem}\label{cap-theorem}}

The \href{https://en.wikipedia.org/wiki/CAP_theorem}{CAP Theorem} has a
lot to say about Coordination Risk. Imagine talking to a distributed
database, where your request (\emph{read} or \emph{write}) can be
handled by one of many agents.

In the diagram below, we have just two agents \texttt{1} and \texttt{2},
in order to keep things simple. \texttt{User\ A} \emph{writes something}
to the database, then \texttt{User\ B} \emph{reads it back} afterwards.

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-cap-1.png}
\caption{User A and User B are both using a distributed database,
managed by Agents 1 and 2, whom each have their own Internal Model}
\end{figure}

According to the CAP Theorem, there are three properties we could desire
in such a system:

\begin{itemize}
\tightlist
\item
  \textbf{Consistency}: Every read receives the most recent value from
  the last write.
\item
  \textbf{Availability}: Every request receives a response.
\item
  \textbf{Partition tolerance}: The system can operate despite the
  isolation (lack of communication with) some of it's agents.
\end{itemize}

The CAP Theorem states that this is a
\href{https://en.wikipedia.org/wiki/Trilemma}{Trilemma}. That is, you
can only have two out of the three properties.

There are plenty of resources on the internet that discuss this in
depth, but let's just illustrate with some diagrams to show how this
plays out. In our diagram example, we'll say that \emph{any} agent can
receive the read or write. So this might be a \textbf{GII} decision
making system, because all the agents are going to need to coordinate to
figure out what the right value is to return for a read, and what the
last value written was. In these, the last write (setting X to 1) was
sent to Agent 1 which then becomes \emph{isolated}, and can't be
communicated with, due to network failure. What will User B get back?

\hypertarget{with-an-ap-system}{%
\subsubsection{With an AP System}\label{with-an-ap-system}}

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-cap-ap.png}
\caption{In an AP system, the User B will get back a \emph{stale value}
for X}
\end{figure}

With \texttt{AP}, you can see that \texttt{User\ B} is getting back a
\emph{stale value}. \texttt{AP} scenarios lead to Race Conditions:
\texttt{Agent\ 1}s availability determines what value \texttt{User\ B}
gets back.

\hypertarget{with-an-cp-system}{%
\subsubsection{With an CP System}\label{with-an-cp-system}}

\includegraphics{images/kite9/coordination-cap-cp.png} .

Where Agent 2 is left waiting for Agent 1 to re-appear, we are
\emph{blocked}. So CP systems lead to Deadlock scenarios.

\hypertarget{with-an-ca-system}{%
\subsubsection{With an CA System}\label{with-an-ca-system}}

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-cap-ca.png}
\caption{In an CA system, we can't have partition tolerance, so in order
to be consistent a single Agent has to do all the work}
\end{figure}

Finally, if we have a CA system, we are essentially saying that
\emph{only one agent is doing the work}. (You can't partition a single
agent, after all). But this leads to Resource Allocation and
\textbf{Contention} around use of the scarce resource of
\texttt{Agent\ 2}'s attention. (Both Coordination Risk issues we met
earlier.)

\hypertarget{some-real-life-examples}{%
\subsection{Some Real-Life Examples}\label{some-real-life-examples}}

This sets an upper bound on Coordination Risk: we \emph{can't} get rid
of it completely in a software system, -or- a system on any other scale.
Fundamentally, coordination problems are inescapable at some level. The
best we can do is mitigate it by agreeing on protocols and doing lots of
communication.

Let's look at some real-life examples of how this manifests in software.

\hypertarget{zookeeper}{%
\subsubsection{ZooKeeper}\label{zookeeper}}

First, \href{https://zookeeper.apache.org}{ZooKeeper} is an Open-Source
datastore, which is used a lot for coordinating a distributed systems,
and storing things like configuration information across them. If the
configuration of a distributed system gets changed, it's important that
\emph{all of the agents in the system know about it}, otherwise\ldots{}
disaster.

This \emph{seems} trivial, but it quickly gets out-of-hand: what happens
if only some of the agents receive the new information? What happens if
a datacentre gets disconnected while the update is happening? There are
lots of edge-cases.

ZooKeeper handles this by communicating inter-agent with it's own
protocol. It elects a \textbf{master agent} (via voting), turning it
into an \textbf{AI}-style team. If the master is lost for some reason, a
new leader is elected. \emph{Writes} are then coordinated via the
\textbf{master agent} who makes sure that a \emph{majority of agents}
have received and stored the configuration change before telling the
user that the transaction is complete. Therefore, ZooKeeper is a
\texttt{CP} system.

\hypertarget{git}{%
\subsubsection{Git}\label{git}}

Second, git is a (mainly) write-only ledger of source changes. However,
as we already discussed above, where different agents make incompatible
changes, someone has to decide how to resolve the conflicts so that we
have a single source of truth.

The Coordination Risk just \emph{doesn't go away}.

Since multiple users can make all the changes they like locally, and
merge them later, Git is an \texttt{AP} system: individual users may
have \emph{wildly} different ideas about what the source looks like
until the merge is complete.

\hypertarget{bitcoin}{%
\subsubsection{Bitcoin}\label{bitcoin}}

Finally, \href{https://en.wikipedia.org/wiki/Bitcoin}{Bitcoin (BTC)} is
a write-only
\href{https://en.wikipedia.org/wiki/Distributed_ledger}{distributed
ledger}, where agents \emph{compete} to mine BTC, but also at the same
time record transactions on the ledger. BTC is also \texttt{AP}, in a
similar way to Git. But new changes can only be appended if you have the
latest version of the ledger. If you append to an out-of-date ledger,
your work will be lost.

Because it's based on outright competition, if someone beats you to
completing a mining task, then your work is wasted. So, there is
\emph{huge} Coordination Risk.

For this reason, BTC agents coordinate into
\href{https://en.bitcoin.it/wiki/Comparison_of_mining_pools}{mining
consortia}, so they can avoid working on the same tasks at the same
time. But this in itself is a problem, because the whole \emph{point} of
BTC is that it's competitive, and no one entity has control. So, mining
pools tend to stop growing before they reach 50\% of the BTC network's
processing power. Taking control would be
\href{https://www.reddit.com/r/Bitcoin/comments/5fe9vz/in_the_last_24hrs_three_mining_pools_have_control/}{politically
disastrous} and confidence in the currency (such as there is) would
likely be lost.

\hypertarget{communication-is-for-coordination}{%
\section{Communication Is For
Coordination}\label{communication-is-for-coordination}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/coordination-risk-2-400dpi.png}
\caption{Coordination Risk - Mitigated by Software Tools}
\end{figure}

So, now we have a fundamental limit on how much Coordination Risk we can
mitigate. And, just as there are plenty of ways to mitigate Coordination
Risk within teams of people, organisations or living organisms, so it's
the case in software.

Earlier in this chapter, we questioned whether Coordination Risk was
just another type of Communication Risk. However, it should be clear
after looking at the examples of competition, cellular life and Vroom
and Yetton's Model that this is exactly \emph{backwards}:

\begin{itemize}
\tightlist
\item
  Most single-celled life has no need for communication: it simply
  competes for the available resources. If it lacks anything it needs,
  it dies.
\item
  There are \emph{no} lines of communication on the \textbf{UI}
  decision-type. It's only when we want to avoid competition, by sharing
  resources and working towards common goals that we need to
  communicate.
\item
  Therefore, the whole point of communication \emph{is for
  coordination}.
\end{itemize}

In the next chapter, Map And Territory Risk, we're going to look at some
new ways in which systems can fail, despite their attempts to
coordinate.

\hypertarget{map-and-territory-risk}{%
\chapter{Map And Territory Risk}\label{map-and-territory-risk}}

As we discussed in the chapter on Abstraction, our understanding of the
world is entirely informed by the names we give things and the
abstractions we create.

(In the same way, \textbf{Risk-First} is about \emph{identifying
patterns} within software development and calling them out.)

Our Internal Models are a model of the world based on these patterns,
and their relationships.

So there is a translation going on here: observations about the
arrangement of \emph{atoms} in the world get turned into patterns of
\emph{information} (measured in bits and bytes).

\begin{figure}
\centering
\includegraphics{images/kite9/mapter-bits-atoms.png}
\caption{Maps and Territories, and Communication happening between them}
\end{figure}

Map And Territory Risk is the risk we face because we base our behaviour
on our Internal Models rather than reality itself. It comes from the
expression ``Confusing the Map for the Territory'', attributed to Alfred
Korzybski:

\begin{quotation}

``Polish-American scientist and philosopher Alfred Korzybski remarked
that''the map is not the territory" and that ``the word is not the
thing'', encapsulating his view that an abstraction derived from
something, or a reaction to it, is not the thing itself. Korzybski held
that many people \emph{do} confuse maps with territories, that is,
confuse models of reality with reality itself."

\sourceatright{\href{https://en.wikipedia.org/wiki/Mapâterritory_relation}{\textemdash  Map-Territory Relation, \emph{Wikipedia}}}
\end{quotation}

In this chapter, we're going to make a case for analysing Map and
Territory Risk along the same axes we introduced for Feature Risk, that
is \textbf{Fitness}, \textbf{Audience} and \textbf{Evolution}. After
that, we are going to widen the scope by looking at Map and Territory
Risk within the context of \textbf{machines}, \textbf{people},
\textbf{hierarchies} and \textbf{markets}.

tbd - diagram of how our actions are based on the map, not the
territory.

\hypertarget{fitness}{%
\section{Fitness}\label{fitness}}

In the picture shown here, from the Telegraph newspaper, the driver
\emph{trusted} the SatNav to such an extent that he didn't pay attention
to the road-signs around him, and ended up getting stuck.

This wasn't borne of stupidity, but experience: SatNavs are pretty
reliable. \emph{So many times} the SatNav had been right, that the
driver stopped \emph{questioning its fallibility}.

\begin{figure}
\centering
\includegraphics{images/sat_nav.png}
\caption{Sat Nav Blunder Sends Asda Van Crashing Narrow Footpath -
Telegraph Newspaper}
\end{figure}

So, there are two Map and Territory Risks here:

\begin{itemize}
\tightlist
\item
  The Internal Model of the \emph{SatNav} contained information that was
  wrong: the track had been marked up as a road, rather than a path.
\item
  The Internal Model of the \emph{driver} was wrong: his abstraction of
  ``the SatNav is always right'' turned out to be only \emph{mostly}
  accurate.
\end{itemize}

\hypertarget{internal-models-as-dependencies-features}{%
\section{Internal Models as Dependencies,
Features}\label{internal-models-as-dependencies-features}}

What are the risks at play here? We've already looked in detail at the
Dependency Risks involved in relying on something like a SatNav, in the
Software Dependency Risk chapter. But here, we are really looking at the
\emph{Internal Models themselves} as a source of Dependency Risk too.

We could argue that the SatNav and the Driver's Internal Model had bugs
in them. That is, they both suffer the Feature Implementation Risk we
saw in the Feature Risk chapter. If a SatNav has too much of this, you'd
end up not trusting it, and getting a new one. With your \emph{personal}
Internal Model, you can't buy a new one, but you may learn to
\emph{trust certain abstractions less}, as this driver did.

In the Feature Risk chapter, we broke down Feature Risk on three axes:
\textbf{Fitness}, \textbf{Evolution} and \textbf{Audience}.

Lets do this again and see how each type of Feature Risk can manifest in
the Internal Model:

\begin{sidewaysfigure}
\centering
\includegraphics{images/generated/risks/map-and-territory/map_and_territory_table_1_sideways-400dpi.png}
\caption{Feature Risk, as manifested in the Internal Model}
\end{sidewaysfigure}

As with Features in a product, Information in an internal model has at
least these three dimensions:

\begin{itemize}
\tightlist
\item
  \textbf{Fitness}: as discussed above with the SatNav example, this is
  how closely the information matches reality, and how \emph{useful that
  is to us} (models that contain too much detail are as bad as models
  with too little).
\item
  \textbf{Audience}: is all about how a piece of information is
  \emph{shared} between many Internal Models, and it's this we are going
  to address further now.
\item
  \textbf{Evolution}: is all about how Internal Models change when they
  meet reality, and we'll cover that last.
\end{itemize}

\hypertarget{audience}{%
\section{Audience}\label{audience}}

We already know a lot about Internal Models and audience, as these have
been the subject of previous chapters:

\begin{itemize}
\tightlist
\item
  We know from looking at Communication Risk that communication allows
  us to \emph{share} information between Internal Models.
\item
  We know from Coordination Risk the difficulties inherent in aligning
  Internal Models so that they cooperate.
\item
  Job markets show us that there is demand for people with certain
  \emph{skills}. This demonstrates to us that Market Risk is as
  applicable to Internal Models containing certain information as it is
  to products containing Features. This was the focus of the Ecosystem
  discussion in Boundary Risk.
\end{itemize}

\ldots{} And, we're all familiar with \emph{memes}:

\begin{quotation}

``A meme acts as a unit for carrying cultural ideas, symbols, or
practices, that can be transmitted from one mind to another through
writing, speech, gestures, rituals, or other imitable phenomena with a
mimicked theme.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Meme}{\textemdash  Meme, \emph{Wikipedia}}}
\end{quotation}

Therefore, we should be able to track the rise-and-fall of \emph{ideas}
much as we can track stock prices. And in effect, this is what
\href{https://trends.google.com}{Google Trends} does. In the chart
below, we can see the relative popularity of two search terms over time.
This is probably as good an indicator as any of the audience for an
abstraction at any point in time.

\begin{figure}
\centering
\includegraphics{images/google-trends.png}
\caption{Relative popularity of ``Machine Learning'' and ``Big Data'' as
search terms on Google Trends, 2011-2018}
\end{figure}

\hypertarget{example-hype-cycles}{%
\subsection{Example: Hype Cycles}\label{example-hype-cycles}}

Most ideas (and most products) have a slow, hard climb to wide-scale
adoption. But some ideas seem to disperse much more rapidly and are
picked up quickly because they are exciting and promising, having
greater ``memetic potential'' within society. One way this evolution
manifests itself in the world is though the
\href{https://en.wikipedia.org/wiki/Hype_cycle}{Hype Cycle}:

\begin{quotation}

``The hype cycle is a branded graphical presentation developed and used
by the American research, advisory and information technology firm
Gartner, for representing the maturity, adoption and social application
of specific technologies. The hype cycle provides a graphical and
conceptual presentation of the maturity of emerging technologies through
five phases.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Hype_cycle}{\textemdash  Hype Cycle, \emph{Wikipedia}}}
\end{quotation}

The five phases (and the ``Hype'' itself) are shown in the chart below,
with the thick black line being ``Hype'':

\begin{figure}
\centering
\includegraphics{images/hype-cycle.png}
\caption{Hype Cycle, along with Map \& Territory Risk}
\end{figure}

Also in this diagram we are showing where the hype originates:

\begin{itemize}
\tightlist
\item
  The \textbf{saturation} of the idea within the audience (a dotted
  line).
\item
  The \textbf{amount known} about the idea by the audience (a Learning
  Curve, if you will, a dashed line).
\end{itemize}

Both of these are modelled with
\href{https://en.wikipedia.org/wiki/Cumulative_distribution_function\#Use_in_statistical_analysis}{Cumulative
Distribution} curves. From these two things, we can figure out where our
maximum Map and Territory Risk lies: it's the point where awareness of
an idea is farthest from the understanding of it. This acts as a
``brake'' on the \textbf{hype} around the idea, corresponding to the
``Trough of Disillusionment''.

Where the \textbf{saturation} and \textbf{knowledge} grow together,
there is no spike in Map and Territory Risk and we don't see the
corresponding ``Trough of Disillusionment'' at all, as shown in this
chart:

\begin{figure}
\centering
\includegraphics{images/hype-cycle2.png}
\caption{Hype Cycle 2: Slower growth of Map and Territory Risk means no
``Trough of Disillusionment''}
\end{figure}

\hypertarget{evolution-1}{%
\section{Evolution}\label{evolution-1}}

The chapter on Communication Risk introduced the following model for
ideas:

\begin{figure}
\centering
\includegraphics{images/generated/communication_marketing-400dpi.png}
\caption{Spread of information between Internal Models}
\end{figure}

But what happens next? As we saw in Boundary Risk, the \textbf{Peter
Principle} applies, people will use dependencies up to the point when
they start breaking down.

\hypertarget{example-metrics}{%
\subsection{Example: Metrics}\label{example-metrics}}

Let's dive into a specific example now: someone finds a useful new
metric that helps in evaluating performance.

It might be:

\begin{itemize}
\tightlist
\item
  \textbf{SLOC (Source Lines Of Code)}: i.e.~the number of lines of code
  each developer writes per day/week whatever.
\item
  \textbf{Function Points}: the number of function points a person on
  the team completes, each sprint.
\item
  \textbf{Code Coverage}: the number of lines of code exercised by unit
  tests.
\item
  \textbf{Response Time}: the time it takes to respond to an emergency
  call, say, or to go from a feature request to production.
\item
  \textbf{Release cadence}: number of releases a team performs, per
  month, say.
\end{itemize}

With some skill, they may be able to \emph{correlate} this metric
against some other more abstract measure of success. For example:

\begin{quotation}

quality is correlated with more releases

\end{quotation}

\begin{quotation}

user-satisfaction is correlated with SLOC

\end{quotation}

\begin{quotation}

revenue is correlated with response time

\end{quotation}

Because the \emph{thing on the right} is easier to measure than
\emph{the thing on the left}, it becomes used as a proxy (or, Map) for
the thing they are really interested in (the Territory). At this point,
it's \emph{easy} to communicate this idea with the rest of the team, and
\emph{the market value of the idea is high}: it is a useful
representation of reality, which is shown to be accurate at a particular
point in time.

But \emph{correlation} doesn't imply \emph{causation}. The \emph{cause}
might be different:

\begin{itemize}
\tightlist
\item
  quality and number of releases might both be down to the simplicity of
  the product.
\item
  user satisfaction and SLOC might both be down to the calibre of the
  developers.
\item
  response time and revenue might both be down to clever team planning.
\end{itemize}

Metrics are seductive because they simplify reality and are easily
communicated. But they \emph{inherently} contain Map and Territory Risk:
By relying \emph{only} on the metrics, you're not really \emph{seeing}
the reality.

The devil is in the detail.

\hypertarget{reality-evolves}{%
\subsection{Reality Evolves}\label{reality-evolves}}

In the case of metrics, this is where they start being used for more
than just indicators, but as measures of performance or targets:

\begin{itemize}
\tightlist
\item
  If a team is \emph{told} to do lots of releases, they will perform
  lots of releases \emph{at the expense of something else}.
\item
  If team members are promoted according to SLOC, they will make sure
  their code takes up as many lines as possible.
\item
  In the UK, ambulances were asked to wait before admitting patients to
  Emergency wards, in order that hospitals could
  \href{https://en.wikipedia.org/wiki/NHS_targets}{meet their targets}.
\end{itemize}

Some of this seems obvious: \emph{Of course} SLOC is a terrible measure
performance! We're not that stupid anymore. The problem is, it's not so
much the \emph{choice} of metric, but the fact that \emph{all} metrics
merely approximate reality with a few numbers. The map is \emph{always}
simpler than the territory, therefore there can be no perfect metrics.

In the same way that markets evolve to demand more features, our
behaviour evolves to incorporate new ideas. The more popular an idea is,
the more people will modify their behaviour as a result of it, and the
more the world will change. Will the idea still be useful as the world
adapts? Although the Hype Cycle model doesn't cover it, ideas and
products all eventually have their day and decline in usefulness.

\hypertarget{bad-ideas}{%
\subsection{Bad Ideas}\label{bad-ideas}}

There are plenty of ideas which \emph{seem a really good idea at the
time} but then end up being terrible. It's only as we \emph{learn about
the products} and realize the hidden Map and Territory Risk that we stop
using them. While SLOC is a minor offender,
\href{https://en.wikipedia.org/wiki/Chlorofluorocarbon}{CFCs} or
\href{https://en.wikipedia.org/wiki/Tetraethyllead}{Leaded Petrol} are
more significant examples.

The following Hype Cycle chart shows an initially promising idea that
turns out to be terrible, and there is a ``Period of Inoculation'' where
the population realise their mistake. There is ``negative hype'' as they
work to phase out the offending idea:

\begin{figure}
\centering
\includegraphics{images/hype-cycle3.png}
\caption{Hype Cycle For Something that turns out to be a \emph{bad}
idea}
\end{figure}

\hypertarget{humans-and-machines}{%
\section{Humans and Machines}\label{humans-and-machines}}

In the example of the SatNav, we saw how the \emph{quality} of Map and
Territory Risk is different for \emph{people} and \emph{machines}.
Whereas people \emph{should} be expected show skepticism to new
(unlikely) information, our databases accept it unquestioningly.
\emph{Forgetting} is an everyday, usually benign part of our human
Internal Model, but for software systems it is a production crisis
involving 3am calls and backups.

For Humans, Map and Territory Risk is exacerbated by
\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{cognitive
biases}:

\begin{quotation}

``Cognitive biases are systematic patterns of deviation from norm or
rationality in judgement, and are often studied in psychology and
behavioural economics.''

\sourceatright{\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{\textemdash  Cognitive Bias, \emph{Wikipedia}}}
\end{quotation}

There are \emph{lots} of cognitive biases. But let's just look at a
couple that are relevant to Map and Territory Risk:

\begin{itemize}
\tightlist
\item
  \textbf{Availability Heuristic}: People overestimate the importance of
  knowledge they have been exposed to.
\item
  \textbf{The Ostrich Effect}: Which is where dangerous information is
  ignored or avoided because of the emotions it will evoke.
\item
  \textbf{Bandwagon Effect}: People like to believe things that other
  people believe. Could this be a factor in the existence of the Hype
  Cycle?
\end{itemize}

\hypertarget{hierarchical-organisations}{%
\section{Hierarchical Organisations}\label{hierarchical-organisations}}

Map And Territory Risk ``trickles down'' through an organisation. The
higher levels have an out-sized ability to pervert the incentives at
lower levels because once an organisation begins to pursue a ``bullshit
objective'', the whole company can align to this.

\href{https://www.huffingtonpost.com/otto-scharmer/the-fish-rots-from-the-he_b_8208652.html}{The
Huffington Post} paints a brilliant picture of how Volkswagen managed to
get caught faking their emissions tests. As they point out:

\begin{quotation}

``The leadership culture of VW probably amplified the problem by
disconnecting itself from the values and trajectory of society, by
entrenching in what another executive in the auto industry once called a
``bullshit-castle''\ldots{} No engineer wakes up in the morning and
thinks: OK, today I want to build devices that deceive our customers and
destroy our planet. Yet it happened. Why? Because of hubris at the
top.''

\sourceatright{\href{https://www.huffingtonpost.com/otto-scharmer/the-fish-rots-from-the-he_b_8208652.html}{\textemdash  Otto Scharmer, \emph{Huffington Post}}.}
\end{quotation}

This article identifies the following process:

\begin{itemize}
\tightlist
\item
  \textbf{De-sensing}: VW Executives ignored \emph{The Territory}
  society around them (such as the green movement), ensuring their maps
  were out of date. The top-down culture made it hard for reality to
  propagate back up the hierarchy.
\item
  \textbf{Hubris/Absencing}: They pursued their own metrics of
  \emph{volume} and \emph{cost}, rather than seeking out others (a la
  the Availability Heuristic Bias). That is, focusing on their own
  \emph{Map}, which is \emph{easier} than checking the \emph{Territory}.
  (See Hubris in the Agency Risk chapter).
\item
  \textbf{Deception}: Backed into a corner, engineers had no choice but
  to find ``creative'' ways to meet the metrics.
\item
  \textbf{Destruction}: Eventually, the truth comes out, to the
  detriment of the company, the environment and the shareholders. As the
  article's title summarizes ``A fish rots from the head down''.
\end{itemize}

\hypertarget{personal-example}{%
\subsection{Personal Example}\label{personal-example}}

A similar (but less catastrophic) personal story from a bank I worked
at, where the objectives end up being mis-aligned \emph{within the
company}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  My team had been tasked with building automated ``smoke tests'' of an
  application. But this was bullshit: We only needed to build these
  \emph{at all} because the application was so complex. The reason it
  was so complex was\ldots{}
\item
  The application was being designed within a ``Framework'' constructed
  by the department. However, the framework was only being used by this
  one application. Building a ``reusable'' framework which is only used
  by a single application is bullshit. But, we had to do this
  because\ldots{}
\item
  The organisational structure was created along a ``matrix'', with
  ``business function'' on one axis and ``functional area'' on another.
  Although we were only building the application for a single business
  function, it was expected to cater with all the requirements from the
  an entire ``functional area''. This was bullshit too, because\ldots{}
\item
  The matrix structure was largely the legacy of a recent merger with
  another department. As
  \href{https://en.wikipedia.org/wiki/Conway\%27s_law}{Conway's Law}
  predicts, our software therefore had to reflect this structure. But
  this was bullshit because\ldots{}
\item
  The matrix structure didn't represent reality in any useful way. It
  was designed to pacify the budget committee at the higher level, and
  try to demonstrate attributes such as \emph{control} and
  \emph{governance}. But this was bullshit too, because\ldots{}
\item
  The budget that was given to our department was really based on how
  much fear the budget holders currently had of the market regulators.
  But this was bullshit too, because\ldots{}
\item
  At a higher level, the executives had realised that our division
  wasn't one of the banks strategic strengths, and was working to close
  it all down anyway.
\end{enumerate}

When faced with so many misaligned objectives, it seemed completely
hopeless to concentrate on the task at hand. But then, a colleague was
able to nihilistically add one final layer to this onion by saying:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  ``It's all about chasing money, which is bullshit, because life is
  bullshit.''
\end{enumerate}

\hypertarget{picking-fights}{%
\subsection{Picking Fights}\label{picking-fights}}

It feels like there's no way back from that.

All of life might well be a big Map and Territory illusion. But let's
analyse just a bit:

\begin{itemize}
\tightlist
\item
  At each layer, the objectives changed. But, they impacted on the
  objectives of the layer below.
\item
  Therefore, it seems like the more layers you have, the less likely it
  is that your objectives become inconsistent between the lower and
  higher levels.
\item
  On a new project, it seems like a good idea to model this stuff: does
  the objective of the work you're about to undertake ``align'' with the
  objectives at a higher level?
\end{itemize}

Trying to spot Map and Territory Risk ahead-of-time in this manner seems
like a useful way of trying to avoid Vanity Projects, and, if you are
good at it, allows you to see which Goals in the organisation are
fragile and likely to change. However, usually, if you are working in a
team, you have limited agency to decide which projects you feel are
valuable.

This comes down to a personal decision: do you want to spend time
working on projects that you know are going in the bin? Some developers
have the attitude that, so long as they get paid, it doesn't matter. But
others are in it for the satisfaction of the work itself, so this ends
up being a personal call.

(This theme will be developed further in Staging and Classifying.)

\hypertarget{markets}{%
\section{Markets}\label{markets}}

So far, we've considered what happens to individuals, teams and
organisations when told to optimise around a particular objective. In
Coordination Risk we looked at how communication was critical for
coordination to happen. And, as we've already discussed, Abstraction is
a key part of communication.

The languages we adopt or create are \emph{sets of useful abstractions}
that allow us to communicate. But what happens when this goes wrong?

\href{https://equilibriabook.com}{Inadequate Equilibria} by Eleizer
Yudkovsky, looks at how perverse incentive mechanisms break not just
departments, but entire societal systems. He highlights one example
involving \emph{academics} and \emph{grantmakers} in academia:

\begin{itemize}
\tightlist
\item
  It's not very apparent which scientists are better than which other
  scientists.
\item
  One proxy is what they've published (scientific papers) and where
  they've published (journals).
\item
  Universities want to attract research grants, and the best way to do
  this is to have the best scientists.
\item
  Because ``best'' isn't measurable, they use the proxy.
\item
  Therefore, immense power rests in the hands of the journals, since
  they can control the money-proxy.
\item
  Therefore, journals are able to charge large amounts of money to
  universities for subscriptions.
\end{itemize}

\begin{quotation}

``Now consider the system of scientific journals\ldots{} Some journals
are prestigious. So university hiring committees pay the most attention
to publications in that journal. So people with the best, most
interesting-looking publications try to send them to that journal. So if
a university hiring committee paid an equal amount of attention to
publications in lower-prestige journals, they'd end up granting tenure
to less prestigious people. Thus, the whole system is a stable
equilibrium that nobody can unilaterally defy except at cost to
themselves.''

\sourceatright{\href{https://equilibriabook.com/molochs-toolbox/}{\textemdash  Inadequate Equilibria, \emph{Eleizer Yudkovsky}}}
\end{quotation}

As the book points out, while everyone \emph{persists} in using an
inadequate abstraction, the system is broken. However, Coordination
would be required for everyone to \emph{stop} doing it this way, which
is hard work. (At least within a hierarchy, Maps can get fixed.)

This is a \emph{small example} from a much larger, closely argued book,
and it's worth taking the time to read a couple of the chapters on this
interesting topic.

As usual, this chapter forms a grab-bag of examples in a complex topic.
But it's time to move on as there is one last stop we have to make on
the Risk Landscape, and that is to look at Operational Risk.

(NB: The Hype Cycle model is available in \textbf{Numbers} form
\href{https://github.com/risk-first/website/blob/master/RiskMatrix.numbers}{here}.)

\begin{figure}
\centering
\includegraphics{images/generated/risks/map-and-territory/map-and-territory-risk-400dpi.png}
\caption{Map And Territory Risk}
\end{figure}

(talk about how operational risk is an extension of this). tbd

\hypertarget{operational-risk}{%
\chapter{Operational Risk}\label{operational-risk}}

In this chapter on \protect\hyperlink{operational-risks}{Operational
Risks}, we're going to start considering the realities of running
software systems in the real world.

Here, we're going to set the scene by looking at what constitutes an
Operational Risk, and then look at the related disciplines of Operations
Management and {[}Operational Risk Management{]}. Following this
background, we'll apply the Risk-First model and dive into the various
mitigations for Operational Risk.

\hypertarget{operational-risks}{%
\section{Operational Risks}\label{operational-risks}}

It's tempting to take a very narrow view of the dependencies of a
system, but Operational Risks are often caused by dependencies we don't
consider - the \emph{context} within which the system is operating. Here
are some examples:

\begin{itemize}
\tightlist
\item
  Staff Dependencies (Staff Risk):

  \begin{itemize}
  \tightlist
  \item
    Freak weather conditions affecting ability of staff to get to work,
    interrupting the development and support teams.
  \item
    Reputational damage caused when staff are rude to the customers.
  \end{itemize}
\item
  Infrastructure Dependencies (Reliability Risk):

  \begin{itemize}
  \tightlist
  \item
    A data-centre going off-line, causing your customers to lose access.
  \item
    A power cut causing backups to fail.
  \item
    Not having enough desks for everyone to sit at.
  \end{itemize}
\item
  Process Dependencies (Process Risk):

  \begin{itemize}
  \tightlist
  \item
    Regulatory change, which means you have to adapt your business
    model.
  \item
    Insufficient controls which means you don't notice when some
    transactions are failing, leaving you out-of-pocket.
  \item
    Data loss because of bugs introduced during an untested release.
  \end{itemize}
\item
  Software Dependencies (Software Dependency Risk):

  \begin{itemize}
  \tightlist
  \item
    Hackers breaking into the system and bringing your service down.
  \end{itemize}
\item
  Agency Dependencies (Agency Risk):

  \begin{itemize}
  \tightlist
  \item
    Suppliers deciding to stop supplying you with something you need.
  \item
    Workers going on strike.
  \item
    Employees trying to steal from the company (bad actors).
  \end{itemize}
\end{itemize}

.. basically, a long laundry-list of everything that can go wrong due to
operating in ``The Real World''.

So,
\href{https://en.wikipedia.org/wiki/Operational_risk_management}{Operational
Risk Management} is the purview of dealing with all the types of issues
listed above:

\begin{quotation}

``Operational Risk Management is the oversight of Operational Risk,
including the risk of loss resulting from inadequate or failed internal
processes and systems; human factors; or external events.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Operational_risk_management}{\textemdash  Operational Risk Management, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{operations-management}{%
\section{Operations Management}\label{operations-management}}

If we are designing a software system to ``live'' in the real world, we
have to be mindful of the environment we're working in, and adapt our
software and processes accordingly. This view of the ``wider'' system is
the discipline of Operations Management. The below diagram (from
\href{http://amzn.eu/d/b6ZjuMu}{``Operations Management'' by \emph{Slack
et al.}}) breaks down some of the concerns of this discipline.

\begin{figure}
\centering
\includegraphics{images/kite9/operations_management.png}
\caption{A General Model of Operations Management}
\end{figure}

In this diagram, a \textbf{Transform Process} (the \textbf{Operation}
itself) is embedded in the \textbf{Environment}, which supplies it with
three key dependencies:

\begin{itemize}
\tightlist
\item
  The \textbf{Resources} it needs, whether \emph{transformed} resources
  (like electricity or information, say).
\item
  It's \textbf{Customers}, which supply it with money in return for
  goods and services, and
\item
  An \textbf{Operational Strategy} to follow.
\end{itemize}

We have looked at processes like the \textbf{Transform Process} in the
chapter on Process Risk. The healthy functioning of this process is the
domain of Operations Management, and in the diagram this involves the
following tasks:

\begin{itemize}
\tightlist
\item
  \textbf{Control}: Ensuring that the Operation is working according to
  its design. This includes quality control.
\item
  \textbf{Improvement}: Improving the operation in response to changes
  in the \textbf{Environment} and the \textbf{Operational Strategy},
  detecting failure and recovering from it.
\item
  \textbf{Planning}: This covers aspects such as capacity planning,
  forecasting and project planning.
\item
  \textbf{Design}: Ensuring that the design of the product and the
  transform process itself fulfils an \textbf{Operational Strategy}.
\end{itemize}

\hypertarget{mitigating-operational-risk}{%
\section{Mitigating Operational
Risk}\label{mitigating-operational-risk}}

We've spent a lot of time looking at the varieties of Dependency Risk on
a software project. But in the ``real world'' of Operational Risk we
have to consider that these dependencies will fail in any number of
unusual ways, and we can't be ready for all of them.

For this reason, the toolbox of mitigations for Operatational Risk is
somewhat different to that for regular dependencies. Here we're going to
focus on four \emph{basic strategies}, and show how they align with the
activities described above.

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/operational-risk-400dpi.png}
\caption{Diagram of Four Strategies to Mitigate Operational Risk}
\end{figure}

As shown in this diagram, these are Meeting Reality, Monitoring \&
Detection, Design \& Change and Forecasting \& Planning.

\hypertarget{meeting-reality-1}{%
\section{Meeting Reality}\label{meeting-reality-1}}

Once exposed to the real world, no system is perfect. This means we must
design-in ways in which the systems we build can improve and change.
Since we don't have a perfect understanding of the world, most of the
Operational Risk we face is Hidden Risks.

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/meeting-reality-400dpi.png}
\caption{Taking action against Operational Risk by Meeting Reality}
\end{figure}

\hypertarget{reputational-risk}{%
\subsection{Reputational Risk}\label{reputational-risk}}

Our production systems are Meeting Reality all the time, and in order to
mitigate Operational Risk we need to take the most advantage of this as
possible. However, conversely, Operational Risk includes
\textbf{Reputational Risk}, which gives us pause: we don't want to
destroy good will created for our organisation, this is very hard to
rebuild.

So there is a tension between ``you only get one chance to make a first
impression'' and ``gilding the lilly'' (perfectionism). In the past I've
seen this stated as:

\begin{quotation}

Pressure to ship vs pressure to improve

\end{quotation}

A Risk-First re-framing of this might be the balance between:

\begin{itemize}
\tightlist
\item
  The perceived Reputational Risk, Feature Risk and Operational Risk of
  going to production (pressure to improve).
\item
  The perceived Scarcity Risks (such as funding, time available, etc) of
  staying in development (pressure to ship).
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/ship-it-400dpi.png}
\caption{Balance of Risks from Delivering Software}
\end{figure}

The ``should we ship?'' decision is therefore a complex one. In Meeting
Reality, we discussed that it's better to do this ``sooner, more
frequently, in smaller chunks and with feedback''. We can meet
Operational Risk \emph{on our own terms} by doing so:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Meet Reality\ldots{}\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Techniques\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{Sooner}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Quality Control Processes, Limited Early-Access Programs, Beta Programs,
Soft Launches, Business Continuity Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{More Frequently}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Continuous Delivery, Sprints\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{In Smaller Chunks}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Modular Releases, Microservices, Feature Toggles, Trial
Populations\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{With Feedback}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
User Communities, Support Groups, Monitoring, Logging, Analytics\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{monitoring-and-detection}{%
\section{Monitoring and Detection}\label{monitoring-and-detection}}

Monitoring \& Detection is the second strategy for mitigating
Operational Risk, and in terms of practices, broadly corresponds to
Slack's \emph{Improvement} category, above.

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/monitoring-detection-400dpi.png}
\caption{Monitoring And Detection}
\end{figure}

Since Humans and machines have different areas of expertise, and because
Operational Risks are often novel, it's often not optimal to try and
automate everything. A good operation will consist of a mix of human and
machine actors, each playing to their strengths (see the table below).

\begin{longtable}[]{@{}ll@{}}
\toprule
Humans Are\ldots{} & Machines Are\ldots{}\tabularnewline
\midrule
\endhead
Good at novel situations & Good at repetitive situations\tabularnewline
Good at adaptation & Good at consistency\tabularnewline
Expensive at scale & Cheap at scale\tabularnewline
Reacting and Anticipating & Recording\tabularnewline
\bottomrule
\end{longtable}

The aim is to build a human-machine operational system that is
\href{https://en.wikipedia.org/wiki/Homeostasis}{Homeostatic}. This is
the property of living things to try and maintain an equilibrium (for
example, body temperature or blood glucose levels), but also applies to
organisations at any scale. The key is to build systems with feedback
loops, even though this leads to more complex systems overall.

\hypertarget{performance-risk}{%
\subsection{Performance Risk}\label{performance-risk}}

As we saw in Map and Territory Risk, it's very easy to fool yourself,
especially around Key Performance Indicators (KPIs) and metrics. Good
Operations Management is about going beyond this and looking for
trouble. Large organisations have
\href{https://en.wikipedia.org/wiki/Audit}{Audit} functions precisely to
guard against their own internal failing Processes and Agency Risk.
Audits could be around software tools, processes, practices, quality and
so on. Practices such as
\href{https://en.wikipedia.org/wiki/Continual_improvement_process}{Continuous
Improvement} and
\href{https://en.wikipedia.org/wiki/Total_quality_management}{Total
Quality Management} also figure here.

\hypertarget{the-operational-context}{%
\subsection{The Operational Context}\label{the-operational-context}}

\begin{itemize}
\tightlist
\item
  \emph{Environmental Scanning} is all about trying to determine which
  changes in the environment are going to impact your operation. Here,
  we are trying to determine the level of Dependency Risk we face for
  external dependencies, such as \emph{suppliers}, \emph{customers} and
  \emph{markets}. Tools like
  \href{https://en.wikipedia.org/wiki/PEST_analysis}{PEST} are relevant
  here, as is
\item
  \href{https://en.wikipedia.org/wiki/Penetration_test}{Penetration
  Testing} is looking for security weaknesses within the operation. See
  \href{https://en.wikipedia.org/wiki/OWASP}{OWASP} for examples.
\item
  \href{https://en.wikipedia.org/wiki/Vulnerability_management}{Vulnerability
  Management} is keeping up-to-date with vulnerabilities in Software
  Depenendencies.
\end{itemize}

\hypertarget{forecasting-and-planning}{%
\section{Forecasting and Planning}\label{forecasting-and-planning}}

Dependencies are not just things we \emph{use}: For a system to run
well, it needs to carefully manage unreliable dependencies, and ensure
their safety and availability. In the example of the humans, say, it's
the difference between
\href{https://en.wikipedia.org/wiki/Hunter-gatherer}{Hunter-Gathering}
(picking up food where we find it) and
\href{https://en.wikipedia.org/wiki/Agriculture}{Agriculture}.

Forecasting and Planning then is a strategy we can bring to bear on
dependency management, and this usually falls to the more human end of
the operation.

\includegraphics{images/generated/risks/operational/forecasting-planning-400dpi.png}
.

\hypertarget{design-and-change}{%
\section{Design and Change}\label{design-and-change}}

You might think that for an IT operation, tasks like Planning and Design
belong within the Development function within an organisation. But there
is (and always has been) significant overlap because it's important that
we design software that allows it to be managed effectively. In recent
years, the ``DevOps'' movement has brought this relationship into
sharper focus.

\begin{figure}
\centering
\includegraphics{images/devops.png}
\caption{DevOps Activities: Development and Operations activities
overlap one-another (Credit: Kharnagy, Wikipedia)}
\end{figure}

Since our operation exists in a world of Red Queen Risk and Feature
Drift, we would expect that the output of our Forecasting and Planning
activities would result in changes to our operation.

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/design-change-400dpi.png}
\caption{Design and Change Activities}
\end{figure}

In a way, we are now back to where we started from, identifying
Dependency Risk, Feature Risk and Complexity Risk that hinders our
operation, and mitigating it through tasks like \emph{software
development}. Our safari of risk is finally complete, it's time to look
back and what we've seen in Staging and Classifying.

\hypertarget{staging-and-classifying}{%
\chapter{Staging And Classifying}\label{staging-and-classifying}}

Our tour is complete.

We've collected on this journey around the Risk Landscape a (hopefully)
good, representative sample of Risks and where to find them. But if we
are good collectors, then before we're done we should
\href{https://en.wikipedia.org/wiki/Entomological_equipment_for_mounting_and_storage}{Stage}
our specimens and do some work in classifying what we've seen.

\begin{figure}
\centering
\includegraphics{images/Beetle_collection.jpg}
\caption{Staged and Classified Beetle Collection, (Credit: Fir0002,
Wikipedia)}
\end{figure}

If you've been reading closely, you'll notice that a number of themes
come up again and again within the different chapters. For example,
concepts like \textbf{Fit}, \textbf{Abstraction}, \textbf{Evolution}.
Although we've been looking at patterns of risk across software
projects, it's time to look at the \emph{patterns within the patterns}.

\hypertarget{the-power-of-abstractions}{%
\section{The Power Of Abstractions}\label{the-power-of-abstractions}}

Abstraction appears as a concept continually throughout the book,
whether we are looking at Communication, Complexity Metrics, Map and
Territory Risk or how it causes Boundary Risk. And, so far, we've looked
at some complicated examples of abstractions, such as network protocols,
dependencies on technology or Business Processes.

There's a good reason for this repetition. Abstraction is at the heart
of \emph{everything we do within software}. So, let's now
\emph{generalize} what is happening with abstraction, but have in mind a
really simple example: having a name for something. So, at the simplest
end, you might be simply \emph{naming a pattern} of behaviour we see in
the real world, such as ``Binge Watching'' or ``Remote Working'', or
naming a category of insects as ``Beetles''.

\hypertarget{using-an-existing-abstraction-means}{%
\subsection{Using An Existing Abstraction
means:}\label{using-an-existing-abstraction-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Mitigating Feature Risk:} Because the abstraction is providing
  you with something \emph{useful}.
\item
  \textbf{Living with Dependency Risk:} We depend on a word in our
  language, or a function in our library, or a service on the Internet.
  But all of these things are \emph{unreliable}. The word might not
  communicate what you want it to, or be understood by the audience, the
  function might not work, the service might be down. Also, language
  \emph{changes} and \emph{evolves}, and the words you are using now
  might not always mean what you want them to mean. Software too changes
  and evolves. We've seen this in Red Queen Risk and Feature Drift Risk.
\item
  \textbf{Accepting Communication Risk.} : Because if you are using the
  abstraction in conversation, the people you are using it with
  \emph{need to understand it too}.
\item
  \textbf{Accepting Map and Territory Risk}: Because the abstraction is
  a simplification, and not the actual thing itself.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/depending-abstraction-400dpi.png}
\caption{Depending on an Abstraction}
\end{figure}

\hypertarget{inventing-a-new-abstraction-means}{%
\subsection{Inventing A New Abstraction
means:}\label{inventing-a-new-abstraction-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Mitigating Feature Risk.} These abstractions are Features in
  the sense that other people can choose to use them, if they fit their
  requirements.
\item
  \textbf{Creating a Protocol.} At the very simplest level (again), this
  is just introducing \emph{new words to a language}. Therefore, we
  create Protocol Risk: what if the person we are communicating with
  \emph{doesn't} know this word?
\item
  \textbf{Increasing Complexity Risk.} Because, the more words we have,
  the more complex the language is.
\item
  \textbf{Creating Boundary Risk.} By naming something, you
  \emph{implicitly} create a boundary, because the world is now divided
  into ``things which \emph{are} X'' and ``things which \emph{are not}
  X''. Sometimes, this abstraction may literally end up having a
  physical boundary to enforce this division (such as, ``My Property /
  Not My Property''). \emph{Boundary Risk is created by abstractions.}
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/inventing-abstraction-400dpi.png}
\caption{Inventing an Abstraction}
\end{figure}

\hypertarget{choosing-between-abstractions-means}{%
\subsection{Choosing Between Abstractions
means:}\label{choosing-between-abstractions-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Overcoming a Learning Curve}: Because you have to \emph{learn}
  a name in order to use it (whether a function, a dog, or the name of
  someone at a party).
\item
  \textbf{Accepting Boundary Risks.} Just using \emph{a single word}
  means accepting the whole \emph{ecosystem} of the language the word is
  in. Using \emph{French words} means the Boundary Risk of the French
  Language.
\item
  \textbf{Accepting Map And Territory Risk.} Because the word refers to
  the \emph{concept} of the thing, and \emph{not the thing itself}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/choosing-abstraction-400dpi.png}
\caption{Choosing an Abstraction}
\end{figure}

\hypertarget{your-feature-risk-is-someone-elses-dependency-risk}{%
\section{Your Feature Risk is Someone Else's Dependency
Risk}\label{your-feature-risk-is-someone-elses-dependency-risk}}

In the Feature Risk chapter, we looked at the problems of
\emph{supplying a dependency to someone else}: you've got to satisfy a
demand Market Risk, and service a segment of the user community Feature
Access Risk. The chapter on Operational Risk went further, looking at
specific aspects of being the supplier of an IT service as a
\emph{dependency}.

However, over the rest of the Dependency Risk chapters, we looked at
this from the point of view of \emph{being a client to someone else}:
you want to find trustworthy, reliable dependencies that don't give up
when you least want them to.

So Feature Risk and Dependency Risk are \emph{two sides of the same
coin}. You face Dependency Risk when you're a client, Feature Risk when
you're the supplier.

Further, to \emph{use} a dependency requires the client and the supplier
to communicate. And, this entails \emph{learning protocols} and other
types of Communication Risk. You have to learn to use it. Maybe it
learns you. This requires changes to your internal model.

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/features-and-dependencies-400dpi.png}
\caption{Features And Dependencies}
\end{figure}

These relationships of features/dependencies are the basis of Supply
Chains and the world-wide network of goods and services that forms the
modern economy. The incredible complexity of this network \emph{should}
mean incredible Complexity Risk, too, but because humans are good at
Coordinating and managing our dependencies, and we rely on market
mechanisms to help us allocate dependencies efficiently.

\hypertarget{the-original-risk}{%
\section{The Original Risk}\label{the-original-risk}}

As we discussed in Dependency Risk, \emph{depending on things} is
necessary for life, whether it is oxygen, food or sunlight. Minimising
Dependency-Risk is therefore the goal of all life. For some species,
this also means dealing with Feature Risk: there's no point trying to
supply a fruit that no creature will eat, for example.

Our problems really start when we try to Coordinate with the
dependencies themselves or each other. As discussed in the chapter on
Coordination, coordination is the root of Communication Risk, as without
coordination, we don't have to care about what the world is trying to
tell us, or what we are trying to tell the world.

\begin{itemize}
\tightlist
\item
  Communication Risk then begets Map and Territory Risk, because
\item
  Communication Risk also means Complexity Risk, because now we have
  built a communication graph, and we saw how to calculate how complex
  that is.
\item
  As discussed in Boundary Risk, this is at a confluence of Dependency
  Risk, Communication Risk and Complexity Risk.
\end{itemize}

The below diagram shows how this causality plays out.

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/origin-of-risk-400dpi.png}
\caption{The Origin Of Risk}
\end{figure}

\hypertarget{towards-a-periodic-table-of-risks}{%
\section{Towards A Periodic Table Of
Risks}\label{towards-a-periodic-table-of-risks}}

As we said at the start, Risk-First is all about developing \emph{A
Pattern Language}. We can use the terms like ``Feature Risk''\_ or
``Learning Curve Risk'' to \emph{explain} phenomena we see on software
projects. If we want to De-Risk our work, we need to be able to explain
what the risks are, and what we expect to do about them.

The diagram below compiles all of the risks we've seen so far on the
journey across the risk landscape. Just like a periodic table, there are
perhaps others left to discover. Please help by reporting back what you
see.

In the next chapter, we will be looking at some Stories Of Failure, and
trying to apply the patterns we've learnt.

\begin{figure}
\centering
\Oldincludegraphics[width=1\maxwidth]{images/generated/staging-and-classifying/periodic-table-large-400dpi.png}
\caption{Periodic Table of Risks}
\end{figure}

\hypertarget{stories-of-failure}{%
\chapter{Stories Of Failure}\label{stories-of-failure}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Failure Modes
\end{enumerate}

\begin{itemize}
\item
  Understanding Failure: what exactly does it mean to fail?
\item
  Personal Failures

  \begin{itemize}
  \tightlist
  \item
    CapsLock: complexity, not using tools.
  \item
    Configuration Tool (Complexity, feature fit, bugs in hibernate
    (dependency risk, then dead-end risk), difficulty mapping domain
    model)
  \item
    Wide Learning (Funding, but also complexity), did we know what we
    were building? Agency risk
  \item
    AreAye - needless complexity XMLBox
  \item
    Agora: Notes / Typing. (Complexity Risk) Archipelago
  \item
    PDC: website redesign. funding. i.e.~schedule risk
  \item
    Hawk: complexity risk in the software. but actually, they made it
    work. offshoring.
  \item
    Dark: market/feature fit?
  \item
    J10: marketing / market fit / Complexity in spades. algorithmic
    complexity
  \item
    DSL: complexity (code generation). complexity = layers. team
    dynamics.
  \item
    REF: complexity. agency risk. failure of goals. m\&t.
  \item
    REF Testing: complexity risk. communication risk?
  \item
    HSC: Trader Comments: feature fit.
  \item
    HSC: Takeover of Symph: Complexity (of change)
  \item
    TT: Feature Fit
  \end{itemize}
\item
  Boehm.
\end{itemize}

https://wwwx.cs.unc.edu/\textasciitilde{}welch/class/comp145/media/docs/Boehm\_Term\_NE\_Fail.pdf

https://www.worksoft.com/top-software-failures-of-2017-so-far

https://sites.hks.harvard.edu/m-rcbg/ethiopia/Publications/Top\%2010\%20Reasons\%20Why\%20Systems\%20Projects\%20Fail.pdf

JC Example 1: Compensation Workbench, rules to uplift payrolls annually
based on certain definitions. e.g tied into performance gradiing, min
wage. Was done off s/s, out of HR system. Analysis done on S/s. But
wanted to do it in the HR database. It took a lot longer than it should.
Underestimated the complexity. Excel could be infinitely complex, but if
you standardize, you lose that. The customer hadn't got experience of
big IT projects - scope creep. No real sense of prioritisation and
focusing on what was iportant. PM was nice, but didn't understand
delivery management. (i.e.~managing risks and issues). Had short
timescale, lead delivery resource underestimated. 2m exercise. Lasted 5m
in the end, but not with full functionality.

\part{Application}

\hypertarget{coming-next}{%
\chapter{Coming Next}\label{coming-next}}

\begin{itemize}
\tightlist
\item
  preview of what's to come in part 3.
\end{itemize}

Bad to leave on the failure notes, let's talk about some successes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What's To Come
\end{enumerate}

\begin{itemize}
\tightlist
\item
  risk based debugging.
\item
  risk based coding.
\end{itemize}

\hypertarget{estimates}{%
\chapter{Estimates}\label{estimates}}

In this chapter, we're going to put a Risk-First spin on the process of
Estimating. But, in order to get there, we first need to start with
understanding \emph{why} we estimate. We're going to look at some ``Old
Saws'' of software estimation and what we can learn from them. Finally,
we'll bring our Risk-First menagerie to bear on de-risking the
estimation process.

\hypertarget{the-purpose-of-estimating}{%
\section{The Purpose Of Estimating}\label{the-purpose-of-estimating}}

Why bother estimating at all? There are two reasons why estimates are
useful:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{To allow for the creation of \emph{events}.} As we saw in
  Deadline Risk, if we can put a date on something, we can mitigate lots
  of Coordination Risk. Having a \emph{release date} for a product
  allows whole teams of people to coordinate their activities in ways
  that hugely reduce the need for Communication. Much like ``attack at
  dawn'' allows disparate units of an army to avoid lots of the
  Coordination Risk inherent in ``attack on my signal''. This is a
  \emph{good reason for estimating}, because by using events you are
  mitigating risk. This is often called a \emph{hard deadline}.
\item
  \textbf{To allow for the estimation of the Pay-Off of an action.} This
  is a \emph{bad reason for estimating}, as we will discuss in detail
  below. But briefly, the main issue is that Pay-Off isn't just about
  figuring out Schedule Risk - you should be looking at all the other
  Attendant Risks of the action too.
\end{enumerate}

\hypertarget{how-estimates-fail}{%
\section{How Estimates Fail}\label{how-estimates-fail}}

Estimates are a huge source of contention in the software world:

\begin{quotation}

``Typically, effort estimates are over-optimistic and there is a strong
over-confidence in their accuracy. The mean effort overrun seems to be
about 30\% and not decreasing over time.''

\sourceatright{\href{https://en.m.wikipedia.org/wiki/Software_development_effort_estimation}{\textemdash  Software Development Effort Estimation, \emph{Wikipedia}}.}
\end{quotation}

Why is it so bad? The problem with a developer answering a question such
as:

\begin{quotation}

How long will it take to deliver X

\end{quotation}

Is the following:

\begin{itemize}
\tightlist
\item
  The developer and the client likely don't agree on exactly what X is,
  and any description of it is inadequate anyway (Invisibility Risk).
\item
  The developer has a less-than-complete understanding of the
  environment he will be delivering X in (Complexity Risk and Map And
  Territory Risk.
\item
  The developer has some vague ideas about how to do X, but he'll need
  to try out various approaches until he finds exactly the right one
  (Boundary Risk and Learning-Curve Risk).
\item
  The developer has no idea what Hidden Risk will surface when he starts
  work on it.
\item
  The developer has no idea what will happen if he takes too long and
  misses the date by a day/week/month/year (Schedule Risk).
\end{itemize}

\ldots{} and so on.

The reason the estimate of \emph{time} is wrong is because All Activity
Is About Mitigating Risk and the estimate of \emph{risk} is wrong.

It's a problem as old as software itself, and in deference to that,
let's examine the estimating problem via some ``Old Saws''.

\hypertarget{old-saw-1-the-10x-developer}{%
\section{Old Saw \#1: The ``10X
Developer''}\label{old-saw-1-the-10x-developer}}

\begin{quotation}

``A 10X developer is an individual who is thought to be as productive as
10 others in his or her field. The 10X developer would produce 10 times
the outcomes of other colleagues, in a production, engineering or
software design environment.''

\sourceatright{\href{https://www.techopedia.com/definition/31673/10X-developer}{\textemdash  10X Developer, \emph{Techopedia}}}
\end{quotation}

Let's try and pull this apart:

\begin{itemize}
\tightlist
\item
  How do we measure this ``productivity''? In Risk-First terms, this is
  about taking action to \emph{transform} our current position on the
  Risk Landscape to a position of more favourable risk. A ``10X
  Developer'' then must be able to take actions that have much higher
  Payoff than a ``1X Developer''. That is mitigating more Initial Risk,
  and generating less Attendant Risk.
\item
  It stands to reason then, that someone taking action \emph{faster}
  will leaving us with less Schedule Risk.
\item
  However, if they are \emph{more expensive}, they may leave us with
  greater Funding Risk afterwards.
\item
  But, Schedule Risk isn't the only risk being transformed: The result
  might be bugs, expensive new dependencies or spaghetti-code
  complexity.
\item
  The ``10X'' developer \emph{must} also leave behind less of these kind
  of risks too.
\item
  That means that the ``10X Developer'' isn't merely faster, but
  \emph{taking different actions}. They are able to use their talent and
  experience to see actions with greater pay-off than the 1X Developer.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/1x-10x-400dpi.png}
\caption{1x Task vs 10X Task}
\end{figure}

Debate rages as to whether the ``10X Developer'' even exists. Crucially,
it would seem that such a thing would be predicated on the existence of
the ``1X Developer'', who gets ``1x'' worth of work done each day. It's
not clear that there is any such thing as an average developer who is
mitigating risk at an average rate.

Even good developers have bad days, weeks or projects. Taking Action is
like placing a bet. Sometimes you lose and the Pay-Off doesn't appear:

\begin{itemize}
\tightlist
\item
  The Open-Source software you're trying to apply to a problem doesn't
  solve it in the way you need.
\item
  A crucial use-case of the problem turns out to change the shape of the
  solution entirely, leading to lots of rework.
\item
  An assumption about how network security is configured turns out to be
  wrong, leading to a lengthy engagement with the infrastructure team.
\end{itemize}

\hypertarget{how-to-be-a-10x-developer}{%
\subsection{How to Be a ``10X
Developer''}\label{how-to-be-a-10x-developer}}

The easiest way to be a ``10X developer'' is to have \emph{done the job
before}. If you're coding in a familiar language, with familiar
libraries and tools, delivering a cookie-cutter solution to a problem in
the same manner you've done several times before, then you will be a
``10X developer'' compared to \emph{you doing it the first time}: -
There's no Learning Curve Risk, because you already learnt everything. -
There's no Dead End Risk because you already know all the right choices
to make.

\hypertarget{old-saw-2-quality-speed-cost-pick-any-two}{%
\section{Old Saw \#2: Quality, Speed, Cost: Pick Any
Two}\label{old-saw-2-quality-speed-cost-pick-any-two}}

\begin{quotation}

The Project Management Triangle (called also the Triple Constraint, Iron
Triangle and ``Project Triangle

\end{quotation}

\begin{quote}
\begin{itemize}
\tightlist
\item
  The quality of work is constrained by the project's budget, deadlines
  and scope (features).
\item
  The project manager can trade between constraints.
\item
  Changes in one constraint necessitate changes in others to compensate
  or quality will suffer."

  \begin{itemize}
  \tightlist
  \item
    \href{https://en.wikipedia.org/wiki/Project_management_triangle}{Project
    Management Triangle, \emph{Wikipedia}}
  \end{itemize}
\end{itemize}
\end{quote}

From a Risk-First perspective, we can now see that this is an
over-simplification. If \emph{quality} is a Feature Fit metric,
\emph{deadlines} is Schedule Risk and \emph{budget} refers to Funding
Risk then that leaves us with a lot of risks unaccounted for:

\begin{itemize}
\tightlist
\item
  I can deliver a project in very short order by building a bunch of
  screens that \emph{do nothing} (accruing \_stunning levels of
  Implementation Risk as I go).
\item
  Or, by relying on a lottery win, project's budget is fine. (Although I
  would have \emph{huge} Funding Risk because \emph{what are the chances
  of winning the lottery?}. (You can bring in \emph{any} project at
  \emph{any} time by accepting crazy levels of risk.
\item
  And Brooks' Law contradicts this by saying you can't trade budget for
  deadlines:
\end{itemize}

\begin{quotation}

``Brooks' law is an observation about software project management
according to which''adding human resources to a late software project
makes it later``.

\sourceatright{\href{https://en.wikipedia.org/wiki/Brooks_law}{\textemdash  Brooks Law, \emph{Wikipedia}}}
\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/brooks-400dpi.png}
\caption{Brooks' Law, Risk-First Style}
\end{figure}

Focusing on just these three variables isn't enough. You can game these
variables by sacrificing others: we need to be looking at the project's
risk \emph{holistically}:

\begin{itemize}
\tightlist
\item
  There's no point in calling a project complete if the dependencies you
  are using are unreliable or undergoing rapid change
\item
  There's no point in delivering the project on time if it's an
  Operational Risk nightmare, and requires constant round-the-clock
  support and will cost a fortune to \emph{run}. (Working on a project
  that ``hits it's delivery date'' but is nonetheless a broken mess once
  in production is too common a sight.)
\item
  There's no point in delivering a project on-budget if the market has
  moved on and needs different features.
\end{itemize}

\hypertarget{old-saw-3-parkinsons-law}{%
\subsection{Old Saw \#3: Parkinson's
Law}\label{old-saw-3-parkinsons-law}}

We've already looked at Parkinson's Law in Agency Risk, but lets recap:

\begin{quotation}

Parkinson's law is the adage that `work expands so as to fill the time
available for its completion'.

\end{quotation}

Let's leave aside the Agency Risk concerns this time. Instead, let's
consider this from a Risk-First perspective. \emph{Of course} work would
expand to fill the time available: \emph{Time available} is an
\emph{absence of Schedule Risk}, it's always going to be sensible to
accept Schedule Risk as a trade-off for other more serious risks.

This is why projects will \emph{always} take at least as long as is
budgeted for them.

\hypertarget{a-case-study}{%
\subsection{A Case Study}\label{a-case-study}}

Let's look at a quick example of this in action, taken from
\href{http://amzn.eu/d/eTWKOsK}{Rapid Development by Steve McConnell}.
At the point of this excerpt, Carl (the Project Manager) is discussing
the schedule with Bill, the project sponsor:

\begin{quotation}

I think it will take about 9 months, but that's just a rough estimate at
this point," Carl said. ``That's not going to work,'' Bill said. ``I was
hoping you'd say 3 or 4 months. We absolutely need to bring that system
in within 6 months. Can you do it in 6?

\end{quotation}

Later in the story, the schedule has slipped twice and is about to slip
again:

\begin{quote}
\ldots{} At the 9-month mark, the team had completed detailed design,
but coding still hadn't begun on some modules. It was clear that Carl
couldn't make the 10-month schedule either. He announced the third
schedule slip number--- to 12 months. Bill's face turned red when Carl
announced the slip, and the pressure from him became more intense.
\texttt{(2)}
\end{quote}

At point \texttt{(2)}, Carl's tries to mitigate Feature Risk by
increasing Schedule Risk, although he knows that Bill will trust him
less for doing this, as shown below:

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/carl1-400dpi.png}
\caption{Carl's Schedule Slip increases Trust and Belief Risks}
\end{figure}

\begin{quote}
Carl began to feel that his job was on the line. Coding proceeded fairly
well, but a few areas needed redesign and reimplementation. The team
hadn't coordinated design details in those areas well, and some of their
implementations conflicted. At the 11-month oversight-committee meeting,
Carl announced the fourth schedule slip--- to 13 months. Bill became
livid. ``Do you have any idea what you're doing?'' he yelled. ``You
obviously don't have any idea! You obviously don't have any idea when
the project is going to be done! I'll tell you when it's going to be
done! It's going to be done by the 13-month mark, or you're going to be
out of a job! I'm tired of being jerked around by you software guys! You
and your team are going to work 60 hours a week until you deliver!''
\texttt{(3)}
\end{quote}

At point \texttt{(3)}, after the schedule slips again, Bill threatens
Carl's job. Why does he do this? Because \emph{he doesn't trust Carl's
evaluation of the Schedule Risk}. By telling Carl that it's his job on
the line, he makes sure Carl appreciates the Schedule Risk. However,
forcing staff to do overtime is a dangerous ploy: it could
disenfranchise the staff, or cause corners to be cut:

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/bill1-400dpi.png}
\caption{Bill's Ultimatum}
\end{figure}

\begin{quote}
Carl felt his blood pressure rise, especially since Bill had backed him
into an unrealistic schedule in the first place. But he knew that with
four schedule slips under his belt, he had no credibility left. He felt
that he had to knuckle under to the mandatory overtime or he would lose
his job. Carl told his team about the meeting. They worked hard and
managed to deliver the software in just over 13 months. Additional
implementation uncovered additional design flaws, but with everyone
working 60 hours a week, they delivered the product through sweat and
sheer willpower. " \texttt{(4)} - McConnell, Steve, \emph{Rapid
Development}
\end{quote}

At point \texttt{(4)}, we see that Bill's gamble worked (for him at
least): the project was delivered on time by the team working overtime
for two months. This was lucky - it seems unlikely that no-one quit and
that the code didn't descend into a mess in that time.

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/team1-400dpi.png}
\caption{Team Response}
\end{figure}

Despite this being a fictional (or fictionalised) example, it rings true
for many projects. What \emph{should} have happened at point
\texttt{(1)}? Both Carl and Bill estimated incorrectly\ldots{} Or did
they?

\hypertarget{agile-estimation}{%
\section{Agile Estimation}\label{agile-estimation}}

One alternative approach, must espoused in DevOps/Agile is to pick a
short-enough period of time (say, two days or two weeks), and figure out
what the most meaningful step towards achieving an objective would be in
that time. By fixing the time period, we remove Schedule Risk from the
equation, don't we?

Well, no. First, how to choose the time period? Schedule Risk tends to
creep back in, in the form of something like
\href{https://en.wikipedia.org/wiki/Man-hour}{Man-Hours} or
\href{https://www.atlassian.com/agile/project-management/estimation}{Story
Points}:

\begin{quotation}

``Story points rate the relative effort of work in a Fibonacci-like
format: 0, 0.5, 1, 2, 3, 5, 8, 13, 20, 40, 100. It may sound
counter-intuitive, but that abstraction is actually helpful because it
pushes the team to make tougher decisions around the difficulty of
work.''

\sourceatright{\href{https://www.atlassian.com/agile/project-management/estimation}{\textemdash  Story Points, \emph{Atlassian}}}
\end{quotation}

Second, the strategy of picking the two-day action with the greatest
Pay-Off is \emph{often good}. After all, this is just Gradient Descent,
and that's a perfectly good way for training
\href{https://en.wikipedia.org/wiki/Machine_learning}{Machine Learning}
systems. However, just like following a river downhill from the top of a
mountain will \emph{often} get you to the sea, it probably won't take
the shortest path, and sometimes you'll get stuck at a lake.

The choice of using gradient descent means that you have given up on
Goals: Essentially, we have here the difference between ``Walking
towards a destination'' and ``Walking downhill''. Or, if you like, a
planned economy and a market economy. But, we don't live in
\emph{either}: everyone lives in some mixture of the two: our
governments \emph{have plans} for big things like roads and hospitals,
and taxes. Other stuff, they leave to the whims of supply and demand. A
project always ends up being the same.

\hypertarget{risk-first-estimating}{%
\section{Risk-First Estimating}\label{risk-first-estimating}}

Let's figure out what we can take away from the above experiences:

\begin{itemize}
\tightlist
\item
  The 10X developer saw, and the difference made by experience implies
  that a lot of the effort on a project comes from Learning Curve Risk
  and Dead End Risk.
\item
  The lesson from ``Quality, Speed, Cost'' is that actually, we need to
  be considering \emph{all} risks, not just some arbitrary milestones on
  a project plan. Project plans can always be gamed, and you can always
  leave risks unaccounted for in order to hit the goals (good old Map
  and Territory Risk strikes again).
\item
  The lesson from the Parkinson's Law was that by giving people a
  \emph{time budget}, you absolve them from Schedule Risk\ldots{} at
  least until they realise they're going to overrun. This gives them one
  less dimension of risk to worry about, but means they end up taking
  all the time you give them, because they are optimising over the
  remaining risks.
\item
  Finally, the lesson from Agile Estimation is that \emph{just
  iterating} is sometimes not as efficient as \emph{using your intuition
  and experience} to find a more optimal path.
\end{itemize}

How can we synthesise this knowledge, along with what we've learned into
something that makes more sense?

\hypertarget{tip-1-estimating-should-be-about-estimating-pay-off}{%
\subsubsection{\texorpdfstring{Tip \#1: Estimating Should be About
\emph{Estimating Pay
Off}}{Tip \#1: Estimating Should be About Estimating Pay Off}}\label{tip-1-estimating-should-be-about-estimating-pay-off}}

For a given action / road-map / business strategy, what Attendant Risks
are we going to have when we get there? Yes, we'll all be older (there
\emph{will be} Schedule Risk), but it's also about:

\begin{itemize}
\tightlist
\item
  What bets are we making about where the market will be?
\item
  What Communication Risk will we face explaining our product to people?
\item
  What Feature Fit risks are we likely to have when we get there?
\item
  What Complexity Risks will we face building our software? How can we
  avoid it ending up as a Big Ball Of Mud?
\item
  Where are we likely to face Boundary Risks and Dead End Risks
\end{itemize}

Instead of the Agile Estimation being about picking out a story-point
number based on some idealised amount of typing that needs to be done,
it should be about surfacing and weighing up risks. e.g:

\begin{itemize}
\tightlist
\item
  ``I think this task is problematic because it's going to massively
  increase our Dependency Risk to add a new database here.''
\item
  ``I don't think we should have component A interacting with component
  B because it'll introduce extra Communication Risk which we will
  always be tripping over.''
\item
  ``I worry we might not understand what the sales team want and are
  facing Implementation Risk. How about we try and get agreement on a
  specification?''
\end{itemize}

\hypertarget{tip-2-the-risk-landscape-is-increasingly-complex-utilise-this}{%
\subsubsection{Tip \#2: The Risk Landscape is Increasingly Complex:
Utilise
This}\label{tip-2-the-risk-landscape-is-increasingly-complex-utilise-this}}

\begin{figure}
\centering
\includegraphics{images/estimates/central-line.png}
\caption{Journey via the Central Line}
\end{figure}

If you were travelling across London from Ealing (in the West) to
Stratford (in the East) the \emph{fastest} route might be to take the
Central Line. You could do it via the A406 road, which would take a
\emph{bit} longer. It would \emph{feel} like you're mainly going in
completely the wrong direction doing that, but it's much faster than
cutting straight through London and you don't pay the congestion charge.

\begin{figure}
\centering
\includegraphics{images/estimates/car.png}
\caption{Journey by Car}
\end{figure}

In terms of risk, they all have different profiles. You're often delayed
in the car, by some amount. The tube is \emph{generally} reliable, but
when it breaks down or is being repaired it might end up quicker to
walk.

If you were doing this same journey on foot, it's a very direct route,
but would take five times longer. However, if you were making this
journey a hundred years ago, that might be the way you chose (horseback
might be a bit faster).

\begin{figure}
\centering
\includegraphics{images/estimates/foot.png}
\caption{Journey on Foot}
\end{figure}

In the software development past, \emph{building it yourself} was the
only way to get anything done. It was like London \emph{before road and
rail}. Nowadays, you are bombarded with choices. It's actually
\emph{worse than London} because it's not even a two-dimensional
geographic space and there are multitudes of different routes and
acceptable destinations. Journey planning on the software Risk Landscape
is an optimisation problem \emph{par excellence}.

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/risk-landscape-400dpi.png}
\caption{Possible Moves On The Risk Landscape}
\end{figure}

Because the modern Risk Landscape is so complex:

\begin{itemize}
\tightlist
\item
  There can be orders of magnitude difference in \emph{time}, with very
  little difference in destination.
\item
  If it's Schedule Risk you're worried about, \emph{Code Yourself} isn't
  a great solution (for the whole thing, anyway). ``Take the tube'' and
  at least partly use something someone built already. There are
  probably multiple alternatives you can consider.
\item
  If no one has built something similar already, then why is that? Have
  you formulated the problem properly?
\item
  Going the wrong way is \emph{so much easier}.
\item
  Dead-Ends (like a broken Central Line) are much more likely to trip
  you up.
\item
  You need to keep up with developments in your field. Read widely.
\end{itemize}

\hypertarget{tip-3-meet-reality-early-on-the-biggest-risks}{%
\subsubsection{Tip \#3: Meet Reality Early on the Biggest
Risks}\label{tip-3-meet-reality-early-on-the-biggest-risks}}

In getting from A to B on the Risk Landscape, imagine that all the
Attendant Risks are the stages of a journey. Some might be on foot,
train, car and so on. In order for your course of action to work, all
the stages in the journey have to succeed.

Although you might have to make the steps of a journey in some order,
you can still mitigate risk in a different order. For example, checking
the trains are running, making sure your bike is working, booking
tickets and taxis, and so on.

The \emph{sensible} approach would be to test the steps \emph{in order
from weakest to strongest}. This means working out how to meet reality
for each risk in turn, in order from biggest risk to smallest.

Often, a \emph{strategy} will be broken up into multiple actions.
\emph{Which are the riskiest actions?} Figure this out, using the
Risk-First vocabulary and the best experience you can bring to bear,
then, perform the actions which Pay Off the biggest risks first.

As we saw from the ``10X Developer'' saw, Learning Curve Risk and Dead
End Risk, are likely to be the biggest risks. How can we front-load this
and tackle these earlier?

\begin{itemize}
\tightlist
\item
  \emph{Having a vocabulary} (like the one Risk-First provides) allows
  us to \emph{at least talk about these}. e.g. ``I believe there is a
  Dead End Risk that we might not be able to get this software to run on
  Linux.''
\item
  Build mock-ups:

  \begin{itemize}
  \tightlist
  \item
    UI wireframes allow us to bottom out the Communication Risk of the
    interfaces we build.
  \item
    Spike Solutions allow us to test algorithms and approaches before
    making them part of the main development.
  \end{itemize}
\item
  Don't pick delivery dates far in the future. Collectively work out the
  biggest risks with your clients, and then arrange the next possible
  date to demonstrate the mitigation.
\item
  Do actions \emph{early} that are \emph{simple} but are nevertheless
  show-stoppers. They are as much a source of Hidden Risk as more
  obviously tricky actions.
\end{itemize}

\hypertarget{tip-4-talk-frankly-about-all-the-risks}{%
\subsubsection{Tip \#4: Talk Frankly About All The
Risks}\label{tip-4-talk-frankly-about-all-the-risks}}

Let's get back to Bill and Carl. What went wrong between points
\texttt{(1)} and \texttt{(2)}? Let's break it down:

\begin{itemize}
\tightlist
\item
  \textbf{Bill \emph{wants} the system in 3-4 months.} It doesn't
  happen.
\item
  \textbf{He says it ``must be delivered in 6 months'', but this doesn't
  happen either.} However, the world (and the project) doesn't end:
  \emph{it carries on}. What does this mean about the truth of his
  statement? Was he deliberately lying, or just espousing his view on
  the Schedule Risk?
\item
  \textbf{Carl's original estimate was 9 months.} Was he working to this
  all along? Did the initial brow-beating over deadlines at point
  \texttt{(1)} contribute to Agency Risk in a way that \emph{didn't}
  happen at point \texttt{(2)}?
\item
  \textbf{Why \emph{did} Bill get so angry?} His understanding of the
  Schedule Risk was, if anything, \emph{worse} than Carl's. It's not
  stated in the account, but it's likely the Trust Risk moved upwards:
  Did his superiors stop trusting him? Was his job at stake?
\item
  \textbf{How could including this risk in the discussion have improved
  the planning process?} Could the conversation have started like this
  instead?
\end{itemize}

\begin{quotation}

I think it will take about 9 months, but that's just a rough estimate at
this point," Carl said. ``That's not going to work,'' Bill said. ``I was
hoping you'd say 3 or 4 months. I need to show the board something by
then or I'm worried they will lose confidence in me and this project

\end{quotation}

\begin{quotation}

OK," said Carl. ``But I'm really concerned we have huge Feature Fit
Risk. The task of understanding the requirements and doing the design is
massive.

\end{quotation}

\begin{quotation}

Well, in my head it's actually pretty simple, " said Bill. ``Maybe I
don't have the full picture, or maybe your idea of what to build is more
complex than I think it needs to be. That's a massive risk right there
and I think we should try and mitigate it right now before things
progress. Maybe I'll need to go back to the board if it's worse than I
think.

\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/bill2-400dpi.png}
\caption{Identifying The Action}
\end{figure}

\hypertarget{tip-5-picture-worrying-futures}{%
\subsubsection{Tip \#5: Picture Worrying
Futures}\label{tip-5-picture-worrying-futures}}

The Bill/Carl problem is somewhat trivial (not to mention likely
fictional). How about one from real life? On a project I was working on
in November some years ago, we had two pieces of functionality we
needed: Bulk Uploads and Spock Integration. (It doesn't really matter
what these are). The bulk uploads would be useful \emph{now}. But, the
Spock Integration wasn't due until January. In the Spock estimation
meeting I wrote the following note:

\begin{quotation}

Spock estimates were 4, 11 and 22 until we broke it down into tasks.
Now, estimates are above 55 for the whole piece. And worryingly, we
probably don't have all the tasks. We know we need bulk uploads in
November. Spock is January. So, do bulk uploads?

\end{quotation}

The team \emph{wanted} to start Bulk Uploads work. After all, from these
estimates it looked like Spock could easily be completed in January.
However, the question should have been:

\begin{quotation}

If it was February now, and we'd \emph{got nothing done}, what would our
biggest risk be?

\end{quotation}

Missing Bulk Uploads wouldn't be a show-stopper, but missing Spock would
be a huge regulatory problem. \emph{Start work on the things you can't
miss. }

This is the essence of De-Risking.

\end{document}  