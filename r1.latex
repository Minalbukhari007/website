% Page setup
\documentclass[11pt]{memoir}
\setstocksize{9.69in}{7.44in}
\settrimmedsize{\stockheight}{\stockwidth}{*}
\setlrmarginsandblock{3.5cm}{2.5cm}{*}
\setulmarginsandblock{2cm}{3cm}{*}
\checkandfixthelayout 
\setheadfoot{\onelineskip}{2\onelineskip}

% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{parskip}    	
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}	

\usepackage{graphicx}					
\usepackage{amssymb}

%SetFonts
\usepackage[T1]{fontenc}
\usepackage{newpxtext,newpxmath}

%Images
\usepackage{graphicx}
% We will generate all images so they have a width .9\maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.9\maxwidth]{#1}}
\usepackage{rotating}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}
\captionsetup[figure]{labelfont={bf,it},textfont={bf,it}}
 \setfloatlocations{figure}{thpb}


% Links
\usepackage[hyphens]{url}
\usepackage[unicode=true]{hyperref}
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={},
            colorlinks=false,
            urlcolor=black,
            linkcolor=black,
            pdfborder={0 0 0}}

% Footers / Page Numbers            (FIX ME)
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
  \renewcommand{\headrulewidth}{0pt}
  \fancyfoot[LE, RO]{\thepage}
  \fancyfoot[C]{\textsl}

% Tables            
\usepackage{longtable,booktabs}
\usepackage[width=.8\textwidth]{caption}
% These lines are needed to make table captions work with longtable:
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{rotating}
 \setfloatlocations{table}{thpb}


% Code Sections
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstnewenvironment{code}{\lstset{basicstyle=\small\ttfamily}}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}


%Links as Notes
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
 \renewcommand{\footnotesize}{\fontsize{6.5pt}{8.5pt}\selectfont}


%Sections
\chapterstyle{veelo}
\setlength{\beforechapskip}{20pt}
\setsechook{\hangsecnum}
\setcounter{secnumdepth}{5}

\begin{document}

\frontmatter

\title{Risk-First Software Development: The Menagerie}
\author{Rob Moffat}

\begin{titlingpage}

\hspace{0.05\textwidth}

\centering

{\Huge\bfseries\textsc{Risk-First}}\\[2\baselineskip]

{\Huge\bfseries\textsc{Software Development}}\\[1\baselineskip]

{\Huge\bfseries\textsc{De-Risked }}\\[2\baselineskip]

{\Huge\textit{Volume 1: The Menagerie}}\\[4\baselineskip]

{\Oldincludegraphics[width=0.5\textwidth]{images/R1_logo_grue.png}}\\[4\baselineskip]

{\Huge\textsc{Rob Moffat}}


\end{titlingpage}

\hypertarget{risk-first-the-menagerie}{%
\section{Risk First: The Menagerie}\label{risk-first-the-menagerie}}

By Rob Moffat

Copyright Â© 2018 Kite9 Ltd.

All rights reserved. No part of this publication may be reproduced,
distributed, or transmitted in any form or by any means, including
photocopying, recording, or other electronic or mechanical methods,
without the prior written permission of the publisher, except in the
case of brief quotations embodied in critical reviews and certain other
noncommercial uses permitted by copyright law. For permission requests,
write to the publisher, addressed ``Attention: Permissions
Coordinator,'' at the address below.

ISBN: 9781717491855

\hypertarget{credits}{%
\subsection{Credits}\label{credits}}

tbd

Cover Images: Biodiversity Heritage Library. Biologia
Centrali-Americana. Insecta. Rhynchota. Hemiptera-Homoptera. Volume 1
(1881-1905)

Cover Design By P. Moffat (\texttt{peter@petermoffat.com})

Thanks to:

\hypertarget{books-in-the-series}{%
\subsection{Books In The Series}\label{books-in-the-series}}

\begin{itemize}
\tightlist
\item
  \textbf{Risk First: The Menagerie:} Book one of the
  \textbf{Risk-First} series argues the case for viewing \emph{all} of
  the activities on a software project through the lens of
  \emph{managing risk}. It introduces the menagerie of different risks
  you're likely to meet on a software project, naming and classifying
  them so that we can try to understand them better.
\item
  \textbf{Risk First: Tools and Practices:} Book two of the \textbf{Risk
  First} series explores the relationship between software project risks
  and the tools and practices we use to mitigate them. Due for
  publication in 2020.
\end{itemize}

\hypertarget{online}{%
\subsection{Online}\label{online}}

Material for the books is freely available to read, drawn from
\texttt{risk-first.org}.

\hypertarget{published-by}{%
\subsection{Published By}\label{published-by}}

\begin{verbatim}
Kite9 Ltd.
14 Manor Close
Colchester
CO6 4AR
\end{verbatim}

\newpage
\setcounter{tocdepth}{0}
\tableofcontents

\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

Welcome to Risk-First!

Let's cover some of the big questions up-front: The why, what, who, how
and where of \emph{The Menagerie}.

\hypertarget{why}{%
\section{Why}\label{why}}

\begin{quotation}

Scrum, Waterfall, Lean, Prince2: what do they all have in common?

\end{quotation}

I've started this because, on my career journey, I've noticed that the
way I do things doesn't seem to match up with the way the books
\emph{say} it should be done. And, I found this odd and wanted to
explore it further. Hopefully, you, the reader, will find something of
use in this.

I started with this observation: \emph{Development Teams} put a lot of
faith in methodology. Sometimes, this faith is often so strong it
borders on religion. (Which in itself is a concern.) For some, this is
Prince2.

\emph{Developers} put a lot of faith in \emph{particular tools} too.
Some developers are pro-or-anti-Java, others are pro-or-anti-XML. All of
them have their views coloured by their \emph{experiences} (or lack of)
with these tools. Was this because their past projects \emph{succeeded}
or \emph{failed} because of them?

As time went by, I came to see that the choice of methodology, process
or tool was contingent on the problem being solved, and the person
solving the problem. We don't face a shortage of tools in IT, or a
shortage of methodologies, or a shortage of practices. Essentially, that
all the tools and methodologies that the industry had supplied were
there to help \emph{minimize the risk of my project failing}.

This book considers that perspective: that building software is all
about \emph{managing risk}, and that these methodologies are
acknowledgements of this fact, and they differ because they have
\emph{different ideas} about which are the most important \emph{risks to
manage}.

\hypertarget{what-this-is}{%
\section{What This Is}\label{what-this-is}}

Hopefully, after reading this, you'll come away with:

\begin{itemize}
\tightlist
\item
  An appreciation of how risk underpins everything we do as developers,
  whether we want it to or not.
\item
  A framework for evaluating methodologies, tools and practices and
  choosing the right one for the task-at-hand.
\item
  A recontextualization of the software process as being an exercise in
  mitigating different kinds of risk.
\item
  The tools to help you decide when a methodology or tool is
  \emph{letting you down}, and the vocabulary to argue for when it's a
  good idea to deviate from it.
\end{itemize}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change too fast

\begin{quotation}

I have this Pattern

\end{quotation}

Does that diminish it? If you have visited the TVTropes website, you'll
know that it's a set of web-pages describing \emph{common patterns} of
narrative, production, character design etc. to do with fiction. For
example:

\begin{quote}
tbd.
\end{quote}

Is it scientific? No.~Is it correct? Almost certainly. TVTropes is a set
of \emph{empirical patterns} for how stories on TV and other media work.
It's really useful, and a lot of fun. (Warning: it's also incredibly
addictive).

In the same way, tbd, the tbd published a book called ``Design Patterns:
tbd''. Which shows you patterns of \emph{structure} within
Object-Oriented programming:

\begin{quote}
tbd.
\end{quote}

\hypertarget{patterns-for-practitioners}{%
\subsection{Patterns For
Practitioners}\label{patterns-for-practitioners}}

This book aimed to be a set of \emph{useful} patterns which
practitioners could use in their software to achieve certain goals. ``I
have this pattern'' was a phrase used to describe how they had seen a
certain set of constraints before, and how they had solved it in
software.

This book was a set of experts handing down their battle-tested
practices for other developers to use, and, whether you like patterns or
not, knowing them is an important part of being a software developer, as
you will see them used everywhere you go and probably use them yourself.

In the same way, this book aims to be a set of \emph{Patterns for
Software Risk}. Hopefully after reading this book, you will see where
risk hides in software projects, and have a name for it when you see it.

\hypertarget{towards-a-periodic-table}{%
\subsection{Towards a ``Periodic
Table''}\label{towards-a-periodic-table}}

In the latter chapters of ``The Menagerie'' we try to assemble these
risk patterns into a cohesive whole. Projects fail because of risks, and
risks arise from predictable sources.

\hypertarget{what-this-is-not}{%
\subsection{What This is Not}\label{what-this-is-not}}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change too fast

Neither is this site isn't going to be an exhaustive guide of every
possible software development practice and methodology. That would just
be too long and tedious.

Neither is this really a practitioner's guide to using any particular
methodology: If you've come here to learn the best way to do
Retrospectives, then you're in the wrong place. There are plenty of
places you can find that information already. Where possible, this site
will link to or reference concepts on Wikipedia or the wider internet
for further reading on each subject.

\hypertarget{who}{%
\section{Who}\label{who}}

This work is intended to be read by people who work on software
projects, and especially those who are involved in managing software
projects.

If you work collaboratively with other people in a software process, you
should find Risk-First a useful lexicon of terms to help describe the
risks you face.

But here's a warning: This is going to be a depressing book to read. It
is book one of a two-book series, but in \textbf{Book One} you only get
to meet the bad guy.

While \textbf{Book Two} is all about \emph{how to succeed}, This book is
all about how projects \emph{fail}. In it, we're going to try and put
together a framework for understanding the risk of failure, in order
that we can reconstruct our understanding of our activities on a project
based on avoiding it.

So, if you are interested in \emph{avoiding your project failing}, this
is probably going to be useful knowledge.

\hypertarget{for-developers}{%
\subsection{For Developers}\label{for-developers}}

Risk-First is a tool you can deploy to immediately improve your ability
to plan your work.

Frequently, as developers we find software methodologies ``done to us''
from above. Risk-First is a toolkit to help \emph{take apart}
methodologies like Scrum, and understand them. Methodologies are
\emph{bicycles}, rather than \emph{religions}. Rather than simply
\emph{believing}, we can take them apart and see how they work.

\hypertarget{for-project-managers-and-team-leads}{%
\subsection{For Project Managers and Team
Leads}\label{for-project-managers-and-team-leads}}

All too often, Project Managers don't have a full grasp of the technical
details of their projects. And this is perfectly normal, as the
specialization belongs below them. However, projects fail because risks
materialize, and risks materialize because the devil is in those
details.

This seems like a lost cause, but there is hope: the ways in which risks
materialize on technical projects is the same every time. With
Risk-First we are attempting to name each of these types of risk, which
allows for a dialog with developers about which risks they face, and the
order they should be tackled.

Risk-First allows a project manager to pry open the black box of
development and talk with developers about their work, and how it will
affect the project. It is another tool in the (limited) arsenal of
techniques a project manager can bring to bear on the task of delivering
a successful project.

\hypertarget{how}{%
\section{How}\label{how}}

One of the original proponents of the Agile Manifesto by stating:

``It's all about risk'' \textgreater{} Kent Beck

This is a promising start. From there, he introduces his methodology,
Extreme Programming, there is no clear model of software risk
underpinning the work, and the relationship between the practices he
espouses and the risks he is avoiding are hidden.

In this book, we are going to introduce a model of software project
risk. This means that in \textbf{Book Two} (Risk-First: Tools and
Practices), we can properly analyse Extreme Programming and
\emph{understand} what drives them. Since they are designed to deliver
successful software projects, they must be about mitigate risks, and we
will uncover \emph{exactly which risks are mitigated} and \emph{how they
do it}.

\hypertarget{where}{%
\section{Where}\label{where}}

All of the material for this book is available Open Source on
\href{https://github.com}{github.com}, and at the
\href{https://risk-first.org}{risk-first.org} website. Please visit,
your feedback is appreciated.

There is no compulsion to buy a print or digital version of the book,
but we'd really appreciate the support. So, if you've read this and
enjoyed it, how about buying a copy for someone else to read?

\hypertarget{a-note-on-references}{%
\subsection{A Note on References}\label{a-note-on-references}}

Where possible, references are to the
\href{https://wikipedia.org}{Wikipedia} website. Wikipedia is not
perfect. There is a case for linking to the original articles and
papers, but by using Wikipedia references are free and easy for everyone
to access, and hopefully will exist for a long time into the future.

On to The Executive Summary

\hypertarget{executive-summary}{%
\chapter{Executive Summary}\label{executive-summary}}

\hypertarget{there-are-lots-of-ways-of-running-software-projects}{%
\section{1. There are Lots of Ways of Running Software
Projects}\label{there-are-lots-of-ways-of-running-software-projects}}

There are lots of different ways to look at a project. For example,
metrics such as ``number of open tickets'', ``story points'', ``code
coverage'' or ``release cadence'' give us a numerical feel for how
things are going and what needs to happen next. We also judge the health
of projects by the practices used on them - Continuous Integration, for
example.

Software methodologies, then, are collections of tools and practices:
``Agile'', ``Waterfall'', ``Lean'' or ``Phased Delivery'' (for example)
all suggest different approaches to running a project, and are
opinionated about the way they think projects should be done and the
tools that should be used.

None of these is necessarily more ``right'' than another- they are
suitable on different projects at different times.

A key question then is: \textbf{how do we select the right tools for the
job?}

\hypertarget{we-can-look-at-projects-in-terms-of-risks}{%
\section{2. We can Look at Projects in Terms of
Risks}\label{we-can-look-at-projects-in-terms-of-risks}}

One way to examine a project in-flight is by looking at the risks it
faces.

Commonly, tools such as RAID logs and RAG status reporting are used.
These techniques should be familiar to project managers and developers
everywhere.

However, the Risk-First view is that we can go much further: that each
item of work being done on the project is mitigating a particular risk.
Risk isn't something that just appears in a report, it actually drives
\emph{everything we do}.

For example:

\begin{itemize}
\tightlist
\item
  A story about improving the user login screen can be seen as reducing
  \emph{the risk of users not signing up}.
\item
  A task about improving the health indicators could be seen as
  mitigating \emph{the risk of the application failing and no-one
  reacting to it}.
\item
  Even a task as basic as implementing a new function in the application
  is mitigating \emph{the risk that users are dissatisfied and go
  elsewhere}.
\end{itemize}

\textbf{One assertion of Risk-First therefore, is that every action you
take on a project is to mitigate some risk.}

\hypertarget{we-can-break-down-risks-on-a-project-methodically}{%
\section{3. We Can Break Down Risks on a Project
Methodically}\label{we-can-break-down-risks-on-a-project-methodically}}

Although risk is usually complicated and messy, other industries have
found value in breaking down the types of risks that affect them and
addressing them individually.

For example:

\begin{itemize}
\tightlist
\item
  In manufacturing, \emph{tolerances} allow for calculating the
  likelihood of defects in production.
\item
  In finance, reserves are commonly set aside for the risks of
  stock-market crashes, and teams are structured around monitoring these
  different risks.
\item
  The insurance industry is founded on identifying particular risks and
  providing financial safety-nets for when they occur, such as death,
  injury, accident and so on.
\end{itemize}

Software risks are difficult to quantify, and mostly, the effort
involved in doing so \emph{exactly} would outweigh the benefit.
Nevertheless, there is value in spending time building
\emph{classifications of risk for software}. That's what Risk-First
does: describes the set of \emph{risk patterns} we see every day on
software projects.

With this in place, we can:

\begin{itemize}
\tightlist
\item
  Talk about the types of risks we face on our projects, using an
  appropriate language.
\item
  Expose Hidden Risks that we hadn't considered before.
\item
  Weigh the risks against each other, and decide which order to tackle
  them.
\end{itemize}

\hypertarget{we-can-analyse-tools-and-techniques-in-terms-of-how-they-mitigate-risk}{%
\section{4. We Can Analyse Tools and Techniques in Terms of how they
Mitigate
Risk}\label{we-can-analyse-tools-and-techniques-in-terms-of-how-they-mitigate-risk}}

If we accept the assertion above that \emph{all} the actions we take on
a project are about mitigating risks, then it stands to reason that the
tools and techniques available to us on a project are there for
mitigating different types of risks.

For example:

\begin{itemize}
\tightlist
\item
  If we do a Code Review of knowledge not being widely-enough shared.
\item
  If we write Unit Tests, we're also mitigating the risk of bugs going
  to production, but we're also mitigating against future changes
  breaking our existing functionality.
\item
  If we enter into a contract with a supplier, we are mitigating the
  risk of the supplier vanishing and leaving us exposed. With the
  contract in place, we have legal recourse against this risk.
\end{itemize}

\textbf{Different tools are appropriate for mitigating different types
of risks.}

\hypertarget{different-methodologies-for-different-risk-profiles}{%
\section{5. Different Methodologies for Different Risk
Profiles}\label{different-methodologies-for-different-risk-profiles}}

In the same way that our tools and techniques are appropriate to dealing
with different risks, the same is true of the methodologies we use on
our projects. We can use a Risk-First approach to examine the different
methodologies, and see which risks they address.

For example:

\begin{itemize}
\tightlist
\item
  \textbf{Agile} methodologies prioritise mitigating the risk that
  requirements capture is complicated, error-prone and that requirements
  change easily.
\item
  \textbf{Waterfall} takes the view that coding effort is an expensive
  risk, and that we should build plans up-front to avoid it.
\item
  \textbf{Lean} takes the view that risk lies in incomplete work and
  wasted work, and aims to minimize that.
\end{itemize}

Although many developers have a methodology-of-choice, the argument here
is that there are tradeoffs with all of these choices. Methodologies are
like \emph{bicycles}, rather than \emph{religions}. Rather than simply
\emph{believing}, we can take them apart and see how they work.

\textbf{We can place methodologies within a framework, and show how
choice of methodology is contingent on the risks faced.}

\hypertarget{driving-development-with-a-risk-first-perspective}{%
\section{6. Driving Development With a Risk-First
Perspective}\label{driving-development-with-a-risk-first-perspective}}

We have described a model of risk within software projects, looking
something like this:

\begin{figure}
\centering
\includegraphics{images/generated/pattern_language-400dpi.png}
\caption{Methdologies, Risks, Practices}
\end{figure}

How do we take this further?

The first idea we explore is that of the Risk Landscape where the risks
on the project are more favourable than where they started.

From there, we examine basic risk archetypes you will encounter on the
software project, to build up a Taxonomy of Software Risk, and look at
which specific tools you can use to mitigate each kind of risk.

Then, we look at different software practices, and how they mitigate
various risks. Beyond this we examine the question: \emph{how can a
Risk-First approach inform the use of this technique?}

For example:

\begin{itemize}
\tightlist
\item
  If we are introducing a \textbf{Sign-Off} in our process, we have to
  balance the risks it \emph{mitigates} (coordination of effort, quality
  control, information sharing) with the risks it \emph{introduces}
  (delays and process bottlenecks).
\item
  If we have \textbf{Redundant Systems}, this mitigates the risk of a
  \emph{single point of failure}, but introduces risks around
  \emph{synchronizing data} and \emph{communication} between the
  systems.
\item
  If we introduce \textbf{Process}, this may make it easier to
  \emph{coordinate as a team} and \emph{measure performance} but may
  lead to bureaucracy, focusing on the wrong goals or over-rigid
  interfaces to those processes.
\end{itemize}

Risk-First aims to provide a framework in which we can \emph{analyse
these choices} and weigh up \emph{accepting} versus \emph{mitigating}
risks.

\textbf{Still interested? Then dive into reading the introduction.}

\mainmatter
\part{Introduction}

\hypertarget{a-simple-scenario}{%
\chapter{A Simple Scenario}\label{a-simple-scenario}}

First up, I'm going to introduce a simple model for thinking about risk.

\hypertarget{a-simple-scenario-1}{%
\section{A Simple Scenario}\label{a-simple-scenario-1}}

Lets for a moment forget about software completely, and think about
\emph{any endeavor at all} in life. It could be passing a test, mowing
the lawn or going on holiday. Choose something now. I'll discuss from
the point of view of ``cooking a meal for some friends'', but you can
play along with your own example.

\hypertarget{goal-in-mind}{%
\subsection{Goal In Mind}\label{goal-in-mind}}

Now, in this endeavour, we want to be successful. That is to say, we
have a Goal In Mind we \emph{probably} have to do some tasks.

If we do nothing, our friends will turn up and maybe there's nothing in
the house for them to eat. Or maybe, the thing that you're going to cook
is going to take hours and they'll have to sit around and wait for you
to cook it and they'll leave before it's ready. Maybe you'll be some
ingredients short, or maybe you're not confident of the steps to prepare
the meal and you're worried about messing it all up.

\hypertarget{attendant-risk}{%
\subsection{Attendant Risk}\label{attendant-risk}}

These \emph{nagging doubts} that are going through your head I'll call
the Attendant Risks: they're the ones that will occur to you as you
start to think about what will happen.

\begin{figure}
\centering
\includegraphics{images/generated/goal_in_mind-400dpi.png}
\caption{Goal In Mind, with the risks you know about}
\end{figure}

When we go about preparing this wonderful evening, we can with these
risks and try to mitigate them: shop for the ingredients in advance,
prepare parts of the meal, maybe practice the cooking in advance. Or, we
can wing it, and sometimes we'll get lucky.

How much effort we expend on mitigating Attendant Risks.

\hypertarget{hidden-risks}{%
\subsection{Hidden Risks}\label{hidden-risks}}

There are also hidden \href{Glossary\#attendant-risk}{Attendant Risks}
that you might not know about: if you're poaching eggs for dinner, you
might know that fresh eggs poach best. These are the ``Unknown
Unknowns'' of
\href{https://en.wikipedia.org/wiki/There_are_known_knowns}{Rumsfeld's
model}.

\begin{figure}
\centering
\includegraphics{images/generated/goal_in_mind-400dpi.png}
\caption{Goal In Mind, the risks you know about and the ones you don't}
\end{figure}

Different people will evaluate the risks differently. (That is, worry
about them more or less.) They'll also \emph{know} about different
risks. They might have cooked the recipe before, or organised lots more
dinner parties than you.

How we evaluate the risks, and which ones we know about depends on our
\textbf{knowledge} and \textbf{experience}, then. And that varies from
person to person (or team to team). Lets call this our Internal Model.

\hypertarget{model-meets-reality}{%
\subsection{Model Meets Reality}\label{model-meets-reality}}

As the dinner party gets closer, we make our preparations, and the
inadequacies of the Internal Model reveal themselves; things we were
worried about may not materialise, things we thought would be minor
risks turn out to be greater.

Our model is forced into contact with reality, and the model changes.

\begin{figure}
\centering
\includegraphics{images/generated/model_vs_reality-400dpi.png}
\caption{How taking action affects Reality, and also changes your
internal model}
\end{figure}

If we had a good model, and took the right actions, we should see
positive outcomes. If we failed to mitigate risks, or took inappropriate
actions, we'll probably see negative outcomes.

\hypertarget{on-to-software}{%
\section{On To Software}\label{on-to-software}}

In this website, we're going to look at the risks in the software
process and how these are mitigated by the various methodologies you can
choose from.

Let's examine the scenario of a new software project, and expand on the
simple model being outlined above: instead of a single person, we are
likely to have a team, and our model will not just exist in our heads,
but in the code we write.

On to Development Process

\hypertarget{development-process}{%
\chapter{Development Process}\label{development-process}}

In the previous chapter we looked at a simple model for risks on any
given activity.

Now, let's look at the everyday process of developing \emph{a new
feature} on a software project, and see how our risk model informs it.

\hypertarget{an-example-process}{%
\section{An Example Process}\label{an-example-process}}

Let's ignore for now the specifics of what methodology is being used -
we'll come to that later. Let's say your team have settled for a process
something like the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Specification}: A new feature is requested somehow, and a
  business analyst works to specify it.
\item
  \textbf{Code And Unit Test}: A developer writes some code, and some
  unit tests.
\item
  \textbf{Integration}: They integrate their code into the code base.
\item
  \textbf{UAT}: They put the code into a User Acceptance Test (UAT)
  environment, and user(s) test it.
\end{enumerate}

\ldots{} All being well, the code is released to production.

Now, it might be waterfall, it might be agile, we're not going to commit
to specifics at this stage. It's probably not perfect, but let's just
assume that \emph{it works for this project} and everyone is reasonably
happy with it.

I'm not saying this is the \emph{right} process, or even a \emph{good}
process: you could add code review, a pilot, integration testing,
whatever. We're just doing some analysis of \emph{what process gives
us}.

\begin{figure}
\centering
\includegraphics{images/generated/development_process_1-400dpi.png}
\caption{A Simple Development Process}
\end{figure}

What's happening here? Why these steps?

\hypertarget{minimizing-risks---overview}{%
\section{Minimizing Risks -
Overview}\label{minimizing-risks---overview}}

I am going to argue that this entire process is \emph{informed by
software risk}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We have \emph{a business analyst} who talks to users and fleshes out
  the details of the feature properly. This is to minimize the risk of
  \textbf{building the wrong thing}.
\item
  We \emph{write unit tests} to minimize the risk that our code
  \textbf{isn't doing what we expected, and that it matches the
  specifications}.
\item
  We \emph{integrate our code} to minimize the risk that it's
  \textbf{inconsistent with the other, existing code on the project}.
\item
  We have \emph{acceptance testing} and quality gates generally to
  \textbf{minimize the risk of breaking production}, somehow.
\end{enumerate}

We could skip all those steps above and just do this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Developer gets wind of new idea from user, logs onto production and
  changes some code directly.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/development_process_2-400dpi.png}
\caption{A Dangerous Development Process}
\end{figure}

We can all see this would be a disaster, but why?

Two reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  You're meeting reality all-in-one-go: all of these risks materialize
  at the same time, and you have to deal with them all at once.
\item
  Because of this, at the point you put code into the hands of your
  users, your Internal Model now need to be dealt with at the same time,
  in production.
\end{enumerate}

\hypertarget{applying-the-model}{%
\section{Applying the Model}\label{applying-the-model}}

Let's look at how our process should act to prevent these risks
materializing by considering an unhappy path, one where at the outset,
we have lots of Hidden Risks ready to materialize. Let's say a
particularly vocal user rings up someone in the office and asks for new
\textbf{Feature X} to be added to the software. It's logged as a new
feature request, but:

\begin{itemize}
\tightlist
\item
  Unfortunately, this feature once programmed will break an existing
  \textbf{Feature Y}.
\item
  Implementing the feature will use some api in a library, which
  contains bugs and have to be coded around.
\item
  It's going to get misunderstood by the developer too, who is new on
  the project and doesn't understand how the software is used.
\item
  Actually, this functionality is mainly served by \textbf{Feature
  Z}\ldots{}
\item
  which is already there but hard to find.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/development_process_3-400dpi.png}
\caption{Development Process - Hidden Risks}
\end{figure}

-or-

\begin{figure}
\centering
\includegraphics{images/generated/development_process_4-400dpi.png}
\caption{Development Process - Hidden Risks}
\end{figure}

This is a slightly contrived example, as you'll see. But let's follow
our feature through the process and see how it meets reality slowly, and
the hidden risks are discovered:

\hypertarget{specification}{%
\subsection{Specification}\label{specification}}

The first stage of the journey for the feature is that it meets the
Business Analyst (BA). The \emph{purpose} of the BA is to examine new
goals for the project and try to integrate them with \emph{reality as
they understands it}. A good BA might take a feature request and vet it
against the internal logic of the project, saying something like:

\begin{itemize}
\tightlist
\item
  ``This feature doesn't belong on the User screen, it belongs on the
  New Account screen''
\item
  ``90\% of this functionality is already present in the Document Merge
  Process''
\item
  ``We need a control on the form that allows the user to select between
  Internal and External projects''
\end{itemize}

In the process of doing this, the BA is turning the simple feature
request \emph{idea} into a more consistent, well-explained
\emph{specification} or \emph{requirement} which the developer can pick
up. But why is this a useful step in our simple methodology? From the
perspective of our Internal Model, we can say that the BA is responsible
for:

\begin{itemize}
\tightlist
\item
  Trying to surface Hidden Risks
\item
  Trying to evaluate Attendant Risk and make it clear to everyone on the
  project.
\end{itemize}

Hopefully, after this stage, our Internal Model might look something
like this:

\begin{figure}
\centering
\includegraphics{images/generated/development_process_ba-400dpi.png}
\caption{BA Specification: exposing hidden risks as soon as possible}
\end{figure}

In surfacing these risks, there is another outcome: while
\textbf{Feature X} might be flawed as originally presented, the BA can
``evolve'' it into a specification, and tie it down sufficiently to
reduce the risks. The BA does all this by simply \emph{thinking about
it}, \emph{talking to people} and \emph{writing stuff down}.

This process of evolving the feature request into a requirement is the
BAs job. From our risk-first perspective, it is \emph{taking an idea and
making it meet reality}. Not the \emph{full reality} of production
(yet), but something more limited. After its brush with reality, the
goal in mind**.

\hypertarget{code-and-unit-test}{%
\subsection{Code And Unit Test}\label{code-and-unit-test}}

The next stage for our feature, \textbf{Feature X (Specification)} is
that it gets coded and some tests get written. Let's look at how our
goal in mind meets a new reality: this time it's the reality of a
pre-existing codebase, which has it's own internal logic.

As the developer begins coding the feature in the software, she will
start with an Internal Model of the software, and how the code fits into
it. But, in the process of implementing it, she is likely to learn about
the codebase, and her Internal Model will develop.

To a large extent, this is the whole point of \emph{type safety}: to
ensure that your Internal Model stays consistent with the reality of the
codebase. If you add code that doesn't fit the reality of the codebase,
you'll know about it with compile errors.

The same thing is true of writing unit tests: again you are testing your
Internal Model against the reality of the system being built, running in
your development environment. Hopefully, this will surface some new
hidden risks, and again, because the goal in mind**.

\begin{figure}
\centering
\includegraphics{images/generated/development_process_code-400dpi.png}
\caption{Coding Process: exposing more hidden risks as you code}
\end{figure}

\hypertarget{integration}{%
\subsection{Integration}\label{integration}}

Integration is where we run \emph{all} the tests on the project, and
compile \emph{all} the code in a clean environment: the ``reality'' of
the development environment can vary from one developer's machine to
another.

So, this stage is about the developer's committed code meeting a new
reality: the clean build.

At this stage, we might discover the Hidden Risk that we'd break
\textbf{Feature Y}

\begin{figure}
\centering
\includegraphics{images/generated/development_process_integration-400dpi.png}
\caption{Integration testing exposes hidden risks before you get to
production}
\end{figure}

\hypertarget{uat}{%
\subsection{UAT}\label{uat}}

Is where our feature meets another reality: \emph{actual users}. I think
you can see how the process works by now. We're just flushing out yet
more Hidden Risks:

\begin{figure}
\centering
\includegraphics{images/generated/development_process_uat-400dpi.png}
\caption{UAT - putting tame users in front of your software is better
than real ones, where the risk is higher}
\end{figure}

\hypertarget{observations}{%
\section{Observations}\label{observations}}

A couple of things:

\textbf{First}, the people setting up the development process
\emph{didn't know} about these \emph{exact} risks, but they knew the
\emph{shape that the risks take}. The process builds ``nets'' for the
different kinds of hidden risks without knowing exactly what they are.
Part of the purpose of this site is to help with this and try and
provide a taxonomy for different types of risks.

\textbf{Second}, are these really risks, or are they \emph{problems we
just didn't know about}? I am using the terms interchangeably, to a
certain extent. Even when you know you have a problem, it's still a risk
to your deadline until it's solved. So, when does a risk become a
problem? Is a problem still just a schedule-risk, or cost-risk? It's
pretty hard to draw a line and say exactly.

\textbf{Third}, the real take-away from this is that all these risks
exist because we don't know 100\% how reality is. Risk exists because we
don't (and can't) have a perfect view of the universe and how it'll
develop. Reality is reality, \emph{the risks just exist in our head}.

\textbf{Fourth}, hopefully you can see from the above that really
\emph{all this work is risk management}, and \emph{all work is testing
ideas against reality}.

\hypertarget{conclusion}{%
\section{Conclusion?}\label{conclusion}}

Could it be that \emph{everything} you do on a software project is risk
management? This is an idea explored in the next chapter.

\hypertarget{all-risk-management}{%
\chapter{All Risk Management}\label{all-risk-management}}

In this chapter, I am going to introduce the idea that everything you do
on a software project is Risk Management.

In the last chapter, we observed that all the activities in a simple
methodology had a part to play in exposing different risks. They worked
to manage risk prior to them creating bigger problems in production.

Here, we'll look at one of the tools in the Project Manager's toolbox,
the \href{http://pmtips.net/blog-new/raid-logs-introduction}{RAID Log},
and observe how risk-centric it is.

\hypertarget{raid-log}{%
\section{RAID Log}\label{raid-log}}

Many project managers will be familiar with the RAID Log. It's simply
four columns on a spreadsheet:

\begin{itemize}
\tightlist
\item
  Risks
\item
  Actions
\item
  Issues
\item
  Decisions
\end{itemize}

Let's try and put the following Attendant Risk into the RAID Log:

\begin{quote}
Debbie needs to visit the client to get them to choose the logo to use
on the product, otherwise we can't size the screen areas exactly.
\end{quote}

\begin{itemize}
\tightlist
\item
  So, is this an \textbf{action}? Certainly. There's definitely
  something for Debbie to do here.
\item
  Is it an \textbf{issue}? Yes, because it's holding up the screen-areas
  sizing thing.
\item
  Is it a \textbf{decision}? Well, clearly, it's a decision for someone.
\item
  Is it a \textbf{risk}? Probably: Debbie might go to the client and
  they \emph{still} don't make a decision. What then?
\end{itemize}

\hypertarget{lets-go-again}{%
\section{Let's Go Again}\label{lets-go-again}}

This is a completely made-up example, deliberately chosen to be hard to
categorize. Normally, items are more one thing than another. But often,
you'll have to make a choice between two categories, if not all four.

This hints at the fact that at some level it's All Risk:

\hypertarget{every-action-mitigates-risk}{%
\subsection{Every Action Mitigates
Risk}\label{every-action-mitigates-risk}}

The reason you are \emph{taking} an action is to mitigate a risk. For
example, if you're coing up new features in the software, this is
mitigating Feature Risk-style \emph{stakeholder risk}.

\hypertarget{every-action-carries-risk.}{%
\subsection{Every Action Carries
Risk.}\label{every-action-carries-risk.}}

\begin{itemize}
\tightlist
\item
  How do you know if the action will get completed?
\item
  Will it overrun on time?
\item
  Will it lead to yet more actions?
\end{itemize}

Consider \emph{coding a feature} (as we did in the earlier Development
Process.

And, as we saw in the Introduction, even something \emph{mundane} like
the Dinner Party had risks.

\hypertarget{an-issue-is-just-a-type-of-risk}{%
\subsection{An Issue is Just A Type of
Risk}\label{an-issue-is-just-a-type-of-risk}}

\begin{itemize}
\tightlist
\item
  Because issues need to be solved\ldots{}
\item
  And solving an issue is an action\ldots{}
\item
  Which, as we just saw also carry risk.
\end{itemize}

One retort to this might be to say: an issue is a problem I have now,
whereas a risk is a problem that \emph{might} occur. I am going to try
and \emph{break} that mindset in the coming pages, but I'll just start
with this:

\begin{itemize}
\tightlist
\item
  Do you know \emph{exactly} how much damage this issue will do?
\item
  Can you be sure that the issue might not somehow go away?
\end{itemize}

\emph{Issues} then, just seem more ``definite'' and ``now'' than
\emph{risks}, right? This classification is arbitrary: they're all just
part of the same spectrum, so stop agonising over which column to put
them in.

\hypertarget{every-decision-is-a-risk.}{%
\subsection{Every Decision is a Risk.}\label{every-decision-is-a-risk.}}

\begin{itemize}
\tightlist
\item
  By the very nature of having to make a decision, there's the risk
  you'll decide wrongly.
\item
  And, there's the time it takes to make the decision.
\item
  And what's the risk if the decision doesn't get made?
\end{itemize}

\hypertarget{failure}{%
\section{Failure}\label{failure}}

tbd.

\hypertarget{what-to-do}{%
\section{What To Do?}\label{what-to-do}}

It makes it much easier to tackle the RAID log if there's only one list:
all you do is pick the worst risk on the list, and deal with it. (In
Risk Theory.

OK, so maybe that \emph{works} for a RAID log (or a Risk log, since
we've thrown out the others), but does it scale to a whole project?

In the next chapter, Software Project Scenario I will make a slightly
stronger case for the idea that it does.

\hypertarget{software-project-scenario}{%
\chapter{Software Project Scenario}\label{software-project-scenario}}

Where do the risks of the project lie?

How do we decide what \emph{needs to be done today} on a software
project?

Let's look again at the simple risk framework from the introduction and
try to apply it at the level of the \emph{entire project}.

\begin{figure}
\centering
\includegraphics{images/generated/model_vs_reality-400dpi.png}
\caption{Taking action changes reality, but it changes your perception
of the attendant risks too}
\end{figure}

\hypertarget{goal-in-mind-1}{%
\section{Goal In Mind}\label{goal-in-mind-1}}

How should we decide how to spend our time today?

What actions should we take? (In Scrum.

If we want to take the right actions, we need to have a good Internal
Model.

Sometimes, we will know that our model is deficient, and our time should
be spend \emph{improving} it, perhaps by talking to our clients, or the
support staff, or other developers, or reading.

But let's say for example, today our Goal In Mind is to grow our user
base.

tbd. image of this goal.

\hypertarget{attendant-risks}{%
\section{Attendant Risks}\label{attendant-risks}}

What are the Attendant Risks that come with that goal? Here are some to
get us started:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The users can't access the system
\item
  The data gets lost, stolen.
\item
  The data is wrong or corrupted
\item
  There are bugs that prevent the functionality working
\item
  The functionality isn't there that the user needs (Feature Risk.
\item
  Our Internal Model of the market is poor, and we could be building the
  wrong thing.
\end{enumerate}

I'm sure you can think of some more.

tbd. image

\hypertarget{evaluating-the-risks}{%
\section{Evaluating The Risks}\label{evaluating-the-risks}}

Next, we can look at each of these risks and consider the threat they
represent. Usually, when evaluating a risk we consider both it's
\textbf{impact} and \textbf{likelihood}.

The same Attendant Risks will be evaluated differently depending on the
\emph{nature of the project} and the mitigations you already have in
place. For example:

\begin{itemize}
\tightlist
\item
  If they \textbf{can't access it}, does that mean that they're stuck
  unable to get on the train? Or they can't listen to music?
\item
  If the \textbf{data is lost}, does this mean that no one can get on
  the plane? Or that the patients have to have their CAT scans done
  again? Or that people's private information is scattered around the
  Internet?
\item
  If the \textbf{data is wrong}, does that mean that the wrong people
  get sent their parcels? Do they receive the wrong orders? Do they end
  up going to the wrong courses?
\item
  If there are \textbf{bugs}, does it mean that their pictures don't end
  up on the internet? Does it mean that they have to restart the
  program? Does it mean that they'll waste time, or that they end up
  thinking they have insurance but haven't?
\item
  If there is \textbf{missing functionality}, will they not buy the
  system? Will they use a competitor's product? Will they waste time
  doing things a harder or less optimal way?
\item
  If our \textbf{Internal Model is wrong}, then is there a chance we are
  building something for a non-existent market? Or annoying our
  customers? Or leaving an opportunity for competitors?
\end{itemize}

\hypertarget{outcomes}{%
\section{Outcomes}\label{outcomes}}

As part of evaluating the risks, we can also \emph{predict} the negative
outcomes if these risks materialise and we don't take action.

\begin{itemize}
\tightlist
\item
  Losing Revenue
\item
  Legal Culpability
\item
  Losing Users
\item
  Bad Reputation
\item
  etc.
\end{itemize}

\hypertarget{a-single-attendant-risk-getting-hacked}{%
\section{A Single Attendant Risk: Getting
Hacked}\label{a-single-attendant-risk-getting-hacked}}

Let's consider a single risk: that the website gets hacked, and
sensitive data is stolen. How we evaluate this risk is going to depend
on a number of factors:

\begin{itemize}
\tightlist
\item
  How many users we have
\item
  The importance of the data
\item
  How much revenue will be lost
\item
  Risk of litigation
\item
  etc.
\end{itemize}

\hypertarget{ashley-maddison}{%
\subsubsection{Ashley Maddison}\label{ashley-maddison}}

We've seen
\href{https://www.acunetix.com/blog/articles/password-hashing-and-the-ashley-madison-hack/}{in
the example of hacks on LinkedIn and Ashley Maddison} that passwords
were not held as hashes in the database. (A practice which experienced
developers mainly would see as negligent).

How does our model explain what happened here?

\begin{itemize}
\tightlist
\item
  It's possible that \emph{at the time of implementing the password
  storage}, hashing was considered, but the evaluation of the risk was
  low: Perhaps, the risk of not shipping quickly was deemed greater. And
  so they ignored this concern.
\item
  It's also possible that for the developers in question this was a
  Hidden Risk, and they hadn't even considered it.
\item
  However, as the number of users of the sites increased, the risk
  increased too, but there was no re-evaluation of the risk otherwise
  they would have addressed it. This was a costly \emph{failure to
  update the Internal Model}.
\end{itemize}

\hypertarget{possible-action}{%
\subsubsection{Possible Action}\label{possible-action}}

When exposing a service on the Internet, it's now a good idea to
\emph{look for trouble}: you should go out and try and improve your
Internal Model.

Thankfully, this is what sites like
\href{https://www.owasp.org/index.php/Top_10-2017_Top_10}{OWASP} are
for: they \emph{tell you about the
\href{Glossary\#attendant-risk}{Attendant Risks}} and further, try to
provide some evaluation of them to guide your actions.

\hypertarget{actions}{%
\section{Actions}\label{actions}}

So, this gives us a guide for one potential action we could take
\emph{today}. But on it's own, this isn't helpful: we would need to
consider this action against the actions we could take to mitigate the
other risks. Can we answer this question:

Which actions give us the biggest benefit in terms of mitigating the
Attendant Risks?

That is, we consider for each possible action:

\begin{itemize}
\tightlist
\item
  The Impact and Likelihood of the Attendant Risks it mitigates
\item
  The Cost of the Action
\end{itemize}

For example, it's worth considering that if we're just starting this
project, risks 1-4 are \emph{negligible}, and we're only going to spend
time building functionality or improving our understanding of the
market. (Which makes sense, right?)

\hypertarget{tacit-and-explicit-modelling}{%
\section{Tacit and Explicit
Modelling}\label{tacit-and-explicit-modelling}}

As we saw in the example of the Dinner Party.

Whether we do this explicitly or not, we are still individually
following this model.

In the next chapter, we're going to take a quick aside into looking at
some Risk Theory.

\hypertarget{risk-theory}{%
\chapter{Risk Theory}\label{risk-theory}}

Here, I am going to recap on some pre-existing knowledge about risk,
generally, in order to set the scene for the next chapter on Meeting
Reality.

\hypertarget{risk-registers}{%
\section{Risk Registers}\label{risk-registers}}

In the previous chapter Software Project Scenario of the project, in
order to decide what to do next.

A \href{https://en.wikipedia.org/wiki/Risk_register}{Risk Register} can
help with this. From Wikipedia:

\begin{quote}
A typical risk register contains:

\begin{itemize}
\tightlist
\item
  A risk category to group similar risks
\item
  The risk breakdown structure identification number
\item
  A brief description or name of the risk to make the risk easy to
  discuss
\item
  The impact (or consequence) if event actually occurs rated on an
  integer scale
\item
  The probability or likelihood of its occurrence rated on an integer
  scale
\item
  The Risk Score (or Risk Rating) is the multiplication of Probability
  and Impact and is often used to rank the risks.
\item
  Common mitigation steps (e.g.~within IT projects) are Identify,
  Analyze, Plan Response, Monitor and Control.
\end{itemize}
\end{quote}

This is Wikipedia's example:

\begin{figure}
\centering
\includegraphics{images/WikipediaRiskRegister2.png}
\caption{Wikipedia Risk Register}
\end{figure}

Some points about this description:

\hypertarget{this-is-a-bells-and-whistles-description}{%
\subsection{This is a Bells-and-Whistles
Description}\label{this-is-a-bells-and-whistles-description}}

Remember back to the Dinner Party example at the start: the Risk
Register happened \emph{entirely in your head}. There is a continuum all
the way from ``in your head'' to Wikipedia's Risk Register description.
Most of the time, it's going to be in your head, or in discussion with
the team, rather than written down.

Most of the value of the \textbf{Risk-First} approach is \emph{in
conversation}. Later, we'll have an example to show how this can work
out.

\hypertarget{probability-and-impact}{%
\subsection{Probability And Impact}\label{probability-and-impact}}

Sometimes, it's better to skip these, and just figure out a Risk Score.
This is because if you think about ``impact'', it implies a definite,
discrete event occurring, or not occurring, and asks you then to
consider the probability of that occurring.

\textbf{Risk-First} takes a view that risks are a continuous quantity,
more like \emph{money} or \emph{water}: by taking an action before
delivering a project you might add a degree of Schedule Risk later on by
a greater amount.

\hypertarget{graphical-analysis}{%
\section{Graphical Analysis}\label{graphical-analysis}}

The Wikipedia page also includes this wonderful diagram showing you
risks of a poorly run barbecue party:

\begin{figure}
\centering
\includegraphics{images/WikipediaRiskRegister1.png}
\caption{Wikipedia Risk Register}
\end{figure}

This type of graphic is \emph{helpful} in deciding what to do next,
although personally I prefer to graph the overall \textbf{Risk Score}
against the \textbf{Cost of Mitigation}: easily mitigated, but expensive
risks can therefore be dealt with first (hopefully).

\hypertarget{unknown-unknowns}{%
\section{Unknown Unknowns}\label{unknown-unknowns}}

In Wikipedia's example, this ficticious BBQ has high fire risk, so one
should begin mitigating there.

But, does this feel right? One of the criticisms of the Risk Register.
That is, mistakenly believing that what's on the Risk Register \emph{is
all there is}.

In the preceding discussions, I have been careful to point out the
existence of Hidden Risks for that very reason. Or, to put another way:

\begin{quote}
What we don't know is what usually gets us killed - Petyr Baelish
\end{quote}

Donald Rumsfeld's famous
\href{https://en.wikipedia.org/wiki/There_are_known_knowns}{Known
Knowns} is also a helpful conceptualization.

\hypertarget{risk-and-uncertainty}{%
\section{Risk And Uncertainty}\label{risk-and-uncertainty}}

Arguably, this site uses the term `Risk' wrongly: most literature
suggests
\href{https://keydifferences.com/difference-between-risk-and-uncertainty.html}{risk
can be measured} whereas uncertainty represents things that cannot.

I am using \textbf{risk} everywhere because later we will talk about
specific risks (e.g. \href{Boundary-Risk}{Boundary Risk} or
\href{Complexity-Risk}{Complexity Risk}), and it doesn't feel
grammatically correct to talk about those as \textbf{uncertainties},
especially given the pre-existing usage in Banking of terms like
\href{https://en.wikipedia.org/wiki/Operational_risk}{Operational Risk}
or
\href{https://www.investopedia.com/terms/r/reputational-risk.asp}{Reputational
risk} which are also not really a-priori measurable.

\hypertarget{the-opposite-of-risk-management}{%
\section{The Opposite Of Risk
Management}\label{the-opposite-of-risk-management}}

Let's look at the classic description of Risk Management:

\begin{quote}
Risk Management is the process of thinking out corrective actions before
a problem occurs, while it's still an abstraction. The opposite of risk
management is crisis management, trying to figure out what to do about
the problem after it happens. - Waltzing With Bears, Tom De Marco \& Tim
Lister
\end{quote}

This is not how \textbf{Risk-First} sees it:

First, we have the notion that Risks are discrete events, again. Some
risks \emph{are} (like gambling on a horse race), but most
\emph{aren't}. In the Dinner Party, for example, bad preparation is
going to mean a \emph{worse} time for everyone, but how good a time
you're having is a spectrum, it doesn't divide neatly into just ``good''
or ``bad''.

Second, the opposite of ``Risk Management'' (or trying to minimize the
``Downside'') is either ``Upside Risk Management'', (trying to maximise
the good things happening), or it's trying to make as many bad things
happen as possible. Humans tend to be optimists (especially when there
are lots of Hidden Risks, hence our focus on Downside Risk. Sometimes
though, it's good to stand back and look at a scenario and think: am I
capturing all the Upside Risk here?

Finally, Crisis Management is \emph{still just Risk Management}: the
crisis (Earthquake, whatever) has \emph{happened}. You can't manage it
because it's in the past. All you can do is Risk Manage the future
(minimize further casualties and human suffering, for example).

Yes, it's fine to say ``we're in crisis'', but to assume there is a
different strategy for dealing with it is a mistake: this is the
\href{https://en.wikipedia.org/wiki/Sunk_costs}{Fallacy of Sunk Costs}.

\hypertarget{invariances-1-panic-invariance}{%
\section{Invariances \#1: Panic
Invariance}\label{invariances-1-panic-invariance}}

You would expect then, that any methods for managing software delivery
should be \emph{invariant} to the level of crisis in the project. If,
for example, a project proceeds using Scrum for eight months, and then
the deadline looms and everyone agrees to throw Scrum out of the window
and start hacking, then \emph{this implies there is a problem with
Scrum}. Or at least, the way it was being implemented.

I call this \textbf{Panic Invariance}: the methodology shouldn't need to
change given the amount of pressure or importance on the table.

\hypertarget{invariances-2-scale-invariance}{%
\section{Invariances \#2: Scale
Invariance}\label{invariances-2-scale-invariance}}

Another test of a methodology is that it shouldn't fall down when
applied at different \emph{scales}. Because, if it does, this implies
that there is something wrong with the methodology. The same is true of
physical laws: if they don't apply under all circumstances, then that
implies something is wrong. For example, Newton's Laws of Motion fail to
calculate the orbital period of Mercury, and this was an early win for
Einstein's Relativity.

Some methodologies are designed for certain scales: Extreme Programming
is designed for small, co-located teams. And, that's useful. But the
fact it doesn't scale tells us something about it: chiefly, that it
considers certain \emph{kinds} of risk, while ignoring others. At small
scales, that works ok, but at larger scales, the bigger risks increase
too fast for it to work.

tbd.

So ideally, a methodology should be applicable at \emph{any} scale: - A
single class or function - A collection of functions, or a library - A
project team - A department - An entire organisation

If the methodology \emph{fails at a particular scale}, this tells you
something about the risks that the methodology isn't addressing. It's
fine to have methodologies that work at different scales, and on
different problems. One of the things that I am exploring with Risk
First is trying to place methodologies and practices within a framework
to say \emph{when} they are applicable.

\hypertarget{value}{%
\section{Value}\label{value}}

``Upside Risk'' isn't a commonly used term: industry tends to prefer
``value'', as in ``Is this a value-add project?''. There is plenty of
theory surrounding \textbf{Value}, such as Porter's Value Chain. This is
all fine so long as we remember:

\begin{itemize}
\tightlist
\item
  \textbf{The pay-off is risky}: Since the \textbf{Value} is created in
  the future, we can't be certain about it happening - we should never
  consider it a done-deal. \textbf{Future Value} is always at risk. In
  finance, for example, we account for this in our future cash-flows by
  discounting them according to the risk of default.
\item
  \textbf{The pay-off amount is risky}: Additionally, whereas in a
  financial transaction (like a loan, say), we might know the size of a
  future payment, in IT projects we can rarely be sure that they will
  deliver a certain return. On some fixed-contract projects this
  sometimes is not true: there may be a date when the
  payment-for-delivery gets made, but mostly we'll be expecting an
  uncertain pay-off.
\end{itemize}

\textbf{Risk-First} is a particular \emph{view} on reality. It's not the
only one. However, I am going to try and make the case that it's an
underutilized one that has much to offer us.

\hypertarget{speed}{%
\section{Speed}\label{speed}}

For example, in Rapid Development by Steve McConnell we have the
following diagram:

\begin{figure}
\centering
\includegraphics{images/rapid_development_pillars.png}
\caption{Rapid Development Pillars- From Steve McConnell}
\end{figure}

tbd. redraw this.

And, this is \emph{fine}, McConnel is structuring the process from the
perspective of \emph{delivering as quickly as possible}. However, here,
I want to turn this on it's head. Exploring Software Development from a
risk-first perspective is an under-explored technique, and I believe it
offers some useful insights. So the aim here is to present the case for
viewing software development like this:

tbd. risk-first diagram.

\hypertarget{net-present-risk}{%
\section{Net Present Risk}\label{net-present-risk}}

If we can view software delivery from the point of view of \emph{value},
then why can't we apply the same tools to Risk too? In order to do this,
let's review ``Eisenhower's Box'' model. This considers two variables:

\begin{itemize}
\tightlist
\item
  How valuable the work is (Importance)
\item
  How soon it is needed (Urgency)
\end{itemize}

tbd. image from wikipedia. text from wikipedia.

Here, we're considering a synthesis of both \emph{time} and
\emph{value}. But Net Present Value allows us to discount value in the
future, which offers us a way to reconcile these two variables:

chart of discounting into the future tbd.

Let's do the same thing with risk? Let's introduce the concept of Net
Present Risk, or NPR:

\begin{quote}
Net Present Risk is tbd.
\end{quote}

Let's look at a quick example to see how this could work out. Let's say
you had the following 3 risks:

\begin{itemize}
\tightlist
\item
  Risk \textbf{A}, which will cost you Â£50 in 5 year's time.
\item
  Risk \textbf{B}, which will cost you Â£70 in 8 year's time.
\item
  Risk \textbf{C}, which will cost you Â£120 in 18 year's time.
\end{itemize}

Which has the biggest NPR? Well, it depends on the discount rate that
you apply. Let's assume we are discounting at 6\% per year. A graph of
the discounted risks looks like this:

tbd, see numbers

On this basis, the biggest risk is \textbf{B}, at about \#45. If we
\emph{reduce} the discount factor to 3\%, we get a different result:

tbd, see numbers.

Now, risk \textbf{C} is bigger.

Because this is \emph{Net} Present Risk, we can also use it to make
decisions about whether or not to mitigate risks. Let's consider the
cost of mitigating each risk \emph{now}:

\begin{itemize}
\tightlist
\item
  Risk \textbf{A} costs Â£20 to mitigate
\item
  Risk \textbf{B} costs Â£50 to mitigate
\item
  Risk \textbf{C} costs Â£100 to mitigate
\end{itemize}

Which is the best deal?

Well, under the 6\% regime, only Risk \textbf{A} is worth mitigating,
because you spend Â£20 today to get rid of \#40 of risk (today). The NPR
is positive at around Â£20, whereas for \textbf{B} and \textbf{C}
mitigations it's under water.

tbd.

Under a 3\% regime, risk \textbf{A} and \textbf{B} are \emph{both} worth
mitigating, as you can see in this graph:

\hypertarget{discounting-the-future-to-zero}{%
\section{Discounting the Future To
Zero}\label{discounting-the-future-to-zero}}

I have worked in teams sometimes where the blinkers go down, and the
only thing that matters is \emph{now}. They may apply a rate of 60\%
per-day, which means that anything with a horizon over a week is
irrelevant. Regimes of such hyperinflation are a sure sign that
something has \emph{really broken down} within a project. Consider in
this case a Discount Factor of 60\% per day, and the following risks:

\begin{itemize}
\tightlist
\item
  Risk A: Â£80 cost, happening \emph{tomorrow}
\item
  Risk B: Â£500 cost, happening in \emph{5 days}.
\end{itemize}

Risk B is almost irrelevant under this regime, as this graph shows:

tbd.

Why do things like this happen? Often, the people involved are under
incredible job-stress: usually they are threatened with the sack on a
daily basis, and therefore feel they have to react. For
publically-listed companies you can also

\begin{itemize}
\tightlist
\item
  more pressure, heavier discounting pooh bear procrastination
\end{itemize}

\hypertarget{is-this-scientific}{%
\section{Is This Scientific?}\label{is-this-scientific}}

\textbf{Risk-First} is an attempt to provide a practical framework,
rather than a scientifically rigorous analysis. In fact, my view is that
you should \emph{give up} on trying to compute risk numerically. You
\emph{can't} work out how long a software project will take based purely
on an analysis of (say) \emph{function points}. (Whatever you define
them to be).

\begin{itemize}
\tightlist
\item
  First, there isn't enough evidence for an approach like this. We
  \emph{can} look at collected data about IT projects, but techniques
  and tools change.
\item
  Second, IT projects have too many confounding factors, such as
  experience of the teams, technologies used etc. That is, the risks
  faced by IT projects are \emph{too diverse} and \emph{hard to
  quantify} to allow for meaningful comparison from one to the next.
\item
  Third, as soon as you \emph{publish a date} it changes the
  expectations of the project (see Student Syndrome.
\item
  Fourth, metrics get first of all misused.
\end{itemize}

Reality is messy. Dressing it up with numbers doesn't change that and
you risk fooling yourself. If this is the case, is there any hope at all
in what we're doing? I would argue yes: \emph{forget precision}. You
should, with experience be able to hold up two separate risks and answer
the question, ``is this one bigger than this one?''

Reality is Reality, so let's meet it.

\hypertarget{meeting-reality}{%
\chapter{Meeting Reality}\label{meeting-reality}}

In this chapter, we will look at how exposing your Internal Model to
reality is in itself a good risk management technique.

\hypertarget{revisiting-the-model}{%
\section{Revisiting the Model}\label{revisiting-the-model}}

In A Simple Scenario, hoping to \textbf{change Reality} with some
positive outcome.

And, in Development Process we looked at how we can meet with reality in
\emph{different forms}: Analysis, Testing, Integration and so on, and
saw how the model could work in each stage of a project.

Finally, in Software Project Scenario we looked at how we could use this
model on a day-to-day basis to inform what we should do next.

So, it should be no surprise to see that there is a \emph{recursive}
nature about this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \textbf{actions we take} each day have consequences: they **expose
  new Hidden Risks
\item
  The actions we take towards achieving a Goal In Mind.
\end{enumerate}

So, let's see how this kind of recursion looks on our model. Note that
here, I am showing \emph{just one possible action}, in reality, you'll
have choices.

\includegraphics{images/generated/model_vs_reality_2-400dpi.png} .

Hopefully, if you've read along so far, this model shouldn't be too hard
to understand. But, how is it helpful?

\hypertarget{navigating-the-risk-landscape}{%
\section{``Navigating the Risk
Landscape''}\label{navigating-the-risk-landscape}}

So, we often have multiple ways of achieving a Goal In Mind.

What's the best way?

I would argue that the best way is the one which accrues the \emph{least
risk} to get it done: each action you take in trying to achieve the
overall Goal In Mind, and it's the experience you bring to bear on these
that will help you navigate through them smoothly.

Ideally, when you take an action, you are trading off a big risk for a
smaller one. Take Unit Testing for example. Clearly, writing Unit Tests
adds to the amount of development work, so on it's own, it adds Schedule
Risk from UAT and adding a smaller risk to \textbf{Development}.

Sometimes, in solving one problem, you can end up somewhere
\emph{worse}: the actions you take to solve a higher-level Attendant
Risk when you embarked on the action, otherwise you'd not have chosen
it.

\hypertarget{an-example-automation}{%
\subsection{An Example: Automation}\label{an-example-automation}}

diagram of how automation reduces process risk, but increases
complexity?

\hypertarget{another-quick-example-mongodb}{%
\subsection{Another Quick Example:
MongoDB}\label{another-quick-example-mongodb}}

On a recent project in a bank, we had a requirement to store a modest
amount of data and we needed to be able to retrieve it fast. The
developer chose to use \href{https://www.mongodb.com}{MongoDB} for this.
At the time, others pointed out that other teams in the bank had had
lots of difficulty deploying MongoDB internally, due to licensing issues
and other factors internal to the bank.

Other options were available, but the developer chose MongoDB because of
their \emph{existing familiarity} with it: therefore, they felt that the
Hidden Risks of MongoDB were \emph{lower} than the other options, and
disregarded the others' opinions.

The data storage Attendant Risk of licensing bureacracy eventually
proved too great, and MongoDB had to be abandoned after much investment
of time.

This is not a criticism of MongoDB: it's simply a demonstration that
sometimes, the cure is worse than the disease. Successful projects are
\emph{always} trying to \emph{reduce} Attendant Risks.

\hypertarget{the-cost-of-meeting-reality}{%
\section{The Cost Of Meeting
Reality}\label{the-cost-of-meeting-reality}}

Meeting reality is \emph{costly}, for example. Going to production can
look like this:

\begin{itemize}
\tightlist
\item
  Releasing software
\item
  Training users
\item
  Getting users to use your system
\item
  Gathering feedback
\end{itemize}

All of these steps take a lot of effort and time. But you don't have to
meet the whole of reality in one go - sometimes that is expensive. But
we can meet it in ``limited ways''.

In all, to de-risk, you should try and meet reality:

\begin{itemize}
\tightlist
\item
  \textbf{Sooner}, so you have time to mitigate the hidden risks it
  uncovers
\item
  \textbf{More Frequently}: so the hidden risks don't hit you all at
  once
\item
  \textbf{In Smaller Chunks}: so you're not overburdened by hidden risks
  all in one go.
\item
  \textbf{With Feedback}: if you don't collect feedback from the
  experience of meeting reality, hidden risks \emph{stay hidden}.
\end{itemize}

tbd this is what testing is all about.

\hypertarget{yagni}{%
\subsection{YAGNI}\label{yagni}}

As a flavour of what's to come, let's look at
\href{https://www.martinfowler.com/bliki/Yagni.html}{YAGNI}, an acronym
for You Aren't Gonna Need It. Martin Fowler says:

\begin{quote}
Yagni originally is an acronym that stands for ``You Aren't Gonna Need
It''. It is a mantra from ExtremeProgramming that's often used generally
in agile software teams. It's a statement that some capability we
presume our software needs in the future should not be built now because
``you aren't gonna need it''.
\end{quote}

\begin{quote}
This principle was first discussed and fleshed out on
\href{http://wiki.c2.com/?YouArentGonnaNeedIt}{Ward's Wiki}
\end{quote}

The idea makes sense: if you take on extra work that you don't need,
\emph{of course} you'll be accreting Attendant Risks.

But, there is always the opposite opinion:
\href{http://wiki.c2.com/?YouAreGonnaNeedIt}{You Are Gonna Need It}. As
a simple example, we often add log statements in our code as we write
it, though following YAGNI strictly says we should leave it out.

\hypertarget{which-is-right}{%
\subsubsection{Which is right?}\label{which-is-right}}

Now, we can say: do the work \emph{if it mitigates your Attendant
Risks}.

\begin{itemize}
\tightlist
\item
  Logging statements are \emph{good}, because otherwise, you're
  increasing the risk that in production, no one will be able to
  understand \emph{how the software went wrong}.
\item
  However, adding them takes time, which might introduce Schedule Risk.
\end{itemize}

So, it's a trade-off: continue adding logging statements so long as you
feel that overall, you're reducing risk.

\hypertarget{do-the-simplest-thing-that-could-possibly-work}{%
\subsection{Do The Simplest Thing That Could Possibly
Work}\label{do-the-simplest-thing-that-could-possibly-work}}

Another mantra from Kent Beck (originator of the Extreme Programming
methodology, is ``Do The Simplest Thing That Could Possibly Work'',
which is closely related to YAGNI and is about looking for solutions
which are simple. Our risk-centric view of this strategy would be:

\begin{itemize}
\tightlist
\item
  Every action you take on a project has it's own Attendant Risks.
\item
  The bigger or more complex the action, the more Attendant Risk it'll
  have.
\item
  The reason you're taking action \emph{at all} is because you're trying
  to reduce risk elsewhere on the project
\item
  Therefore, the biggest payoff is whatever action \emph{works} to
  remove that risk, whilst simultaneously picking up the least amount of
  new Attendant Risk.
\end{itemize}

So, ``Do The Simplest Thing That Could Possibly Work'' is really a
helpful guideline for Navigating the Risk Landscape.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

So, here we've looked at Meeting Reality, which basically boils down to
taking actions to manage risk and seeing how it turns out:

\begin{itemize}
\tightlist
\item
  Each Action you take is a step on the Risk Landscape
\item
  Each Action is a cycle around our model.
\item
  Each cycle, you'll expose new Hidden Risks.
\item
  Preferably, each cycle should reduce the overall Attendant Risk
\end{itemize}

Surely, the faster you can do this, the better? Let's
investigate\ldots{}

\hypertarget{cadence}{%
\chapter{Cadence}\label{cadence}}

Let's go back to the model again, introduced in Meeting Reality:

\begin{figure}
\centering
\includegraphics{images/generated/model_vs_reality_2-400dpi.png}
\caption{Meeting Reality: reality is changed and so is your internal
model.}
\end{figure}

As you can see, it's an idealized \textbf{Feedback Loop}.

How \emph{fast} should we go round this loop? Is there a right answer?
The longer you leave your goal in mind, the longer it'll be before you
find out how it really stacks up against reality.

Testing your goals in mind against reality early and safely is how
you'll manage risk effectively, and to do this, you need to set up
\textbf{Feedback Loops}. e.g.

\begin{itemize}
\tightlist
\item
  \textbf{Bug Reports and Feature Requests} tell you how the users are
  getting on with the software.
\item
  Monitoring Tools and Logs allow you to find out how your software is
  doing in reality.
\item
  \textbf{Dog-Fooding} i.e using the software you write yourself might
  be faster than talking to users.
\item
  Continuous Delivery is about putting software into production as soon
  as it's written.
\item
  \textbf{Integration Testing} is a faster way of meeting \emph{some}
  reality than continually deploying code and re-testing it manually.
\item
  \textbf{Unit Testing} is a faster feedback loop than Integration
  Testing.
\item
  \textbf{Compilation} warns you about logical inconsistencies in your
  code.
\end{itemize}

.. and so on.

\hypertarget{time-reality-trade-off}{%
\subsection{Time / Reality Trade-Off}\label{time-reality-trade-off}}

This list is arranged so that at the top, we have the most visceral,
most \emph{real} feedback loop, but at the same time, the slowest.

At the bottom, a good IDE can inform you about errors in your Internal
Model in real time, by way of highlighting compilation errors . So, this
is the fastest loop, but it's the most \emph{limited} reality.

Imagine for a second that you had a special time-travelling machine.
With it, you could make a change to your software, and get back a report
from the future listing out all the issues people had faced using it
over its lifetime, instantly.

That'd be neat, eh? If you did have this, would there be any point at
all in a compiler? Probably not, right?

The whole \emph{reason} we have tools like compilers is because they
give us a short-cut way to get some limited experience of reality
\emph{faster} than would otherwise be possible. Because, cadence is
really important: the faster we test our ideas, the more quickly we'll
find out if they're correct or not.

\hypertarget{development-cycle-time}{%
\subsection{Development Cycle Time}\label{development-cycle-time}}

One thing that often astounds me is how developers can ignore the fast
feedback loops at the bottom of the list, because the ones nearer the
top \emph{will do}. In the worst cases, changing two lines of code,
running the build script, deploying and then manually testing out a
feature. And then repeating.

If you're doing it over and over, this is a terrible waste of time. And,
you get none of the benefit of a permanent suite of tests to run again
in the future.

The
\href{http://www.agilenutshell.com/episodes/41-testing-pyramid}{Testing
Pyramid} hints at this truth:

\begin{itemize}
\tightlist
\item
  \textbf{Unit Tests} have a \emph{fast feedback loop}, so have
  \emph{lots of them}.
\item
  \textbf{Integration Tests} have a slightly \emph{slower feedback
  loop}, so have \emph{few of them}. Use them when you can't write unit
  tests (at the application boundaries).
\item
  \textbf{Manual Tests} have a \emph{very slow feedback loop}, so have
  \emph{even fewer of them}. Use them as a last resort.
\end{itemize}

\hypertarget{production}{%
\subsection{Production}\label{production}}

You could take this chapter to mean that Continuous Delivery is always
and everywhere a good idea. I \emph{guess} that's not a bad take-away,
but it's clearly more nuanced than that.

Yes, CD will give you faster feedback loops, but getting things into
production is not the whole story: the feedback loop isn't complete
until people have used the code, and reported back to the development
team.

The right answer is to use the fastest feedback loop possible,
\emph{which actually does give you feed back}.

\hypertarget{recap}{%
\section{Recap}\label{recap}}

Let's look at the journey so far:

\begin{itemize}
\item
  In A Simple Scenario of the world couldn't capture everything about
  reality, and so some things were down to chance.
\item
  In the Development Process we looked at how common software
  engineering conventions like Unit Testing, User Acceptance Testing and
  Integration could help us manage the risk of taking an idea to
  production, by \emph{gradually} introducing it to reality in stages.
\item
  In It's All Risk Management we took a leap of faith: Could
  \emph{everything} we do just be risk management? And we looked at the
  RAID log and thought that maybe it could be.
\item
  Next, in A Software Project Scenario we looked at how you could treat
  the project-as-a-whole as a risk management exercise, and treat the
  goals from one day to the next as activities to mitigate risk.
\item
  Some Risk Theory was an aside, looking at some terminology and the
  useful concept of a Risk Register.
\item
  Then, generalizing the lessons of the Development Process article, we
  examined the idea that Meeting Reality.
\item
  Finally, above, we looked at Cadence, and how feedback loops allow you
  Navigate the Risk Landscape more effectively, by showing you more
  quickly when you're going wrong.
\end{itemize}

What this has been building towards is supplying us with a vocabulary
with which to communicate to our team-mates about which Risks are
important to us, which actions we believe are the right ones, and which
tools we should use.

Let's have a look at an example of how this might work:

\hypertarget{a-conversation}{%
\chapter{A Conversation}\label{a-conversation}}

After so much theory, it seems like it's time to look at how we can
apply these principles in the real world.

The following is based the summary of an issue from just a few weeks
ago. It's heavily edited and anonymized, and I've tried to add the
\textbf{Risk-First} vocabulary along the way, but otherwise, it's real.

Some background: \textbf{Synergy} is an online service with an
app-store, and \textbf{Eve} and \textbf{Bob} are developers working for
\textbf{Large Corporation LTD}, which wants to have an application
accepted into Synergy's app-store.

Synergy's release means that the app-store refresh will happen in a few
weeks, so this is something of a hard deadline: if we miss it, the next
release will be four months away.

\hypertarget{a-risk-conversation}{%
\section{A Risk Conversation}\label{a-risk-conversation}}

\textbf{Eve}: We've got a problem with the Synergy security review.

\textbf{Bob}: Tell me.

\textbf{Eve}: Well, you know Synergy did their review and asked us to
upgrade our Web Server to only allow TLS version 1.1 and greater?

\textbf{Bob}: Yes, I remember: We discussed it as a team and thought the
simplest thing would be to change the security settings on the Web
Server, but we all felt it was pretty risky. We decided that in order to
flush out Hidden Risk, we'd upgrade our entire production site to use it
\emph{now}, rather than wait for the app launch.

\textbf{Eve}: Right, and it \emph{did} flush out Hidden Risk: some
people using Windows 7, downloading Excel spreadsheets on the site,
couldn't download them: for some reason, that combination didn't support
anything greater than TLS version 1.0. So, we had to back it out.

\textbf{Bob}: Ok, well I guess it's good we found out \emph{now}. It
would have been a disaster to discover this after the go-live.

\textbf{Eve}: Yes. So, what's our next-best action to mitigate this?

\textbf{Bob}: Well, we could go back to Synergy and ask them for a
reprieve, but I think it'd be better to mitigate this risk now if we
can\ldots{} they'll definitely want it changed at some point.

\textbf{Eve}: How about we run two web-servers? One for the existing
content, and one for our new Synergy app? We'd have to get a new
external IP address, handle DNS setup, change the firewalls, and then
deploy a new version of the Web Server software on the production boxes.

\textbf{Bob}: This feels like there'd be a lot of Attendant Risk as we
go.

\textbf{Eve}: Well, you're correct on the first one. But, I've done this
before not that long ago for a Chinese project, so I know the process -
we shouldn't run into any new Hidden Risk.

\textbf{Bob}: Ok, fair enough. But isn't there something simpler we can
do? Maybe some settings in the Web Server?

\textbf{Eve}: Well, if we were using Apache, yes, it would be easy to do
this. But, we're using Baroque Web Server, and it \emph{might} support
it, but the documentation isn't very clear.

\textbf{Bob}: Ok, and upgrading it is a \emph{big} risk, right? We'd
have to migrate all of our configuration\ldots{}

\textbf{Eve}: Yes, let's not go there. But if we changing the settings
on Baroque, we have the Attendant Risk with the security changes that we
don't know about yet.

\textbf{Bob}: Ok, I can see that buys us something, but time is really
short and we have holidays coming up.

\textbf{Eve}: Yes. How about for now, we go with the isolated server,
and review next week? If it's working out, then great, we continue with
it. Otherwise, if we're not making progress next week, then it'll be
because our isolation solution is meeting more risk than we originally
thought. We can try the settings change in that case.

\textbf{Bob}: Fair enough, it sounds like we're managing the risk
properly, and because we can hand off a lot of this to the Networking
Team, we can get on with mitigating our biggest risk on the project, the
authentication problem, in the meantime.

\textbf{Eve}: Right. I'll check in with the Networking Team each day and
make sure it doesn't get forgotten.

\hypertarget{aftermath}{%
\section{Aftermath}\label{aftermath}}

Hopefully, this type of conversation will feel familiar. It should.
There's nothing ground-breaking at all in what we've covered so far;
it's more-or-less just Risk Management theory.

If you can now apply it in conversation, like we did above, then that's
one extra tool you have for delivering software.

So with the groundwork out of the way, let's get on to Part 2 and
investigate The Risk Landscape.

\hypertarget{de-risking}{%
\chapter{De Risking}\label{de-risking}}

Describe the basic process here.

Avoiding, evading, luck etc.

learned helplessness (head in the sand)

Opportunity Cost.

``nice problems to have''

Owning Risks - and the large corporate ``Why are enterprises so slow?''
- Zwischenzugs

Owning Risk is the weird thing here. Corporations are all about
\emph{not} owning risk. We have audit to spot risks, and deal with them,
but Audit is therefore itself a risk, which needs to be avoided. This is
the organisation managing risks away from itself ( or higher
management).

\part{Risk}

\hypertarget{risk-landscape}{%
\chapter{Risk Landscape}\label{risk-landscape}}

Risk is messy. It's not always easy to tease apart the different
components of risk and look at them individually. Let's look at a
high-profile recent example to see why.

\hypertarget{the-financial-crisis}{%
\section{The Financial Crisis}\label{the-financial-crisis}}

In the \href{https://en.wikipedia.org/wiki/Financial_services}{Financial
Services} industry, whole \emph{departments} exist to calculate things
like:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Market_risk}{Market Risk}: the
  risk that the amount some asset you hold/borrow/have loaned is going
  to change in value.
\item
  \href{https://en.wikipedia.org/wiki/Credit_risk}{Credit Risk}: the
  risk that someone who owes you a payment at a specific point in time
  might not pay it back.
\item
  \href{https://en.wikipedia.org/wiki/Liquidity_risk}{Liquidity Risk}:
  the risk that you can't find a market to sell/buy something, usually
  leading to a shortage of ready cash.
\end{itemize}

\ldots{} and so on. But, we don't need to know the details exactly to
understand this story.

They get expressed in ways like this:

\begin{quotation}

we have a 95\% chance that today we'll lose less than Â£100

\end{quotation}

In the financial crisis, though, these models of risk didn't turn out to
be much use. Although there are lots of conflicting explanations of what
happened, one way to look at it is this:

\begin{itemize}
\tightlist
\item
  Liquidity difficulties (i.e.~amount of cash you have for day-to-day
  running of the bank) caused some banks to not be able to cover their
  interest payments.
\item
  This caused credit defaults (the thing that
  \href{https://en.wikipedia.org/wiki/Credit_risk}{Credit Risk} measures
  were meant to guard against) even though the banks \emph{technically}
  were solvent.
\item
  That meant that, in time, banks got bailed out, share prices crashed
  and there was lots of
  \href{https://en.wikipedia.org/wiki/Quantitative_easing}{Quantitative
  Easing}.
\item
  All of which had massive impacts on the markets in ways that none of
  the Market Risk models foresaw.
\end{itemize}

All the \href{Glossary\#Risk}{Risks} were
\href{https://www.investopedia.com/terms/c/correlation.asp}{correlated}.
That is, they were affected by the \emph{same underlying events}, or
\emph{each other}.

\hypertarget{the-risk-landscape-again}{%
\section{The Risk Landscape Again}\label{the-risk-landscape-again}}

It's like this with software risks, too, sadly.

In Meeting Reality, and how a software project tries to \emph{navigate}
across this landscape, testing the way as it goes, and trying to get to
a position of \emph{more favourable risk}.

It's tempting to think of our \href{Risk-Landscape}{Risk Landscape} as
being like a
\href{https://en.wikipedia.org/wiki/Fitness_landscape}{Fitness
Landscape}. That is, you have a ``cost function'' which is your height
above the landscape, and you try and optimise by moving downhill in a
\href{https://en.wikipedia.org/wiki/Gradient_descent}{Gradient Descent}
fashion.

However, there's a problem with this: As we said in Risk Theory.

I am going to try and show you some of the fauna of the Risk Landscape
is also different. But, just as I can tell you that the landscape
outside your window will probably will have some roads, trees, fields,
forests, buildings, and that the buildings are likely to be joined
together by roads, I can tell you some general things about risks too.

In fact, we're going to try and categorize the kinds of things we see on
this Risk Landscape. But, this isn't going to be perfect:

\begin{itemize}
\tightlist
\item
  One risk can ``blend'' into another just like sometimes a ``field'' is
  also a ``car-park'' or a building might contain some trees (but isn't
  a forest).
\item
  There is \emph{correlation} between different risks: one risk may
  cause another, or two risks may be due to the same underlying cause.
\item
  As we saw in Part 1, mitigating one risk can give rise to another, so
  risks are often \emph{inversely correlated}.
\end{itemize}

\hypertarget{why-should-we-categorize-the-risks}{%
\section{Why Should We Categorize The
Risks?}\label{why-should-we-categorize-the-risks}}

This is a ``spotters' guide'' to risks, not an in-depth encyclopedia.

If we were studying insects, this might be a guide giving you a
description and a picture of each insect, telling you where to find it
and what it does. That doesn't mean that this is \emph{all} there is to
know. Just as a scientist could spend her entire life studying a
particular species of bee, each of the risks we'll look at really has a
whole sub-discipline of Computer Science attached to it, which we can't
possibly hope to cover all of.

As software developers, we can't hope to know the detailed specifics of
the whole discipline of
\href{https://en.wikipedia.org/wiki/Complexity_theory}{Complexity
Theory}, or
\href{https://en.wikipedia.org/wiki/Concurrency_(computer_science)}{Concurrency
Theory}. But, we're still required to operate in a world where these
things exist. So, we may as well get used to them, and ensure that we
respect their primacy. We are operating in \emph{their} world, so we
need to know the rules.

\hypertarget{were-all-naturalists-now}{%
\section{We're all Naturalists Now}\label{were-all-naturalists-now}}

This is a new adventure. There's a long way to go. Just as naturalists
are able to head out and find new species of insects and plants, we
should expect to do the same. This is by no means a complete picture -
it's barely a sketch.

It's a big, crazy, evolving world of software. Help to fill in the
details. Report back what you find.

\hypertarget{our-tour-itinerary}{%
\section{Our Tour Itinerary}\label{our-tour-itinerary}}

Below is a table outlining the different risks we'll see. There
\emph{is} an order to this: the later risks are written assuming a
familiarity with the earlier ones. Hopefully, you'll stay to the end and
see everything, but you're free to choose your own tour if you want to.

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Feature Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you haven't built features the market needs, or they contain bugs,
or the market changes underneath you. \strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Complexity Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Your software is so complex it makes it hard to change, understand or
run.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Communication Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks associated with getting messages heard and understood.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Dependency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks of depending on other people, products, software, functions, etc.
This is a general look at dependencies, before diving into specifics
like\ldots{}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Schedule Risk.\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Software Dependency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you choose to depend on a software library, service or
function.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Process Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you depend on a business process, or human process to give you
something you need.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Boundary Risk and it's hard to get back to where you want to be.\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Agency Risk, which might not align with those of the project or
team.\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to the fact that systems contain multiple agents, which need
to work together.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Map And Territory Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Operational Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Software is embedded in a system containing people, buildings, machines
and other services. Operational risk considers this wider picture of
risk associated with running a software service or business in the real
world.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

On each page we'll start by looking at the category of the risk \emph{in
general}, and then break this down into some specific subtypes. At the
end, in Staging and Classifying we'll have a recap about what we've seen
and make some guesses about how things fit together.

So, let's get started with Feature Risk.

\hypertarget{feature-risk}{%
\chapter{Feature Risk}\label{feature-risk}}

Feature Risk is the category of software risk to do with features that
have to be in your software. It is the risk that you face by \emph{not
having features that your clients need}.

In a way, Feature Risk is very fundamental: if there were \emph{no}
feature risk, the job would be done already, either by you, or by
another product, and the product would be perfect!

As a simple example, if your needs are served perfectly by Microsoft
Excel, then you don't have any Feature Risk.

Not considering Feature Risk means that you might be building the wrong
functionality, for the wrong audience or at the wrong time. And
eventually, this will come down to lost money, business, acclaim, or
whatever else reason you are doing your project for. So let's unpack
this concept into some of it's variations.

\hypertarget{feature-fit-risk}{%
\section{Feature Fit Risk}\label{feature-fit-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/fit-risk-400dpi.png}
\caption{Feature Risk}
\end{figure}

This is the one we've just discussed above: the feature that you (or
your clients) want to use in the software \emph{isn't there}. Now, as
usual, you could call this an issue, but we're calling it a Risk because
it's not clear exactly \emph{how many} people are affected, or how
badly.

\begin{itemize}
\tightlist
\item
  This might manifest itself as complete \emph{absence} of something you
  need, e.g ``Where is the word count?''
\item
  It could be that the implementation isn't complete enough, e.g ``why
  can't I add really long numbers in this calculator?''
\end{itemize}

\hypertarget{features-dont-work-properly}{%
\subsection{Features Don't Work
Properly}\label{features-dont-work-properly}}

\href{Feature-Risk}{Feature Risk} also includes things that don't work
as expected: That is to say,
\href{https://en.wikipedia.org/wiki/Software_bug}{bugs}. Although the
distinction between ``a missing feature'' and ``a broken feature'' might
be worth making in the development team, we can consider these both the
same kind of risk: \emph{the software doesn't do what the user expects}.

\begin{figure}
\centering
\includegraphics{images/generated/implementation-risk-400dpi.png}
\caption{Implementation Risk}
\end{figure}

(At this point, it's worth pointing out that sometimes, \emph{the user
expects the wrong thing}. This is a different but related risk, which
could be down to Training

\hypertarget{regression-risk}{%
\section{Regression Risk}\label{regression-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/regression-risk-400dpi.png}
\caption{Regression Risk}
\end{figure}

Regression Risk of the whole thing.

Also, while delivering new features can delight your customers, breaking
existing ones will annoy them. This is something we'll come back to in
Reputation Risk.

\hypertarget{conceptual-integrity-risk}{%
\section{Conceptual Integrity Risk}\label{conceptual-integrity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/conceptual-integrity-risk-400dpi.png}
\caption{Conceptual Integrity Risk}
\end{figure}

Sometimes, users \emph{swear blind} that they need some feature or
other, but it runs at odds with the design of the system, and plain
\emph{doesn't make sense}. Often, the development team can spot this
kind of conceptual failure as soon as it enters the Backlog. Usually,
it's in coding that this becomes apparent.

tbd: feature phones.

Sometimes, it can go for a lot longer. I once worked on some software
that was built as a score-board within a chat application. However,
after we'd added much-asked-for commenting and reply features to our
score-board, we realised we'd implemented a chat application
\emph{within a chat application}, and had wasted our time enormously.

Which leads to Greenspun's 10th Rule:

\begin{quotation}

``Any sufficiently complicated C or Fortran program contains an ad-hoc,
informally-specified, bug-ridden, slow implementation of half of Common
Lisp.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Greenspun's_tenth_rule}{\textemdash  Greenspun's 10th Rule, \emph{Wikipedia}}}
\end{quotation}

This is a particularly pernicious kind of Feature Risk. Human needs are
fractal in nature: the more you examine them, the more differences you
can find. The aim of a product is to capture some needs at a
\emph{general} level: you can't hope to ``please all of the people all
of the time''.

Conceptual Integrity Risk is the risk that chasing after features leaves
the product making no sense, and therefore pleasing no-one.

\hypertarget{feature-access-risk}{%
\section{Feature Access Risk}\label{feature-access-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/feature-access-risk-400dpi.png}
\caption{Feature Access Risk}
\end{figure}

Sometimes, features can work for some people and not others: this could
be down to
\href{https://en.wikipedia.org/wiki/Accessibility}{Accessibility}
issues, language barriers or localization.

You could argue that the choice of \emph{platform} is also going to
limit access: writing code for XBox-only leaves PlayStation owners out
in the cold. This is \emph{largely} Feature Access Risk is related here.

In Marketing, minimizing Feature Access Risk.

\hypertarget{market-risk}{%
\subsection{Market Risk}\label{market-risk}}

Feature Access Risk on it:

\begin{figure}
\centering
\includegraphics{images/generated/market-risk-400dpi.png}
\caption{Market Risk}
\end{figure}

\begin{quotation}

``Market risk is the risk of losses in positions arising from movements
in market prices.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Market_risk}{\textemdash  Market Risk, \emph{Wikipedia}}}
\end{quotation}

I face market risk when I own (i.e.~have a \emph{position} in) some
\href{http://apple.com}{Apple} stock. \href{http://apple.com}{Apple's}'s
stock price will decline if a competitor brings out an amazing product,
or if fashions change and people don't want their products any more.

In the same way, \emph{you} have Market Risk on the product or service
you are building: the \emph{market} decides what it is prepared to pay
for this, and it tends to be outside your control.

\hypertarget{feature-drift-risk}{%
\section{Feature Drift Risk}\label{feature-drift-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/feature-drift-risk-400dpi.png}
\caption{Feature Drift Risk}
\end{figure}

\textbf{Feature Drift} is the tendency that the features people need
\emph{change over time}. For example, at one point in time, supporting
IE6 was right up there for website developers, but it's not really
relevant anymore. Although that change took \emph{many} years to
materialize, other changes are more rapid.

The point is: Requirements captured \emph{today} might not make it to
\emph{tomorrow}, especially in the fast-paced world of IT. This is
partly because the market \emph{evolves} and becomes more discerning.
This happens in several ways:

\begin{itemize}
\tightlist
\item
  Features present in competitor's versions of the software become
  \emph{the baseline}, and they're expected to be available in your
  version.
\item
  Certain ways of interacting become the norm (e.g.~querty.
\item
  Features decline in usefulness: \emph{Printing} is less important now
  than it was, for example.
\end{itemize}

Feature Drift Risk uncovered on the project as it progresses.

\hypertarget{fashion}{%
\subsection{Fashion}\label{fashion}}

Fashion plays a big part in IT, as this
\href{https://designers.hubspot.com/blog/the-history-of-web-design-infographic}{infographic
on website design shows}. True, websites have got easier to use as time
has gone by, and users now expect this. Also, bandwidth is greater now,
which means we can afford more media and code on the client side.
However, \emph{fashion} has a part to play in this.

By being \emph{fashionable}, websites are communicating: \emph{this is a
new thing}, \emph{this is relevant}, \emph{this is not terrible}: all of
which is mitigating a Communication Risk. Users are all-too-aware that
the Internet is awash with terrible, abandon-ware sites that are going
to waste their time. How can you communicate that you're not one of them
to your users?

\hypertarget{delight}{%
\section{Delight}\label{delight}}

If this breakdown of Feature Risk, but should be treated in the usual
Risk-First way: \emph{pick the biggest risk you can mitigate next}.

Consider Feature Risk from both the down-side and the up-side:

\begin{itemize}
\tightlist
\item
  What are we missing?
\item
  How can we be \emph{even better}?
\end{itemize}

Hopefully, this has given you some ideas about what Feature Risk and how
it affects what we build.

\hypertarget{analysis}{%
\section{Analysis}\label{analysis}}

At this point, it would be easy to stop and say, look, here are a bunch
of Feature Risk as we go on in order to build our understanding of other
risks, so it's probably worth spending a bit of time up front to
classify what we've found.

The Feature Risks identified here basically exist in a 3-dimensional
space:

\begin{itemize}
\tightlist
\item
  \textbf{Fit}: How well the features fit for a particular client.
\item
  \textbf{Audience}: The range of clients (the \emph{market}) that may
  be able to use this feature.
\item
  \textbf{Evolution}: The way the fit and the audience changes and
  evolves as time goes by.
\end{itemize}

\hypertarget{fit}{%
\subsection{Fit}\label{fit}}

\begin{quotation}

``Survival Of The Fittest

\end{quotation}

Darwin's conception of fitness was not one of athletic prowess, but how
well an organism worked within the landscape.

tbd: definition of biological fitness

Fit Risk all hint at different aspects of this ``fitness''. We can
conceive of the relationships between them in the following way:

\begin{figure}
\centering
\includegraphics{images/kite9/all_feature_risk_1.png}
\caption{Feature Risks Assembled}
\end{figure}

For further reading, you can check out
\href{http://en.wikipedia.org/SERVQUAL}{The Service Quality Model},
whcih this model is derived from. This model analyses the types of
\emph{quality gaps} in services, and how consumer expectations and
perceptions of a service arise. In
\href{Staging-And-Classifying\#Your-Feature-Risk-is-Someone-Else-s-Dependency-Risk}{Staging
And Classifying}, we'll come back and build on this model further.

\hypertarget{fit-and-audience}{%
\subsection{Fit and Audience}\label{fit-and-audience}}

Two risks, Feature Access Risk rollercoaster, being one moment highly
valued and the next irrelevant.

\hypertarget{fit-audience-and-evolution}{%
\subsection{Fit, Audience and
Evolution}\label{fit-audience-and-evolution}}

Two risks further consider how the \textbf{Fit} and \textbf{Audience}
\emph{change}: Regression Risk. We call this \emph{evolution} in the
sense that:

\begin{itemize}
\tightlist
\item
  Our product's features \emph{evolve} with time, and changes made by
  the development team.
\item
  Our audience changes and evolves as it is exposed to our product and
  competing products.
\item
  The world as a whole is an evolving system within which our product
  exists.
\end{itemize}

tbd. regression risk and feature drift risk.

\hypertarget{applying-feature-risk}{%
\section{Applying Feature Risk}\label{applying-feature-risk}}

Consider Feature Risk carefully next time you are grooming the backlog:

\begin{itemize}
\tightlist
\item
  Can you judge which tasks mitigate the most Feature Risk?
\item
  Are you delivering features that are valuable to a large audience? How
  well do you understand your audience? How does the size of the
  audience for a task impact it's importance in the backlog?
\item
  Does the audience \emph{know} that the features exist? How do you
  communicate feature availability to them?
\item
  How does writing a specification mitigate Fit Risk? For what other
  reasons are you writing specifications?
\end{itemize}

In the next chapter, we are going to unpack this third point further.
Somewhere between ``what the customer wants'' and ``what you give them''
is a \emph{dialog}. In using a software product, users are engaging in a
\emph{dialog} with its features. If the features don't exist, hopefully
they will engage in a dialog with the development team to get them
added.

These dialogs are prone to risk, and this is the subject of the next
chapter, Communication-Risk.

\hypertarget{complexity-risk}{%
\chapter{Complexity Risk}\label{complexity-risk}}

Complexity Risk. However, in this chapter, we're going to be
specifically focusing on \emph{code you write}: the size of your
code-base, the number of modules, the interconnectedness of the modules
and how well-factored the code is.

\begin{figure}
\centering
\includegraphics{images/generated/complexity-risk-400dpi.png}
\caption{Complexity Risks}
\end{figure}

You could think of this chapter, then, as \textbf{Codebase Risk}: We'll
look at three separate measures of codebase complexity and talk about
Technical Debt, and look at places in which \textbf{Codebase Risk} is at
it's greatest.

\hypertarget{kolmogorov-complexity}{%
\section{Kolmogorov Complexity}\label{kolmogorov-complexity}}

The standard Computer-Science definition of complexity, is
\href{https://en.wikipedia.org/wiki/Kolmogorov_complexity}{Kolmogorov
Complexity}. This is:

\begin{quote}
``\ldots{}is the length of the shortest computer program (in a
predetermined programming language) that produces the object as
output.'' - Kolmogorov Complexity, Wikipedia
\end{quote}

This is a fairly handy definition for us, as it means that to in writing
software to solve a problem, there is a lower bound on the size of the
software we write. In practice, this is pretty much impossible to
quantify. But that doesn't really matter: the techniques for
\emph{moving in that direction} are all that we are interested in, and
this basically amounts to compression.

Let's say we wanted to write a javascript program to output this string:

\begin{verbatim}
abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd
\end{verbatim}

We might choose this representation:

\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return} \StringTok{"abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd"}\NormalTok{ (}\DecValTok{45}\NormalTok{)}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

The numbers in brackets indicate how many symbols each line contains, so
in total, this code block contains \textbf{53 symbols}, if you count
\texttt{function}, \texttt{out} and \texttt{return} as one symbol each.

But, if we write it like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                    (}\DecValTok{11}\NormalTok{)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return}\NormalTok{ ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{        (}\DecValTok{16}\NormalTok{)}
\NormalTok{        ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{;}\NormalTok{                               (}\DecValTok{6}\NormalTok{ )}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

With this version, we now have \textbf{41 symbols} (\textbf{ABCD} is a
single symbol, because we could have called it anything). And with this
version:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                    (}\DecValTok{11}\NormalTok{)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                            (}\DecValTok{7}\NormalTok{ )}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\ldots{} we have \textbf{26 symbols}.

\hypertarget{abstraction}{%
\subsection{Abstraction}\label{abstraction}}

What's happening here is that we're \emph{exploiting a pattern}: we
noticed that \texttt{ABCD} occurs several times, so we defined it a
single time and then used it over and over, like a stamp. Separating the
\emph{definition} of something from the \emph{use} of something as we've
done here is called ``abstraction''. We're going to come across it over
and over again in this part of the book, and not just in terms of
computer programs.

By applying techniques such as Abstraction, we can improve in the
direction of the Kolmogorov limit. And, by allowing ourselves to say
that \emph{symbols} (like \texttt{out} and \texttt{ABCD}) are worth one
complexity point, we've allowed that we can be descriptive in our
\texttt{function} name and \texttt{const}. Naming things is an important
part of abstraction, because to use something, you have to be able to
refer to it.

\hypertarget{trade-off}{%
\subsection{Trade-Off}\label{trade-off}}

But we could go further down into
\href{https://en.wikipedia.org/wiki/Code_golf}{Code Golf} territory.
This javascript program plays
\href{https://en.wikipedia.org/wiki/Fizz_buzz}{FizzBuzz} up to 100, but
is less readable than you might hope:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{<}\DecValTok{100}\OperatorTok{;}\NormalTok{)}\VariableTok{document}\NormalTok{.}\AttributeTok{write}\NormalTok{(((}\OperatorTok{++}\NormalTok{i}\OperatorTok{%}\DecValTok{3}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Fizz'}\NormalTok{)}\OperatorTok{+}
\NormalTok{(i}\OperatorTok{%}\DecValTok{5}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Buzz'}\NormalTok{)}\OperatorTok{||}\NormalTok{i)}\OperatorTok{+}\StringTok{"<br>"}\NormalTok{)                           (}\DecValTok{62}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So there is at some point a trade-off to be made between Complexity Risk
is about \emph{misunderstanding}: The more complex a piece of software
is, the more difficulty users will have understanding it, and the more
difficulty developers will have changing it.

\hypertarget{connectivity}{%
\section{Connectivity}\label{connectivity}}

A second, useful measure of complexity comes from graph theory, and that
is the connectivity of a graph:

\begin{quotation}

``\ldots{}the minimum number of elements (nodes or edges) that need to
be removed to disconnect the remaining nodes from each other''

\sourceatright{\href{https://en.wikipedia.org/wiki/Connectivity_(graph_theory)}{\textemdash  Connectivity, \emph{Wikipedia}}}
\end{quotation}

To see this in action, have a look at the below graph:

\begin{figure}
\centering
\includegraphics{images/generated/connectivity_1-400dpi.png}
\caption{Graph 1}
\end{figure}

It has 10 vertices, labelled \textbf{a} to \textbf{j}, and it has 15
edges (or links) connecting the vertices together. If any single edge
were removed from this diagram, the 10 vertices would still be linked
together. Because of this, we can say that the graph is
\emph{2-connected}. That is, to disconnect any single vertex, you'd have
to remove \emph{at least} two edges.

As a slight aside, let's consider the \textbf{Kolmogorov Complexity} of
this graph, by inventing a mini-language to describe graphs. It could
look something like this:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<}\NormalTok{item}\OperatorTok{>} \OperatorTok{:}\NormalTok{ [}\OperatorTok{<}\NormalTok{item}\OperatorTok{>,}\NormalTok{]}\OperatorTok{*} \OperatorTok{<}\NormalTok{item}\OperatorTok{>}\NormalTok{    # Indicates that the item}
\NormalTok{                              # before the colon}
\NormalTok{                              # has a connection to all}
\NormalTok{                              # the items after the colon}
\end{Highlighting}
\end{Shaded}

So our graph could be defined like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ b}\OperatorTok{,}\NormalTok{c}\OperatorTok{,}\NormalTok{d}
\NormalTok{b}\OperatorTok{:}\NormalTok{ c}\OperatorTok{,}\NormalTok{f}\OperatorTok{,}\NormalTok{e}
\NormalTok{c}\OperatorTok{:}\NormalTok{ f}\OperatorTok{,}\NormalTok{d}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}\OperatorTok{,}\NormalTok{j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{g}\OperatorTok{:}\NormalTok{ j}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{i}\OperatorTok{:}\NormalTok{ j}
\NormalTok{                                                      (}\DecValTok{39}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's remove some of those extra links:

\begin{figure}
\centering
\includegraphics{images/generated/connectivity_2-400dpi.png}
\caption{Graph 2}
\end{figure}

In this graph, I've removed 6 of the edges. Now, we're in a situation
where if any single edge is removed, the graph becomes
\emph{unconnected}. That is, it's broken into distinct chunks. So, it's
\emph{1-connected}.

The second graph is clearly simpler than the first. And, we can show
this by looking at the \textbf{Kolgomorov Complexity} in our little
language:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{g}
\NormalTok{b}\OperatorTok{:}\NormalTok{ f}
\NormalTok{c}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{f}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{                                                      (}\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Connectivity} is also \textbf{Complexity}. Heavily connected
programs/graphs are much harder to work with than less-connected ones.
Even \emph{laying out} the first graph sensibly is a harder task than
the second (the second is a doddle). But the reason programs with
greater connectivity are harder to work with is that changing one module
potentially impacts many others.

\hypertarget{hierarchies-and-modularization}{%
\section{Hierarchies and
Modularization}\label{hierarchies-and-modularization}}

In the second, simplified graph, I've arranged it as a hierarchy, which
I can do now that it's only 1-connected. For 10 vertices, we need 9
edges to connect everything up. It's always:

\begin{verbatim}
  edges = vertices - 1
\end{verbatim}

Note that I could pick any hierarchy here: I don't have to start at
\textbf{c} (although it has the nice property that it has two roughly
even sub-trees attached to it).

How does this help us? Imagine if \textbf{a} - \textbf{j} were modules
of a software system, and the edges of the graph showed communications
between the different sub-systems. In the first graph, we're in a worse
position: who's in charge? What deals with what? Can I isolate a
component and change it safely? What happens if one component
disappears? But, in the second graph, it's easier to reason about,
because of the reduced number of connections and the new heirarchy of
organisation.

On the downside, perhaps our messages have farther to go now: in the
original \textbf{i} could send a message straight to \textbf{j}, but now
we have to go all the way via \textbf{c}. But this is the basis of
\href{https://en.wikipedia.org/wiki/Modular_programming}{Modularization}
and \href{https://en.wikipedia.org/wiki/Hierarchy}{Hierarchy}.

As a tool to battle complexity, we don't just see this in software, but
everywhere in our lives. Society, business, nature and even our bodies:

\begin{itemize}
\tightlist
\item
  \textbf{Organelles} - such as
  \href{https://en.wikipedia.org/wiki/Mitochondrion}{Mitochondria}.
\item
  \textbf{Cells} - such as blood cells, nerve cells, skin cells in the
  \href{https://en.wikipedia.org/wiki/List_of_distinct_cell_types_in_the_adult_human_body}{Human
  Body}.
\item
  \textbf{Organs} - like hearts livers, brains etc.
\item
  \textbf{Organisms} - like you and me.
\end{itemize}

The great complexity-reducing mechanism of modularization is that
\emph{you only have to consider your local environment}. Elements of the
program that are ``far away'' in the hierarchy can be relied on not to
affect you. This is somewhat akin to the \textbf{Principal Of Locality}:

\begin{quotation}

``Spatial locality refers to the use of data elements within relatively
close storage locations.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Locality_of_reference}{\textemdash  Locality Of Reference, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{cyclomatic-complexity}{%
\section{Cyclomatic Complexity}\label{cyclomatic-complexity}}

A variation on this graph connectivity metric is our third measure of
complexity,
\href{https://en.wikipedia.org/wiki/Cyclomatic_complexity}{Cyclomatic
Complexity}. This is:

\begin{verbatim}
Cyclomatic Complexity = edges â vertices + 2P,
\end{verbatim}

Where \textbf{P} is the number of \textbf{Connected Components}
(i.e.~distinct parts of the graph that aren't connected to one another
by any edges).

So, our first graph had a \textbf{Cyclomatic Complexity} of 7.
\texttt{(15\ -\ 10\ +\ 2)}, while our second was 1.
\texttt{(9\ -\ 10\ +\ 2)}.

Cyclomatic complexity is all about the number of different routes
through the program. The more branches a program has, the greater it's
cyclomatic complexity. Hence, this is a useful metric in Testing: the
more branches you have, the more tests you'll need to exercise them all.

\hypertarget{more-abstraction}{%
\section{More Abstraction}\label{more-abstraction}}

Although we ended up with our second graph having a \textbf{Cyclomatic
Complexity} of 1 (the minimum), we can go further through abstraction,
because this representation isn't minimal from a \textbf{Kolmogorov
Complexity} point-of-view. For example, we might observe that there are
further similarities in the graph that we can ``draw out'':

\begin{figure}
\centering
\includegraphics{images/generated/connectivity_3-400dpi.png}
\caption{Complexity 3}
\end{figure}

Here, we've spotted that the structure of subgraphs \textbf{P1} and
\textbf{P2} are the same: we can have the same functions there to
assemble those. Noticing and exploiting patterns of repetition is one of
the fundamental tools we have in the fight against Complexity Risk.

So, we've looked at some measures of software structure complexity, in
order that we can say ``this is more complex than this''. However, we've
not really said why complexity entails Risk.

\hypertarget{complexity-as-mass}{%
\section{Complexity As Mass}\label{complexity-as-mass}}

The first way to look at complexity is as \textbf{Mass} or
\textbf{Inertia} : a software project with more complexity has greater
\textbf{Inertia} or \textbf{Mass} than one with less complexity.

Newton's Second Law states:

\begin{quotation}

``F = \emph{m}\textbf{a}, ( Force = Mass x Acceleration )''

\sourceatright{\href{https://en.wikipedia.org/wiki/Newtons_laws_of_motion}{\textemdash  Netwon's Laws Of Motion, \emph{Wikipedia}}}
\end{quotation}

That is, in order to move your project \emph{somewhere new}, and make it
do new things, you need to give it a push, and the more \textbf{Mass} it
has, the more \textbf{Force} you'll need to move (accelerate) it.

\textbf{Inertia} and \textbf{Mass} are equivalent concepts in physics:

\begin{quotation}

``mass is the quantitative or numerical measure of a body's inertia,
that is of its resistance to being accelerated''.

\sourceatright{\href{https://en.wikipedia.org/wiki/Inertia\#Mass_and_inertia}{\textemdash  Inertia, \emph{Wikipedia}}}
\end{quotation}

You could stop here and say that the more lines of code a project
contains, the higher it's mass. And, that makes sense, because in order
to get it to do something new, you're likely to need to change more
lines.

But there is actually some underlying sense in which \emph{this is
real}, as discussed in this
\href{https://www.youtube.com/user/1veritasium}{Veritasium} video. To
paraphrase:

\begin{quotation}

``Most of your mass you owe due to E=mcÂ², you owe to the fact that your
mass is packed with energy, because of the \textbf{interactions} between
these quarks and gluon fluctuations in the gluon field\ldots{} what we
think of as ordinarily empty space\ldots{} that turns out to be the
thing that gives us most of our mass.''

\sourceatright{\href{https://www.youtube.com/watch?annotation_id=annotation_3771848421&feature=iv&src_vid=Xo232kyTsO0&v=Ztc6QPNUqls}{\textemdash  Your Mass is NOT From the Higgs Boson, \emph{Veritasium}}}
\end{quotation}

I'm not an expert in physics, \emph{at all}, and so there is every
chance that I am pushing this analogy too hard. But, substituting quarks
and gluons for pieces of software we can (in a very handwaving-y way)
say that more complex software has more \textbf{interactions} going on,
and therefore has more mass than simple software.

The reason I am labouring this analogy is to try and make the point that
Complexity Risk is really fundamental:

\begin{itemize}
\tightlist
\item
  Feature Risk: like \textbf{money}.
\item
  Schedule Risk: like \textbf{time}.
\item
  Complexity Risk: like \textbf{mass}.
\end{itemize}

At a basic level, Complexity Risk: more complexity means you need more
force to get things done, which takes longer.

\hypertarget{technical-debt}{%
\section{Technical Debt}\label{technical-debt}}

The most common way we talk about unnecessary complexity in software is
as Technical Debt:

\begin{quotation}

``Shipping first time code is like going into debt. A little debt speeds
development so long as it is paid back promptly with a rewrite\ldots{}
The danger occurs when the debt is not repaid. Every minute spent on
not-quite-right code counts as interest on that debt. Entire engineering
organizations can be brought to a stand-still under the debt load of an
unconsolidated implementation, object-oriented or otherwise.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Technical_debt}{Ward Cunningham, 1992}}
\end{quotation}

Building a perfect first-time solution is a waste, because perfection
takes a long time. You're taking on more attendant Schedule Risk more
slowly than you could.

A quick-and-dirty, over-complex implementation mitigates the same
Feature Risk.

But, having mitigated the Feature Risk the software to reduce this risk
again.

\hypertarget{kitchen-analogy}{%
\section{Kitchen Analogy}\label{kitchen-analogy}}

It's often hard to make the case for minimizing Technical Debt

One helpful analogy I have found is to imagine your code-base is a
kitchen. After preparing a meal (i.e.~delivering the first
implementation), \emph{you need to tidy up the kitchen}. This is just
something everyone does as a matter of \emph{basic sanitation}.

Now of course, you could carry on with the messy kitchen. When tomorrow
comes and you need to make another meal, you find yourself needing to
wash up saucepans as you go, or working around the mess by using
different surfaces to chop on.

It's not long before someone comes down with food poisoning.

We wouldn't tolerate this behaviour in a restaurant kitchen, so why put
up with it in a software project?

\hypertarget{feature-creep}{%
\section{Feature Creep}\label{feature-creep}}

In Brooks' essay ``No Silver Bullet - Essence and Accident in Software
Engineering'', a distinction is made between:

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{Essence}: \emph{the difficulties inherent in the nature of the
  software.}
\item
  \textbf{Accident}: \emph{those difficulties that attend its production
  but are not inherent.} -
  \href{https://en.wikipedia.org/wiki/No_Silver_Bullet}{Fred Brooks,
  \emph{No Silver Bullet}}
\end{itemize}
\end{quote}

The problem with this definition is that we are accepting features of
our software as \emph{essential}.

The \textbf{Risk-First} approach is that if you want to mitigate some
Feature Risk as a result. But, that's a \emph{choice you get to make}.

Therefore, \href{https://en.wikipedia.org/wiki/Feature_creep}{Feature
Creep} (or
\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}) is a failure to observe this basic equation: instead of
considering this trade off, you're building every feature possible. This
has an impact on \href{Complexity-Risk}{Complexity Risk}, which in turn
impacts \href{Communication-Risk}{Communication Risk} and also
\href{Schedule-Risk}{Schedule Risk}.

Sometimes, feature-creep happens because either managers feel they need
to keep their staff busy, or the staff decide on their own that they
need to keep themselves busy. But now, we can see that basically this
boils down to bad risk management.

\begin{quotation}

``Perfection is Achieved Not When There Is Nothing More to Add, But When
There Is Nothing Left to Take Away''

\sourceatright{\href{}{Antoine de Saint-Exupery}}
\end{quotation}

\hypertarget{dead-end-risk}{%
\section{Dead-End Risk}\label{dead-end-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/dead-end-risk-400dpi.png}
\caption{Dead-End Risk}
\end{figure}

Dead-End Risk is where you build functionality that you \emph{think} is
useful, only to find out later that actually, it was a dead-end, and is
superceded by something else.

For example, let's say that the Accounting sub-system needed password
protection (so you built this). Then the team realised that you needed a
way to \emph{change the password} (so you built that). Then, that you
needed to have more than one user of the Accounting system so they would
all need passwords (ok, fine).

Finally, the team realises that actually logging-in would be something
that all the sub-systems would need, and that it had already been
implemented more thoroughly by the Approvals sub-system.

At this point, you realise you're in a \textbf{Dead End}:

\begin{itemize}
\tightlist
\item
  \textbf{Option 1}: You carry on making minor incremental improvements
  to the accounting password system (carrying the extra Complexity Risk.
\item
  \textbf{Option 2}: You rip out the accounting password system, and
  merge in the Approvals system, surfacing new, hidden Complexity Risk
  in the process, due to the difficulty in migrating users from the old
  to new way of working.
\item
  \textbf{Option 3}: You start again, trying to take into account both
  sets of requirements at the same time, again, possibly surfacing new
  hidden Complexity Risk due to the combined approach.
\end{itemize}

Sometimes, the path from your starting point to your goal on the Risk
Landscape will take you to dead ends: places where the only way towards
your destination is to lose something, and do it again another way.

This is because you surface new Hidden Risk in the solutions you choose.
This happens a lot.

\hypertarget{source-control}{%
\subsection{Source Control}\label{source-control}}

\href{https://en.wikipedia.org/wiki/Version_control}{Version Control
Systems} like \href{https://en.wikipedia.org/wiki/Git}{Git} are a useful
mitigation of \href{Complexity-Risk\#dead-end-risk}{Dead-End Risk},
because it means you can \emph{go back} to the point where you made the
bad decision and go a different way. Additionally, they provide you with
backups against the often inadvertent
\href{Complexity-Risk\#dead-end-risk}{Dead-End Risk} of someone wiping
the hard-disk.

\hypertarget{the-re-write}{%
\subsection{The Re-Write}\label{the-re-write}}

\textbf{Option 3}, Rewriting code or a whole project can seem like a way
to mitigate Complexity Risk, but it usually doesn't work out too well.
As Joel Spolsky says:

\begin{quote}
There's a subtle reason that programmers always want to throw away the
code and start over. The reason is that they think the old code is a
mess. And here is the interesting observation: they are probably wrong.
The reason that they think the old code is a mess is because of a
cardinal, fundamental law of programming: \emph{It's harder to read code
than to write it.} -
\href{https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/}{Things
You Should Never Do, Part 1, \emph{Joel Spolsky}}
\end{quote}

The problem that Joel is outlining here is that the developer mistakes
hard-to-understand code for unnecessary Complexity Risk.

\hypertarget{where-complexity-hides}{%
\section{Where Complexity Hides}\label{where-complexity-hides}}

Complexity isn't spread evenly within a software project. Some problems,
some areas, have more than their fair share of issues. We're going to
cover a few of these now, but be warned, this is not a complete list by
any means:

\begin{itemize}
\tightlist
\item
  Memory Management
\item
  Protocols / Types
\item
  Algorithmic (Space and Time) Complexity
\item
  Concurrency / Mutability
\item
  Networks / Security
\end{itemize}

\hypertarget{memory-management}{%
\subsection{Memory Management}\label{memory-management}}

Memory Management is another place where Complexity Risk hides:

\begin{quotation}

``Memory leaks are a common error in programming, especially when using
languages that have no built in automatic garbage collection, such as C
and C++.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Memory_leak}{\textemdash  Memory Leak, \emph{Wikipedia}}}
\end{quotation}

\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{Garbage
Collectors} (as found in Javascript or Java) offer you the deal that
they will mitigate the \href{Complexity-Risk}{Complexity Risk} of you
having to manage your own memory, but in return perhaps give you fewer
guarantees about the \emph{performance} of your software. Again, there
are times when you can't accommodate this
\href{Operational-Risk\#performance-risk}{Operational Risk}, but these
are rare and usually only affect a small portion of an entire
software-system.

\hypertarget{protocols-and-types}{%
\subsection{Protocols And Types}\label{protocols-and-types}}

Whenever two components of a software system need to interact, they have
to establish a protocol for doing so. There are lots of different ways
this can work, but the simplest example I can think of is where some
component \textbf{a} calls some function \textbf{b}. e.g:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c) }\OperatorTok{\{}
    \ControlFlowTok{return} \StringTok{"whatever"} \CommentTok{// do something here.}
\OperatorTok{\}}

\KeywordTok{function} \AttributeTok{a}\NormalTok{() }\OperatorTok{\{}
    \KeywordTok{var}\NormalTok{ bOut }\OperatorTok{=} \AttributeTok{b}\NormalTok{(}\StringTok{"one"}\OperatorTok{,} \StringTok{"two"}\OperatorTok{,} \StringTok{"three"}\NormalTok{)}\OperatorTok{;}
    \ControlFlowTok{return} \StringTok{"something "}\OperatorTok{+}\NormalTok{bOut}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

If component \textbf{b} then changes in some backwards-incompatible way,
say:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{,}\NormalTok{ d }\CommentTok{/* new parameter */}\NormalTok{) }\OperatorTok{\{}
    \ControlFlowTok{return} \StringTok{"whatever"} \CommentTok{// do something here.}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then, we can say that the protocol has changed. This problem is so
common, so endemic to computing that we've had compilers that check
function arguments \href{https://en.wikipedia.org/wiki/Compiler}{since
the 1960's}. The point being is that it's totally possible for the
compiler to warn you about when a protocol within the program has
changed.

The same is basically true of
\href{https://en.wikipedia.org/wiki/Data_type}{Data Types}: whenever we
change the \textbf{Data Type}, we need to correct the usages of that
type. Note above, I've given the \texttt{javascript} example, but I'm
going to switch to \texttt{typescript} now:

\begin{verbatim}
interface BInput {
    a: string,
    b: string,
    c: string,
    d: string
}

function b(in: BInput): string {
    return "whatever" // do something here.
}
\end{verbatim}

Now, of course, there is a tradeoff: we \emph{mitigate} Complexity Risk.

Nevertheless, compilers and type-checking are so prevalent in software
that clearly, you have to accept that in most cases, the trade-off has
been worth it: Even languages like \href{https://clojure.org}{Clojure}
have been retro-fitted with
\href{https://github.com/clojure/core.typed/wiki/User-Guide}{type
checkers}.

We're going to head into much more detail on this in the chapter on
Protocol Risk.

\hypertarget{space-and-time-complexity}{%
\subsection{Space and Time Complexity}\label{space-and-time-complexity}}

So far, we've looked at a couple of definitions of complexity in terms
of the codebase itself. However, in Computer Science there is a whole
branch of complexity theory devoted to how the software \emph{runs},
namely \href{https://en.wikipedia.org/wiki/Big_O_notation}{Big O
Complexity}.

Once running, an algorithm or data structure will consume space or
runtime dependent on it's characteristics. As with
\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{Garbage
Collectors}, these characteristics can introduce
\href{Operational-Risk\#performance-risk}{Performance Risk} which can
easily catch out the unwary. By and large, using off-the-shelf data
structures and algorithms helps, but you still need to know their
performance characteristics.

The \href{http://bigocheatsheet.com}{Big O Cheatsheet} is a wonderful
resource to investigate this further.

\hypertarget{concurrency-mutability}{%
\subsection{Concurrency / Mutability}\label{concurrency-mutability}}

Although modern languages include plenty of concurrency primitives,
(such as the
\href{https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/package-summary.html}{java.util.concurrent}
libraries), concurrency is \emph{still} hard to get right.

\href{https://en.wikipedia.org/wiki/Race_condition}{Race conditions} and
\href{https://en.wikipedia.org/wiki/Deadlock}{Deadlocks} \emph{thrive}
in over-complicated concurrency designs: complexity issues are magnified
by concurrency concerns, and are also hard to test and debug.

Recently, languages such as \href{https://clojure.org}{Clojure} have
introduced
\href{https://en.wikipedia.org/wiki/Persistent_data_structure}{persistent
collections} to alleviate concurrency issues. The basic premise is that
any time you want to \emph{change} the contents of a collection, you get
given back a \emph{new collection}. So, any collection instance is
immutable once created. The tradeoff is again attendant
\href{Operational-Risk\#performance-Risk}{Performance Risk} to mitigate
\href{Complexity-Risk}{Complexity Risk}.

An important lesson here is that choice of language can reduce
complexity: and we'll come back to this in Software Dependency Risk.

\hypertarget{networking-security}{%
\subsection{Networking / Security}\label{networking-security}}

The last area I want to touch on here is networking. There are plenty of
Complexity Risk.

In the case of security considerations, exploits \emph{thrive} on the
complexity of your code, and the weaknesses that occur because of it. In
particular, Schneier's Law says, never implement your own crypto scheme:

\begin{quotation}

``Anyone, from the most clueless amateur to the best cryptographer, can
create an algorithm that he himself can't break. It's not even hard.
What is hard is creating an algorithm that no one else can break, even
after years of analysis.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Bruce_Schneier\#Cryptography}{Bruce Schneier, 1998} }
\end{quotation}

Luckily, most good languages include crypto libraries that you can
include to mitigate these Complexity Risks from your own code-base.

This is a strong argument for the use of libraries. But, when should you
use a library and when should you implement yourself? This is again
covered in the chapter on Software Dependency Risk.

tbd - next chapter.

costs associated with complexity risk

CHANGE is also more risky why?

\hypertarget{communication-risk}{%
\chapter{Communication Risk}\label{communication-risk}}

Communication Risk is the risk of communication between entities
\emph{going wrong}, due to loss or misunderstanding. Consider this: if
we all had identical knowledge, there would be no need to do any
communicating at all, and therefore and also no Communication Risk.

But, people are not all-knowing oracles. We rely on our \emph{senses} to
improve our Internal Models.

Communication Risk isn't just for people; it affects computer systems
too.

\hypertarget{a-model-of-communication}{%
\section{A Model Of Communication}\label{a-model-of-communication}}

In 1948, Claude Shannon proposed this definition of communication:

\begin{quotation}

``The fundamental problem of communication is that of reproducing at one
point, either exactly or approximately, a message selected at another
point.''

\sourceatright{\href{https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication}{\textemdash  A Mathematical Theory Of Communication, \emph{Claude Shannon}}  <!-- tweet-end -->}
\end{quotation}

And from this same paper, we get the following (slightly adapted) model.

\begin{figure}
\centering
\includegraphics{images/generated/communication_1-400dpi.png}
\caption{Shannon's Communication Model}
\end{figure}

We move from top-left (``I want to send a message to someone'') to
bottom left, clockwise, where we hope the message has been understood
and believed. (I've added this last box to Shannon's original diagram.)

One of the chief concerns in Shannon's paper is the step between
\textbf{Transmission} and \textbf{Reception}. He creates a theory of
information (measured in \textbf{bits}), the upper-bounds of information
that can be communicated over a channel and ways in which Communication
Risk between these processes can be mitigated by clever
\textbf{Encoding} and \textbf{Decoding} steps.

But it's not just transmission. Communication Risk exists at each of
these steps. Let's imagine a short exchange where someone,
\textbf{Alice} is trying to send a message to \textbf{Bob}:

\begin{itemize}
\tightlist
\item
  \textbf{Alice} might be \textbf{motivated} to send a message to tell
  \textbf{Bob} something, only to find out that \emph{he already knew
  it}, or it wasn't useful information for them.
\item
  In the \textbf{composition} stage, \textbf{Alice} might mess up the
  \emph{intent} of the message: instead of ``Please buy chips'' she
  might say, ``Please buy chops''.
\item
  In the \textbf{encoding} stage, \textbf{Alice} might not speak clearly
  enough to be understood, and\ldots{}
\item
  In the \textbf{transmission} stage, \textbf{Alice} might not say it
  loudly enough for \textbf{Bob} to\ldots{}
\item
  \textbf{receive} the message clearly (maybe there is background
  noise).
\item
  Having heard \textbf{Alice} say something, can \textbf{Bob}
  \textbf{decode} what was said into a meaningful sentence?
\item
  Then, assuming that, will they \textbf{interpret} correctly which type
  of chips (or chops) \textbf{Alice} was talking about? Does ``Please
  buy chips'' convey all the information they need?
\item
  Finally, assuming \emph{everything else}, will \textbf{Bob} believe
  the message? Will they \textbf{reconcile} the information into their
  Internal Model and act on it? Perhaps not, if \textbf{Bob} thinks that
  there are chips at home already.
\end{itemize}

\hypertarget{approach-to-communication-risk}{%
\section{Approach To Communication
Risk}\label{approach-to-communication-risk}}

There is a symmetry about the steps going on in Shannon's diagram, and
we're going to exploit this in order to break down Communication Risk
into it's main types.

\begin{figure}
\centering
\includegraphics{images/generated/communication_2-400dpi.png}
\caption{Communication Risk 2}
\end{figure}

To get inside Communication Risk, we need to understand
\textbf{Communication} itself, whether between \emph{machines},
\emph{people} or \emph{products}: we'll look at each in turn. In order
to do that, we're going to examine four basic concepts in each of these
settings:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Communication_channel}{Channels},
  the medium via which the communication is happening.
\item
  \href{https://en.wikipedia.org/wiki/Communication_protocol}{Protocols}
  - the systems of rules that allow two or more entities of a
  communications system to transmit information.
\item
  \href{https://en.wikipedia.org/wiki/Message}{Messages}: The
  information we want to convey.
\item
  Internal Models is the reason why we're communicating.
\end{itemize}

And, as we look at these four areas, we'll consider the Attendant Risks
of each.

\hypertarget{channels}{%
\section{Channels}\label{channels}}

There are lots of different types of media for communicating (e.g.~TV,
Radio, DVD, Talking, Posters, Books, Phones, The Internet, etc. ) and
they all have different characteristics. When we communicate via a given
medium, it's called a \emph{channel}.

The channel \emph{characteristics} depend on the medium, then. Some
obvious ones are cost, utilisation, number of people reached, simplex or
duplex (parties can transmit and receive at the same time), persistence
(a play vs a book, say), latency (how long messages take to arrive) and
bandwidth (the amount of information that can be transmitted in a period
of time).

Channel characteristics are important: in a high-bandwidth, low-latency
situation, \textbf{Alice} and \textbf{Bob} can \emph{check} with each
other that the meaning was transferred correctly. They can discuss what
to buy, they can agree that \textbf{Alice} wasn't lying or playing a
joke.

The channel characteristics also imply suitability for certain
\emph{kinds} of messages. A documentary might be a great way of
explaining some economic concept, whereas an opera might not be.

\hypertarget{channel-risk}{%
\section{Channel Risk}\label{channel-risk}}

Shannon discusses that no channel is perfect: there is always the
\textbf{risk of noise} corrupting the signal. A key outcome from
Shannon's paper is that there is a tradeoff: within the capacity of the
channel (the \textbf{Bandwidth}), you can either send lots of
information with \emph{higher} risk that it is wrong, or less
information with \emph{lower} risk of errors. And, rather like the
Kolgomorov complexity result, the more \emph{randomness} in the signal,
the less compressible it is, and therefore the more \emph{bits} it will
take to transmit.

\begin{figure}
\centering
\includegraphics{images/generated/channel-risk-400dpi.png}
\caption{Communication Channel Risk}
\end{figure}

But channel risk goes wider than just this mathematical example:
messages might be delayed or delivered in the wrong order, or not be
acknowledged when they do arrive. Sometimes, a channel is just an
inappropriate way of communicating. When you work in a different
time-zone to someone else on your team, there is \emph{automatic}
Channel Risk, because instantaneous communication is only available for
a few hours' a day.

When channels are \textbf{poor-quality}, less communication occurs.
People will try to communicate just the most important information. But,
it's often impossible to know a-priori what constitutes ``important''.
This is why Extreme Programming by ensuring high-quality communication
channels are in place.

At other times, channels can contain so much information that we can't
hope to receive all the messages. In these cases, we don't even observe
the whole channel, just parts of it. For example, you might have a few
YouTube channels that you subscribe to, but hundreds of hours of video
are being posted on YouTube every second, so there is no way you can
keep up with all of it.

\begin{figure}
\centering
\includegraphics{images/generated/communication_channel_risks-400dpi.png}
\caption{Communication Channels}
\end{figure}

\hypertarget{marketing-communications}{%
\subsubsection{Marketing
Communications}\label{marketing-communications}}

When we are talking about a product or a brand, mitigating
\href{Communication-Risk\#channel-risk}{Channel Risk} is the domain of
\href{https://en.wikipedia.org/wiki/Marketing_communications}{Marketing
Communications}. How do you ensure that the information about your
(useful) project makes it to the right people? How do you address the
right channels?

This works both ways. Let's looks at some of the \textbf{Channel Risks}
from the point of view of a hypothetical software tool, \textbf{D},
which would really useful in my software:

\begin{itemize}
\tightlist
\item
  The concept that there is such a thing as \textbf{D} which solves my
  problem isn't something I'd even considered.
\item
  I'd like to use something like \textbf{D}, but how do I find it?
\item
  There are multiple implementations of \textbf{D}, which is the best
  one for the task?
\item
  I know \textbf{D}, but I can't figure out how to solve my problem in
  it.
\item
  I've chosen \textbf{D}, I now need to persuade my team that \textbf{D}
  is the correct solution\ldots{}
\item
  \ldots{} and then they also need to understand \textbf{D} to do their
  job too.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/communication_marketing-400dpi.png}
\caption{Communication Marketing}
\end{figure}

Internal Models when needed.

\hypertarget{protocols}{%
\section{Protocols}\label{protocols}}

In this chapter, I want to examine the concept of
\href{https://en.wikipedia.org/wiki/Communication_protocol}{Communication
Protocols} and how they relate to
\href{Glossary\#abstraction}{Abstraction}.

So, to do this, let's look in a bit of detail at how web pages are
loaded. When considering this, we need to broaden our terminology.
Although so far we've talked about \textbf{Senders} and
\textbf{Receivers}, we now need to talk from the point of view of
who-depends-on-who. If you're \emph{depended on}, then you're a
``Server'', whereas if you require communication with something else,
you're a ``Client''. Thus, clients depend on servers in order to load
pages.

This is going to involve (at least) six separate protocols, the top-most
one being the
\href{https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol}{HTTP
Protocol}. As far as the HTTP Protocol is concerned, a \emph{client}
makes an \texttt{HTTP\ Request} at a specific URL and the
\texttt{HTTP\ Response} is returned in a predictable format that the
browser can understand.

Let's have a quick look at how that works with a \texttt{curl} command,
which allows me to load a web page from the command line. We're going to
try and load Google's preferences page, and see what happens. If I type:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>} \ExtensionTok{curl}\NormalTok{ -v http://google.com/preferences}
\end{Highlighting}
\end{Shaded}

\hypertarget{dns---domain-name-system}{%
\subsection{1. DNS - Domain Name
System}\label{dns---domain-name-system}}

Then, the first thing that happens is this:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{*}\NormalTok{ Rebuilt URL to: http://google.com/}
\ExtensionTok{*}\NormalTok{   Trying 216.58.204.78...}
\end{Highlighting}
\end{Shaded}

At this point, curl has used
\href{https://en.wikipedia.org/wiki/Domain_Name_System}{DNS} to
\emph{resolve} the address ``google.com'' to an IP address. This is some
\href{Glossary\#abstraction}{Abstraction}: instead of using the
machine's \href{https://en.wikipedia.org/wiki/IP_address}{IP Address} on
the network, \texttt{216.58.204.78}, I can use a human-readable address,
\texttt{google.com}. The address \texttt{google.com} doesn't necessarily
resolve to that same address each time: \emph{They have multiple IP
addresses for \texttt{google.com}}. But, for the rest of the
\texttt{curl} request, I'm now set to just use this one.

\hypertarget{ip---internet-protocol}{%
\subsection{2. IP - Internet Protocol}\label{ip---internet-protocol}}

But this hints at what is beneath the abstraction: although I'm loading
a web-page, the communication to the Google server happens by
\href{https://en.wikipedia.org/wiki/Internet_Protocol}{IP Protocol} -
it's a bunch of discrete ``packets'' (streams of binary digits). You can
think of a packet as being like a real-world parcel or letter.

Each packet consists of two things:

\begin{itemize}
\tightlist
\item
  An address, which tells the network components (such as routers and
  gateways) where to send the packet, much like you'd write the address
  on the outside of a parcel.
\item
  The \emph{payload}, the stream of bytes for processing at the
  destination. Like the contents of the parcel.
\end{itemize}

But, even this concept of ``packets'' is an Abstraction. Although all
the components of the network interoperate with this protocol, we might
be using Wired Ethernet, or WiFi, 4G or \emph{something else}.

\hypertarget{wifi-protocol}{%
\subsection{3. 802.11 - WiFi Protocol}\label{wifi-protocol}}

I ran this at home, using WiFi, which uses
\href{https://en.wikipedia.org/wiki/IEEE_802.11}{IEEE 802.11 Protocol},
which allows my laptop to communicate with the router wirelessly, again
using an agreed, standard protocol. But even \emph{this} isn't the
bottom, because this is actually probably specifying something like
\href{https://en.wikipedia.org/wiki/MIMO-OFDM}{MIMO-OFDM}, giving
specifications about frequencies of microwave radiation, antennas,
multiplexing, error-correction codes and so on. And WiFi is just the
first hop: after the WiFi receiver, there will be protocols for
delivering the packets via the telephony system.

\hypertarget{tcp---transmission-control-protocol}{%
\subsection{4. TCP - Transmission Control
Protocol}\label{tcp---transmission-control-protocol}}

Anyway, the next thing that happens is this:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{*}\NormalTok{ TCP_NODELAY set}
\ExtensionTok{*}\NormalTok{ Connected to google.com (216.58.204.78) }\ExtensionTok{port}\NormalTok{ 80 (#0)}
\end{Highlighting}
\end{Shaded}

The second obvious \href{Glossary\#abstraction}{Abstraction} going on
here is that \texttt{curl} now believes it has a
\href{https://en.wikipedia.org/wiki/Transmission_Control_Protocol}{TCP}
connection. The TCP connection abstraction gives us the surety that the
packets get delivered in the right order, and retried if they go
missing. Effectively it \emph{guarantees} these things, or that it will
have a connection failure if it can't keep it's guarantee.

But, this is a fiction - TCP is built on the IP protocol, packets of
data on the network. So there are lots of packets floating around which
say ``this connection is still alive'' and ``I'm message 5 in the
sequence'' and so on in order to maintain this fiction. But that means
that the HTTP protocol can forget about this complexity and work with
the fiction of a connection.

\hypertarget{http---hypertext-transfer-protocol}{%
\subsection{5. HTTP - Hypertext Transfer
Protocol}\label{http---hypertext-transfer-protocol}}

Next, we see this:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>} \ExtensionTok{GET}\NormalTok{ /preferences HTTP/1.1     (1)}
\OperatorTok{>} \ExtensionTok{Host}\NormalTok{: google.com              (2)}
\OperatorTok{>} \ExtensionTok{User-Agent}\NormalTok{: curl/7.54.0       (3)}
\OperatorTok{>} \ExtensionTok{Accept}\NormalTok{: */*                   (4)}
\OperatorTok{>}                               \KeywordTok{(}\ExtensionTok{5}\KeywordTok{)}
\end{Highlighting}
\end{Shaded}

This is now the HTTP protocol proper, and these 5 lines are sending
information \emph{over the connection} to the Google server.

\begin{itemize}
\tightlist
\item
  \texttt{(1)} says what version of HTTP we are using, and the path
  we're loading (\texttt{/preferences} in this case).
\item
  \texttt{(2)} to \texttt{(4)} are \emph{headers}. They are name-value
  pairs, separated with a colon. The HTTP protocol specifies a bunch of
  these names, and later versions of the protocol might introduce newer
  ones.
\item
  \texttt{(5)} is an empty line, which indicates that we're done with
  the headers, please give us the response. And it does:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<} \ExtensionTok{HTTP/1.1}\NormalTok{ 301 Moved Permanently}
\OperatorTok{<} \ExtensionTok{Location}\NormalTok{: http://www.google.com/preferences}
\OperatorTok{<} \ExtensionTok{Content-Type}\NormalTok{: text/html}\KeywordTok{;} \VariableTok{charset=}\NormalTok{UTF-8}
\OperatorTok{<} \ExtensionTok{Date}\NormalTok{: Sun, 08 Apr 2018 10:24:34 GMT}
\OperatorTok{<} \ExtensionTok{Expires}\NormalTok{: Tue, 08 May 2018 10:24:34 GMT}
\OperatorTok{<} \ExtensionTok{Cache-Control}\NormalTok{: public, max-age=2592000}
\OperatorTok{<} \ExtensionTok{Server}\NormalTok{: gws}
\OperatorTok{<} \ExtensionTok{Content-Length}\NormalTok{: 230}
\OperatorTok{<} \ExtensionTok{X-XSS-Protection}\NormalTok{: 1}\KeywordTok{;} \VariableTok{mode=}\NormalTok{block}
\OperatorTok{<} \ExtensionTok{X-Frame-Options}\NormalTok{: SAMEORIGIN}
\OperatorTok{<}
\OperatorTok{<}\ExtensionTok{HTML}\OperatorTok{><}\NormalTok{HEAD}\OperatorTok{><}\NormalTok{meta http-equiv=}\StringTok{"content-type"}
\VariableTok{content=}\StringTok{"text/html;charset=utf-8"}\OperatorTok{>}
\OperatorTok{<}\ExtensionTok{TITLE}\OperatorTok{>}\NormalTok{301 Moved}\OperatorTok{<}\NormalTok{/TITLE}\OperatorTok{><}\NormalTok{/HEAD}\OperatorTok{><}\NormalTok{BODY}\OperatorTok{>}
\OperatorTok{<}\ExtensionTok{H1}\OperatorTok{>}\NormalTok{301 Moved}\OperatorTok{<}\NormalTok{/H1}\OperatorTok{>}
\ExtensionTok{The}\NormalTok{ document has moved}
\OperatorTok{<}\NormalTok{/}\ExtensionTok{BODY}\OperatorTok{><}\NormalTok{/HTML}\OperatorTok{>}
\ExtensionTok{*}\NormalTok{ Connection }\CommentTok{#0 to host google.com left intact}
\end{Highlighting}
\end{Shaded}

There's a lot going on here, but we can break it down really easily into
3 chunks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The first line is the
  \href{https://en.wikipedia.org/wiki/List_of_HTTP_status_codes}{HTTP
  Status Code}. \texttt{301} is a code meaning that the page has moved.
\item
  The next 9 lines are HTTP headers again (name-value pairs). The
  \texttt{Location:} directive tells us where the page has moved to.
  Instead of trying \texttt{http://google.com/preferences}, we should
  have used:
\end{enumerate}

\begin{quote}
\texttt{http://www.google.com/preferences}.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The lines starting \texttt{\textless{}HTML\textgreater{}} are now some
  HTML to display on the screen to tell the user that the page has
  moved.
\end{enumerate}

\hypertarget{html---hypertext-markup-language}{%
\subsection{6. HTML - Hypertext Markup
Language}\label{html---hypertext-markup-language}}

Although \href{https://en.wikipedia.org/wiki/HTML}{HTML} is a language,
a language is also a protocol. (After all, language is what we use to
encode our ideas for transmission as speech.) In the example we gave,
this was a very simple page telling the client that it's looking in the
wrong place. In most browsers, you don't get to see this: the browser
will understand the meaning of the \texttt{301} error and redirect you
to the location.

Let's look at all the protocols we saw here:

\begin{figure}
\centering
\includegraphics{images/generated/communication_protocols-400dpi.png}
\caption{Protocol Stack}
\end{figure}

Each protocol ``passes on'' to the next one in the chain. On the left,
we have the representation most suitable for the \emph{messages}: HTTP
is designed for browsers to use to ask for and receive web pages. As we
move right, we are converting the message more and more into a form
suitable for the Channel: in this case, microwave transmission.

By having a stack of protocols, we are able to apply
\href{https://en.wikipedia.org/wiki/Separation_of_concerns}{Separation
Of Concerns}, each protocol handling just a few concerns:

\begin{itemize}
\tightlist
\item
  \texttt{HTML} Abstraction: A language for describing the contents of a
  web-page.
\item
  \texttt{HTTP} Abstraction: Name-Value pairs, agreed on by both
  \texttt{curl} and Google, URLs and error codes.
\item
  \texttt{DNS} Abstraction: Names of servers to IP Addresses.
\item
  \texttt{TCP} Abstraction: The concept of a ``connection'' with
  guarantees about ordering and delivery.
\item
  \texttt{IP} Abstraction: ``Packets'' with addresses and payloads.
\item
  \texttt{WiFi} Abstraction: ``Networks'', 802.11 flavours.
\item
  Transmitters, Antennas, error correction codes, etc.
\end{itemize}

\texttt{HTTP} ``stands on the shoulders of giants''. Not only does it
get to use pre-existing protocols like \texttt{TCP} and \texttt{DNS} to
make it's life easier, it got \texttt{802.11} ``for free'' when this
came along and plugged into the existing \texttt{IP} protocol. This is
the key value of abstraction: you get to piggy-back on \emph{existing}
patterns, and use them yourself.

The protocol mediates between the message and the channel. Where this
goes wrong, we have Protocol Risk. This is a really common issue for IT
systems, but also sometimes for human communication too.

\hypertarget{protocol-risk}{%
\section{Protocol Risk}\label{protocol-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/protocol-risk-400dpi.png}
\caption{Protocol Risk}
\end{figure}

Generally, any time where you have different parts of a system
communicating with each other, and one part can change incompatibly with
another you have Protocol Risk.

Locally, (within our own project), where we have control, we can
mitigate this risk using compile-time checking (as discussed already in
Complexity Risk.

Let's look at some types of Protocol Risk:

\hypertarget{protocol-incompatibility-risk}{%
\subsection{Protocol Incompatibility
Risk}\label{protocol-incompatibility-risk}}

The people you find it \emph{easiest} to communicate with are your
friends and family, those closest to you. That's because you're all
familiar with the same protocols. Someone from a foreign country,
speaking a different language and having a different culture, will
essentially have a completely incompatible protocol for spoken
communication to you.

Within software, there are also competing, incompatible protocols for
the same things, which is maddening when your protocol isn't supported.
Although the world seems to be standardizing, there used to be
\emph{hundreds} of different image formats. Photographs often use
\href{https://en.wikipedia.org/wiki/TIFF}{TIFF},
\href{https://en.wikipedia.org/wiki/Raw_image_format}{RAW} or
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG}, whilst we also have
\href{https://en.wikipedia.org/wiki/Scalable_Vector_Graphics}{SVG} for
vector graphics, \href{https://en.wikipedia.org/wiki/GIF}{GIF} for
images and animations and
\href{https://en.wikipedia.org/wiki/Portable_Network_Graphics}{PNG} for
other bitmap graphics.

\hypertarget{protocol-versioning-risk}{%
\subsection{Protocol Versioning Risk}\label{protocol-versioning-risk}}

Even when systems are talking the same protocol, there can be problems.
When we have multiple, different systems owned by different parties, on
their own upgrade cycles, we have \textbf{Protocol Versioning Risk}: the
risk that either client or server could start talking in a version of
the protocol that the other side hasn't learnt yet. There are various
mitigating strategies for this. We'll look at two now: \textbf{Backwards
Compatibility} and \textbf{Forwards Compatibility}.

\hypertarget{protocol-complexity}{%
\subsection{Protocol Complexity}\label{protocol-complexity}}

tbd. abstraction - virtue between two vices. Postel's law.

\hypertarget{backward-compatibility}{%
\subsubsection{Backward Compatibility}\label{backward-compatibility}}

Backwards Compatibility mitigates
\href{Communication-Risk\#protocol-versioning-risk}{Protocol Versioning
Risk}. Quite simply, this means, supporting the old format until it
falls out of use. If a server is pushing for a change in protocol it
either must ensure that it is Backwards Compatible with the clients it
is communicating with, or make sure they are upgraded concurrently. When
building \href{https://en.wikipedia.org/wiki/Web_service}{web services},
for example, it's common practice to version all APIs so that you can
manage the migration. Something like this:

\begin{itemize}
\tightlist
\item
  Server publishes \texttt{/api/v1/something}.
\item
  Clients use \texttt{/api/v1/something}.
\item
  Server publishes \texttt{/api/v2/something}.
\item
  Clients start using \texttt{/api/v2/something}.
\item
  Clients (eventually) stop using \texttt{/api/v2/something}.
\item
  Server retires \texttt{/api/v2/something} API.
\end{itemize}

\hypertarget{forward-compatibility}{%
\subsubsection{Forward Compatibility}\label{forward-compatibility}}

\texttt{HTML} and \texttt{HTTP} provide ``graceful failure'' to mitigate
Protocol Risk: while its expected that all clients can parse the syntax
of \texttt{HTML} and \texttt{HTTP}, it's not necessary for them to be
able to handle all of the tags, attributes and rules they see. The
specification for both these standards is that if you don't understand
something, ignore it. Designing with this in mind means that old clients
can always at least cope with new features, but it's not always
possible.

\texttt{JavaScript} \emph{can't} support this: because the meaning of
the next instruction will often depend on the result of the previous
one.

Does human language support this? To some extent! New words are added to
our languages all the time. When we come across a new word, we can
either ignore it, guess the meaning, ask or look it up. In this way,
human language has \textbf{Forward Compatibility} features built in.

\hypertarget{protocol-implementation-risk}{%
\subsection{Protocol Implementation
Risk}\label{protocol-implementation-risk}}

A second aspect of Protocol Risk as possible, generally we run tests in
a subset of browsers, and use a lowest-common-denominator approach to
choosing protocol and language features.

\begin{figure}
\centering
\includegraphics{images/generated/communication_protocol_risks-400dpi.png}
\caption{Communication Protocols Risks}
\end{figure}

\hypertarget{messages}{%
\section{Messages}\label{messages}}

\begin{figure}
\centering
\includegraphics{images/generated/message-risk-400dpi.png}
\caption{Message Risk}
\end{figure}

Although Shannon's Communication Theory is about transmitting
\textbf{Messages}, messages are really encoded \textbf{Ideas} and
\textbf{Concepts}, from an \textbf{Internal Model}.

\hypertarget{internal-model-assumption-risk}{%
\subsection{Internal Model Assumption
Risk}\label{internal-model-assumption-risk}}

When we construct messages in a conversation, we have to make judgements
about what the other person already knows. When talking to children,
it's often hard work because they \emph{assume} that you have knowledge
of everything they do. This is called
\href{https://en.wikipedia.org/wiki/Theory_of_mind}{Theory Of Mind}: the
appreciation that your knowledge is different to other people's, and
adjusting you messages accordingly.

When teaching, this is called
\href{https://en.wikipedia.org/wiki/Curse_of_knowledge}{The Curse Of
Knowledge}: teachers have difficulty understanding students' problems
\emph{because they already understand the subject}. For example, if I
want to tell you about a new
\href{https://en.wikipedia.org/wiki/JDBC_driver}{JDBC Driver}, this
pre-assumes that you know what JDBC is: the message has a dependency on
prior knowledge.

\hypertarget{message-dependency-risk}{%
\subsection{Message Dependency Risk}\label{message-dependency-risk}}

A second, related problem is actually Dependency Risk will not be rich
enough to understand the new messages.

This happens when messages get missed, or delivered out of order. In the
past, TV shows were only aired once a week at a particular time. So
writers were constrained plot-wise by not knowing whether their audience
would have seen the previous week's episode. Therefore, often the state
of the show would ``reset'' week-to-week, allowing you to watch it in
\emph{any} order.

The same \textbf{Message Dependency Risk} exists for computer software:
if there is replication going on between instances of an application,
and one of the instances misses some messages, you end up with a
``\href{https://en.wikipedia.org/wiki/Split-brain_(computing)}{Split
Brain}'' scenario, where later messages can't be processed because they
refer to an application state that doesn't exist. For example, a message
saying:

\begin{verbatim}
Update user 53's surname to 'Jones'
\end{verbatim}

only makes sense if the application has previously had the message

\begin{verbatim}
Create user 53 with surname 'Smith'
\end{verbatim}

\hypertarget{misinterpretation-risk}{%
\subsection{Misinterpretation Risk}\label{misinterpretation-risk}}

People don't rely on rigorous implementations of abstractions like
computers do; we make do with fuzzy definitions of concepts and ideas.
We rely on Abstraction to move between the name of a thing and the
\emph{idea of a thing}.

While machines only process \emph{information}, people's brains run on
concepts and ideas. For people, abstraction is critical: nothing exists
unless we have a name for it. Our world is just atoms, but we don't
think like this. \emph{The name is the thing}.

\begin{quotation}

``The famous pipe. How people reproached me for it! And yet, could you
stuff my pipe? No, it's just a representation, is it not? So if I had
written on my picture ``This is a pipe'', I'd have been lying!''

\sourceatright{\href{https://en.wikipedia.org/wiki/The_Treachery_of_Images}{\textemdash  Rene Magritte, of \emph{The Treachery of Images}}}
\end{quotation}

This brings about Misinterpretation Risk: names are not \emph{precise},
and concepts mean different things to different people. We can't be sure
that people have the same meaning for concepts that we have.

\hypertarget{invisibility-risk}{%
\subsection{Invisibility Risk}\label{invisibility-risk}}

Another cost of Abstraction it lets the function of a thing hide behind
the layers of abstraction and become invisible.

\hypertarget{invisibility-risk-in-software}{%
\subsubsection{Invisibility Risk In
Software}\label{invisibility-risk-in-software}}

As soon as you create a function, you are doing abstraction. You are
saying: ``I now have this operation. The details, I won't mention again,
but from now on, it's called \textbf{f}'' And suddenly, ``\textbf{f}''
hides. It is working invisibly. Things go on in \textbf{f} that people
don't necessarily need to understand. There may be some documentation,
or tacit knowledge around what \textbf{f} is, and what it does, but it's
not necessarily right. Referring to \textbf{f} is a much simpler job
than understanding \textbf{f}.

We try to mitigate this via (for the most part) documentation, but this
is a terrible deal: because we can't understand the original,
(un-abstracted) implementation, we now need to write some simpler
documentation, which \emph{explains} the abstraction, in terms of
further abstractions, and this is where things start to get murky.

Invisibility Risk But you can carelessly \emph{hide things from
yourself} with software:

\begin{itemize}
\tightlist
\item
  Adding a thread to an application that doesn't report whether it's
  worked, failed, or is running out of control and consuming all the
  cycles of the CPU.
\item
  Redundancy can increase reliability, but only if you know when servers
  fail, and fix them quickly. Otherwise, you only see problems when the
  last server fails.
\item
  When building a webservice, can you assume that it's working for the
  users in the way you want it to?
\end{itemize}

When you build a software service, or even implement a thread, ask
yourself: ``How will I know next week that this is working properly?''
If the answer involves manual work and investigation, then your
implementation has just cost you in Invisibility Risk.

\hypertarget{invisibility-risk-in-conversation}{%
\subsubsection{Invisibility Risk In
Conversation}\label{invisibility-risk-in-conversation}}

Invisibility Risk in communication, and this saves us time when we're
talking. It would be \emph{painful} to have conversations if, say, the
other person needed to understand everything about how cars worked in
order to discuss cars.

For people, Abstraction is a tool that we can use to refer to other
concepts, without necessarily knowing how the concepts work. This
divorcing of ``what'' from ``how'' is the essence of abstraction and is
what makes language useful.

The debt of Invisibility Risk comes due when you realise that \emph{not}
being given the details \emph{prevents} you from reasoning about it
effectively. Let's think about this in the context of a project status
meeting, for example:

\begin{itemize}
\tightlist
\item
  Can you be sure that the status update contains all the details you
  need to know?
\item
  Is the person giving the update wrong or lying?
\item
  Do you know enough about the details of what's being discussed in
  order to make informed decisions about how the project is going?
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/communication_message_risks-400dpi.png}
\caption{Message Risk}
\end{figure}

\hypertarget{internal-models}{%
\section{Internal Models}\label{internal-models}}

So finally, we are coming to the root of the problem: communication is
about transferring ideas and concepts from one Internal Model to
another.

The communication process so far has been fraught with risks, but we
have a few more to come.

\hypertarget{trust-belief-risk}{%
\subsection{Trust \& Belief Risk}\label{trust-belief-risk}}

Although protocols can sometimes handle security features of
communication (such as
\href{https://en.wikipedia.org/wiki/Authentication}{Authentication} and
preventing
\href{https://en.wikipedia.org/wiki/Man-in-the-middle_attack}{man-in-the-middle
attacks}), trust goes further than this, intersecting with
\href{Agency-Risk}{Agency Risk}: can you be sure that the other party in
the communication is acting in your best interests?

Even if the receiver trusts the communicator, they may not trust the
message. Let's look at some reasons for that:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/World_view}{Weltanschauung (World
  View)}: The ethics, values and beliefs in the receiver's
  \href{Glossary\#Internal-Model}{Internal Model} may be incompatible to
  those from the sender.
\item
  \href{https://en.wikipedia.org/wiki/Relativism}{Relativism} is the
  concept that there are no universal truths. Every truth is from a
  frame of reference. For example, what constitutes \emph{offensive
  language} is dependent on the listener.
\item
  \href{https://en.wikipedia.org/wiki/Psycholinguistics}{Psycholinguistics}
  is the study of humans aquire languages. There are different languages
  and dialects, (and \emph{industry dialects}), and we all understand
  language in different ways, take different meanings and apply
  different contexts to the messages.
\end{itemize}

From the point-of-view of Marketing Communications.

\hypertarget{reputational-risk}{%
\subsection{Reputational Risk}\label{reputational-risk}}

tbd.

\hypertarget{learning-curve-risk}{%
\subsection{Learning-Curve Risk}\label{learning-curve-risk}}

If the messages we are receiving force us to update our
\href{Glossary\#Internal-Model}{Internal Model} too much, we can suffer
from the problem of ``too steep a
\href{https://en.wikipedia.org/wiki/Learning_curve}{Learning Curve}'' or
``\href{https://en.wikipedia.org/wiki/Information_overload}{Information
Overload}'', where the messages force us to adapt our
\href{Glossary\#Internal-Model}{Internal Model} too quickly for our
brains to keep up.

Commonly, the easiest option is just to ignore the information channel
completely in these cases.

\hypertarget{reading-code}{%
\subsection{Reading Code}\label{reading-code}}

It's often been said that code is \emph{harder to read than to write}:

\begin{quotation}

If you ask a software developer what they spend their time doing,
they'll tell you that they spend most of their time writing code.
However, if you actually observe what software developers spend their
time doing, you'll find that they spend most of their time trying to
understand code.

\end{quotation}

By now it should be clear that it's going to be \emph{both} quite hard
to read and write: the protocol of code is actually designed for the
purpose of machines communicating, not primarily for people to
understand. Making code human readable is a secondary concern to making
it machine readable.

But now we should be able to see the reasons it's harder to read than
write too:

\begin{itemize}
\tightlist
\item
  When reading code, you are having to shift your
  \href{Glossary\#Internal-Model}{Internal Model} to wherever the code
  is, accepting decisions that you might not agree with and accepting
  counter-intuitive logical leaps. i.e.
  \href{Communication-Risk\#learning-curve-risk}{Learning Curve Risk}.
  \emph{(cf.
  \href{https://en.wikipedia.org/wiki/Principle_of_least_astonishment}{Principle
  of Least Surprise})}
\item
  There is no Feedback Loop. When you write code, your compiler and
  tests give you this.
\item
  While reading code \emph{takes less time} than writing it, this also
  means the Learning Curve is steeper.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/communication_internal_model_risks-400dpi.png}
\caption{Internal Model Risks}
\end{figure}

\hypertarget{communication-risk-wrap-up}{%
\section{Communication Risk Wrap Up}\label{communication-risk-wrap-up}}

So, here's a summary of where we've arrived with our model of
communication risk:

\begin{figure}
\centering
\includegraphics{images/generated/communication_3-400dpi.png}
\caption{Communication 2}
\end{figure}

There's no point to Communication unless you have someone or something
to communicate with! So next it's time to look at Dependency Risk.

this seems complex tbd.

\hypertarget{dependency-risk}{%
\chapter{Dependency Risk}\label{dependency-risk}}

Dependency Risk else. One simple example could be that the software
service you write might depend on a server to run on. If the server goes
down, the service goes down too. In turn, the server depends on
electricity from a supplier, as well as a network connection from a
provider. If either of these dependencies aren't met, the service is out
of commission.

Dependencies can be on \emph{events}, \emph{people}, \emph{teams},
\emph{processes}, \emph{software}, \emph{services}, \emph{money}: pretty
much \emph{any resource}. Dependencies add risk to any project because
the reliability of the project itself is now a function involving the
reliability of the dependency.

In order to avoid repetition, and also to break down this large topic,
we're going to look at this over 6 chapters:

\begin{itemize}
\tightlist
\item
  In this first chapter will look at dependencies \emph{in general}, and
  specifically on \emph{events}, and some of the variations on
  Dependency Risk.
\item
  Next, we'll look at Schedule Risk, because time and money are key
  dependencies in any project.
\item
  Then, we'll move on to look specifically at Software Dependency Risk,
  covering using libraries, software services and building on top of the
  work of others.
\item
  After, we'll take a look at Process Risk, but we'll be considering
  more organisational factors and how bureaucracy comes into the
  picture.
\item
  Next, we'll take a closer look at Boundary Risk. These are the risks
  you face in choosing the wrong things to depend on.
\item
  Finally, we'll wrap up this analysis with a look at some of the
  specific problems around working with other people or businesses in
  Agency Risk.
\end{itemize}

\hypertarget{why-have-dependencies}{%
\section{Why Have Dependencies?}\label{why-have-dependencies}}

Luckily for us, the things we depend on in life are, for the most part,
abundant: water to drink, air to breathe, light, heat and most of the
time, food for energy.

This isn't even lucky though: life has adapted to build dependencies on
things that it can \emph{rely} on.

Although life exists at the bottom of the ocean around
\href{https://en.wikipedia.org/wiki/Hydrothermal_vent}{hydrothermal
vents}, it is a very different kind of life to us, and has a different
set of dependencies given it's circumstances.

This tells us a lot about Dependency Risk right here:

\begin{itemize}
\tightlist
\item
  On the one hand, depending on something else is very often helpful,
  and quite often essential. (For example, all animals that \emph{move}
  seem to depend on oxygen).
\item
  However, as soon as you have dependencies, you need to take into
  account of their \emph{reliability}. (Living near a river or stream
  gives you access to fresh water, for example).
\item
  Successful organisms \emph{adapt} to the dependencies available to
  them (like the thermal vent creatures).
\item
  There is likely to be \emph{competition} for a dependency when it is
  scarce (think of droughts and famine).
\end{itemize}

So, dependencies are a trade-off. They give with one hand and take with
the other. Our modern lives are full of dependency (just think of the
chains of dependency needed for putting a packet of biscuits on a
supermarket shelf, for example), but we accept this extra complexity
because it makes life \emph{easier}.

\hypertarget{simple-made-easy}{%
\section{Simple Made Easy}\label{simple-made-easy}}

In Rich Hickey's talk,
\href{https://www.infoq.com/presentations/Simple-Made-Easy}{Simple Made
Easy} he discusses the difference between \emph{simple} software systems
and \emph{easy} (to use) ones, heavily stressing the virtues of simple
over easy. It's an incredible talk and well worth watching.

But. Living systems are not simple. Not anymore. They evolved in the
direction of increasing complexity because life was \emph{easier} that
way. In the ``simpler'' direction, life is first \emph{harder} and then
\emph{impossible}, and then an evolutionary dead-end.

Depending on things makes \emph{your job easier}. It's just
\href{https://en.wikipedia.org/wiki/Division_of_labour}{division of
labour} and dependency hiearchies, as we saw in
\href{Complexity-Risk\#Hierarchies-and-Modularization}{Hierarchies and
Modularization}.

Our economic system and our software systems exhibit the same
tendency-towards-complexity. For example, the television in my house now
is \emph{vastly more complicated} than the one in my home when I was a
child. But, it contains much more functionality and consumes much less
power and space.

\hypertarget{event-dependencies}{%
\section{Event Dependencies}\label{event-dependencies}}

Let's start with dependencies on \emph{events}.

We rely on events occuring all the time in our lives, and so this is a
good place to start in our analysis of Dependency Risk generally. And,
as we will see, all the risks that apply to events pretty much apply to
all the other kinds of dependencies we'll look at.

Arguably, the event dependencies are the simplest to express, too:
usually, a \emph{time} and a \emph{place}. For example: - ``I can't
start shopping until the supermarket opens at 9am'', or - ``I must catch
my bus to work at 7:30am''.

In the first example, you can't \emph{start} something until a
particular event happens. In the latter example, you must \emph{be
ready} for an event at a particular time.

\hypertarget{events-mitigate-risk}{%
\subsection{Events Mitigate Risk\ldots{}}\label{events-mitigate-risk}}

Having an event occur in a fixed time and place is mitigating risk:

\begin{itemize}
\tightlist
\item
  By taking the bus, we are mitigating our own Schedule Risk reducing
  the amount of time we're going to spend on the activity of getting to
  work.
\item
  Events are a mitigation for Coordination Risk. Agreeing a date for a
  product launch, for example, allows lots of teams to coordinate their
  activities.
\item
  It's not entirely necessary to even take the bus: you could walk, or
  go by another form of transport. But, effectively, this just swaps one
  dependency for another: if you walk, this might well take longer and
  use more energy, so you're just picking up Schedule Risk on a
  different scarce resource - your money.
\end{itemize}

\hypertarget{but-events-lead-to-attendant-risk}{%
\subsection{But, Events Lead To Attendant
Risk}\label{but-events-lead-to-attendant-risk}}

By \emph{deciding to use the bus} we've Taken Action.

\begin{figure}
\centering
\includegraphics{images/kite9/dependency-risk-event.png}
\caption{Action Diagram showing risks mitigated by having an
\emph{event}}
\end{figure}

However, as we saw in A Simple Scenario.

So, we're going to look at Dependency Risk from 7 different
perspectives, many of which we've already touched on in the other
chapters.

\begin{itemize}
\tightlist
\item
  Schedule Risk
\item
  Reliability Risk
\item
  Scarcity Risk
\item
  Communication Risk
\item
  Complexity Risk
\item
  Feature Fit Risk
\item
  Dead-End Risk
\end{itemize}

(Although you might be able to think of a few more.)

Let's look at each of these in turn.

\hypertarget{schedule-risk}{%
\section{Schedule Risk}\label{schedule-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/schedule-risk-400dpi.png}
\caption{Schedule Risk}
\end{figure}

By agreeing a \emph{time} and \emph{place} for something to happen,
you're introducing Deadline Risk. Miss the deadline, and you miss the
bus, or the start of the meeting or get fined for not filling your tax
return on time.

As discussed above, \emph{schedules} (such as bus timetables) exist so
that \emph{two or more parties can coordinate}, and Deadline Risk is on
\emph{all} of the parties. While there's a risk I am late, there's also
a risk the bus is late. I might miss the start of a concert, or the band
might keep everyone waiting.

Each party can mitigate Deadline Risk with \emph{slack}. That is,
ensuring that the exact time of the event isn't critical to your plans:

\begin{itemize}
\tightlist
\item
  Don't build into your plans a \emph{need} to start shopping at 9am.
\item
  Arrive at the bus-stop \emph{early}.
\end{itemize}

The amount of slack you build into the schedule is likely dependent on
the level of risk you face: I tend to arrive a few minutes early for a
bus, because the risk is \emph{low} (there'll be another bus along
soon), however I try to arrive over an hour early for a flight, because
I can't simply get on the next flight straight away, and I've already
paid for it, so the risk is \emph{high}.

Deadline Risk becomes very hard to manage when you have to coordinate
actions with lots of tightly-constrained events. So what else can give?
We can reduce the number of \emph{parties} involved in the event, which
reduces risk, or, we can make sure all the parties are in the same
\emph{place} to begin with.

\hypertarget{reliability-risk}{%
\section{Reliability Risk}\label{reliability-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/reliability-risk-400dpi.png}
\caption{Reliability Risk}
\end{figure}

Deadline Risk.

Luckily, there is quite a lot of existing science around reliability.
For example:

\begin{itemize}
\tightlist
\item
  If a component \textbf{A} depends on component \textbf{B}, unless
  there is some extra redundancy around \textbf{B}, then \textbf{A}
  \emph{can't} be more reliable than \textbf{B}.
\item
  Is \textbf{A} or \textbf{B} a
  \href{https://en.wikipedia.org/wiki/Single_point_of_failure}{Single
  Point Of Failure} in a system?
\item
  Are there bugs in \textbf{B} that are going to prevent it working
  correctly in all circumstances?
\end{itemize}

This kind of stuff is encapsulated in the science of
\href{https://en.wikipedia.org/wiki/Reliability_engineering}{Reliability
Engineering}. For example,
\href{https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis}{Failure
mode and effects analysis (FEMA)}:

\begin{quotation}

``\ldots{}was one of the first highly structured, systematic techniques
for failure analysis. It was developed by reliability engineers in the
late 1950s to study problems that might arise from malfunctions of
military systems.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis}{\textemdash  FEMA, \emph{Wikipedia}}}
\end{quotation}

This was applied on NASA missions, and then more recently in the 1970's
to car design following the
\href{https://en.wikipedia.org/wiki/Ford_Pinto\#Design_flaws_and_ensuing_lawsuits}{Ford
Pinto exploding car} affair.

\hypertarget{scarcity-risk}{%
\section{Scarcity Risk}\label{scarcity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/scarcity-risk-400dpi.png}
\caption{Scarcity Risk}
\end{figure}

Let's get back to the bus (which, hopefully, is still working). What if,
when it arrives, it's already full of passengers? Let's term this,
Scarcity Risk - the chance that a dependency is over-subscribed and you
can't use it the way you want. This is clearly an issue for nearly every
kind of dependency: buses, supermarkets, concerts, teams, services and
people.

You could also call this \emph{availability risk} or \emph{capacity
risk} of the resource. Here are a selection of mitigations:

\begin{itemize}
\tightlist
\item
  \textbf{Buffers}: Smoothing out peaks and troughs in utilisation.
\item
  \textbf{Reservation Systems}: giving clients information \emph{ahead}
  of the dependency usage about whether the resource will be available
  to them.
\item
  \textbf{Graceful degradation}: Ensuring \emph{some} service in the
  event of over-subscription. It would be no use allowing people to cram
  onto the bus until it can't move.
\item
  \textbf{Demand Management}: Having different prices during busy
  periods helps to reduce demand. Having ``first class'' seats means
  that higher-paying clients can get service even when the train is
  full. \href{https://www.uber.com}{Uber} adjust prices in real-time by
  so-called
  \href{https://www.uber.com/en-GB/drive/partner-app/how-surge-works/}{Surge
  Pricing}. This is basically turning
  \href{Dependency-Risk\#Scarcity-Risk}{Scarcity Risk} into a
  \href{Feature-Risk\#market-risk}{Market Risk} problem.
\item
  \textbf{Queues}: Again, these provide a ``fair'' way of dealing with
  scarcity by exposing some mechanism for prioritising use of the
  resource. Buses operate a first-come-first-served system, whereas
  emergency departments in hospitals triage according to need.
\item
  \textbf{Pools}: Reserving parts of a resource for particular
  customers.
\item
  \textbf{Horizontal Scaling}: allowing a scarce resource to flexibly
  scale according to how much demand there is. (For example, putting on
  extra buses when the trains are on strike, or opening extra check-outs
  at the supermarket.)
\end{itemize}

Much like Reliability Risk, there is science for it:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Queueing_theory}{Queue Theory} is
  all about building mathematical models of buffers, queues, pools and
  so forth.
\item
  \href{https://en.wikipedia.org/wiki/Logistics}{Logistics} is the
  practical organisation of the flows of materials and goods around
  things like \href{https://en.wikipedia.org/wiki/Supply_chain}{Supply
  Chains}.
\item
  And \href{https://en.wikipedia.org/wiki/Project_management}{Project
  Management} is in large part about ensuring the right resources are
  avaiable at the right times. We'll be taking a closer look at that in
  the Part 3 chapters on \url{Prioritisation} and the
  \href{PMBoK}{Project Managment Body Of Knowledge}.
\end{itemize}

\hypertarget{communication-risk-1}{%
\section{Communication Risk}\label{communication-risk-1}}

\begin{figure}
\centering
\includegraphics{images/generated/communication-risk-400dpi.png}
\caption{Communication Risk}
\end{figure}

We've already looked at communication risk in a lot of depth, and we're
going to go deeper still in Software Dependency Risk and talked about
the levels of awareness that you could have with dependencies. i.e.

\begin{itemize}
\tightlist
\item
  The concept that there is such a thing as \textbf{D} which solves my
  problem isn't something I'd even considered.
\item
  I'd like to use something like \textbf{D}, but how do I find it?
\item
  There are multiple implementations of \textbf{D}, which is the best
  one for the task?
\item
  I know \textbf{D}, but I can't figure out how to solve my problem in
  it.
\end{itemize}

Let's apply this to our Bus scenario:

\begin{itemize}
\tightlist
\item
  Am I aware that there is public transport in my area?
\item
  How do I find out about the different options?
\item
  How do I choose between buses, taxis, cars etc.
\item
  How do I understand the timetable, and apply it to my problem?
\end{itemize}

\hypertarget{silo-mentality}{%
\subsection{Silo Mentality}\label{silo-mentality}}

Finding out about bus schedules is easy. But in a large company,
\href{Communication-Risk}{Communication Risk} and especially
\href{Communication-Risk\#invisibility-risk}{Invisibility Risk} are huge
problems. This tends to get called
``\href{https://en.wikipedia.org/wiki/Information_silo\#Silo_mentality}{Silo
Mentality}'', that is, ignoring what else is going on in other divisions
of the company or
\href{https://en.wikipedia.org/wiki/Not_invented_here}{``not invented
here''} syndrome:

\begin{quotation}

``In management the term silo mentality often refers to information
silos in organizations. Silo mentality is caused by divergent goals of
different organizational units.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Information_silo\#Silo_mentality}{\textemdash  Silo Mentality, \emph{Wikipedia}}}
\end{quotation}

Ironically, \emph{more communication} might not be the answer - if
channels are provided to discover functionality in other teams you can
still run into Trust Risk in terms of too low a signal-to-noise ratio,
or desperate self-promotion.

Silo Mentality is exacerbated by the problems you would face in
\emph{budgeting} if suddenly all the divisions in an organisation
started providing dependencies for each other. This starts to require a
change to organisational structure towards being a set of individual
businesses marketing services to one another, rather than a
division-based one. We'll look more closely at these kind of
organisational issues in the Coordination Risk chapter.

\hypertarget{complexity-risk-1}{%
\section{Complexity Risk}\label{complexity-risk-1}}

Dependencies are usually a mitigation for Complexity Risk, you just need
to interact with the dependency properly to get the job done. Buses are
\emph{perfect} for people who can't drive, after all.

But this means that all of the issues of abstractions that we covered in
Communication Risk apply:

\begin{itemize}
\tightlist
\item
  There is Invisiblity Risk because you probably don't have a full view
  of what the dependency is doing. Nowadays, bus stops have a digital
  ``arrivals'' board which gives you details of when the bus will
  arrive, and shops publish their opening hours online. But, abstraction
  always means the loss of some detail.
\item
  There is Misinterpretation Risk, because often the dependency might
  mistake your instructions. This is endemic in software, where it's
  nearly impossible to describe exactly what you want up-front.
\end{itemize}

\hypertarget{fit-risk}{%
\section{Fit Risk}\label{fit-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/feature-risk-400dpi.png}
\caption{Feature Fit Risk}
\end{figure}

Sometimes, the bus will take you to lots of in-between places you
\emph{didn't} want to go. This is Fit Risk. There, we considered two
problems:

\begin{itemize}
\tightlist
\item
  The feature (or now, dependency) doesn't provide all the functionality
  you need. This was Fit Risk. An example might be the supermarket not
  stocking everything you wanted.
\item
  The feature / dependency provides far too much, and you have to accept
  more complexity than you need. This was Conceptual Integrity Risk. An
  example of this might be the supermarket being \emph{too big}, and you
  spend a lot longer navigating it than you wanted to.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/dependency-risk-fit.png}
\caption{Feature Fit: A Two-Dimensional Problem (at least)}
\end{figure}

\hypertarget{dead-end-risk-and-boundary-risk}{%
\section{Dead-End Risk and Boundary
Risk}\label{dead-end-risk-and-boundary-risk}}

When you choose something to depend on, you can't be certain that it's
going to work out in your favour. Sometimes, the path from your starting
point to your goal on the Risk Landscape, which we looked at before.

Boundary Risk if you've not had to follow a path to get to it.

We're also going to look at Boundary Risk in more detail later, but I
want to introduce it here. Here are some examples:

\begin{itemize}
\tightlist
\item
  If I choose to program some software in Java, I will find it hard to
  integrate libraries from other languages. The dependencies available
  to Java software are different to those in Javascript, or C\#. Having
  gone down a Java route, there are \emph{higher risks} associated with
  choosing incompatible technologies. Yes, I can pick dependencies that
  use C\# (still), but I am now facing greater complexity risk than if
  I'd just chosen to do everything in C\# in the first place.
\item
  If I choose one database over another, I am \emph{limited to the
  features of that database}. This is not the same as a dead-end: I can
  probably build what I want to build, but the solution will be
  ``bounded'' by the dependency choices I make. One of the reasons we
  have standards like
  \href{https://en.wikipedia.org/wiki/Java_Database_Connectivity}{Java
  Database Connectivity (JDBC)} is to mitigate
  \href{Complexity-Risk\#dead-end-risk}{Dead End Risk} around databases,
  so that we can move to a different database later.
\item
  If I choose to buy a bus ticket, I've made a decision not to travel by
  train, even though later on it might turn out that the train was a
  better option. Buying the bus ticket is Boundary Risk: I may be able
  to get a refund, but having chosen the dependency I've set down a path
  on the risk landscape.
\end{itemize}

\hypertarget{managing-dependency-risk}{%
\section{Managing Dependency Risk}\label{managing-dependency-risk}}

Arguably, managing Dependency Risk by organising the available
dependencies into some kind of useful order.

There are \emph{some} tools for managing dependency risk:
\href{https://en.wikipedia.org/wiki/Gantt_chart}{Gantt Charts} for
example, arrange work according to the capacity of the resources
(i.e.~dependencies) available, but also the \emph{dependencies between
the tasks}. If task \textbf{B} requires the outputs of task \textbf{A},
then clearly task \textbf{A} comes first and task \textbf{B} starts
after it finishes. We'll look at this more in
\href{Process-Risk}{Process Risk}.

We'll look in more detail at project management in the \emph{practices}
part, later. But now let's get into the specifics with Schedule Risk.

\hypertarget{schedule-risk-1}{%
\chapter{Schedule Risk}\label{schedule-risk-1}}

Schedule Risk is the term for risks you face because of \emph{lack of
time}.

You could also call this ``Chronological Risk'' or just ``Time Risk'' if
you wanted to.

\begin{figure}
\centering
\includegraphics{images/generated/schedule-risk-400dpi.png}
\caption{Schedule Risk}
\end{figure}

Schedule Risk is very pervasive, and really underlies \emph{everything}
we do. People \emph{want} things, but they \emph{want them at a certain
time}. We need to eat and drink every day, for example. We might value
having a great meal, but not if we have to wait three weeks for it.

And let's go completely philosophical for a second: Were you to attain
immortality, you'd probably not feel the need to buy \emph{anything}.
You'd clearly have no \emph{needs}, and anything you wanted, you could
create yourself within your infinite time-budget. Rocks don't need
money, after all.

Let's look at some specific kinds of Schedule Risk.

\hypertarget{opportunity-risk}{%
\section{Opportunity Risk}\label{opportunity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/opportunity-risk-400dpi.png}
\caption{Opportunity Risk}
\end{figure}

\href{Schedule-Risk\#opportunity-risk}{Opportunity Risk} is really the
concern that whatever we do, we have to do it \emph{in time}. If we wait
too long, we'll miss the
\href{https://en.wikipedia.org/wiki/Window_of_opportunity}{Window Of
Opportunity} for our product or service.

Any product idea is necessarily of it's time: the Goal In Mind,
reflecting a view on reality at a specific \emph{point in time}.

How long will that remain true for? This is your \emph{opportunity}: it
exists apart from any deadlines you set yourself, or funding options.
It's purely, ``how long will this idea be worth doing?''

With any luck, decisions around \emph{funding} your project will be tied
into this, but it's not always the case. It's very easy to undershoot or
overshoot the market completely and miss the window of opportunity.

\hypertarget{the-ipad}{%
\subsection{The iPad}\label{the-ipad}}

For example, let's look at the
\href{https://en.wikipedia.org/wiki/History_of_tablet_computers}{iPad},
which was introduced in 2010 and was hugely successful.

This was not the first tablet computer. Apple had already tried to
introduce the \href{https://en.wikipedia.org/wiki/Apple_Newton}{Newton}
in 1989, and Microsoft had released the
\href{https://en.wikipedia.org/wiki/Microsoft_Tablet_PC}{Tablet PC} in
1999. But somehow, they both missed the
\href{https://en.wikipedia.org/wiki/Window_of_opportunity}{Window Of
Opportunity}. Possibly, the window existed because Apple had changed
changed the market with their release of the iPhone, which left people
open to the idea of a tablet being ``just a bigger iPhone''.

But maybe now, the iPad's window is closing? We have more \emph{wearable
computers} like the
\href{https://en.wikipedia.org/wiki/Apple_Watch}{Apple Watch}, and
voice-controlled devices like
\href{https://en.wikipedia.org/wiki/Amazon_Alexa}{Alexa} or
\href{https://en.wikipedia.org/wiki/Siri}{Siri}. Peak iPad was in 2014,
according to
\href{https://www.statista.com/statistics/269915/global-apple-ipad-sales-since-q3-2010/}{this
graph}.

So, it seems Apple timed the iPad to hit the peak of the Window of
Opportunity.

But, even if you time the Window Of Opportunity correctly, you might
still have the rug pulled from under your feet due to a different kind
of Schedule Risk, such as\ldots{}

\hypertarget{deadline-risk}{%
\section{Deadline Risk}\label{deadline-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/deadline-risk-400dpi.png}
\caption{Deadline Risk}
\end{figure}

Often when running a software project, you're given a team of people and
told to get something delivered by a certain date. i.e.~you have an
artificially-imposed Deadline on delivery.

What happens if you miss the deadline? It could be: - The funding on the
project runs out, and it gets cancelled. - You have to go back to a
budgeting committee, and get more money. - The team gets replaced,
because of lack of faith.

.. or something else.

Deadlines can be set by an authority in order to \emph{sharpen focus}
and reduce \href{Coordination-Risk}{Coordination Risk}. This is how we
arrive at tools like
\href{https://en.wikipedia.org/wiki/SMART_criteria}{SMART Objectives}
and \href{https://en.wikipedia.org/wiki/Performance_indicator}{KPI's
(Key Performance Indicators)}. Time scales change the way we evaluate
goals, and the solutions we choose.

In JFK's quote:

\begin{quotation}

First, I believe that this nation should commit itself to achieving the
goal, before this decade is out, of landing a man on the moon and
returning him safely to the Earth.

\end{quotation}

The 9-year timespan came from an authority figure (the president) and
helped a huge team of people coordinate their efforts and arrive at a
solution that would work within a given time-frame.

Compare with this quote:

\begin{quote}
``I love deadlines. I love the whooshing noise they make as they go
by.'' - \href{https://en.wikipedia.org/wiki/Douglas_Adams}{Douglas
Adams}
\end{quote}

As a successful author, Douglas Adams \emph{didn't really care} about
the deadlines his publisher's gave him. The Deadline Risk was minimal
for him, because the publisher wouldn't be able to give his project to
someone else to complete.

Sometimes, deadlines are set in order to \emph{coordinate work between
teams}. The classic example being in a battle, to coordinate attacks.
When our deadlines are for this purpose, we're heading towards
Coordination Risk territory.

\hypertarget{student-syndrome}{%
\subsection{Student Syndrome}\label{student-syndrome}}

\href{https://en.wikipedia.org/wiki/Student_syndrome}{Student Syndrome}
is, according to Wikipedia:

\begin{quotation}

Student syndrome refers to planned procrastination, when, for example, a
student will only start to apply themselves to an assignment at the last
possible moment before its deadline.

\end{quotation}

Arguably, there is good psychological, evolutionary and risk-based
reasoning behind procrastination: the further in the future the Deadline
Risk is, the more we discount it. If we're only ever mitigating our
\emph{biggest risks}, then deadlines in the future don't matter so much,
do they? And, putting efforts into mitigating future risks that
\emph{might not arise} is wasted effort.

Or at least, that's the argument. If you're Discounting the Future To
Zero then you'll be pulling all-nighters in order to deliver any
assignment.

So, the problem with Student Syndrome \emph{later} than you would have
with the original, pressing deadline \ldots{} and you end up being late
because of them.

We'll look at mitigations for this in Part 3's chapter on
Prioritisation.

\hypertarget{funding-risk}{%
\section{Funding Risk}\label{funding-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/funding-risk-400dpi.png}
\caption{Funding Risk}
\end{figure}

On a lot of software projects, you are ``handed down'' deadlines from
above, and told to deliver by a certain date or face the consequences.
But sometimes you're given a budget instead, which really just adds
another layer of abstraction to the Schedule Risk: That is, do I have
enough funds to cover the team for as long as I need them?

This grants you some leeway as now you have two variables to play with:
the \emph{size} of the team, and \emph{how long} you can run it for. The
larger the team, the shorter the time you can afford to pay for it.

In startup circles, this ``amount of time you can afford it'' is called
the \href{https://en.wiktionary.org/wiki/runway}{``Runway''}: you have
to get the product to ``take-off'' before the runway ends. So you could
term this component as ``Runway Risk''.

Startups often spend a lot of time courting investors in order to get
funding and mitigate this type of Schedule Risk, as usually the same
people are trying to raise funds as build the project itself.

\hypertarget{staff-risk}{%
\section{Staff Risk}\label{staff-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/staff-risk-400dpi.png}
\caption{Staff Risk}
\end{figure}

If a startup has a ``Runway'', then the chances are that the founders
and staff do too, as this article
\href{https://www.entrepreneur.com/article/223135}{explores}. It
identifies the following risks:

\begin{itemize}
\tightlist
\item
  Company Cash: The \textbf{Runway} of the startup itself
\item
  Founder Cash: The \textbf{Runway} for a founder, before they run out
  of money and can't afford their rent.
\item
  Team Cash: The \textbf{Runway} for team members, who may not have the
  same appetite for risk as the founders do.
\end{itemize}

You need to consider how long your staff are going to be around,
especially if you have
\href{https://en.wikipedia.org/wiki/Key_person_insurance\#Key_person_definition}{Key
Man Risk} on some of them. People like to have new challenges, or move
on to live in new places, or simply get bored. The longer your project
goes on for, the more \href{Schedule-Risk\#staff-risk}{Staff Risk} you
will have to endure, and you can't rely on getting the
\href{Agency-Risk}{best staff for failing projects}.

In the chapter on Coordination-Risk.

\hypertarget{red-queen-risk}{%
\section{Red-Queen Risk}\label{red-queen-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/red-queen-risk-400dpi.png}
\caption{Red Queen Risk}
\end{figure}

A more specific formulation of Schedule Risk, which is that whatever you
build at the start of the project will go slowly more-and-more out of
date as the project goes on.

This is named after the Red Queen quote from Alice in Wonderland:

\begin{quote}
``My dear, here we must run as fast as we can, just to stay in place.
And if you wish to go anywhere you must run twice as fast as that.'' -
\href{https://www.goodreads.com/quotes/458856-my-dear-here-we-must-run-as-fast-as-we}{Lewis
Carroll, \emph{Alice in Wonderland}}
\end{quote}

The problem with software projects is that tools and techniques change
\emph{really fast}. In 2011, 3DRealms released Duke Nukem Forever after
\href{https://en.wikipedia.org/wiki/Duke_Nukem_Forever}{15 years in
development}, to negative reviews:

\begin{quotation}

\ldots{} most of the criticism directed towards the game's long loading
times, clunky controls, offensive humor, and overall aging and dated
design.

\end{quotation}

Now, they didn't \emph{deliberately} take 15 years to build this game
(lots of things went wrong). But, the longer it took, the more their
existing design and code-base were a liability rather than an asset.

Personally, I have suffered the pain on project teams where we've had to
cope with legacy code and databases because the cost of changing them
was too high. And any team who is stuck using
\href{https://en.wikipedia.org/wiki/Visual_Basic}{Visual Basic 6.0} is
here. It's possible to ignore \href{Schedule-Risk\#red-queen-risk}{Red
Queen Risk} for a time, but this is just another form of
\href{Complexity-Risk}{Technical Debt} which eventually comes due.

\hypertarget{schedule-risk-and-feature-risk}{%
\section{Schedule Risk and Feature
Risk}\label{schedule-risk-and-feature-risk}}

In the chapter on Feature Risk, the idea that the value of your product
is itself at risk from the morÃ©s of the market, share prices being the
obvious example of that effect. In Finance, we measure this using
\emph{money}, and we can put together probability models based on how
much money you might make or lose.

With Schedule Risk, the underlying measure is \emph{time}:

\begin{itemize}
\tightlist
\item
  ``If I implement feature X, I'm picking up something like 5 days of
  Schedule Risk.''
\item
  ``If John goes travelling that's going to hit us with lots of Schedule
  Risk while we train up Anne.''
\end{itemize}

\ldots{} and so on. Clearly, in the same way as you don't know exactly
how much money you might lose or gain on the stock-exchange, you can't
put precise numbers on Schedule Risk either.

Schedule Risk.

\hypertarget{software-dependency-risk}{%
\chapter{Software Dependency Risk}\label{software-dependency-risk}}

In this chapter, we're going to look specifically at \emph{Software}
dependencies, although many of the concerns we'll raise here apply
equally to all the other types of dependency we outlined in Dependency
Risk.

\hypertarget{kolmogorov-complexity-cheating}{%
\section{Kolmogorov Complexity:
Cheating}\label{kolmogorov-complexity-cheating}}

In the earlier chapter on Complexity Risk, and the idea that your
codebase had some kind of minimal level of complexity based on the
output it was trying to create. This is a neat idea, but in a way, we
cheated. Let's look at how.

We were trying to figure out the shortest (Javascript) program to
generate this output:

\begin{verbatim}
abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd
\end{verbatim}

And we came up with this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                         (}\DecValTok{11}\NormalTok{ symbols)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                           (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                 (}\DecValTok{7}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

Which had \textbf{26} symbols in it.

Now, here's the cheat: The \texttt{repeat()} function was built into
Javascript in 2015 in
\href{http://www.ecma-international.org/ecma-262/6.0/}{ECMAScript 6.0}.
If we'd had to program it ourselves, we might have added this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{repeat}\NormalTok{(s}\OperatorTok{,}\NormalTok{n) }\OperatorTok{\{}\NormalTok{                     (}\DecValTok{10}\NormalTok{ symbols)}
    \KeywordTok{var}\NormalTok{ a}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{                              (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{while}\NormalTok{(}\VariableTok{a}\NormalTok{.}\AttributeTok{length}\OperatorTok{<}\NormalTok{n)}\OperatorTok{\{}\NormalTok{                     (}\DecValTok{9}\NormalTok{ symbols)}
        \VariableTok{a}\NormalTok{.}\AttributeTok{push}\NormalTok{(s)                          (}\DecValTok{6}\NormalTok{ symbols)}
    \OperatorTok{\}}\NormalTok{                                      (}\DecValTok{1}\NormalTok{ symbol)}
    \ControlFlowTok{return} \VariableTok{a}\NormalTok{.}\AttributeTok{join}\NormalTok{(}\StringTok{''}\NormalTok{)}\OperatorTok{;}\NormalTok{                     (}\DecValTok{10}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

\ldots{} which would be an extra \textbf{44} symbols (in total
\textbf{70}), and push us completely over the original string encoding
of \textbf{53} symbols. So, \emph{encoding language is important}.

Conversely, if ECMAScript 6.0 had introduced a function called
\texttt{abcdRepeater(n)} we'd have been able to do this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                           (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \AttributeTok{abcdRepeater}\NormalTok{(}\DecValTok{10}\NormalTok{)                (}\DecValTok{6}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

.. and re-encode to \textbf{14} symbols. Now, clearly there are some
problems with all this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clearly, \emph{language matters}: the Kolmogorov complexity is
  dependent on the language, and the features the language has built in.
\item
  The exact Kolmogorov complexity is uncomputable anyway (it's the
  \emph{theoretical} minimum program length). It's just a fairly
  abstract idea, so we shouldn't get too hung up on this. There is no
  function to be able to say, ``what's the Kolmogorov complexity of
  string X''
\item
  What is this new library function we've created? Is
  \texttt{abcdRepeater} going to be part of \emph{every} Javascript? If
  so, then we've shifted Codebase Risk
\item
  Are there equivalent functions for every single other string? If so,
  then compilation is no longer a tractable problem: is
  \texttt{return\ abcdRepeater(10)} correct code? Well, now we have a
  massive library of different \texttt{XXXRepeater} functions to compile
  against to see if it is\ldots{} So, what we \emph{lose} in Kolmogorov
  Complexity.
\item
  Language design, then, is about \emph{ergonomics}. After you have
  passed the relatively low bar of providing
  \href{https://en.wikipedia.org/wiki/Turing_completeness}{Turing
  Completeness}, the key is to provide \emph{useful} features that
  enable problems to be solved, without over-burdening the user with
  features they \emph{don't} need. And in fact, all software is about
  this.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-ergonomics.png}
\caption{Software Dependency Ergonomics: finding the sweet spot between
too many features and too few}
\end{figure}

\hypertarget{ergonomics-examined}{%
\section{Ergonomics Examined}\label{ergonomics-examined}}

Have a look at some physical tools, like a hammer, or spanner. To look
at them, they are probably \emph{simple} objects, obvious, strong and
dependable. Their entire behaviour is encapsulated in their form. Now,
if you have a drill or sander to hand, look at the design of this too.
If it's well-designed, then from the outside it is simple, perhaps with
only one or two controls. Inside, it is complex and contains a motor,
perhaps a transformer, and is maybe made of a hundred different
components.

But outside, the form is simple, and designed for humans to use. This is
\emph{\href{https://en.wikipedia.org/wiki/Human_factors_and_ergonomics}{ergonomics}}:

\begin{quotation}

``Human factors and ergonomics (commonly referred to as Human Factors),
is the application of psychological and physiological principles to the
(engineering and) design of products, processes, and systems. The goal
of human factors is to reduce human error, increase productivity, and
enhance safety and comfort with a specific focus on the interaction
between the human and the thing of interest.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Human_factors_and_ergonomics}{\textemdash  Human Factors and Ergonomics, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{interfaces}{%
\subsection{Interfaces}\label{interfaces}}

The interface of a tool is the part we touch and interact with. By
striving for simplicity, the interface reduces Communication Risk.

The interface of a system expands when you ask it to do a wide variety
of things. An easy-to-use drill does one thing well: it turns drill-bits
at useful levels of torque for drilling holes and sinking screws. But if
you wanted it to also operate as a lathe, a sander or a strimmer (all
basically mechanical things going round) you would have to sacrifice the
ergonomic simplicity for a more complex interface, probably including
adapters, extensions, handles and so on.

So, we now have split complexity into two: - The inner complexity of the
tool (how it works internally, it's own Kolmogorov Complexity. - The
complexity of the instructions that we need to write to make the tool
work (the interface Kolmogorov Complexity.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-complexity.png}
\caption{Types of Complexity For a Software Dependency}
\end{figure}

\hypertarget{software-tools}{%
\subsection{Software Tools}\label{software-tools}}

In the same way as with a hand-tool, the bulk of the complexity of a
software tool is hidden behind it's interface. But, the more complex the
\emph{purpose} of the tool, the more complex the interface will be.

Software is not constrained by \emph{physical} ergonomics in the same
way as a tool is. But ideally, it should have conceptual ergonomics:
ideally, complexity is hidden away from the user behind the
\href{https://en.wikipedia.org/wiki/Application_programming_interface}{Application
Programming Interface (API)}. This is the familiar concept of
\href{Glossary\#abstraction}{Abstraction} we've already looked at.

That is, the tool should be as simple to use and understand as possible.
This is the
\href{https://en.wikipedia.org/wiki/Principle_of_least_astonishment}{Principal
Of Least Astonishment}:

\begin{itemize}
\tightlist
\item
  \textbf{The abstractions should map easily to how the user expects the
  tool to work.} For example, I \emph{expect} the trigger on a drill to
  start the drill turning.
\item
  \textbf{The abstractions should leverage existing idioms and
  knowledge.} In a new car, I \emph{expect} to know what the symbols on
  the dashboard mean, because I've driven other cars.
\item
  \textbf{The abstractions provide me with only the functions I need.}
  Because everything else is confusing and gets in the way.
\end{itemize}

The way to win, then, is to allow a language to be extensible as-needed
with features written by third parties. By supplying mechanisms for
extension a language can provide insurances against the Boundary Risk of
adopting it.

\hypertarget{types-of-software-dependencies}{%
\section{Types Of Software
Dependencies}\label{types-of-software-dependencies}}

There are lots of ways you can depend on software. Here though, we're
going to focus on just three main types: 1. \textbf{Code Your Own}:
write some code ourselves to meet the dependency. 2. \textbf{Software
Libraries}: importing code from the Internet, and using it in our
project. Often, libraries are Open Source (this is what we'll consider
here). 3. \textbf{Software as a Service}: calling a service on the
Internet, (probably via \texttt{http}) This is often known as
\href{https://en.wikipedia.org/wiki/Software_as_a_service}{SaaS, or
Software as a Service}.

All 3 approaches involve a different risk-profile. Let's look at each in
turn, from the perspective of which risks get mitigated, and which risks
are accentuated.

\hypertarget{code-your-own}{%
\subsection{1. Code Your Own}\label{code-your-own}}

Initially, writing our own code was the only game in town: when I
started programming, you had a user guide, BASIC and that was pretty
much it. Tool support was very thin-on-the-ground. Programs and
libraries could be distributed as code snippets \emph{in magazines}
which could be transcribed and run, and added to your program. This
spirit lives on somewhat in StackOverflow and JSFiddle, where you are
expected to ``adopt'' others' code into your own project.

One of the hidden risks of embarking on a code-your-own approach is that
the features you need are \emph{not} apparent from the outset. What
might appear to be a trivial implementation of some piece of
functionality can often turn into it's own industry as more and more
hidden Feature Risk is uncovered.

For example, as we discussed in our earlier treatment of Dead-End Risk,
building log-in screens \emph{seemed like a good idea}. However, this
gets out-of-hand fast when you need: - A password reset screen - To
email the reset links to the user - An email verification screen - A
lost account screen - Reminders to complete the sign up process -
\ldots{} and so on.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-code-your-own.png}
\caption{Code-Your-Own mitigates immediate feature risk, but at the
expense of schedule risk, complexity risk and communication risk. There
is also a hidden risk of features you don't yet know you need.}
\end{figure}

\hypertarget{unwritten-software}{%
\subsection{Unwritten Software}\label{unwritten-software}}

Sometimes, you will pick up a dependency on \emph{unwritten software}.
This commonly happens when work is divided amongst team members, or
teams.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-unwritten-1.png}
\caption{Sometimes, a module you're writing will depend on unwritten
code}
\end{figure}

If a component \textbf{A} of our project \emph{depends} on \textbf{B}
for some kind of processing, you might not be able to complete
\textbf{A} before writing \textbf{B}. This makes \emph{scheduling} the
project harder, and if component \textbf{A} is a risky part of the
project, then the chances are you'll want to mitigate risk there first.

But it also hugely increases Communication Risk because now you're being
asked to communicate with a dependency that doesn't really exist yet,
\emph{let alone} have any documentation.

There are a couple of ways to do this:

\begin{itemize}
\tightlist
\item
  \textbf{Standards}: If component \textbf{B} is a database, a queue,
  mail gateway or something else with a standard interface, then you're
  in luck. Write \textbf{A} to those standards, and find a cheap, simple
  implementation to test with. This gives you time to sort out exactly
  what implementation of \textbf{B} you're going for. This is not a
  great long-term solution, because obviously, you're not using the
  \emph{real} dependency- you might get surprised when the behaviour of
  the real component is subtly different. But it can reduce Schedule
  Risk in the short-term.
\item
  \textbf{Coding To Interfaces}: If standards aren't an option, but the
  surface area of \textbf{B} that \textbf{A} uses is quite small and
  obvious, you can write a small interface for it, and work behind that,
  using a \href{https://en.wikipedia.org/wiki/Mock_object}{Mock} for
  \textbf{B} while you're waiting for finished component. Write the
  interface to cover only what \textbf{A} \emph{needs}, rather than
  everything that \textbf{B} \emph{does} in order to minimize the risk
  of \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{Leaky
  Abstractions}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-unwritten-2.png}
\caption{Coding to a standard on an interface breaks the dependency on
unwritten software}
\end{figure}

\hypertarget{conways-law}{%
\subsection{Conway's Law}\label{conways-law}}

If the dependency is being written by another person, another team or in
another country, communication risks pile up. When this happens, you
will want to minimize \emph{as much as possible} the interface
complexity, since the more complex the interface, the worse the
Communication Risk will be. The tendency then is to make the interfaces
between teams or people \emph{as simple as possible}, modularizing along
these organisational boundaries.

In essence, this is
\href{https://en.wikipedia.org/wiki/Conway\%27s_law}{Conway's Law}:

\begin{quotation}

organizations which design systems \ldots{} are constrained to produce
designs which are copies of the communication structures of these
organizations.

\end{quotation}

\hypertarget{software-libraries}{%
\subsection{2. Software Libraries}\label{software-libraries}}

By choosing a particular software library, we are making a move on the
Risk Landscape. But, in return we expect to pick up: - Communication
Risk: because we now have to learn how to communicate with this new
dependency. - Boundary Risk - because now are limited to using the
functionality provided by this dependency. We have chosen it over
alternatives and changing to something else would be more work and
therefore costly.

But, it's quite possible that we could wind up in a worse place than we
started out, by using a library that's out-of-date, riddled with bugs or
badly supported. i.e.~Full of new, hidden Feature Risk.

It's \emph{really easy} to make bad decisions about which tools to use
because the tools don't (generally) advertise their deficiencies. After
all, they don't generally know how \emph{you} will want to use them.

\hypertarget{software-libraries---hidden-risks}{%
\subsection{Software Libraries - Hidden
Risks}\label{software-libraries---hidden-risks}}

Currently, choosing software dependencies looks like a ``bounded
rationality''-type process:

\begin{quotation}

``Bounded rationality is the idea that when individuals make decisions,
their rationality is limited by the tractability of the decision
problem, the cognitive limitations of their minds, and the time
available to make the decision.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Bounded_rationality}{\textemdash  Bounded Rationality, \emph{Wikipedia}}}
\end{quotation}

Unfortunately, we know that most decisions \emph{don't} really get made
this way. We have things like
\href{https://en.wikipedia.org/wiki/Confirmation_bias}{Confirmation
Bias} (looking for evidence to support a decision you've already made)
and \href{https://en.wikipedia.org/wiki/Cognitive_inertia}{Cognitive
Inertia} (ignoring evidence that would require you to change your mind)
to contend with.

But, leaving that aside, let's try to build a model of what this
decision making process \emph{should} involve. Luckily, other authors
have already considered the problem of choosing good software libraries,
so let's start there.

In the table below, I am summarizing three different sources (linked at
the end of the chapter), which give descriptions of which factors to
look for when choosing open-source libraries.

\begin{figure}
\centering
\Oldincludegraphics[width=1\maxwidth]{images/generated/software_dependency_table_1_large-400dpi.png}
\caption{Software Dependencies}
\end{figure}

Some take-aways:

\begin{itemize}
\tightlist
\item
  Feature Risk is a big concern. How can you be sure that the project
  will do what you want it to do ahead of schedule? Will it contain bugs
  or missing features? By looking at factors like \emph{release
  frequency} and \emph{size of the community} you get a good feel for
  this which is difficult to fake.
\item
  Boundary Risk is also very important. You are going to have to
  \emph{live} with your choices for the duration of the project, so it's
  worth spending the effort to either ensure that you're not going to
  regret the decision, or that you can change direction later.
\item
  Third is Communication Risk is also a good reason to pick \emph{tools
  you are already familiar with}.
\end{itemize}

\hypertarget{complexity-risk-2}{%
\subsection{Complexity Risk?}\label{complexity-risk-2}}

One thing that none of the sources consider (at least from the outset)
is the Complexity Risk of using a solution: - Does it drag in lots of
extra dependencies that seem unnecessary for the job in hand? If so, you
could end up in
\href{https://en.wikipedia.org/wiki/Dependency_hell}{Dependency Hell},
with multiple, conflicting versions of libraries in the project. - Do
you already have a dependency providing this functionality? So many
times, I've worked on projects that import a \emph{new} dependency when
some existing (perhaps transitive) dependency has \emph{already brought
in the functionality}. For example, there are plenty of libraries for
\href{https://en.wikipedia.org/wiki/JSON}{JSON} marshalling, but if I'm
also using a web framework the chances are it already has a dependency
on one already. - Does it contain lots of functionality that isn't
relevant to the task you want it to accomplish? e.g.~Using Java when a
shell script would do (on a non-Java project)

To give an extreme example of this, I once worked on an application
which used \href{https://en.wikipedia.org/wiki/Hazelcast}{Hazlecast} to
cache log-in session tokens for a 3rd party datasource. But, the app is
only used once every month, and session IDs can be obtained in
milliseconds. So\ldots{} why cache them? Although Hazlecast is an
excellent choice for in-memory caching across multiple JVMs, it is a
complex piece of software (after all, it does lots of stuff). By doing
this, you have introduced extra dependency risk, cache invalidation
risks, networking risks, synchronisation risks and so on, for actually
no benefit at all\ldots{} Unless, it's about
\href{Agency-Risk\#CV-building}{CV Building}.

Sometimes, the amount of complexity \emph{goes up} when you use a
dependency for \emph{good reason}. For example, in Java, you can use
\href{https://en.wikipedia.org/wiki/Java_Database_Connectivity}{Java
Database Connectivity (JDBC)} to interface with various types of
database. \href{https://en.wikipedia.org/wiki/Spring_Framework}{Spring
Framework} (a popular Java library) provides a thing called a
\texttt{JDBCTemplate}. This actually makes your code \emph{more}
complex, and can prove very difficult to debug. However, it prevents
some security issues, handles resource disposal and makes database
access more efficient. None of those are essential to interfacing with
the database, but not using them is
\href{Complexity-Risk\#technical-debt}{Technical Debt} that can bite you
later on.

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-library.png}
\caption{Software Libraries Risk Tradeoff}
\end{figure}

\hypertarget{software-as-a-service}{%
\subsection{3. Software as a Service}\label{software-as-a-service}}

Businesses opt for Software as a Service (SaaS) because: - It vastly
reduces the Complexity Risk they face in their organisations.
e.g.~managing the software or making changes to it. - Payment is usually
based on \emph{usage}, mitigating Schedule Risk. e.g.~Instead of having
to pay for in-house software administrators, they can leave this
function to the experts. - Potentially, you outsource the Operational
Risk to a third party. e.g.~ensuring availability, making sure data is
secure and so on.

SaaS is now a very convenient way to provide \emph{commercial} software.
Popular examples of SaaS might be
\href{https://en.wikipedia.org/wiki/Salesforce.com}{SalesForce}, or
\href{https://en.wikipedia.org/wiki/Gmail}{GMail}. Both of which follow
the commonly-used
\href{https://en.wikipedia.org/wiki/Freemium}{Freemium} model, where the
basic service is provided free, but upgrading to a paid account gives
extra benefits.

By providing the software on their own servers, the commercial
organisation has a defence against \emph{piracy}, as well as being able
to control the Complexity Risk.

Let's again recap the risks raised in some of the available literature:

\begin{figure}
\centering
\Oldincludegraphics[width=1\maxwidth]{images/generated/software_dependency_table_2_large-400dpi.png}
\caption{Software As A Service Dependencies}
\end{figure}

Some take-aways:

\begin{itemize}
\tightlist
\item
  Clearly, Operational Risk is now a big concern. By depending on a
  third-party organisation you are tying yourself to its success or
  failure in a much bigger way than just by using a piece of open-source
  software. What happens to data security, both in the data centre and
  over the internet?
\item
  With Feature Risk you now have to condend with the fact that the
  software will be upgraded \emph{outside your control}, and you may
  have limited control over which features get added or changed.
\item
  Boundary Risk.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-saas.png}
\caption{Risk Tradeoff From Using \_Software as a Service (SaaS)}
\end{figure}

\hypertarget{a-matrix-of-options}{%
\section{A Matrix of Options}\label{a-matrix-of-options}}

We've looked at just 3 different ways of providing a software
dependency: SaaS, Libraries and code-your-own.

But these are not the only ways to do it, and there's clearly no one
\emph{right} way. Although here we have looked just at ``Commercial
Saas'' and ``Free Open Source'', in reality, these are just points in a
two-dimensional space involving \emph{Pricing} and \emph{Hosting}.

Let's expand this view slightly and look at where different pieces of
software sit on these axes:

\begin{sidewaysfigure}
\centering
\includegraphics{images/generated/software_dependency_table_3_sideways-400dpi.png}
\caption{Software Dependencies, Pricing, Delivery Matrix Risk Profiles}
\end{sidewaysfigure}

\begin{itemize}
\tightlist
\item
  Where there is value in the
  \href{https://en.wikipedia.org/wiki/Network_effect}{Network Effect},
  it's often a sign that the software will be free, or open source:
  programming languages and Linux are the obvious examples of this. Bugs
  are easier to find when there are lots of eyes looking, and learning
  the skill to use the software has less \href{Boundary-Risk}{Boundary
  Risk} if you know you'll be able to use it at any point in the future.
\item
  At the other end of the spectrum, clients will happily pay for
  software if it clearly \textbf{reduces complexity}. Take
  \href{https://en.wikipedia.org/wiki/Amazon_Web_Services}{Amazon Web
  Services (AWS)}. The essential trade here is that you substitute the
  complexity of hosting and maintaining various pieces of software, in
  exchange for monthly payments
  (\href{Schedule-Risk\#Funding-Risk}{Funding Risk} for you). Since the
  AWS \emph{interfaces} are specific to Amazon, there is significant
  \href{Boundary-Risk}{Boundary Risk} in choosing this option.
\item
  In the middle there are lots of \textbf{substitute options} and
  therefore high competition. Because of this, prices are pushed towards
  zero, and and therefore often advertising is used to monetarize the
  product. \href{https://en.wikipedia.org/wiki/Angry_Birds}{Angry Birds}
  is a classic example: initially, it had demo and paid versions,
  however
  \href{https://en.wikipedia.org/wiki/Rovio_Entertainment}{Rovio}
  discovered there was much more money to be made through advertising
  than from the
  \href{https://www.deconstructoroffun.com/blog/2017/6/11/how-angry-birds-2-multiplied-quadrupled-revenue-in-a-year}{paid-for
  app}.
\end{itemize}

\hypertarget{managing-risks}{%
\subsection{Managing Risks}\label{managing-risks}}

So far, we've considered only how the different approaches to Software
Dependencies or other.

But with Software Dependencies we can construct dependency networks to
give us all kinds of features and mitigate all kinds of risk. That is,
\emph{the features we are looking for are to mitigate some kind of
risk}.

For example, I might start using
\href{https://en.wikipedia.org/wiki/WhatsApp}{WhatsApp} for example,
because I want to be able to send my friends photos and text messages.
However, it's likely that those same features are going to allow us to
mitigate \href{Communication-Risk}{Communication Risk} and
\href{Coordination-Risk}{Coordination Risk} when we're next trying to
meet up.

Let's look at some:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.40\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.55\columnwidth}\raggedright
Examples of Software Mitigating That Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Calendar tools, Bug Tracking, Distributed Databases\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Map-And-Territory-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
The Internet, generally. Excel, Google, ``Big Data'', Reporting
tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Schedule-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Planning Software, Project Mangement Software\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Communication-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Email, Chat tools, CRM tools like SalesForce, Forums, Twitter,
Protocols\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Process-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Reporting tools, online forms, process tracking tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Agency-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Auditing tools, transaction logs, Timesheet software, HR Software\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Operational-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Support tools like ZenDesk, Grafana, InfluxDB, Geneos\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Feature-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Every piece of software you use!\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{back-to-ergonomics}{%
\section{Back To Ergonomics}\label{back-to-ergonomics}}

What's clear from this analysis is that software dependencies don't
\emph{conquer} any risk - the moves they make on the Risk Landscape are
\emph{subtle}. Whether or not you end up in a more favourable position
risk-wise is going to depend heavily on the quality of the execution and
the skill of the implementor.

In particular, \emph{choosing} dependencies can be extremely difficult.
As we discussed above, the usefulness of any tool depends on its fit for
purpose, it's \emph{ergonomics within a given context}. It's all too
easy to pick a good tool for the wrong job:

\begin{quotation}

``I suppose it is tempting, if the only tool you have is a hammer, to
treat everything as if it were a nail.''

\sourceatright{\href{https://en.wiktionary.org/wiki/if_all_you_have_is_a_hammer,_everything_looks_like_a_nail}{\textemdash  Abraham Maslow, \emph{Toward a Psychology of Being}} <!-- tweet-end -->}
\end{quotation}

With software dependencies, we often have to live with the decisions we
make for a long time. In my experience, given the Boundary Risks
associated with getting this wrong, not enough time is spent really
thinking about this in advance.

Let's take a closer look at this problem in the next chapter, Boundary
Risk.

\begin{longtable}[]{@{}l@{}}
\toprule
Sources\tabularnewline
\midrule
\endhead
\href{https://www.software.ac.uk/resources/guides/defending-your-code-against-dependency-problems}{sd1
- Defending your code against dependency problems}\tabularnewline
\href{https://stackoverflow.com/questions/2960371/how-to-choose-an-open-source-library}{sd2
- How to choose an open source library}\tabularnewline
\href{https://www.forbes.com/sites/forbestechcouncil/2017/07/20/open-source-to-use-or-not-to-use-and-how-to-choose/2/\#39e67e445a8c}{sd3
- Open Source - To use or not to use}\tabularnewline
\href{https://www.zdnet.com/article/saas-checklist-nine-factors-to-consider-when-selecting-a-vendor/}{sd4
- Saas Checklist - Nine Factors to Consider}\tabularnewline
\href{http://sandhill.com/article/how-to-evaluate-saas-vendors-five-key-considerations/}{sd5
- How to Evaluate Saas Vendors}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{process-risk}{%
\chapter{Process Risk}\label{process-risk}}

Process Risk, as we will see, is the risk you take on whenever you
embark on completing a \emph{process}.

\begin{quotation}

``\textbf{Process:} A process is a set of activities that interact to
achieve a result.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Process}{\textemdash  Process, \emph{Wikipedia}}}
\end{quotation}

In the software development world (and the business world generally)
processes commonly involve \emph{forms}: If you're filling out a form
(whether on paper or on a computer) then you're involved in a process of
some sort, whether an ``Account Registration'' process, ``Loan
Application'' process or ``Consumer Satisfaction Survey'' process. But
sometimes, they involve events occuring: a
\href{https://en.wikipedia.org/wiki/Software_build}{build process} might
start after you commit some code, for example.

\hypertarget{the-purpose-of-process}{%
\section{The Purpose Of Process}\label{the-purpose-of-process}}

Process exists to mitigate other kinds of risk, and for this reason,
we'll be looking at them again in Part 3: Practices, where we'll look at
how you can design processes to mitigate risks on your own project.

Until we get there, let's look at some examples of how process can
mitigate other risks:

\begin{itemize}
\tightlist
\item
  \href{Coordination-Risk}{Coordination Risk}: You can often use process
  to help people coordinate. For example, a
  \href{https://en.wikipedia.org/wiki/Production_line}{Production Line}
  is a process where work being done by one person is pushed to the next
  person when it's done. A meeting booking process ensures that people
  will all attend a meeting together at the same place and time, and
  that a room is available for it.
\item
  Dependency Risk onto the person asking for the loan, by making it part
  of the process and not accepting the application until this has been
  provided.
\item
  Complexity Risk. mcdonalds. tbd
\item
  Operational Risk itself.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-introduction.png}
\caption{Introducing process can mitigate many risks for a team, but
there are attendant process risks created.}
\end{figure}

These are all examples of Risk Mitigation. Let's see how this comes
about.

\hypertarget{evolution-of-business-process}{%
\section{Evolution Of Business
Process}\label{evolution-of-business-process}}

Before we get to examining what constitues \href{Process-Risk}{Process
Risks}, let's consider how processes \emph{form}. Specifically, we're
going to look at
\href{https://en.wikipedia.org/wiki/Business_process}{Business Process}:

\begin{quotation}

``\textbf{Business Process} or \textbf{Business Method} is a collection
of related, structured activities or tasks that in a specific sequence
produces a service or product (serves a particular business goal) for a
particular customer or customers.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Business_process}{\textemdash  Business Process, \emph{Wikipedia}}}
\end{quotation}

Business Processes often arise in response to an unmet need within an
organisation. And, as we said above, they are usually there to mitigate
other risks. Let's look at an example lifecycle of how that can happen.

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-0.png}
\caption{Step 0: Clients \texttt{C} need \texttt{A} to do their jobs}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  Let's say, there exists a group of people inside a company \texttt{C},
  which need a certain something \texttt{A} in order to get their jobs
  done. It might be a producing a resource, or dealing with some source
  of complexity, or whatever.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-1.png}
\caption{Step 1: Person B doing A for company C}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Person \texttt{B} in a company starts producing \texttt{A} \emph{as a
  service to others}. This is really useful! It makes the the lives of
  clients in \texttt{C} much easier as they have an easier path to
  \texttt{A} than before. \texttt{B} gets busy keeping \texttt{C} happy.
  No one cares. But then, \texttt{B} goes on holiday. \texttt{A} doesn't
  get done, and people now care: the Dependency Risk is suddenly
  apparent.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-2.png}
\caption{Step 2: Team T is created to do A for Company C}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Either, \texttt{B} co-opts other people to help, gets given a team
  (\texttt{T}), or someone else forms a team \texttt{T} containing
  \texttt{B} to get the job done ``properly''.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{T} is responsible for doing \texttt{A}, but it needs to supply
  the company with \texttt{A} reliably and responsibly, otherwise there
  will be trouble, so they try and please all of their clients as far as
  possible.
\item
  This is a good deal for their clients within \texttt{C}, but because
  there is a lot of variation in what the clients ask for, \texttt{T}
  end up absorbing a lot of Complexity Risk and are overworked.
\item
  This is attendant Schedule Risk impacts their ability to reliably
  deliver \texttt{A}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-3.png}
\caption{Team T protects itself from complexity with a process, P}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{T} organises bureaucratically, so that there is a controlled
  process (\texttt{P}) by which \texttt{A} can be accessed. Like a cell,
  they have arranged a protective barrier around themselves, the
  strength of which depends on the power conferred to them by control of
  \texttt{A}.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{P} probably involves filling in a form (or following some
  other Protocol.
\item
  \texttt{T} can now deal with requests on a first-come-first-served
  basis and deal with them all in the same way: Complexity Risks are now
  the problem of the form-filler in \texttt{C}.
\item
  \texttt{T} has mitigated Schedule Risk they are willing to take on.
\item
  \texttt{C} now has Process Risk: will their requirements for
  \texttt{A} be met by \texttt{T}? They have to submit to the process to
  find out\ldots{}
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-4.png}
\caption{Team T protects itself from Coordination issues with signoffs
or other barriers}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  But it's hard to make sure the right clients get access to \texttt{A}
  at the right times, and it's necessary to synchronize access across
  company \texttt{C}. (A Coordination Risk
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{T} reacts and sets up sign-off, authorization or monetary
  barriers around \texttt{A}, moving the Coordination Risk issue out of
  their team.
\item
  But, for \texttt{C}, this \emph{again} increases the Process Risk
  involved in using \texttt{A}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-5.png}
\caption{Team T increases bureaucratic load, and pushes Process Risk
onto C}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  But, there are abuses of \texttt{A}: people either misuse it, or use
  it too much. (These are Operational Risks.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \texttt{T} reacts by \emph{increasing} the amount of \emph{process} to
  use \texttt{A}, mitigating Operational Risk within their team,
  but\ldots{}
\item
  This corresponds to greater Process Risk for clients in company
  \texttt{C}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/process-risk-6.png}
\caption{Person D acts as a middleman for customers needing some variant
of \texttt{A}}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Person \texttt{D}, who has experience working with team \texttt{T}
  acts as a middleman for customers requiring some variant of \texttt{A}
  for a subset of \texttt{C}. They are able to help navigate the
  bureaucratic process (handle with Process Risk. The cycle potentially
  starts again: will \texttt{D} end up becoming a new team, with a new
  process?
\end{enumerate}

In this example, you can see how the organisation evolves to mitigate
risk around the use (and misuse) of \texttt{A}: First, Complexity Risk
was created to mitigate everything else. This is an example of
\emph{Process following Strategy}:

\begin{quote}
In this conception, you can see how the structure of an organisation
(the teams and processes within it, the heirarchy of control) will
`evolve' from the resources of the organisation and the strategy it
pursues. Processes evolve to meet the needs of the organisation." -
\href{http://www.mintzberg.org/books/strategy-safari}{Minzberg,
\emph{Strategy Safari}}
\end{quote}

\hypertarget{an-example---release-process}{%
\section{An Example - Release
Process}\label{an-example---release-process}}

For many years I have worked in the Finance Industry, and it's given me
time to observe how, across an entire industry, process can evolve, both
in response to regulatory pressure but also because of organisational
maturity, and mitigating risks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initially, I could release software by logging onto the production
  accounts with a password that everyone knew, and deploy software or
  change data in the database.
\item
  The first issue with this is bad actors: How could you know that the
  numbers weren't being altered in the databases? Production auditing
  came in so that at least you could tell \emph{who was changing what},
  in order to point the blame later.
\item
  But, there was still plenty of scope for deliberate or accidental
  damage. I personally managed to wipe production data on one occasion
  by mistaking it for a development environment. Eventually, passwords
  were taken out of the hands of developers and you needed approval to
  ``break glass'' to get onto production.
\item
  Change Requests were introduced. This is another approval process
  which asks you to describe what you want to change in production, and
  why you want to change it. In most places, this was quite an onerous
  process, so the unintended consequence was that release cadence was
  reduced.
\item
  The change request software is generally awful, making the job of
  raising change requests tedious and time-consuming. Therefore,
  developers would \emph{automate} the processes for release, sometimes
  including the process to write the change request. This allowed them
  to improve release cadence, at the expense of owning more code.
\item
  Auditors didn't like the fact that this automation existed, because
  effectively, that meant that developers could get access to production
  with the press of a button, effectively taking you back to step 1. So
  auditing of Change Requests had to happen.
\end{enumerate}

\ldots{} and so on.

\hypertarget{process-risks}{%
\section{Process Risks}\label{process-risks}}

\begin{figure}
\centering
\includegraphics{images/generated/process-risk-400dpi.png}
\caption{Process Risk}
\end{figure}

\textbf{Process Risk}, then, is a type of Dependency Risk manifests
itself in fairly predictable ways:

\begin{itemize}
\tightlist
\item
  Reliability Risk the process is covering.
\item
  Invisibility Risk for visibility: it's often not possible to see how
  far along a process is to completion. Sometimes, you can do this to an
  extent. For example, when I send a package for delivery, I can see
  roughly how far it's got on the tracking website. But, this is still
  less-than-complete information, and is a representation of reality.
\item
  Fit Risk: You have to be careful to match the process to the outcome
  you want. Sometimes, it's easy to waste time on the wrong process.
\item
  Dead-End Risk: Even if you have the right process, initiating a
  process has no guarantee that your efforts won't be wasted and you'll
  be back where you started from. The chances of this happening increase
  as you get further from the standard use-case for the process, and the
  sunk cost increases with the length of time the process takes to
  report back.
\item
  Agency Risk: Due to Parkinson's Law, see below.
\item
  Operational Risk, which we'll address further in it's own chapter.
\item
  Credit Risk: Where you pay for something to be done, but then end up
  without the outcome you want. Let's look at that in more detail.
\end{itemize}

\hypertarget{processes-and-invisibility-risk}{%
\subsection{Processes And Invisibility
Risk}\label{processes-and-invisibility-risk}}

Processes tend to work well for the common cases, because \emph{practice
makes perfect}. but they are really tested when unusual situations
occur. Expanding processes to deal with edge-cases incurs Complexity
Risk, so often it's better to try and have clear boundaries of what is
``in'' and ``out'' of the process' domain.

Sometimes, processes are \emph{not} used commonly. How can we rely on
them anyway? Usually, the answer is to build in extra feedback loops
anyway:

\begin{itemize}
\tightlist
\item
  Testing that backups work, even when no backup is needed.
\item
  Running through a disaster recovery scenario at the weekend.
\item
  Increasing the release cadence, so that we practice the release
  process more.
\end{itemize}

The feedback loops allow us to perform Retrospectives and Reviews to
improve our processes.

\hypertarget{bureaucracy-risk}{%
\subsection{Bureaucracy Risk}\label{bureaucracy-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/bureaucracy-risk-400dpi.png}
\caption{Bureaucracy Risk}
\end{figure}

Where we've talked about process evolution above, the actors involved
have been acting in good faith: they are working to mitigate risk in the
organisation. The Process Risk.

But \href{https://en.wikipedia.org/wiki/Parkinson\%27s_law}{Parkinson's
Law} takes this one step further: the human actors shaping the
organisation will abuse their positions of power in order to further
their own careers (this is \href{Agency-Risk}{Agency Risk}, which we
will come to in a future chapter):

\begin{quotation}

``Parkinson's law is the adage that''work expands so as to fill the time
available for its completion``. It is sometimes applied to the growth of
bureaucracy in an organization\ldots{} He explains this growth by two
forces: (1) `An official wants to multiply subordinates, not rivals' and
(2) `Officials make work for each other.'\,''

\sourceatright{\href{https://en.wikipedia.org/wiki/Parkinson%27s_law}{\textemdash  Parkinson's Law, \emph{Wikipedia}}  }
\end{quotation}

This implies that there is a tendency for organisations to end up with
\emph{needless levels of Bureaucratic Risk}.

\hypertarget{credit-risk}{%
\subsection{Credit Risk}\label{credit-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/credit-risk-400dpi.png}
\caption{Credit Risk}
\end{figure}

Where the process you depend on is being run by a third-party
organisation, (or that party depends on you) you are looking at Credit
Risk:

\begin{quotation}

``A credit risk is the risk of default on a debt that may arise from a
borrower failing to make required payments\ldots{} For example\ldots{} A
business or consumer does not pay a trade invoice when due {[}or{]} A
business does not pay an employee's earned wages when due''

\sourceatright{\href{https://en.wikipedia.org/wiki/Credit_risk}{\textemdash  Credit Risk, \emph{Wikipedia}}}
\end{quotation}

Money is \emph{changing hands} between you and the supplier of the
process, and often, the money doesn't transfer \emph{at the same time}
as the process is performed. Let's look at an example: Instead of
hosting my website on a server in my office, I could choose to host my
software project with an online provider. I am trading Complexity Risk,
because now, I have to care that the supplier is solvent.

There's a couple of ways this could go wrong: They may \emph{take my
payment}, but then turn off my account. Or, they could go bankrupt, and
leave me with the costs of moving to another provider (this is also
Dead-End Risk.

Mechanisms like
\href{https://en.wikipedia.org/wiki/Insurance_policy}{insurance},
\href{https://en.wikipedia.org/wiki/Contract}{contracts} and
\href{https://en.wikipedia.org/wiki/Guarantee}{guarantees} help mitigate
this risk at the cost of complexity and expense.

\hypertarget{sign-offs}{%
\subsection{Sign-Offs}\label{sign-offs}}

Often, Processes will include sign-off steps. The Sign-Off is an
interesting mechanism: - By signing off on something for the business,
people are usually in some part staking their reputation on something
being right. - Therefore, you would expect that sign-off involves a lot
of Agency Risk: people don't want to expose themselves in
career-limiting ways. - Therefore, the bigger the risk they are being
asked to swallow, the more cumbersome and protracted the sign off
process.

Often, Sign Offs of all the effort gone into getting the sign off if
they don't.

This is a nasty situation, but there are a couple of ways to de-risk
this: - break Sign Offs down into bite-size chunks of risk that are
acceptable to those doing the sign-off. - Agree far-in-advance the
sign-off criteria. As discussed in Risk Theory, people have a habit of
heavily discounting future risk, and it's much easier to get agreement
on the \emph{criteria} than it is to get the sign-off.

\hypertarget{software-processes}{%
\subsection{Software Processes}\label{software-processes}}

tbd

tbd. processes as a response to legal environment.

\hypertarget{boundary-risk}{%
\chapter{Boundary Risk}\label{boundary-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/boundary-risk-400dpi.png}
\caption{Boundary Risk}
\end{figure}

In the previous few chapters on Dependency Risk several times, but now
it's time to tackle it head-on and discuss this important type of risk.

In terms of the Risk Landscape, and introduces a maze-like component to
it. It also means that we have to make \emph{decisions} about which way
to go, knowing that our future paths are constrained by the decisions we
make.

\begin{figure}
\centering
\includegraphics{images/generated/dead-end-risk-400dpi.png}
\caption{Dead-End Risk}
\end{figure}

And, as we discussed in Complexity Risk, and we've done work that we
need to throw away. In this case, we'll have to head back and make a
different decision.

\hypertarget{emergence-through-choice}{%
\section{Emergence Through Choice}\label{emergence-through-choice}}

Boundary Risk. Because of that, it's going to take a bit of time to pick
it apart and understand it, so we're going to build up to this in
stages.

Let's start with an obvious example: Musical Instruments. Let's say you
want to learn to play some music. There are a \emph{multitude} of
options available to you, and you might choose an \emph{uncommon}
instrument like a
\href{https://en.wikipedia.org/wiki/Balalaika}{Balalaika} or a
\href{https://en.wikipedia.org/wiki/Theremin}{Theremin}, or you might
choose a \emph{common} one like a piano or guitar. In any case, once you
start learning this instrument, you have picked up the three risks
above:

\begin{itemize}
\tightlist
\item
  Dependency Risk on it in order to play music, so get to the music shop
  and buy one.
\item
  Communication Risk in order to be able to do that.
\item
  Complexity Risk, with all the attendant complexity of looking after
  that instrument, tuning it, and so on.
\end{itemize}

Those risks are true for \emph{any} instrument you choose. However, if
you choose the \emph{uncommon} instrument like the
\href{https://en.wikipedia.org/wiki/Balalaika}{Balalaika}, you have
\emph{worse} \href{Boundary-Risk}{Boundary Risk}, because the
\emph{ecosystem} for the balalaika is smaller. It might be hard to find
a tutor, or a band needing a balalaika. You're unlikely to find one in a
friend's house (compared to the piano, say).

Even choosing the Piano has Boundary Risk and changing to a different
path is \emph{expensive}.

Also, it stands to reason that making \emph{any} choice is better than
making \emph{no} choice, because you can't try and learn \emph{all} the
instruments. Doing that, you'd make no meaningful progress on any of
them.

\hypertarget{boundary-risk-for-software-dependencies}{%
\section{Boundary Risk For Software
Dependencies}\label{boundary-risk-for-software-dependencies}}

Let's look at a software example now.

As discussed in Software Dependency Risk of that interface. If you want
to work with it, you have to use it's protocol, it won't come to you.

Let's take a look at a hypothetical system structure, in the
accompanying diagram. In this design, we have are transforming data from
the \texttt{input} to the \texttt{output}. But how should we do it?

\begin{itemize}
\tightlist
\item
  We could go via \texttt{a}, using the Protocols of \texttt{a}, and
  having a dependency on \texttt{a}.
\item
  We could go via \texttt{b}, using the Protocols of \texttt{b}, and
  having a dependency on \texttt{b}.
\item
  We could choose the middle route, and avoid the dependency, but
  potentially pick up lots more Complexity Risk.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/boundary-risk-ps.png}
\caption{Our System receives data from the \texttt{input}, translates it
and sends it to the \texttt{output}. But which dependency should we use
for the translation, if any?}
\end{figure}

This is a basic \textbf{Translation} job from \texttt{input} to
\texttt{output}. Since we are talking about \textbf{Translation}, we are
clearly talking about Communication Risk again: our task in
\textbf{Integrating} all of these components is \emph{to get them to
talk to each other}.

From a Cyclomatic Complexity, because we don't know that we'll be able
to make them \emph{talk to each other} properly:

\begin{itemize}
\tightlist
\item
  Maybe \texttt{a} outputs dates in a strange calendar format that we
  won't understand.
\item
  Maybe \texttt{b} works on some streaming API basis, that is
  incompatible with the input protocol.
\item
  Maybe \texttt{a} runs on Windows, whereas our code runs on Linux.
\end{itemize}

\ldots{} and so on.

\hypertarget{boundary-risk-pinned-down}{%
\section{Boundary Risk Pinned Down}\label{boundary-risk-pinned-down}}

Wherever we integrate dependencies with complex Protocols. It is:

\begin{itemize}
\tightlist
\item
  The \emph{sunk cost} of the Learning Curve we've overcome to integrate
  the dependency, when it fails to live up to expectations.
\item
  The likelihood of, and costs of changing in the future.
\item
  The rarity of alternatives (or, conversely, the risk of Lock In.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/software-dependency-library.png}
\caption{The tradeoff for using a library}
\end{figure}

As we saw in Software Dependency Risk is a big factor in choosing
libraries and services. However, it can apply to any kind of dependency:

\begin{itemize}
\tightlist
\item
  If you're depending on a Process or Organisation, they might change
  their products or quality, making the effort you put into the
  relationship worthless.
\item
  If you're depending on Staff, they might leave, meaning your efforts
  on training them don't pay back as well as you hoped.
\item
  If you're depending on an Event occuring at a particular time, you
  might have a lot of work to reorganise your life if it changes time or
  place.
\end{itemize}

\hypertarget{avoiding-boundary-risk-now}{%
\section{Avoiding Boundary Risk
Now\ldots{}}\label{avoiding-boundary-risk-now}}

Because of Boundary Risk, we can avoid accreting it by choose the
\emph{simplest} and \emph{fewest} dependencies for any job. Let's look
at some examples:

\begin{itemize}
\tightlist
\item
  \texttt{mkdirp} is an \href{https://www.npmjs.com}{npm} module
  defining a single function. This function takes a single string
  parameter and recursively creating directories. Because the
  \href{Communication-Risk}{protocol} is so simple, there is almost no
  \href{Boundary-Risk}{Boundary Risk}.
\item
  Using a database with a
  \href{https://en.wikipedia.org/wiki/Java_Database_Connectivity}{JDBC}
  driver comes with \emph{some} \href{Boundary-Risk}{Boundary Risk}: but
  the boundary is specified by a standard. Although the standard doesn't
  cover every aspect of the behaviour of the database, it does minimize
  risk, because if you are familiar with one JDBC driver, you'll be
  familiar with them all, and swapping one for another is relatively
  easy.
\item
  Using a framework like \href{https://spring.io}{Spring},
  \href{https://redux.js.org}{Redux} or
  \href{https://angularjs.org}{Angular} comes with higher
  \href{Boundary-Risk}{Boundary Risk}: you are expected to yield to the
  framework's way of behaving throughout your application. You cannot
  separate the concern easily, and swapping out the framework for
  another is likely to leave you with a whole new set of assumptions and
  interfaces to deal with.
\end{itemize}

\hypertarget{and-in-the-future}{%
\section{\ldots{} And In The Future}\label{and-in-the-future}}

Unless your project \emph{ends}, you can never be completely sure that
Boundary Risk \emph{isn't} going to stop you making a move you want. For
example:

\begin{itemize}
\tightlist
\item
  \texttt{mkdirp} might not work on a new device's Operating System,
  forcing you to swap it out.
\item
  You might discover that the database you chose satisfied all the
  features you needed at the start of the project, but came up short
  when the requirements changed later on.
\item
  The front-end framework you chose might go out-of-fashion, and it
  might be hard to find developers interested in working on the project
  because of it.
\end{itemize}

This third point is perhaps the most interesting aspect of Boundary
Risk.

\hypertarget{plugins-ecosystems-and-evolution}{%
\section{Plugins, Ecosystems and
Evolution}\label{plugins-ecosystems-and-evolution}}

On the face of it,
\href{https://en.wikipedia.org/wiki/WordPress}{WordPress} and
\href{https://en.wikipedia.org/wiki/Drupal}{Drupal} \emph{should} be
very similar:

\begin{itemize}
\tightlist
\item
  They are both
  \href{https://en.wikipedia.org/wiki/Content_management_system}{Content
  Management Systems}
\item
  They both use a
  \href{https://en.wikipedia.org/wiki/LAMP_(software_bundle)}{LAMP
  (Linux, Apache, MySql, PHP) Stack}
\item
  They were both started around the same time (2001 for Drupal, 2003 for
  WordPress)
\item
  They are both Open-Source, and have a wide variety of
  \href{https://en.wikipedia.org/wiki/Plug-in_(computing)}{Plugins}.
  That is, ways for other programmers to extend the functionality in new
  directions.
\end{itemize}

In practice, they are very different. This could be put down to
different \emph{design goals}: it seems that WordPress was focused much
more on usability, and an easy learning curve, whereas Drupal supported
plugins for building things with complex data formats. It could also be
down to the \emph{design decisions}: although they both support Plugins,
they do it in very different ways.

(Side note: I wasn't short of go-to examples for this. I could have
picked on \href{https://en.wikipedia.org/wiki/TeamCity}{Team City} and
\href{https://en.wikipedia.org/wiki/Jenkins_(software)}{Jenkins} here
(\href{https://en.wikipedia.org/wiki/Continuous_integration}{Continuous
Integration} tools), or
\href{https://en.wikipedia.org/wiki/Apache_Maven}{Maven} and
\href{https://en.wikipedia.org/wiki/Gradle}{Gradle} (build tools). All
of these support
\href{https://en.wikipedia.org/wiki/Plug-in_(computing)}{plugins}, and
the \emph{choice} of plugins is dependent on which I've chosen, despite
the fact that the platforms are solving pretty much the same problems. )

\hypertarget{ecosystems-and-systems}{%
\subsection{Ecosystems and Systems}\label{ecosystems-and-systems}}

The quality, and choice of plugins for a given platform, along with
factors such as community and online documentation is often called its
\href{https://en.wikipedia.org/wiki/Software_ecosystem}{ecosystem}:

\begin{quotation}

``as a set of businesses functioning as a unit and interacting with a
shared market for software and services, together with relationships
among them''

\sourceatright{\href{https://en.wikipedia.org/wiki/Software_ecosystem}{\textemdash  Software Ecosystem, \emph{Wikipedia}}}
\end{quotation}

You can think of the ecosystem as being like the footprint of a town or
a city, consisting of the buildings, transport network and the people
that live there. Within the city, and because of the transport network
and the amenities available, it's easy to make rapid, useful moves on
the Risk Landscape in a common way.

tbd: talk about complexity within the boundary. (increased convenience?)

Ecosystem size is one key determinant of Boundary Risk are unlikely to
collide with it. The boundary \emph{got large} because other developers
before you hit the boundary and did the work building the software
equivalents of bridges and roads and pushing it back so that the
boundary didn't get in their way.

In a small ecosystem, you are much more likely to come into contact with
the edges of the boundary. \emph{You} will have to be the developer that
pushes back the frontier and builds the roads for the others. This is
hard work.

\hypertarget{evolution}{%
\subsection{Evolution}\label{evolution}}

In the real world, there is a tendency for \emph{big cities to get
bigger}. The more people that live there, the more services they
provide, and therefore, the more immigrants they attract. And, it's the
same in the software world. In both cases, this is due to the
\href{https://en.wikipedia.org/wiki/Network_effect}{Network Effect}:

\begin{quotation}

``A network effect (also called network externality or demand-side
economies of scale) is the positive effect described in economics and
business that an additional user of a good or service has on the value
of that product to others. When a network effect is present, the value
of a product or service increases according to the number of others
using it.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Network_effect}{\textemdash  Network Effect, \emph{Wikipedia}}}
\end{quotation}

You can see the same effect in the adoption rates of WordPress and
Drupal, shown in the chart below. Note: this is over \emph{all sites on
the internet}, so Drupal accounts for hundreds of thousands of sites. In
2018, WordPress is approximately 32\% of all websites. For Drupal it's
2\%.

\begin{figure}
\centering
\includegraphics{images/wordpress-drupal-chart.png}
\caption{Wordpress vs Drupal adoption over 8 years, according to
\href{https://w3techs.com/technologies/history_overview/content_management/all/y}{w3techs.com}}
\end{figure}

Did WordPress gain this march because it was better than Drupal? That's
arguable. That it's this way round could be \emph{entirely accidental},
and a result of Network Effect.

And maybe, they aren't comparable: Given the same problems, the people
in each ecosystem have approached them and solved them in different
ways. And, this has impacted the `shape' of the abstractions, and the
protocols you use in each. Complexity \emph{emerges}, and the ecosystem
gets more complex and opinionated, much like the way in which the
network of a city will evolve over time in an unpredictable way.

But, by now, if they \emph{are} to be compared side-by-side, WordPress
\emph{should be better} due to the sheer number of people in this
ecosystem who are\ldots{}

\begin{itemize}
\tightlist
\item
  Creating web sites.
\item
  Using those sites.
\item
  Submitting bug requests.
\item
  Fixing bugs.
\item
  Writing documentation.
\item
  Building plugins.
\item
  Creating features.
\item
  Improving the core platform.
\end{itemize}

But, there are two further factors to consider\ldots{}

\hypertarget{the-peter-principle}{%
\subsubsection{1. The Peter Principle}\label{the-peter-principle}}

When a tool or platform is popular, it is under pressure to increase in
complexity. This is because people are attracted to something useful,
and want to extend it to new purposes. This is known as \emph{The Peter
Principle}:

\begin{quotation}

``The Peter principle is a concept in management developed by Laurence
J. Peter, which observes that people in a hierarchy tend to rise to
their `level of incompetence'.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Peter_principle}{\textemdash  The Peter Principle, \emph{Wikipedia}}}
\end{quotation}

Although designed for \emph{people}, it can just as easily be applied to
any other dependency you can think of. Let's look at
\href{https://en.wikipedia.org/wiki/Java_(software_platform)}{Java} as
an example of this.

Java is a very popular platform. Let's look at how the number of public
classes (a good proxy for the boundary) has increased with each release:

\begin{figure}
\centering
\includegraphics{images/java_classes_by_version.png}
\caption{Java Public Classes By Version (3-9)}
\end{figure}

Why does this happen?

\begin{itemize}
\tightlist
\item
  More and more people are using Java for more and more things. It's
  popularity begets more popularity.
\item
  Human needs are \emph{fractal} in complexity.
\item
  There is \href{Feature-Risk\#feature-drift-risk}{Feature Drift Risk}:
  our requirements evolve with time.
  \href{https://en.wikipedia.org/wiki/Android_software_development}{Android
  Apps} weren't even a thing when Java 3 came out, for example, yet they
  are all written in Java now, and Java has had to keep up.
\end{itemize}

\hypertarget{backward-compatibility-1}{%
\subsubsection{2. Backward
Compatibility}\label{backward-compatibility-1}}

As we saw in Software Dependency Risk.

Each new version has a greater functional scope than the one before
(pushing back Boundary Risk as there is more functionality to deal with.

\hypertarget{focus-vs-overreach}{%
\subsection{Focus vs Overreach}\label{focus-vs-overreach}}

\begin{figure}
\centering
\includegraphics{images/kite9/boundary-risk-peter-principle.png}
\caption{The Peter Principle: Backward Compatibility + Extension leads
to complexity and learning curve risk}
\end{figure}

You can see in the diagram the Peter Principle at play: as more
responsibility is given to a dependency, the more complex it gets, and
the greater the learning curve to work with it. Large ecosystems like
Java react to Learning Curve Risk by having copious amounts of
literature to read or buy to help, but it is still off-putting.

Because Complexity is Mass. This means that when the world changes,
\emph{new} systems will come along to plug the gaps.

This implies a trade-off: - Sometimes it's better to accept the Boundary
Risk innate in a smaller system than try to work within the bigger, more
complex system.

example:

In the late 80's and 90's there was a massive push towards
\emph{building functionality in the database}. Relational Database
Managment Systems (RDBMSs) were all-in-one solutions, expensive
platforms that you purchased and built \emph{everything} inside.
However, this dream didn't last:

why? (need some research here).

This tbd

tbd. diagram here.

\hypertarget{beating-boundary-risk-with-standards}{%
\section{Beating Boundary Risk With
Standards}\label{beating-boundary-risk-with-standards}}

Sometimes, technology comes along that allows us to cross boundaries,
like a \emph{bridge} or a \emph{road}. This has the effect of making it
easy to to go from one self-contained ecosystem to another. Going back
to WordPress, a simple example might be the \href{}{Analytics Dashboard}
which provides
\href{https://en.wikipedia.org/wiki/Google_Marketing_Platform}{Google
Analytics} functionality inside WordPress.

I find, a lot of code I write is of this nature: trying to write the
\emph{glue code} to join together two different \emph{ecosystems}.

Standards allow us to achieve the same thing, in one of two ways:

\begin{itemize}
\tightlist
\item
  \textbf{Mode 1: Abstract over the ecosystems.} Provide a
  \emph{standard} protocol (a \emph{lingua franca}) which can be
  converted down into the protocol of any of a number of competing
  ecosystems.
\item
  \textbf{Mode 2: Force adoption.} All of the ecosystems start using the
  standard for fear of being left out in the cold. Sometimes, a
  standards body is involved, but other times a ``de facto'' standard
  emerges that everyone adopts.
\end{itemize}

Let's look at some examples:

\begin{itemize}
\item
  \href{https://en.wikipedia.org/wiki/ASCII}{ASCII}: fixed the
  different-character-sets boundary risk by being a standard that others
  could adopt. Before everyone agreed on ASCII, copying data from one
  computer system to another was a massive pain, and would involve some
  kind of translation.
  \href{https://en.wikipedia.org/wiki/Unicode}{Unicode} continues this
  work. (\textbf{Mode 1})
\item
  \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C}: The
  C programming language provided a way to get the same programs
  compiled against different CPU instruction sets, therefore providing
  some \emph{portability} to code. The problem was, each different
  operating system would still have it's own libraries, and so to
  support multiple operating systems, you'd have to write code against
  multiple different libraries. (\textbf{Mode 2})
\item
  \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}
  took what C did and went one step further, providing interoperability
  at the library level. Java code could run anywhere where Java was
  installed. (\textbf{Mode 2})
\item
  \href{https://en.wikipedia.org/wiki/Internet_Protocol}{Internet
  Protocol}: As we saw in
  \href{Communication-Risk\#protocol-risk}{Communication Risk}, the
  Internet Protocol (IP) is the \emph{lingua franca} of the modern
  internet. However, at one period of time, there were many competing
  standards. and IP was the ecosystem that ``won'', and was subsequently
  standardized by the
  \href{https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force}{IETF}.
  (\textbf{Mode 1})
\end{itemize}

\hypertarget{complex-boundaries}{%
\section{Complex Boundaries}\label{complex-boundaries}}

As shown in the above diagram, mitigating
\protect\hyperlink{boundary-risk}{Boundary Risk} involves taking on
complexity. The more Protocol Complexity the bridge will necessarily be.

\begin{sidewaystable} 

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.18\columnwidth}\raggedright
Protocol Risk From A\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Protocol Risk From B\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Resulting Bridge Complexity\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\raggedright
Example\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Simple\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Changing from one date format to another.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Status Dashboard, tbd\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Object-Relational Mapping (ORM) Tools, (see below)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High + Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Moderate, Versioned\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Simple Phone App, e.g.~note-taker or calculator\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Modern browser (see below)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Very Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Google Search, Scala (see below)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\end{sidewaystable} 

From examining the {[}Protocol Risk{]}{[}br1{]} at each end of the
bridge you are creating, you can get a rough idea of how complex the
endeavour will be:

\begin{itemize}
\tightlist
\item
  If it's low-risk at both ends, you're probably going to be able to
  knock it out easily. Like translating a date, or converting one file
  format to another.
\item
  Where one of the protocols is \emph{evolving}, you're definitely going
  to need to keep releasing new versions. The functionality of a
  \texttt{Calculator} app on my phone remains the same, but new versions
  have to be released as the phone APIs change, screens change
  resolution and so on.
\item
  tbd
\end{itemize}

Where boundaries

tbd Trying to create a complex, fractal surface. User requirements are
fractal in nature.

\hypertarget{object-relational-mapping}{%
\subsection{Object-Relational Mapping}\label{object-relational-mapping}}

For example, Object Relational Mapping (ORM) like {[}Java{]}. Building a
\emph{general} library that does this and is useful tbd said:

\begin{quote}
`Object/Relational Mapping is the Vietnam of Computer Science' -
\href{http://blogs.tedneward.com/post/the-vietnam-of-computer-science/}{Ted
Neward}
\end{quote}

This is a particularly difficult problem because the two ecosystems are
so \emph{rich} and \emph{complex} in the functionality they expose. But
what are the alternatives?

\begin{itemize}
\tightlist
\item
  Either back to building functionality within the database again, using
  stored procedures
\item
  Building Object Oriented Databases. It's interesting that neither of
  these really worked out.
\item
  Custom-building the bridge between the systems, one database call
  at-a-time in your own software.
\end{itemize}

This is tbd hobson's choice, there is strong debate about whether ORM or
not, and clearly will depend on your circumstances.

\hypertarget{scala}{%
\subsection{Scala}\label{scala}}

Mapping between complex boundaries is expecially difficult if the
Boundaries is an old, large and complex ecosystem, you would imagine
that it would have a slow-enough rate of change that abstracting
technologies can be built on top of it safely.

Indeed, we see that happening with Clojure and offering compatibility
with it.

\protect\hyperlink{scala}{Scala} is arguably the first mainstream
language that tried to do the same thing: it is trying to build a
Functional Programming paradigm.

The problem faced by Scala, Java moved to include this new functionality
too. If they hadn't, the developer community would have slowly drifted
away and used Scala instead.

So, in a sense, Scala is a \emph{success story}: they were able to force
change to Java. But, once Java had changed, Scala was in the difficult
position of having two sets of competing features in the platform: the
existing Scala streams, and the new Java streams.

Clojure can interop with Java because on one side, the boundary is
simple: lisp is a simple language which lends itself to reimplementation
within other platforms. Therefore, the complexity of the bridge is
\emph{simple}: all that needs to be provided is a way to call methods
from Java to clojure.

Scala and Java have a complex relationship because Scala creates it's
own complex boundary: it is syntactically and functionally a broad
language with lots of features. And so is Java. Mapping from one to the
other is therefore

for interop here. Why is one so different from the other?

\hypertarget{browsers}{%
\subsection{Browsers}\label{browsers}}

Web browsers are another suprisingly complex boundary. They have to
understand the following protocols:

\begin{itemize}
\tightlist
\item
  HTTP
\item
  HTML
\item
  Various image formats
\item
  Javascript for web-page \emph{interactivity}
\item
  CSS for web-page styling, animation and so on.
\item
  \ldots{} and several others.
\end{itemize}

Handling any one of these protocols alone is a massive endeavour, so
browsers are built on top of Software Libraries and so on.

One way of looking at the browser is that it is a \emph{function}, where
those elements listed above are the \emph{inputs} to the function, and
the output is \emph{what is displayed on the screen}, as shown in the
image below.

tbd. browser as a function

There are three specific problems that make this a really complex
boundary:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  All of the standards above are \emph{evolving and improving}. And,
  although HTML5 is a reasonably well-specified standard, in reality,
  web pages tend not to adhere exactly to the letter of it. People make
  mistakes in the HTML they write, and it's up to the browser to try and
  figure out what they \emph{meant} to write, rather than what they did
  write. This makes the \emph{input} to the function extremely complex.
\item
  Similarly, the \emph{output} of the function is not well defined
  either, and relies a lot on people's \emph{subjective aesthetic
  judgement}. For example, if you insert a
  \texttt{\textless{}table\textgreater{}} into an HTML page, the
  specification doesn't say anything about exactly how big the table
  should be, the size of it's borders, the spacing of the content and so
  on. At least, initially, \emph{none} of this was covered by the HTML
  Specification specification is over time clearing this up, but it's
  not \emph{exactly nailed down}, which means\ldots{}
\item
  That because there are various different browsers (Chrome and each
  browser has multiple different versions, released over a period of
  many years, you cannot, as a web-page developer know, \emph{a priori}
  what your web-page will look like to a user.
\end{enumerate}

As developers trying to build software to be delivered over the
internet, this is therefore a source of common Boundary Risk. If you
were trying to build software to work in \emph{all browsers} and
\emph{all versions}, this problem would be nearly insurmountable. So, in
order to tackle this risk, we do the following:

\begin{itemize}
\tightlist
\item
  We pick a small (but commonly used) subset of browsers, and use
  features from the specifications that we know commonly work in that
  subset.
\item
  We test across the subset. Again, testing is \emph{harder than it
  should be}, because of problem 2 above, that the expected output is
  not exactly defined. This generally means you have to get humans to
  apply their \emph{subjective aesthetic judgement}, rather than getting
  machines to do it.
\item
  There is considerable pressure on browser developers to ensure
  consistency of behaviour across the implementations. If all the
  browsers work the same, then we don't face the Boundary Risk of having
  to choose just one to make our software work in. However, it's not
  always been like this\ldots{}
\end{itemize}

\hypertarget{vendor-lock-in}{%
\section{Vendor Lock-In}\label{vendor-lock-in}}

In the late 1990s, faced with the emergence of the nascent World Wide
Web.

There are two questions we need to ask about this, from the
point-of-view of understanding Boundary Risk:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Why was this a successful strategy?
\item
  Why did they stop doing this?
\end{enumerate}

Let's look at the first question then. Yes, it was a successful
strategy. In the 1990s, browser functionality was rudimentary.
Developers were \emph{desperate} for more features, and for more control
over what appeared on their webpages. And, Internet Explorer (IE): they
were able to get more of the functionality they wanted in the browser.

It's worth pointing out, \emph{this was not a new strategy}:

\begin{itemize}
\tightlist
\item
  Processor Chip manufacturers had done something similar in the tbds:
  by providing features (instructions) on their processors that other
  vendors didn't have, they made their processors more attractive to
  system integrators. However, since the instructions were different on
  different chips, this created Boundary Risk.
\item
  We have two main \emph{mobile} ecosystems: Apple exist which allow you
  to build
\item
  Currently, Amazon Web Services (AWS). They are both racing to build
  new functionality, but at the same time it's hard to move from one
  vendor to another as there is no standardization on the tools.
\item
  As we saw above, Database vendors tried to do the same thing with
  features in the database. Oracle particularly makes money over
  differentiating itself from competitors by providing features that
  other vendors don't have. Tom tbd provides a compelling argument for
  using these features thus:
\end{itemize}

\begin{quote}
tbd.
\end{quote}

The next question, is why did Microsoft \emph{stop} pursuing this
strategy? It seems that the answer is because they were made to. tbd.

\hypertarget{everyday-boundary-risks}{%
\section{Everyday Boundary Risks}\label{everyday-boundary-risks}}

Boundary Risk occurs all the time. Let's look at some ways:

\begin{itemize}
\tightlist
\item
  \textbf{Configuration}: When software has to be deployed onto a
  server, there has to be configuration (usually on the command line, or
  via configuration property files) in order to bridge the boundary
  between the \emph{environment it's running in} and the \emph{software
  being run}. Often, this is setting up file locations, security keys
  and passwords, and telling it where to find other files and services.
\item
  \textbf{Integration Testing}: Building a unit test is easy. You are
  generally testing some code you have written, aided with a testing
  framework. Your code and the framework are both written in the same
  language, which means low boundary risk. But, to \emph{integration
  test} you need to step outside this boundary and so it becomes much
  harder. This is true whether you are integrating with other systems
  (providing or supplying them with data) or parts of your own system
  (say testing the client-side and server parts together).
\item
  \textbf{User Interface Testing}: If you are supplying a
  user-interface, then the interface with the user is already a complex,
  under-specified risky protocol: can you be sure that the screen hasn't
  got strange glitches, that the mouse moves correctly, that the
  proportions on the screen are correct on all browsers?
\item
  \textbf{Jobs}: When you pick a new technology to learn and add to your
  CV, it's worth keeping in mind how useful this will be to you in the
  future. It's career-limiting to be stuck in a dying ecosystem and need
  to retrain.
\item
  \textbf{Teams}: if you're given license to build a new product within
  an existing team, are you creating Boundary Risk by using tools that
  the team aren't familiar with?
\item
  \textbf{Organisatations}: Getting teams or departments to work with
  each other often involves breaking down Boundary Risk. Often the
  departments use different tool-sets or processes, and have different
  goals making the translation harder. tbd
\end{itemize}

\hypertarget{boundary-risk-and-change}{%
\subsection{Boundary Risk and Change}\label{boundary-risk-and-change}}

You can't always be sure that a dependency now will always have the same
guarantees in the future:

\begin{itemize}
\tightlist
\item
  \textbf{Ownership changes} Microsoft. What will happen to the
  ecosystem around github now?
\item
  \textbf{Licensing changes}. (e.g. \href{http://oracle.com}{Oracle}
  buys \textbf{Tangosol} who make
  \href{https://en.wikipedia.org/wiki/Oracle_Coherence}{Coherence} for
  example). Having done this, they increase the licensing costs of
  Tangosol to huge levels, milking the \href{}{Cash Cow} of the
  installed user-base, but ensuring no-one else is likely to use it.
\item
  \textbf{Better alternatives become available}: As a real example of
  this, I began a project in 2016 using \href{}{Apache Solr}. However,
  in 2018, I would probably use
  \href{https://en.wikipedia.org/wiki/Elasticsearch}{ElasticSearch}. In
  the past, I've built websites using Drupal and then later converted
  them to use WordPress.
\end{itemize}

\hypertarget{patterns-in-boundary-risk}{%
\section{Patterns In Boundary Risk}\label{patterns-in-boundary-risk}}

In Feature Risk, we saw that the features people need change over time.
Let's get more specific about this:

\begin{itemize}
\tightlist
\item
  Human need is Fractal. This means that over time, software products
  have evolved to more closely map to human needs. Software that would
  have delighted us ten years ago lacks the sophistication we expect
  today.
\item
  Software and hardware are both is improving with time, due to
  evolution and the ability to support greater and greater levels of
  complexity.
\item
  Abstractions build too. As we saw in Process Risk, we
  \emph{encapsulate} earlier abstractions in order to build later ones.
\end{itemize}

If all this is true, the only thing we can expect in the future is that
the lifespan of any ecosystem will follow an arc through creation,
adoption, growth, use and finally either be abstracted over or
abandoned.

tbd diagram.

Although our discipline is a young one, we should probably expect to see
``Software Archaeology'' in the same way as we see it for biological
organisms. Already we can see the dead-ends in the software evolutionary
tree: COBOL and BASIC languages, CASE systems. Languages like FORTH live
on in PostScript, SQL is still embedded in everything

Boundary risk is \emph{inside} and \emph{outside}

\hypertarget{agency-risk}{%
\chapter{Agency Risk}\label{agency-risk}}

Coordinating a team. But, people have their own goals, too. Sometimes,
the goals harmlessly co-exist with the team's goal, but other times they
don't.

This is Agency Risk in order to invest it, but they don't necessarily
have your best interests at heart. They may instead elect to invest the
money in ways that help them, or outright steal it.

\begin{quotation}

``This dilemma exists in circumstances where agents are motivated to act
in their own best interests, which are contrary to those of their
principals, and is an example of moral hazard.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Principalâagent_problem}{\textemdash  Principal-Agent Problem, \emph{Wikipedia}}}
\end{quotation}

The less visibility you have of the agent's activities, the bigger the
risk. However, the whole \emph{point} of giving the money to the agent
was that you would have to spend less time and effort managing it.

\begin{figure}
\centering
\includegraphics{images/kite9/agency-risk-monitoring.png}
\caption{Mitigating Agency Risk Through Monitoring}
\end{figure}

\href{Agency-Risk}{Agency Risk} clearly includes the behaviour of
\href{https://en.wiktionary.org/wiki/bad_actor}{Bad Actors}. But, this
is a very strict definition of \href{Agency-Risk}{Agency Risk}. In
software development, we're not lending each other money, but we are
being paid by the project sponsor, so they are assuming
\href{Agency-Risk}{Agency Risk} by employing us.

As we saw in the previous chapter on Process Risk doesn't just apply to
people: it can apply to \emph{running software} or \emph{whole teams}.

Let's look at some examples of borderline Agency Risk situations, in
order to sketch out where the domain of this risk lies.

\hypertarget{personal-lives}{%
\section{Personal Lives}\label{personal-lives}}

We can't (shouldn't) expect people on a project to sacrifice their
personal lives for the success of the project, right? Except that
\href{https://en.wikipedia.org/wiki/Video_game_developer\#\%22Crunch_time\%22}{``Crunch
Time''} is exactly how some software companies work:

\begin{quotation}

``Game development\ldots{} requires long working hours and dedication
from their employees. Some video game developers (such as Electronic
Arts) have been accused of the excessive invocation of''crunch
time``.''Crunch time" is the point at which the team is thought to be
failing to achieve milestones needed to launch a game on schedule. "

\sourceatright{\href{https://en.wikipedia.org/wiki/Video_game_developer\#"Crunch_time"}{\textemdash  Crunch Time, \emph{Wikipedia}}}
\end{quotation}

People taking time off, going to funerals, looking after sick relatives
and so on are all Agency Risk of having \emph{staff} rather than
\emph{slaves}.

\hypertarget{the-hero}{%
\section{The Hero}\label{the-hero}}

\begin{quotation}

``The one who stays later than the others is a hero.''

\sourceatright{\href{http://wiki.c2.com/?HeroCulture}{\textemdash  Hero Culture, \emph{Ward's Wiki}} <!-- tweet-end -->}
\end{quotation}

Conversely, Heroes put in more hours and try to rescue projects
single-handedly, often cutting corners like team communication and
process in order to get there.

Sometimes, projects don't get done without heroes. But other times, the
hero has an alternative agenda than just getting the project done:

\begin{itemize}
\tightlist
\item
  A need for control, and for their own vision.
\item
  A preference to work alone.
\item
  A desire for recognition and acclaim from colleagues.
\item
  For the job security of being a
  \href{https://en.wikipedia.org/wiki/Key_person_insurance}{Key Man}.
\end{itemize}

A team \emph{can} make use of heroism, but it's a double-edged sword.
The hero can becomes a bottleneck.

\hypertarget{consultancies}{%
\section{Consultancies}\label{consultancies}}

When you work with an external consultancy, there is \emph{always} more
Agency Risk than with a direct employee. This is because as well as your
goals and the employee's goals, there is also the consultancy's goals.

This is a good argument for not using consultancies, but sometimes the
technical expertise they bring can outweigh this risk.

Also, try to look for \emph{hungry} consultancies: if you being a happy
client is valuable to them, they will work at a discount (either working
cheaper, harder or longer or more carefully) as a result.

\hypertarget{cv-building}{%
\section{CV Building}\label{cv-building}}

This is when someone decides that the project needs a dose of ``Some
Technology X'', but in actual fact, this is either completely unhelpful
to the project (incurring large amounts of Complexity Risk, or merely
less useful than something else.

It's very easy to spot CV building: look for choices of technology that
are incongruently complex compared to the problem they solve, and then
challenge by suggesting a simpler alternative.

\hypertarget{career-risk}{%
\section{Career Risk}\label{career-risk}}

\hypertarget{devil-makes-work}{%
\section{Devil Makes Work}\label{devil-makes-work}}

Heroes can be useful, but \emph{underused} project members are a
nightmare. The problem is, people who are not fully occupied begin to
worry that actually, the team would be better off without them, and then
wonder if their jobs are at risk.

The solution to this is ``busy-work'': finding tasks that, at first
sight, look useful, and then delivering them in an over-elaborate way
(\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}) that'll keep them occupied. This will leave you with more
\href{Complexity-Risk}{Complexity Risk} than you had in the first place.

Even if they don't worry about their jobs, doing this is a way to stave
off \emph{boredom}.

\hypertarget{pet-projects}{%
\section{Pet Projects}\label{pet-projects}}

\begin{quote}
A project, activity or goal pursued as a personal favourite, rather than
because it is generally accepted as necessary or important. -
\href{https://en.wiktionary.org/wiki/pet_project}{Pet Project,
\emph{Wiktionary}}
\end{quote}

Sometimes, budget-holders have projects they value more than others
without reference to the value placed on them by the business. Perhaps
the project has a goal that aligns closely with the budget holder's
passions, or its related to work they were previously responsible for.

Working on a pet project usually means you get lots of attention (and
more than enough budget), but due to Map and Territory Risk, it can fall
apart very quickly under scrutiny.

\hypertarget{morale-risk}{%
\section{Morale Risk}\label{morale-risk}}

\begin{quote}
Morale, also known as Esprit de Corps is the capacity of a group's
members to retain belief in an institution or goal, particularly in the
face of opposition or hardship -
\href{https://en.wikipedia.org/wiki/Morale}{Morale, \emph{Wikipedia}}
\end{quote}

Sometimes, the morale of the team or individuals within it dips, leading
to lack of motivation. Morale Risk might be caused by:

\begin{itemize}
\tightlist
\item
  External factors: Perhaps the employees' dog has died, or they're
  simply tired of the industry, or are not feeling challenged.
\item
  If the team don't believe a goal is achievable, they won't commit
  their full effort to it. This might be due to to a difference in the
  evaluation of the risks on the project between the team members and
  the leader.
\item
  If the goal isn't considered sufficiently worthy, or the team isn't
  sufficiently valued.
\item
  In military science, a second meaning of morale is how well supplied
  and equipped a unit is. This would also seem like a useful reference
  point for IT projects. If teams are under-staffed or under-equipped,
  this will impact on motivation too.
\end{itemize}

\hypertarget{hubris-ego}{%
\section{Hubris \& Ego}\label{hubris-ego}}

It seems strange that humans are over-confident. You would have thought
that evolution would drive out this trait but apparently it's not so:

\begin{quotation}

``Now, new computer simulations show that a false sense of optimism,
whether when deciding to go to war or investing in a new stock, can
often improve your chances of winning.''

\sourceatright{\href{https://news.nationalgeographic.com/news/2011/09/110914-optimism-narcissism-overconfidence-hubris-evolution-science-nature/}{\textemdash  Evolution of Narcissism, \emph{National Geographic}}}
\end{quotation}

In any case, humans have lots of self-destructive tendencies that
\emph{haven't} been evolved away, and we get by.

Development is a craft, and ideally, we'd like developers to take pride
in their work. Too little pride means lack of care, but too much pride
is \emph{hubris}, and the belief that you are better than you really
are. Who does hubris benefit? Certainly not the team, and not the goal,
because hubris blinds the team to hidden risks that they really should
have seen.

Although over-confidence might be a useful trait when bargaining with
other humans, the thesis of everything so far is that Meeting Reality
will punish your over-confidence again and again.

Perhaps it's a little unfair to draw out one human characteristic for
attention. After all, we are riddled with biases

\hypertarget{software-processes-and-teams}{%
\section{Software Processes And
Teams}\label{software-processes-and-teams}}

Agency Risk doesn't just refer to people - it refers to anything which
has agency over it's actions.

\begin{quotation}

``Agency is the capacity of an actor to act in a given
environment\ldots{} Agency may either be classified as unconscious,
involuntary behavior, or purposeful, goal directed activity (intentional
action).''

\sourceatright{\href{https://en.wikipedia.org/wiki/Agency_(philosophy)}{\textemdash  Agency, \emph{Wikipedia}} }
\end{quotation}

There is significant Agency Risk in running software \emph{at all}.
Since computer systems follow rules we set for them, we shouldn't be
surprised when those rules have exceptions that lead to disaster. For
example:

\begin{itemize}
\tightlist
\item
  A process continually writing log files until the disks fill up,
  crashing the system.
\item
  Bugs causing data to get corrupted, causing financial loss.
\item
  Malware infecting a system, and sending your passwords and data to
  undesirables.
\end{itemize}

Agency Risk that don't align with those of the overall organisation. For
example:

\begin{itemize}
\tightlist
\item
  A team introduces excessive Bureaucracy in order to avoid work it
  doesn't like.
\item
  A team gets obsessed with a particular technology, or their own
  internal process improvement, at the expense of delivering business
  value.
\item
  A marginalised team forces their services on other teams in the name
  of ``consistency''. (This can happen a lot with ``Architecture'',
  ``Branding'' and ``Testing'' teams, sometimes for the better,
  sometimes for the worse.)
\end{itemize}

\hypertarget{its-about-goals}{%
\section{It's About Goals}\label{its-about-goals}}

\begin{figure}
\centering
\includegraphics{images/generated/agency-risk-400dpi.png}
\caption{Agency Risk}
\end{figure}

We've looked here at some illustrative examples of Agency Risk between
the different agents, whether they are \emph{people}, \emph{teams} or
\emph{software}.

So, having looked at agents \emph{individually}, it's time to look more
closely at Goals when aligning them amongst multiple agents.

On to Coordination Risk\ldots{}

\hypertarget{coordination-risk}{%
\chapter{Coordination Risk}\label{coordination-risk}}

Coordination Risk is embodied in the phrase ``Too Many Cooks Spoil The
Broth'': more people, opinions or agents often make results worse.

\begin{figure}
\centering
\includegraphics{images/generated/coordination-risk-400dpi.png}
\caption{Coordination Risk}
\end{figure}

As in \href{Agency-Risk}{Agency Risk}, we are going to use the term
\emph{agent}, which refers to anything with
\href{https://github.com/risk-first/website/wiki/Agency-Risk\#software-processes-and-teams}{agency}
in a system to decide it's own fate. That is, an agent has an
\href{Glossary\#Internal-Model}{Internal Model}, and can
\href{Glossary\#take-action}{take actions} based on it. Here, we're
going to work on the assumption that the agents \emph{are} working
towards a common \href{Glossary\#Goal-In-Mind}{Goal}, even though in
reality it's not always the case, as we saw in the chapter on
\href{Agency-Risk}{Agency Risk}.

In this chapter, we'll first build up A Model Of Coordination Risk .
We'll look at: - Team Decision Making, - Living Organisms, - Larger
Organisations and the staff within them, - and Software Processes.

\ldots{} and we'll consider how Coordination Risk is a problem at each
scale.

But for now, let's crack on and examine where Coordination Risk comes
from.

\hypertarget{a-model-of-coordination-risk}{%
\section{A Model Of Coordination
Risk}\label{a-model-of-coordination-risk}}

Earlier, in Dependency Risk: other parties want to use them in a
different way.

\hypertarget{competition}{%
\subsection{Competition}\label{competition}}

The basic problem of Coordination Risk, which is wasteful.

Why is this wasteful?

One argument could come from
\href{https://en.wikipedia.org/wiki/Diminishing_returns}{Diminishing
Returns}, which says that the earlier units of a resource (say,
chocolate bars) give you more benefit than later ones.

We can see this in the graph below. Let's say A and B compete over a
resource, of which there are 5 units available. For every extra A takes,
B loses one. The X axis shows A's consumption of the resource, so the
biggest benefit to A is in the consumption of the first unit.

\begin{figure}
\centering
\includegraphics{images/sharing.png}
\caption{Sharing Resources. 5 units are available, and the X axis shows
A's consumption of the resource. B gets whatever remains. Total benefit
is maximised somewhere in the middle}
\end{figure}

As you can see, by \emph{sharing}, it's possible that the \emph{total
benefit} is greater than it can be for either individual. But sharing
requires coordination. Further, the more competitors involved, the
\emph{worse} a winner-take-all outcome is for total benefit.

Just two things are needed for competition to occur:

\begin{itemize}
\tightlist
\item
  Individual agents, trying to achieve Goals.
\item
  Scarce Resources, which the agents want to use as Dependencies.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-2.png}
\caption{A model of competition: scarce resources, and individual agents
competing for them.}
\end{figure}

\hypertarget{coordination-via-communication}{%
\subsection{Coordination via
Communication}\label{coordination-via-communication}}

The only way that the agents can move away from competition towards
coordination is via Communication, and this is where their coordination
problems begin.

You might think, therefore, that this is just another type of
Communication Risk. If they coordinate, and leave in an orderly fashion,
they might all get out. If they don't, and there's a scramble for the
door, more people might die.

But commonly, Coordination Risk available for communication.

\hypertarget{problems-of-coordination}{%
\section{Problems Of Coordination}\label{problems-of-coordination}}

Let's unpack this idea, and review some classic problems of
coordination, none of which can be addressed without good communication:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Merging Data}. If you are familiar with the source code
  control system, \href{https://en.wikipedia.org/wiki/Git}{Git}, you
  will know that this is a \emph{distributed} version control system.
  That means that two or more people can propose changes to the same
  files without knowing about each other. This means that at some later
  time, \href{https://en.wikipedia.org/wiki/Git}{Git} then has to merge
  (or reconcile) these changes together. Git is very good at doing this
  automatically, but sometimes, different people can independently
  change the same lines of code and these will have to be merged
  manually. In this case, a human arbitrator ``resolves'' the
  difference, either by combining the two changes or picking a winner.
\item
  \textbf{Consensus}. Making group decisions (as in elections) is often
  decided by votes. But having a vote is a coordination issue, and
  requires that everyone has been told the rules:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Where will the vote be held?
\item
  How long do you provide for the vote?
\item
  What do you do about absentees?
\item
  What if people change their minds in the light of new information?
\item
  How do you ensure everyone has enough information to make a good
  decision?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  \textbf{Factions}. Sometimes, it's hard to coordinate large groups at
  the same time, and ``factions'' can occur. That the world isn't a
  single big country is probably partly a testament to this: countries
  are frequently separated by geographic features that prevent the easy
  flow of communication (and force). We can also see this in distributed
  systems, with the
  \href{https://en.wikipedia.org/wiki/Split-brain_(computing)}{``split
  brain''} problem. This is where a network of processes becomes
  disconnected (usually due to a network failure between data centers),
  and you end up with two, smaller networks with different knowledge.
  We'll address in more depth later.
\item
  \href{https://en.wikipedia.org/wiki/Resource_allocation}{Resource
  Allocation}: Ensuring that the right people are doing the right work,
  or the right resources are given to the right people is a coordination
  issue. On a grand scale, we have
  \href{https://en.wikipedia.org/wiki/Logistics}{Logistics}, and
  \href{https://en.wikipedia.org/wiki/Economic_system}{Economic
  Systems}. On a small scale, the office's \emph{room booking system}
  solves the coordination issue of who gets a meeting room using a
  first-come-first-served booking algorithm.
\item
  \href{https://en.wikipedia.org/wiki/Deadlock}{Deadlock}: Deadlock
  refers to a situation where, in an environment where multiple parallel
  processes are running, the processing stops and no-one can make
  progress because the resources each process needs are being reserved
  by another process. This is a specific issue in
  \href{https://en.wikipedia.org/wiki/Resource_allocation}{Resource
  Allocation}, but it's one we're familiar with in the computer science
  industry. Compare with
  \href{https://en.wikipedia.org/wiki/Gridlock}{Gridlock}, where traffic
  can't move because other traffic is occupying the space it wants to
  move to already.
\item
  \href{https://en.wikipedia.org/wiki/Race_condition}{Race Conditions}:
  A race condition is where we can't be sure of the result of a
  calculation, because it is dependent on the ordering of events within
  a system. For example, two separate threads writing the same memory at
  the same time (one ignoring and over-writing the work of the other) is
  a race.
\item
  \textbf{Contention}: Where there is Scarcity Risk itself. However if
  it isn't, it's the \emph{users} of the dependency who'll need to
  coordinate to use the resource fairly, again, by communicating with
  each other.
\end{enumerate}

\hypertarget{team-decision-making}{%
\section{Team Decision Making}\label{team-decision-making}}

Within a team, Coordination Risk is worse on projects with more members,
and worse in organizations with more staff.

If you are engaged in a solo project, do you suffer from
\href{Coordination-Risk}{Coordination Risk} at all? Maybe: sometimes,
you can feel ``conflicted'' about the best way to solve a problem. And
weirdly, usually \emph{not thinking about it} helps. Sleeping too. (Rich
Hickey calls this
``\href{https://www.youtube.com/watch?v=f84n5oFoZBc}{Hammock Driven
Development}''). This is probably because, unbeknownst to you, your
subconscious is furiously communicating internally, trying to resolve
these conflicts itself, and will let you know when it's come to a
resolution.

\href{https://en.wikipedia.org/wiki/Vroom-Yetton_decision_model}{Vroom
and Yetton} introduced a model of group decision making which delineated
five different styles of decision making within a team. These are
summarised in the table below (\textbf{AI, AII, CI, CII, GII}). To this,
I have added a sixth (\textbf{UI}), which is the \emph{uncoordinated}
option, where everyone competes. In the accompanying diagrams I have
adopted the following convention: - Thin lines with arrow-heads show a
flow of \emph{information}, either one-way or two-way. - Thick lines
show a flow of \emph{opinion}. - Boxes with corners are \emph{decision
makers}, whereas curved corners don't have a part in the decision.

\begin{figure}
\centering
\includegraphics{images/kite9/vroom-yetton.png}
\caption{Vroom And Yetton Decision Making Styles. ``d'' indicates
authority in making a decision. Thin lines with arrow-heads show
information flow, whilst thick lines show \emph{opinions} being passed
around.}
\end{figure}

\begin{sidewaystable} 

\begin{longtable}[]{@{}llllll@{}}
\toprule
\begin{minipage}[b]{0.07\columnwidth}\raggedright
Type\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedright
People Involved In Decision\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedright
Opinions\strut
\end{minipage} & \begin{minipage}[b]{0.24\columnwidth}\raggedright
Channels Of Communication\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{UI}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
0\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Competition\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
\emph{No Coordination}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{AI}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textbf{s} (One message to each \textbf{subordinate})\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Maximum Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Autocratic, top-down\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{AII}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
2 x \textbf{s} (Messages from/to each \textbf{subordinate})\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Autocratic, with information flow up.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{CI}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textgreater{} 2 x \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Individual Consultations\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{CII}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textgreater{} \textbf{s}2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Group Consultation\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{GII}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
\textgreater{} \textbf{s}2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Maximum Communication Risk, Schedule Risk\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
Group Consultation with voting\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\end{sidewaystable} 

At the top, you have the \emph{least} consultative styles, and at the
bottom, the \emph{most}. At the top, decisions are made with just the
leader's Internal Model of the rest of the team are increasingly brought
into play.

The decisions at the top are faster, but don't do much for mitigating
\textbf{Coordination Risk}. The ones below take longer, (incurring
Schedule Risk.

The trick is to be able to tell which approach is suitable at which
time. Everyone is expected to make decisions \emph{within their realm of
expertise}: you can't have developers continually calling meetings to
discuss whether they should be using an
\href{https://en.wikipedia.org/wiki/Abstract_factory_pattern}{Abstract
Factory} or a
\href{https://en.wikipedia.org/wiki/Factory_method_pattern}{Factory
Method}, this would waste time. The critical question is therefore,
``what's the biggest risk?'' - Is the Coordination Risk too. - Is the
Schedule Risk greater? If you have a 1-hour meeting with eight people to
decide a decision, that's \emph{one man day} gone right there: group
decision making is \emph{expensive}.

Hopefully, this model shows how \emph{organisation} can reduce
Coordination Risk:

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-1.png}
\caption{Coordination Risk traded for Complexity Risk, Schedule Risk and
Communication Risk}
\end{figure}

\hypertarget{staff-as-agents}{%
\subsection{Staff As Agents}\label{staff-as-agents}}

Staff in a team have a dual nature: they are \textbf{Agents} and
\textbf{Resources} at the same time. The team depends over their own
actions.

Part of Coordination Risk. So it's worth considering how varied people's
models can be: - Different skill levels - Different experiences -
Expertise in different areas - Preferences - Personalities

The job of harmonzing this on a project would seem to fall to the team
leader, but actually people are self-organising to some extent. This
process is called
\href{https://en.wikipedia.org/wiki/Tuckman\%27s_stages_of_group_development}{Team
Development}:

\begin{quotation}

``The forming--storming--norming--performing model of group development
was first proposed by Bruce Tuckman in 1965, who said that these phases
are all necessary and inevitable in order for the team to grow, face up
to challenges, tackle problems, find solutions, plan work, and deliver
results.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Tuckman%27s_stages_of_group_development}{\textemdash  Tuckman's Stages Of Group Development, \emph{Wikipedia}}}
\end{quotation}

Specifically, this describes a process whereby a new group will form and
then be required to work together. In the process, they will have many
\emph{disputes}. Ideally, the group will resolve these disputes
internally and emerge as a \emph{Team}, with a common Goal In Mind.

They can be encouraged with orthogonal practices such as
\href{https://en.wikipedia.org/wiki/Team_building}{team-building
exercises} (generally, submitting everyone to extreme experiences in
order to bond them together). With enough communication bandwidth and
detente, a motivated team will self-organise code reviews, information
exchange and improve their practices.

As decribed above, the job of Coordination issues like:

\begin{itemize}
\tightlist
\item
  People leaving, taking their Internal Models.
\item
  People requiring external training, to understand new tools and
  techniques Learning-Curve Risk.
\item
  People being protective about their knowledge in order to protect
  their jobs Agency Risk.
\item
  Where there are mixed ability levels, senior developers not helping
  juniors as it ``slows them down''.
\item
  People not getting on and not helping each other.
\end{itemize}

\begin{quotation}

``As a rough rule, three programmers organised into a team can do only
twice the work of a single programmer of the same ability - because of
time spent on coordination problems.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Gerald_Weinberg}{Gerald Wienberg, The Psychology of Computer Programming} }
\end{quotation}

\hypertarget{in-living-organisms}{%
\section{In Living Organisms}\label{in-living-organisms}}

Vroom and Yetton's organisational style isn't relevant to just teams of
people. We can see it in the natural world too. Although \emph{the
majority} of cellular life on earth (by weight) is
\href{http://www.stephenjaygould.org/library/gould_bacteria.html}{single
celled organisms}, the existence of \emph{humans} (to pick a single
example) demonstrates that sometimes it's better to try to mitigate
\href{Coordination-Risk}{Coordination Risk} and work as a team,
accepting the \href{Complexity-Risk}{Complexity Risk} and
\href{Communication-Risk}{Communication Risk} this entails. As soon as
cells start working together, they either need to pass \emph{resources}
between them, or \emph{control} and \emph{feedback}.

For example, in the human body, we have various
\href{https://en.wikipedia.org/wiki/List_of_systems_of_the_human_body}{systems}:

\begin{itemize}
\tightlist
\item
  The
  \href{https://en.wikipedia.org/wiki/Respiratory_system}{Respiratory
  System} which is responsible for ensuring that
  \href{https://en.wikipedia.org/wiki/Red_blood_cell}{Red Blood Cells}
  are replenished with Oxygen, as well as disposing of Carbon Dioxide.
\item
  The
  \href{https://en.wikipedia.org/wiki/Human_digestive_system}{Digestive
  System} which is responsible for extracting nutrition from food and
  putting them in our
  \href{https://en.wikipedia.org/wiki/Blood_plasma}{Blood Plasma}.
\item
  The
  \href{https://en.wikipedia.org/wiki/Circulatory_system}{Circulatory
  System} which is responsible for moving blood cells to all the rest of
  the body.
\item
  The \href{https://en.wikipedia.org/wiki/Nervous_system}{Nervous
  System} which is responsible for collecting information from all the
  parts of the body, dealing with it in the
  \href{https://en.wikipedia.org/wiki/Brain}{Brain} and issuing
  commands.
\item
  The \href{https://en.wikipedia.org/wiki/Motor_system}{Motor System}
  which contains muscles and bones, and allows us to move about.
\end{itemize}

\ldots{} and many others. Each of these systems contains organs, which
contain tissues, which contain cells of different types. (Even cells are
complex systems containing multiple different, communicating
sub-systems.) There is huge \href{Complexity-Risk}{Complexity Risk}
here: the entire organism fails if one of these systems fail (they are
\href{https://en.wikipedia.org/wiki/Single_point_of_failure}{Single
Points Of Failure}, although we can get by despite the failure of one
lung or one leg say).

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-organism.png}
\caption{Hierarchy of Function in the Human Body}
\end{figure}

\href{https://www.quora.com/What-is-the-most-complex-object-in-the-universe}{Some
argue} that the human nervous system is the most complex known artifact
in the universe: there is huge attendant
\href{Communication-Risk}{Communication Risk} to running the human body.
But, given the success of humanity as a species, you must conclude that
these steps on the evolutionary \href{Risk-Landscape}{Risk Landscape}
have benefitted us in our ecological niche.

The key observation from looking at biology is this: most of the cells
in the human body \emph{don't get a vote}. Muscles in the motor system
have an \textbf{AI} or \textbf{AII} relationship with the brain - they
do what they are told, but there are often nerves to report pain back.
The only place where \textbf{CII} or \textbf{GII} \emph{could} occur is
in our brains, when we try to make a decision and weigh up the pros and
cons.

This means that there is a deal: \emph{most} of the cells in our body
accede control of their destiny to ``the system''. Living within the
system of the human body is a better option than going it alone.
Occasionally, due to mutation, we can end up with
\href{https://en.wikipedia.org/wiki/Cancer}{Cancer}, which is where one
cell genetically ``forgets'' its purpose in the whole system and goes
back to selfish individual self-replication (\textbf{UI}). We have
\href{https://en.wikipedia.org/wiki/White_blood_cell}{White Blood Cells}
in the body to shut down this kind of behaviour and try to kill the
rogue cells. In the same way, society has a police force to stop
undesireable behaviour amongst its citizens.

\hypertarget{large-organisations}{%
\section{Large Organisations}\label{large-organisations}}

Working in a large organisation often feels like being a cell in a
larger organism. Just as cells live and die, but the organism goes on,
in the same way, workers come and go from a large company but the
organisation goes on. By working in an organisation, we give up
self-control and competition and accept \textbf{AI} and \textbf{AII}
power structures above us, but we trust that there is symbiotic value
creation on both sides of the employment deal.

\emph{Less} consultative decision making styles are more appropriate
then when we don't have the luxury of high-bandwidth channels for
discussion, or when the number of parties rises above a room-full of
people. As you can see from the table above, for \textbf{CII} and
\textbf{GII} decision-making styles, the amount of communication
increases non-linearly with the number of participants, so we need
something simpler. As we saw in the Complexity Risk chapter, hierarchies
are an excellent way of economizing on number of different communication
channels, and we use these frequently when there are lots of parties to
coordinate.

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-organisation-temp.png}
\caption{Hierarchy of Function in an Organisation}
\end{figure}

In large organisations, teams are created and leaders chosen for those
teams precisely to mitigate Communication Risk. We're all familiar with
this: control of the team is ceded to the leader, who takes on the role
of `handing down' direction from above, but also `reporting up' issues
that cannot be resolved within the team. In Vroom and Yetton's model,
this is moving from a \textbf{GII} or \textbf{CII} to an \textbf{AI} or
\textbf{AII} style of leadership.

As shown in the diagram above, we end up with a hierarchy of groups,
each having it's own decision-making style. The team leader at the
bottom level is a \emph{decision maker} within his team, but moving up,
doesn't have decision making power in the next team up.. and so on.

Sometimes, parts of an organisation are encouraged \emph{not} to
coordinate, but to compete. In the diagram above, we have an
\href{https://en.wikipedia.org/wiki/Multi-divisional_form}{M-Form}
organisation, composed of \emph{competing divisions}.

Clearly, this is just a \emph{model}, it's not set in stone and decision
making styles usually change from day-to-day and decision to decision.
The same is not true in our software - \emph{rules are rules}.

\hypertarget{in-software-processes}{%
\section{In Software Processes}\label{in-software-processes}}

It should be pretty clear that we are applying the Scale Invariance.

As before, in order to face Coordination Risk.

\hypertarget{cap-theorem}{%
\subsection{CAP Theorem}\label{cap-theorem}}

The \href{https://en.wikipedia.org/wiki/CAP_theorem}{CAP Theorem} has a
lot to say about \href{Coordination-Risk}{Coordination Risk}. Imagine
talking to a distributed database, where your request (\emph{read} or
\emph{write}) can be handled by one of many agents.

In the diagram below, we have just two agents \texttt{1} and \texttt{2},
in order to keep things simple. \texttt{User\ A} \emph{writes something}
to the database, then \texttt{User\ B} \emph{reads it back} afterwards.

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-cap-1.png}
\caption{User A and User B are both using a distributed database,
managed by Agents 1 and 2, whom each have their own Internal Model}
\end{figure}

According to the \href{https://en.wikipedia.org/wiki/CAP_theorem}{CAP
Theorem}, there are three properties we could desire in such a system:

\begin{itemize}
\tightlist
\item
  \textbf{Consistency}: Every read receives the most recent value from
  the last write.
\item
  \textbf{Availability}: Every request receives a response.
\item
  \textbf{Partition tolerance}: The system can operate despite the
  isolation (lack of communication with) some of it's agents.
\end{itemize}

The \href{https://en.wikipedia.org/wiki/CAP_theorem}{CAP Theorem} states
that this is a \href{https://en.wikipedia.org/wiki/Trilemma}{Trilemma}.
That is, you can only have two out of the three properties.

There are plenty of resources on the internet that discuss this in
depth, but let's just illustrate with some diagrams to show how this
plays out. In our diagram example, we'll say that \emph{any} agent can
receive the read or write. So this might be a \textbf{GII} decision
making system, because all the agents are going to need to coordinate to
figure out what the right value is to return for a read, and what the
last value written was. In these, the last write (setting X to 1) was
sent to Agent 1 which then becomes \emph{isolated}, and can't be
communicated with, due to network failure. What will User B get back?

\hypertarget{with-an-ap-system}{%
\subsubsection{With an AP System}\label{with-an-ap-system}}

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-cap-ap.png}
\caption{In an AP system, the User B will get back a \emph{stale value}
for X}
\end{figure}

With \texttt{AP}, you can see that \texttt{User\ B} is getting back a
\emph{stale value}. \texttt{AP} scenarios lead to
\href{https://en.wikipedia.org/wiki/Race_condition}{Race Conditions}:
\texttt{Agent\ 1}s availability determines what value \texttt{User\ B}
gets back.

\hypertarget{with-an-cp-system}{%
\subsubsection{With an CP System}\label{with-an-cp-system}}

\includegraphics{images/kite9/coordination-cap-cp.png} .

Where Agent 2 is left waiting for Agent 1 to re-appear, we are
\emph{blocked}. So CP systems lead to
\href{https://en.wikipedia.org/wiki/Deadlock}{Deadlock} scenarios.

\hypertarget{with-an-ca-system}{%
\subsubsection{With an CA System}\label{with-an-ca-system}}

\begin{figure}
\centering
\includegraphics{images/kite9/coordination-cap-ca.png}
\caption{In an CA system, we can't have partition tolerance, so in order
to be consistent a single Agent has to do all the work}
\end{figure}

Finally, if we have a CA system, we are essentially saying that
\emph{only one agent is doing the work}. (You can't partition a single
agent, after all). But this leads to
\href{https://en.wikipedia.org/wiki/Resource_allocation}{Resource
Allocation} and \textbf{Contention} around use of the scarce resource of
\texttt{Agent\ 2}'s attention. (Both
\href{Coordination-Risk}{Coordination Risk} issues we met earlier.)

\hypertarget{some-real-life-examples}{%
\subsection{Some Real-Life Examples}\label{some-real-life-examples}}

This sets an upper bound on Coordination Risk: we \emph{can't} get rid
of it completely in a software system, -or- a system on any other scale.
Fundamentally, coordination problems are inescapable at some level. The
best we can do is mitigate it by agreeing on protocols and doing lots of
communication.

Let's look at some real-life examples of how this manifests in software.

\hypertarget{zookeeper}{%
\subsubsection{ZooKeeper}\label{zookeeper}}

First, \href{https://zookeeper.apache.org}{ZooKeeper} is an Open-Source
datastore, which is used a lot for coordinating a distributed systems,
and storing things like configuration information across them. If the
configuration of a distributed system gets changed, it's important that
\emph{all of the agents in the system know about it}, otherwise\ldots{}
disaster.

This \emph{seems} trivial, but it quickly gets out-of-hand: what happens
if only some of the agents receive the new information? What happens if
a datacentre gets disconnected while the update is happening? There are
lots of edge-cases.

ZooKeeper handles this by communicating inter-agent with it's own
protocol. It elects a \textbf{master agent} (via voting), turning it
into an \textbf{AI}-style team. If the master is lost for some reason, a
new leader is elected. \emph{Writes} are then coordinated via the
\textbf{master agent} who makes sure that a \emph{majority of agents}
have received and stored the configuration change before telling the
user that the transaction is complete. Therefore, ZooKeeper is a
\texttt{CP} system.

\hypertarget{git}{%
\subsubsection{Git}\label{git}}

Second, \href{https://en.wikipedia.org/wiki/Git}{git} is a (mainly)
write-only ledger of source changes. However, as we already discussed
above, where different agents make incompatible changes, someone has to
decide how to resolve the conflicts so that we have a single source of
truth.

The Coordination Risk just \emph{doesn't go away}.

Since multiple users can make all the changes they like locally, and
merge them later, Git is an \texttt{AP} system: individual users may
have \emph{wildly} different ideas about what the source looks like
until the merge is complete.

\hypertarget{bitcoin}{%
\subsubsection{Bitcoin}\label{bitcoin}}

Finally, \href{https://en.wikipedia.org/wiki/Bitcoin}{Bitcoin (BTC)} is
a write-only
\href{https://en.wikipedia.org/wiki/Distributed_ledger}{distributed
ledger}, where agents \emph{compete} to mine BTC, but also at the same
time record transactions on the ledger. BTC is also \texttt{AP}, in a
similar way to Git. But new changes can only be appended if you have the
latest version of the ledger. If you append to an out-of-date ledger,
your work will be lost.

Because it's based on outright competition, if someone beats you to
completing a mining task, then your work is wasted. So, there is
\emph{huge} Coordination Risk.

For this reason, BTC agents \href{Coordination-Risk}{coordinate} into
\href{https://en.bitcoin.it/wiki/Comparison_of_mining_pools}{mining
consortia}, so they can avoid working on the same tasks at the same
time. But this in itself is a problem, because the whole \emph{point} of
BTC is that it's competitive, and no one entity has control. So, mining
pools tend to stop growing before they reach 50\% of the BTC network's
processing power. Taking control would be
\href{https://www.reddit.com/r/Bitcoin/comments/5fe9vz/in_the_last_24hrs_three_mining_pools_have_control/}{politically
disastrous} and confidence in the currency (such as there is) would
likely be lost.

\hypertarget{communication-is-for-coordination}{%
\section{Communication Is For
Coordination}\label{communication-is-for-coordination}}

So, now we have a fundamental limit on how much Coordination Risk within
teams of people, organisations or living organisms, so it's the case in
software.

Earlier in this chapter, we questioned whether Coordination Risk.
However, it should be clear after looking at the examples of
competition, cellular life and Vroom and Yetton's Model that this is
exactly \emph{backwards}:

\begin{itemize}
\tightlist
\item
  Most single-celled life has no need for communication: it simply
  competes for the available resources. If it lacks anything it needs,
  it dies.
\item
  There are \emph{no} lines of communication on the \textbf{UI}
  decision-type. It's only when we want to avoid competition, by sharing
  resources and working towards common goals that we need to
  communicate.
\item
  Therefore, the whole point of communication \emph{is for
  coordination}.
\end{itemize}

In the next chapter, Map And Territory Risk, we're going to look at some
new ways in which systems can fail, despite their attempts to
coordinate.

\hypertarget{map-and-territory-risk}{%
\chapter{Map And Territory Risk}\label{map-and-territory-risk}}

As we discussed in the chapter on Abstraction, our understanding of the
world is entirely informed by the names we give things and the
abstractions we create.

(In the same way, \textbf{Risk-First} is about \emph{identifying
patterns} within software development and calling them out.)

Our Internal Models are a model of the world based on these patterns,
and their relationships.

So there is a translation going on here: observations about the
arrangement of \emph{atoms} in the world get turned into patterns of
\emph{information} (measured in bits and bytes).

\begin{figure}
\centering
\includegraphics{images/kite9/mapter-bits-atoms.png}
\caption{Maps and Territories, and Communication happening between them}
\end{figure}

Map And Territory Risk rather than reality itself. It comes from the
expression ``Confusing the Map for the Territory'', attributed to Alfred
Korzybski:

\begin{quotation}

``Polish-American scientist and philosopher Alfred Korzybski remarked
that''the map is not the territory" and that ``the word is not the
thing'', encapsulating his view that an abstraction derived from
something, or a reaction to it, is not the thing itself. Korzybski held
that many people \emph{do} confuse maps with territories, that is,
confuse models of reality with reality itself."

\sourceatright{\href{https://en.wikipedia.org/wiki/Mapâterritory_relation}{\textemdash  Map-Territory Relation, \emph{Wikipedia}}}
\end{quotation}

In this chapter, we're going to make a case for analysing Map and
Territory Risk within the context of \textbf{machines}, \textbf{people},
\textbf{hierarchies} and \textbf{markets}.

tbd - diagram of how our actions are based on the map, not the
territory.

\hypertarget{fitness}{%
\section{Fitness}\label{fitness}}

In the picture shown here, from the Telegraph newspaper, the driver
\emph{trusted} the SatNav to such an extent that he didn't pay attention
to the road-signs around him, and ended up getting stuck.

This wasn't borne of stupidity, but experience: SatNavs are pretty
reliable. \emph{So many times} the SatNav had been right, that the
driver stopped \emph{questioning its fallibility}.

\begin{figure}
\centering
\includegraphics{images/sat_nav.png}
\caption{Sat Nav Blunder Sends Asda Van Crashing Narrow Footpath -
Telegraph Newspaper}
\end{figure}

So, there are two Map and Territory Risks here:

\begin{itemize}
\tightlist
\item
  The Internal Model of the \emph{SatNav} contained information that was
  wrong: the track had been marked up as a road, rather than a path.
\item
  The Internal Model of the \emph{driver} was wrong: his abstraction of
  ``the SatNav is always right'' turned out to be only \emph{mostly}
  accurate.
\end{itemize}

\hypertarget{internal-models-as-dependencies-features}{%
\section{Internal Models as Dependencies,
Features}\label{internal-models-as-dependencies-features}}

What are the risks at play here? We've already looked in detail at the
Dependency Risks too.

We could argue that the SatNav and the Driver's Internal Model, you
can't buy a new one, but you may learn to \emph{trust certain
abstractions less}, as this driver did.

In the Feature Risk on three axes: \textbf{Fitness}, \textbf{Evolution}
and \textbf{Audience}.

Lets do this again and see how each type of Feature Risk:

\begin{sidewaysfigure}
\centering
\includegraphics{images/generated/map_and_territory_table_1_sideways-400dpi.png}
\caption{Feature Risk, as manifested in the Internal Model}
\end{sidewaysfigure}

As with Features has at least these three dimensions:

\begin{itemize}
\tightlist
\item
  \textbf{Fitness}: as discussed above with the SatNav example, this is
  how closely the information matches reality, and how \emph{useful that
  is to us} (models that contain too much detail are as bad as models
  with too little).
\item
  \textbf{Audience}: is all about how a piece of information is
  \emph{shared} between many Internal Models, and it's this we are going
  to address further now.
\item
  \textbf{Evolution}: is all about how Internal Models change when they
  meet reality, and we'll cover that last.
\end{itemize}

\hypertarget{audience}{%
\section{Audience}\label{audience}}

We already know a lot about Internal Models and audience, as these have
been the subject of previous chapters:

\begin{itemize}
\tightlist
\item
  We know from looking at Communication Risk.
\item
  We know from Coordination Risk so that they cooperate.
\item
  Job markets show us that there is demand for people with certain
  \emph{skills}. This demonstrates to us that Market Risk.
\end{itemize}

\ldots{} And, we're all familiar with \emph{memes}:

\begin{quotation}

``A meme acts as a unit for carrying cultural ideas, symbols, or
practices, that can be transmitted from one mind to another through
writing, speech, gestures, rituals, or other imitable phenomena with a
mimicked theme.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Meme}{\textemdash  Meme, \emph{Wikipedia}}}
\end{quotation}

Therefore, we should be able to track the rise-and-fall of \emph{ideas}
much as we can track stock prices. And in effect, this is what
\href{https://trends.google.com}{Google Trends} does. In the chart
below, we can see the relative popularity of two search terms over time.
This is probably as good an indicator as any of the audience for an
abstraction at any point in time.

\begin{figure}
\centering
\includegraphics{images/google-trends.png}
\caption{Relative popularity of ``Machine Learning'' and ``Big Data'' as
search terms on Google Trends, 2011-2018}
\end{figure}

\hypertarget{example-hype-cycles}{%
\subsection{Example: Hype Cycles}\label{example-hype-cycles}}

Most ideas (and most products) have a slow, hard climb to wide-scale
adoption. But some ideas seem to disperse much more rapidly and are
picked up quickly because they are exciting and promising, having
greater ``memetic potential'' within society. One way this evolution
manifests itself in the world is though the
\href{https://en.wikipedia.org/wiki/Hype_cycle}{Hype Cycle}:

\begin{quotation}

``The hype cycle is a branded graphical presentation developed and used
by the American research, advisory and information technology firm
Gartner, for representing the maturity, adoption and social application
of specific technologies. The hype cycle provides a graphical and
conceptual presentation of the maturity of emerging technologies through
five phases.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Hype_cycle}{\textemdash  Hype Cycle, \emph{Wikipedia}}}
\end{quotation}

The five phases (and the ``Hype'' itself) are shown in the chart below,
with the thick black line being ``Hype'':

\begin{figure}
\centering
\includegraphics{images/hype-cycle.png}
\caption{Hype Cycle, along with Map \& Territory Risk}
\end{figure}

Also in this diagram we are showing where the hype originates:

\begin{itemize}
\tightlist
\item
  The \textbf{saturation} of the idea within the audience (a dotted
  line).
\item
  The \textbf{amount known} about the idea by the audience (a Learning
  Curve.
\end{itemize}

Both of these are modelled with
\href{https://en.wikipedia.org/wiki/Cumulative_distribution_function\#Use_in_statistical_analysis}{Cumulative
Distribution} curves. From these two things, we can figure out where our
maximum \href{}{Map and Territory Risk} lies: it's the point where
awareness of an idea is furthest from the understanding of it. This acts
as a ``brake'' on the \textbf{hype} around the idea, corresponding to
the ``Trough of Disillusionment''.

Where the \textbf{saturation} and \textbf{knowledge} grow together,
there is no spike in Map and Territory Risk and we don't see the
corresponding ``Trough of Disillusionment'' at all, as shown in this
chart:

\begin{figure}
\centering
\includegraphics{images/hype-cycle2.png}
\caption{Hype Cycle 2: Slower growth of Map and Territory Risk means no
``Trough of Disillusionment''}
\end{figure}

\hypertarget{evolution-1}{%
\section{Evolution}\label{evolution-1}}

The chapter on Communication Risk introduced the following model for
ideas:

\begin{figure}
\centering
\includegraphics{images/generated/communication_marketing-400dpi.png}
\caption{Spread of information between Internal Models}
\end{figure}

But what happens next? As we saw in Boundary Risk, the \textbf{Peter
Principle} applies, people will use dependencies up to the point when
they start breaking down.

\hypertarget{example-metrics}{%
\subsection{Example: Metrics}\label{example-metrics}}

Let's dive into a specific example now: someone finds a useful new
metric that helps in evaluating performance.

It might be:

\begin{itemize}
\tightlist
\item
  \textbf{SLOC (Source Lines Of Code)}: i.e.~the number of lines of code
  each developer writes per day/week whatever.
\item
  \textbf{Function Points}: the number of function points a person on
  the team completes, each sprint.
\item
  \textbf{Code Coverage}: the number of lines of code exercised by unit
  tests.
\item
  \textbf{Response Time}: the time it takes to respond to an emergency
  call, say, or to go from a feature request to production.
\item
  \textbf{Release cadence}: number of releases a team performs, per
  month, say.
\end{itemize}

With some skill, they may be able to \emph{correlate} this metric
against some other more abstract measure of success. For example:

\begin{quotation}

quality is correlated with more releases

\end{quotation}

\begin{quotation}

user-satisfaction is correlated with SLOC

\end{quotation}

\begin{quotation}

revenue is correlated with response time

\end{quotation}

Because the \emph{thing on the right} is easier to measure than
\emph{the thing on the left}, it becomes used as a proxy (or, Map) for
the thing they are really interested in (the Territory). At this point,
it's \emph{easy} to communicate this idea with the rest of the team, and
\emph{the market value of the idea is high}: it is a useful
representation of reality, which is shown to be accurate at a particular
point in time.

But \emph{correlation} doesn't imply \emph{causation}. The \emph{cause}
might be different:

\begin{itemize}
\tightlist
\item
  quality and number of releases might both be down to the simplicity of
  the product.
\item
  user satisfaction and SLOC might both be down to the calibre of the
  developers.
\item
  response time and revenue might both be down to clever team planning.
\end{itemize}

Metrics are seductive because they simplify reality and are easily
communicated. But they \emph{inherently} contain Map and Territory Risk:
By relying \emph{only} on the metrics, you're not really \emph{seeing}
the reality.

The devil is in the detail.

\hypertarget{reality-evolves}{%
\subsection{Reality Evolves}\label{reality-evolves}}

In the case of metrics, this is where they start being used for more
than just indicators, but as measures of performance or targets:

\begin{itemize}
\tightlist
\item
  If a team is \emph{told} to do lots of releases, they will perform
  lots of releases \emph{at the expense of something else}.
\item
  If team members are promoted according to SLOC, they will make sure
  their code takes up as many lines as possible.
\item
  In the UK, ambulances were asked to wait before admitting patients to
  Emergency wards, in order that hospitals could
  \href{https://en.wikipedia.org/wiki/NHS_targets}{meet their targets}.
\end{itemize}

Some of this seems obvious: \emph{Of course} SLOC is a terrible measure
performance! We're not that stupid anymore. The problem is, it's not so
much the \emph{choice} of metric, but the fact that \emph{all} metrics
merely approximate reality with a few numbers. The map is \emph{always}
simpler than the territory, therefore there can be no perfect metrics.

In the same way that markets evolve to demand more features model
doesn't cover it, ideas and products all eventually have their day and
decline in usefulness.

\hypertarget{bad-ideas}{%
\subsection{Bad Ideas}\label{bad-ideas}}

There are plenty of ideas which \emph{seem a really good idea at the
time} but then end up being terrible. It's only as we \emph{learn about
the products} and realize the hidden \href{}{Map and Territory Risk}
that we stop using them. While SLOC is a minor offender,
\href{https://en.wikipedia.org/wiki/Chlorofluorocarbon}{CFCs} or
\href{https://en.wikipedia.org/wiki/Tetraethyllead}{Leaded Petrol} are
more significant examples.

The following Hyph Cycle chart shows an initially promising idea that
turns out to be terrible, and there is a ``Period of Inoculation'' where
the population realise their mistake. There is ``negative hype'' as they
work to phase out the offending idea:

\begin{figure}
\centering
\includegraphics{images/hype-cycle3.png}
\caption{Hype Cycle For Something that turns out to be a \emph{bad}
idea}
\end{figure}

\hypertarget{humans-and-machines}{%
\section{Humans and Machines}\label{humans-and-machines}}

In the example of the SatNav, we saw how the \emph{quality} of Map and
Territory Risk, but for software systems it is a production crisis
involving 3am calls and backups.

For Humans, \href{}{Map and Territory Risk} is exacerbated by
\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{cognitive
biases}:

\begin{quotation}

``Cognitive biases are systematic patterns of deviation from norm or
rationality in judgment, and are often studied in psychology and
behavioral economics.''

\sourceatright{\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{\textemdash  Cognitive Bias, \emph{Wikipedia}}}
\end{quotation}

There are \emph{lots} of cognitive biases. But let's just look at a
couple that are relevant to Map and Territory Risk:

\begin{itemize}
\tightlist
\item
  \textbf{Availability Heuristic}: People overestimate the importance of
  knowledge they have been exposed to.
\item
  \textbf{The Ostrich Effect}: Which is where dangerous information is
  ignored or avoided because of the emotions it will evoke.
\item
  \textbf{Bandwagon Effect}: People like to believe things that other
  people believe. Could this be a factor in the existence of the Hype
  Cycle?
\end{itemize}

\hypertarget{hierarchical-organisations}{%
\section{Hierarchical Organisations}\label{hierarchical-organisations}}

Map And Territory Risk ``trickles down'' through an organisation. The
higher levels have an outsize ability to pervert the incentives at lower
levels because once an organisation begins to pursue a ``bullshit
objective'', the whole company can align to this.

\href{https://www.huffingtonpost.com/otto-scharmer/the-fish-rots-from-the-he_b_8208652.html}{The
Huffington Post} paints a brilliant picture of how Volkswagen managed to
get caught faking their emissions tests. As they point out:

\begin{quotation}

``The leadership culture of VW probably amplified the problem by
disconnecting itself from the values and trajectory of society, by
entrenching in what another executive in the auto industry once called a
``bullshit-castle''\ldots{} No engineer wakes up in the morning and
thinks: OK, today I want to build devices that deceive our customers and
destroy our planet. Yet it happened. Why? Because of hubris at the
top.''

\sourceatright{\href{https://www.huffingtonpost.com/otto-scharmer/the-fish-rots-from-the-he_b_8208652.html}{\textemdash  Otto Scharmer, \emph{Huffington Post}}.}
\end{quotation}

This article identifies the following process:

\begin{itemize}
\tightlist
\item
  \textbf{De-sensing}: VW Executives ignored \emph{The Territory}
  society around them (such as the green movement), ensuring their maps
  were out of date. The top-down culture made it hard for reality to
  propagate back up the hierarchy.
\item
  \textbf{Hubris/Absencing}: They pursued their own metrics of
  \emph{volume} and \emph{cost}, rather than seeking out others (a la
  the Availability Heuristic Bias). That is, focusing on their own
  \emph{Map}, which is \emph{easier} than checking the \emph{Territory}.
  (See Hubris.
\item
  \textbf{Deception}: Backed into a corner, engineers had no choice but
  to find ``creative'' ways to meet the metrics.
\item
  \textbf{Destruction}: Eventually, the truth comes out, to the
  detriment of the company, the environment and the shareholders. As the
  article's title summarizes ``A fish rots from the head down''.
\end{itemize}

\hypertarget{personal-example}{%
\subsection{Personal Example}\label{personal-example}}

A similar (but less catastrophic) personal story from a bank I worked
at, where the objectives end up being mis-aligned \emph{within the
company}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  My team had been tasked with building automated ``smoke tests'' of an
  application. But this was bullshit: We only needed to build these
  \emph{at all} because the application was so complex. The reason it
  was so complex was\ldots{}
\item
  The application was being designed within a ``Framework'' constructed
  by the department. However, the framework was only being used by this
  one application. Building a ``reuasable'' framework which is only used
  by a single application is bullshit. But, we had to do this
  because\ldots{}
\item
  The organisational structure was created along a ``matrix'', with
  ``business function'' on one axis and ``functional area'' on another.
  Although we were only building the application for a single business
  function, it was expected to cater with all the requirements from the
  an entire ``functional area''. This was bullshit too, because\ldots{}
\item
  The matrix structure was largely the legacy of a recent merger with
  another department. As Conway's Law predicts, our software therefore
  had to reflect this structure. But this was bullshit because\ldots{}
\item
  The matrix structure didn't represent reality in any useful way. It
  was designed to pacify the budget committee at the higher level, and
  try to demonstrate attributes such as \emph{control} and
  \emph{governance}. But this was bullshit too, because\ldots{}
\item
  The budget that was given to our department was really based on how
  much fear the budget holders currently had of the market regulators.
  But this was bullshit too, because\ldots{}
\item
  At a higher level, the executives had realised that our division
  wasn't one of the banks strategic strengths, and was working to close
  it all down anyway.
\end{enumerate}

When faced with so many mis-aligned objectives, it seemed completely
hopeless to concentrate on the task at hand. But then, a colleague was
able to nihilistically add one final layer to this onion by saying:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  ``It's all about chasing money, which is bullshit, because life is
  bullshit.''
\end{enumerate}

\hypertarget{picking-fights}{%
\subsection{Picking Fights}\label{picking-fights}}

It feels like there's no way back from that.

All of life might well be a big Map and Territory illusion. But let's
analyse just a bit:

\begin{itemize}
\tightlist
\item
  At each layer, the objectives changed. But, they impacted on the
  objectives of the layer below.
\item
  Therefore, it seems like the more layers you have, the less likely it
  is that your objectives become inconsistent between the lower and
  higher levels.
\item
  On a new project, it seems like a good idea to model this stuff: does
  the objective of the work you're about to undertake ``align'' with the
  objectives at a higher level?
\end{itemize}

Trying to spot Map and Territory Risk in the organisation are fragile
and likely to change. However, usually, if you are working in a team,
you have limited agency to decide which projects you feel are valuable.

This comes down to a personal decision: do you want to spend time
working on projects that you know are going in the bin? Some developers
have the attitude that, so long as they get paid, it doesn't matter. But
others are in it for the satisfaction of the work itself, so this ends
up being a personal call.

(This theme will be developed further in Staging and Classifying

\hypertarget{markets}{%
\section{Markets}\label{markets}}

So far, we've considered what happens to individuals, teams and
organisations when told to optimise around a particular objective. In
Coordination Risk is a key part of communication.

The languages we adopt or create are \emph{sets of useful abstractions}
that allow us to communicate. But what happens when this goes wrong?

\href{https://equilibriabook.com}{Inadequate Equilibria} by Eleizer
Yudkovsky, looks at how perverse incentive mechanisms break not just
departments, but entire societal systems. He highlights one example
involving \emph{academics} and \emph{grantmakers} in academia:

\begin{itemize}
\tightlist
\item
  It's not very apparent which scientists are better than which other
  scientists.
\item
  One proxy is what they've published (scientific papers) and where
  they've published (journals).
\item
  Universities want to attract research grants, and the best way to do
  this is to have the best scientists.
\item
  Because ``best'' isn't measureable, they use the proxy.
\item
  Therefore, immense power rests in the hands of the journals, since
  they can control the money-proxy.
\item
  Therefore, journals are able to charge large amounts of money to
  universities for subscriptions.
\end{itemize}

\begin{quotation}

``Now consider the system of scientific journals\ldots{} Some journals
are prestigious. So university hiring committees pay the most attention
to publications in that journal. So people with the best, most
interesting-looking publications try to send them to that journal. So if
a university hiring committee paid an equal amount of attention to
publications in lower-prestige journals, they'd end up granting tenure
to less prestigious people. Thus, the whole system is a stable
equilibrium that nobody can unilaterally defy except at cost to
themselves.''

\sourceatright{\href{https://equilibriabook.com/molochs-toolbox/}{\textemdash  Inadequate Equilibria, \emph{Eleizer Yudkovsky}}}
\end{quotation}

As the book points out, while everyone \emph{persists} in using an
inadequate abstraction, the system is broken. However, Coordination

This is a \emph{small example} from a much larger, closely argued book,
and it's worth taking the time to read a couple of the chapters on this
interesting topic.

As usual, this chapter forms a grab-bag of examples in a complex topic.
But it's time to move on as there is one last stop we have to make on
the Risk Landscape.

(NB: The Hype Cycle model is available in \textbf{Numbers} form
\href{https://github.com/risk-first/website/blob/master/RiskMatrix.numbers}{here}.)

\begin{figure}
\centering
\includegraphics{images/generated/map-and-territory-risk-400dpi.png}
\caption{Map And Territory Risk}
\end{figure}

(talk about how operational risk is an extension of this). tbd

\hypertarget{operational-risk}{%
\chapter{Operational Risk}\label{operational-risk}}

In this chapter on \protect\hyperlink{operational-risks}{Operational
Risks}, we're going to take our head out of the clouds a bit and start
considering the realities of running software systems in the real world.
After all, Coordination Risk: real-world concerns for anyone running a
business.

\hypertarget{a-recap}{%
\section{A Recap}\label{a-recap}}

But before we go there, let's try and recap on where we've come so far.
So far, we've been looking at risks to \emph{systems in general}:

\begin{itemize}
\item
\item
\item
\item
  \protect\hyperlink{communication-risk-1}{Communication Risk}: how they
  mitigate Coordination Risk by taking on
  \protect\hyperlink{communication-risk-1}{Communication Risk}.
\end{itemize}

Here is a diagram that shows how these different elements line up:

\begin{figure}
\centering
\includegraphics{images/kite9/production-1.png}
\caption{Systemic View of Risks}
\end{figure}

(tbd, remove outside client)

\hypertarget{operational-risks}{%
\section{Operational Risks}\label{operational-risks}}

It's tempting to take a very narrow view of the dependencies of a
system, but Operational Risks are often caused by dependencies we don't
consider - the \emph{context} within which the system is operating. Here
are some examples:

\begin{itemize}
\tightlist
\item
  Staff Dependencies (Staff Risk:

  \begin{itemize}
  \tightlist
  \item
    Freak weather conditions affecting ability of staff to get to work,
    interrupting the development and support teams.
  \item
    Reputational damage caused when staff are rude to the customers.
  \end{itemize}
\item
  Infrastructure Dependencies (Availability Risk:

  \begin{itemize}
  \tightlist
  \item
    A data-centre going off-line, causing your customers to lose access.
  \item
    A power cut causing backups to fail.
  \item
    Not having enough desks for everyone to sit at.
  \end{itemize}
\item
  Process Dependencies (Process Risk:

  \begin{itemize}
  \tightlist
  \item
    Regulatory change, which means you have to adapt your business
    model.
  \item
    Insufficient controls which means you don't notice when some
    transactions are failing, leaving you out-of-pocket.
  \item
    Data loss because of bugs introduced during an untested release.
  \end{itemize}
\item
  Software Dependencies (Software Dependency Risk:

  \begin{itemize}
  \tightlist
  \item
    Hackers breaking into the system and bringing your service down.
  \end{itemize}
\item
  Agency Dependencies (Agency Risk:

  \begin{itemize}
  \tightlist
  \item
    Suppliers deciding to stop supplying you with something you need.
  \item
    Workers going on strike.
  \item
    Employees trying to steal from the company (bad actors).
  \end{itemize}
\end{itemize}

.. basically, a long laundry-list of everything that can go wrong due to
operating in ``The Real World''. Although these issues don't exist with
\emph{ideal} dependencies, pragmatically, when we design our system, we
design in features to \emph{strengthen} it against Operational Risks.

For example, as we saw in Development Process, but again reduced the
likelihood of bugs making it into production.

Dependencies are not just things we \emph{use}, then: For a system to
run well, it needs to carefully manage unreliable dependencies, and
ensure their safety and availability. In the example of the human food
system, say, it's the difference between Hunter-Gathering.

\hypertarget{operational-risk-management}{%
\section{Operational Risk
Management}\label{operational-risk-management}}

Since we have looked in detail at various types of Dependency Risk:

\begin{quotation}

``Operational Risk Management is the oversight of Operational Risk,
including the risk of loss resulting from inadequate or failed internal
processes and systems; human factors; or external events.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Operational_risk_management}{\textemdash  Operational Risk Management, \emph{Wikipedia}}}
\end{quotation}

\includegraphics{images/kite9/production-2.png} tbd, need to modify
this,

\hypertarget{mitigating-operational-risk}{%
\section{Mitigating Operational
Risk}\label{mitigating-operational-risk}}

Operational Risk, with reference to embedding the system of dependencies
in the real world. There are various activities then that Operational
Risks, then are things that happen \emph{to} our carefully constructed,
theoretical system, as shown in this diagram:

diagram: our system -\textgreater{} event's exploit weakness
-\textgreater{} effect -\textgreater{} reaction -\textgreater{} recovery
-\textgreater{} adaptation

(our system: meeting reality, deployment) (event: detection) (weakness:
minimization (see Security risk)) (effect: what happens, how much chaos
ensues) (sensing / detection) (reaction: monitoring, etc) (recovery: how
we fix it) (adaptation: how the system changes in the future)
(prediction: how to forecast failures) pestle, environmental scanning. /
anticipation (practicing: e.g.~testing failover etc.) (changing outside
world)

These are properties not only of software systems, but biological
systems, and businesses too. Let's now take each in turn and inspect it
further.

Therefore, one of the best defences against Operational Risk is dealing
with the issues quickly once they happen. This requires:

Good Feedback Loops and rapid response to issues.

tbd, talk with John about this

\hypertarget{meeting-reality-1}{%
\section{Meeting Reality}\label{meeting-reality-1}}

So in this second model, we are now considering that the world is a
dangerous, untrustworthy place where \emph{bad things happen}, either
deliberately or accidentally. And, since we don't have a perfect
understanding of the world, most of the Production Risk.

Putting software into production is Meeting Reality will materialize. If
we observe these and take action to mitigate them, then our system can
get stronger. cybernetics, antifragile tbd.

It is tempting to delay Meeting Reality. In the past I've seen this
stated as:

\begin{quote}
Pressure to ship becomes greater than pressure to improve tbd
\end{quote}

A Risk-First reframing of this might be the balance between:

\begin{itemize}
\tightlist
\item
  The perceived \protect\hyperlink{reputational-risk-1}{Reputational
  Risk}, Feature Risk
\item
  The perceived Schedule Risks
\end{itemize}

The ``should we ship?'' decision is therefore a complex one. In Meeting
Reality on our own terms by doing so:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Meet Reality\ldots{}\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Techniques\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{Sooner}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Limited Early-Access Programs, Beta Programs, Soft Launches\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{More Frequently}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
{[}Continuous Delivery{]}, Sprints\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{In Smaller Chunks}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Modular Releases Trial Populations\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{With Feedback}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
User Communities, Support Groups, Monitoring, Logging, Analytics\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{external-events}{%
\section{External Events}\label{external-events}}

We're familiar with the concept of taking steps on the
\protect\hyperlink{risk-landscape}{Risk Landscape}, wherein we take
action are more acceptable to us. However, now we have to contend with
the idea that external events \emph{also} change the risk landscape too.
If there is sudden bad weather, we might have a risk of a power-cut, and
the losses that might entail to productivity or sales. If there is a
change of government, that might impact the contracts we've written, or
the security of our servers or staff.

Being \emph{in production} is accepting that the Risk Landscape is a
volatile, uncaring place. But it's worse than that, since we also have
to contend with {[}Bad Actors{]}, who are deliberately out to exploit
weaknesses in the systems we build.

Ordinarily, when we transact with a {[}Dependency{]}, it should be the
case that after the transaction, there is value on both sides of the
transaction. This could be, \emph{you do my accounting}, I pay you
money. On both sides, financial risks are reduced. If the price is too
high, or too low, we see one or other side getting the better deal, and
\emph{capturing an unfair share of the value}.

With a {[}Bad Actor{]}, we're in a situation more like a zero-sum game:
value is \emph{taken} from one party and \emph{transferred} to the
other. These are exactly the dependency relationships that societies
\emph{don't} condone: there is net \emph{zero} or \emph{negative} value
in the transaction.

\begin{figure}
\centering
\includegraphics{images/deal.png}
\caption{In this diagram, B does a deal with A, the value of the product
B gets from A is always 4, but the price varies with the X axis. When
the price is zero, B captures all the value, but as the price increases,
it becomes a worse and worse deal for B, and the net value heads towards
zero or negative.}
\end{figure}

\begin{itemize}
\tightlist
\item
  Regulatory Risk Legal Risk (Pestle?)
\end{itemize}

\hypertarget{weaknesses}{%
\section{Weaknesses}\label{weaknesses}}

Security of supply

Complex systems (ones which contain multiple, interacting parts, like
the ones in the above diagrams) have to contend with their external
environments, and try to minimize the ways in which they get interrupted
from outside either by \emph{Bad Actors} or external events. In the tbd

Interestingly, security is handled in very similar ways at all sorts of
levels:

\begin{itemize}
\tightlist
\item
  \textbf{Walls}: defences \emph{around} the complex system, to protect
  it's parts from the external environment.
\item
  \textbf{Doors}: ways to get \emph{in} and \emph{out} of the complex
  system, possibly with \emph{locks}.
\item
  \textbf{Guards}: to make sure only the right things go in and out.
  (i.e.~to try and keep out \emph{Bad Actors}).
\item
  \textbf{Police}: to defend from \emph{within} the system, against
  Agency Risk and \emph{invaders}.
\item
  \textbf{Subterfuge}: Hiding, camouflage, disguises, pretending to be
  something else. tbd
\end{itemize}

These work various levels in our own bodies: our \emph{cells} have
\emph{cell walls} around them, and \emph{cell membranes} that act as the
guards to allow things in and out. Our \emph{bodies} have \emph{skin} to
keep the world out, and we have \emph{mouths}, \emph{eyes}, \emph{pores}
and so on to allow things in and out. We have an \emph{immune system} to
act as the police.

Our societies work in similar ways: in medieval times, a city would have
walls, guards and doors to keep out intruders. Nowadays, we have customs
control, borders and passports.

We're waking up to the realisation that our software systems need to
work the same way: we have Firewalls to protect our organisations, we
lock down \emph{ports} on servers to ensure there are the minimum number
of doors to guard and we \emph{police} the servers ourselves with
monitoring tools and anti-virus software.

\begin{verbatim}
- Security Risk
  - Hacking
  - Denial Of Service
  - Security, Trust and Complexity
  - oWASp
\end{verbatim}

tbd, How much do compilers do for you? Now, they prevent many kinds of
security error. Libraries too.

\hypertarget{operational-risk-1}{%
\section{Operational Risk}\label{operational-risk-1}}

When processes fail, this is called \emph{Operational Risk}:

tbd - Wikipedia definition

This is a very specific name for Reliability Risk with regard to
processes. In the UK each year, X number of people are killed in car
accidents. If you regard driving a car from A to B as a process, then
you could say that car accidents are
\protect\hyperlink{operational-risk-1}{Operational Risk}. Why do we
tolerate such costly operational risk in the UK. Could it be reduced?
Well, yes. There are lots of ways. One way is that we could just reduce
the speed limit.

It is interesting that we \emph{don't} do that: although we know the
driving process fails, and fails in a way that is costly to human lives,
as a society we value the freedom, the economic efficiency and time
savings that come from not mitigating this operational risk. Changing
the speed limit would have it's own risks, of course: there would be a
complicated transition to manage. However, if ten times as many people
were killed in car accidents, and it was shown that reducing the speed
limit would help, maybe it would be done. The Operational Risk.

The point of this is that we \emph{accept} Operational Risk as we go.
However, if opportunities rise to mitigate it, which don't leave us with
a net risk increase elsewhere, we'll make those improvements.

tbd. diagram version 3.

Mitigating Security Risk is a trade-off. You can spent \emph{a lot} of
time and effort on this, only to never face the

secrets: how to mitigate this

\hypertarget{effect-impact}{%
\section{Effect / Impact}\label{effect-impact}}

Sometimes, it's possible to measure the impact of Operational Risks. For
example, if a software system fails, and leaves customers unable to
access it, this can have a measurable financial impact in lost revenues
or damages. Car recall example tbd. - fight club

Impact is usually proportional to some of the below variables:

\begin{itemize}
\tightlist
\item
  Number of customers affected.
\item
  Number of transactions affected.
\item
  Size of the transactions
\item
  Length of time systems were affected.
\end{itemize}

stuff that can go wrong in production

changing stuff in production is harder than changing it in test, as you
have to \emph{migrate}.

all the costs of breaking stuff, and damaging the running of the
business.

reputation damage (you only get one chance to make a first impression)

\begin{itemize}
\item
  You don't know all the ways the software will get used in production.
\item
  Different browsers, versions of code, accessiblilty.
\item
  CAn you support all the users? IS there enough kit? WIll you know?
\end{itemize}

Correlation - Upgrades ( tell story of Research upgrade that went wrong
because we were upgrading at the same time as an outage) - Single points
of failure.

reputational damage

\hypertarget{reaction-recovery}{%
\section{Reaction \& Recovery}\label{reaction-recovery}}

\hypertarget{reliability-risk-1}{%
\section{Reliability Risk}\label{reliability-risk-1}}

\begin{verbatim}
- Feedback Loops
   - Bug reports, feedback
   - Quality of feedback
   - Internal Controls
     - Agency Risk meets Production Risk (bad actors, controls)



  - Contingency Planning
  - Disaster Recovery
        - Performance Degradation / Runaway processes  (Performance Risk)

        - Support (trade off - promptness vs ability)

  Sometimes, the reaction of the company makes things worse - streisand effect? others?

  - Poor monitoring, visibility risk meets operational risk (otherwise, it doesn't matter - good example here)
  - Correlation  (need a good example here)
  - Monitoring Tools and Logs
\end{verbatim}

\hypertarget{prevention}{%
\section{Prevention}\label{prevention}}

\begin{itemize}
\tightlist
\item
  How we learn from our mistakes
\item
  You can't know everything
\item
  Reality changes anyway
\end{itemize}

\hypertarget{performance-risk}{%
\section{Performance Risk}\label{performance-risk}}

There is a lot more to Operational Risk. Here, we've touched on it, and
sketched the edges of it enough for it to be familiar and fit in our
framework.

\hypertarget{reputational-risk-1}{%
\section{Reputational Risk}\label{reputational-risk-1}}

\hypertarget{high-profile-cases}{%
\section{High-Profile Cases}\label{high-profile-cases}}

\hypertarget{maturity}{%
\section{Maturity}\label{maturity}}

https://math.nist.gov/IFIP-UQSC-2011/slides/Oberkampf.pdf
https://www.bsimm.com/framework/intelligence/attack-models.html ISO27001

OWASP

\hypertarget{staging-and-classifying}{%
\chapter{Staging And Classifying}\label{staging-and-classifying}}

Our tour is complete.

We've collected on this journey around the Risk Landscape our collection
on some solid {[}Mounting Boards{]}, and do some work in classifying
what we've seen.

tbd collecting image

If you've been reading closely, you'll notice that a number of themes
come up again and again within the different chapters. For example,
concepts like \textbf{Fit}, \textbf{Abstraction}, \textbf{Evolution}.
Although we've been looking at patterns of risk across software
projects, it's time to look at the \emph{patterns within the patterns}.

\hypertarget{first-a-recap}{%
\section{First, A Recap}\label{first-a-recap}}

tbd. list of risks, broken down

\hypertarget{some-observations}{%
\section{Some Observations}\label{some-observations}}

\hypertarget{the-power-of-abstractions}{%
\subsection{1. The Power Of
Abstractions}\label{the-power-of-abstractions}}

Abstraction.

There's a good reason for this repetition. Abstraction is at the heart
of \emph{everything we do within software}. So, let's now
\emph{generalize} what is happening with abstraction, but have in mind
\emph{a really simple example}: giving a name to something.

\hypertarget{inventing-an-abstraction-means}{%
\subsubsection{Inventing an Abstraction
means:}\label{inventing-an-abstraction-means}}

\begin{itemize}
\tightlist
\item
  **Creating a Feature in the sense that other people can choose to use
  them, if they fit their requirements.
\item
  **Creating a Boundary. \emph{Boundary Risk is created by
  abstractions.}
\item
  **Creating a Protocol: what if the person we are communicating with
  \_doesn't know this word?
\item
  \textbf{Increasing Complexity.} Because, the more words we have, the
  more complex the language is.
\end{itemize}

tbd, diagram.

\hypertarget{choosing-an-abstraction-means}{%
\subsubsection{Choosing an Abstraction
means:}\label{choosing-an-abstraction-means}}

\begin{itemize}
\tightlist
\item
  **Overcoming a Learning Curve.
\item
  **Accepting Boundary Risks.
\item
  \textbf{Accepting Map And Territory Risk.} Because the word refers to
  the \emph{concept} of the thing, and \emph{not the thing itself}.
\end{itemize}

tbd. diagram

\hypertarget{depending-on-an-abstraction-means}{%
\subsubsection{Depending On an Abstraction
means:}\label{depending-on-an-abstraction-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Living with Dependency Risk:} We depend on a word in our
  language, or a function in our library, or a service on the internet.
  But all of these things are \emph{unreliable}. The word might not
  communicate what you want it to, or be understood by the audience, the
  function might not work, the service might be down.
\item
  **Accepting Evolution.
\item
  **Accepting Coordination Risk, we need to consider how to work with
  it.
\end{itemize}

tbd diagram.

\hypertarget{your-feature-risk-is-someone-elses-dependency-risk}{%
\subsection{2. Your Feature Risk is Someone Else's Dependency
Risk}\label{your-feature-risk-is-someone-elses-dependency-risk}}

In the Feature Risk went further, looking at specific aspects of being
the supplier of an IT service as a dependency.

However, over the rest of the Dependency Risk chapters, we looked at
this from the point of view of \emph{being a client to someone else}:
you want to find trustworthy, reliable dependencies that don't give up
when you least want them to.

So Feature Risk when you're the supplier.

We've looked at three dimensions of Feature Risk: - Fit - Evolution -
Audience

(recap this)

Dependency Risk has three dimensions too:

\begin{itemize}
\item
  Schedule (things happening in time, running out of stuff. e.g I need
  enough money to get this done, etc. I need enough patience, enough
  loyalty, trust, entente.)
\item
  Technology (depending on software, hardware, etc. )
\item
  Organisation (arrangements of people
\item
  Agency (people/machines/processes/organisations doing what you asked,
  working with you)
\item
\end{itemize}

Using a dependency requires learning a \emph{protocol}. You have to
learn to use it. Maybe it learns you. This requires changes to your
internal model.

Internal Model - Communication -- Dependency Goal

\hypertarget{coordination-risk-as-eden}{%
\subsection{3. Coordination Risk As
Eden}\label{coordination-risk-as-eden}}

\begin{itemize}
\tightlist
\item
  similar to \_threading/deadlocking issues
\item
  Coordination is how you deal with abstractions. and this means
  communication.
\end{itemize}

tbd diagram: abstractions -\textgreater{} agency -\textgreater{}
coordintion -\textgreater{} communication

One thing that should be apparent is that there are similarities in the
risks between all the kinds of

\begin{itemize}
\tightlist
\item
  draw a diagram of this system. mark on all the different risks using
  numbers. mention specifically that since this is a diagram, it is a
  ``map''.
\end{itemize}

\hypertarget{towards-a-periodic-table-of-risks}{%
\section{Towards A Periodic Table Of
Risks}\label{towards-a-periodic-table-of-risks}}

tbd, diagram, explanatory text.

\hypertarget{patterns}{%
\section{Patterns}\label{patterns}}

As we said at the start our work, we need to be able to explain what the
risks are, and what we expect to do about them.

So, lastly in part 2 let's put our language to work, and look at some
past project failures. Can we apply our lexicon to them?

On to Stories Of Failure.

\hypertarget{stories-of-failure}{%
\chapter{Stories Of Failure}\label{stories-of-failure}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Failure Modes
\end{enumerate}

\begin{itemize}
\item
  Understanding Failure: what exactly does it mean to fail?
\item
  Personal Failures

  \begin{itemize}
  \tightlist
  \item
    CapsLock: complexity, not using tools.
  \item
    Configuration Tool (Complexity, feature fit, bugs in hibernate
    (dependency risk, then dead-end risk), difficulty mapping domain
    model)
  \item
    Wide Learning (Funding, but also complexity), did we know what we
    were building? Agency risk
  \item
    AreAye - needless complexity XMLBox
  \item
    Agora: Notes / Typing. (Complexity Risk) Archipelago
  \item
    PDC: website redesign. funding. i.e.~schedule risk
  \item
    Hawk: complexity risk in the software. but actually, they made it
    work. offshoring.
  \item
    Dark: market/feature fit?
  \item
    J10: marketing / market fit / Complexity in spades. algorithmic
    complexity
  \item
    DSL: complexity (code generation). complexity = layers. team
    dynamics.
  \item
    REF: complexity. agency risk. failure of goals. m\&t.
  \item
    REF Testing: complexity risk. communication risk?
  \item
    HSC: Trader Comments: feature fit.
  \item
    HSC: Takeover of Symph: Complexity (of change)
  \item
    TT: Feature Fit
  \end{itemize}
\item
  Boehm.
\end{itemize}

https://wwwx.cs.unc.edu/\textasciitilde{}welch/class/comp145/media/docs/Boehm\_Term\_NE\_Fail.pdf

https://www.worksoft.com/top-software-failures-of-2017-so-far

https://sites.hks.harvard.edu/m-rcbg/ethiopia/Publications/Top\%2010\%20Reasons\%20Why\%20Systems\%20Projects\%20Fail.pdf

JC Example 1: Compensation Workbench, rules to uplift payrolls annually
based on certain definitions. e.g tied into performance gradiing, min
wage. Was done off s/s, out of HR system. Analysis done on S/s. But
wanted to do it in the HR database. It took a lot longer than it should.
Underestimated the complexity. Excel could be infinitely complex, but if
you standardize, you lose that. The customer hadn't got experience of
big IT projects - scope creep. No real sense of prioritisation and
focusing on what was iportant. PM was nice, but didn't understand
delivery management. (i.e.~managing risks and issues). Had short
timescale, lead delivery resource underestimated. 2m exercise. Lasted 5m
in the end, but not with full functionality.

\part{Application}

\hypertarget{coming-next}{%
\chapter{Coming Next}\label{coming-next}}

\begin{itemize}
\tightlist
\item
  preview of what's to come in part 3.
\end{itemize}

Bad to leave on the failure notes, let's talk about some successes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What's To Come
\end{enumerate}

\begin{itemize}
\tightlist
\item
  risk based debugging.
\item
  risk based coding.
\end{itemize}

\hypertarget{estimates}{%
\chapter{Estimates}\label{estimates}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Purpose of Estimating
\item
  (coordination risk)
\item
  trying to work out \emph{the value} of doing some work
\item
  How Estimates Fail
\item
  Hidden Risk
\item
  Visible Risk
\item
\end{enumerate}

\hypertarget{how-estimates-fail}{%
\section{How Estimates Fail}\label{how-estimates-fail}}

The problem with a developer answering a question such as:

\begin{quotation}

How long will it take to deliver X

\end{quotation}

Is the following:

\begin{itemize}
\tightlist
\item
  The developer likely doesn't know what X is, and any description of it
  is inadequate anyway (Invisibility Risk.
\item
  The developer has a less-than-complete understanding of the
  environment he will be delivering X in (Complexity Risk.
\item
  The developer has some vague ideas about how to do X, but he'll need
  to try out various approaches until he finds exactly the right one
  (Boundary Risk.
\item
  The developer has no idea what Hidden Risk will surface when he starts
  work on it.
\item
  What will happen if he takes too long and misses the date by a
  day/week/month/year. (Schedule Risk
\end{itemize}

\ldots{} and so on. So, his estimate is both wrong, and contingent on
what exact risks appear.

\hypertarget{an-aside}{%
\section{An Aside}\label{an-aside}}

tbd quality, time, functionality pick two of three.

\hypertarget{agile}{%
\section{Agile}\label{agile}}

One alternative approach, must espoused in DevOps/Agile is to pick a
short-enough period of time (say, two days or two weeks), and figure out
what the most meaningful step towards achieving an objective would be in
that time. By fixing the time period, we remove Schedule Risk from the
equation.

The problems with this are: - First, this is just Gradient Descent. -
Second, what happens after the two days? If you \emph{abandon the work},
then maybe you are giving up too early: a day or two more might have
cracked it. If you undergo the planning process again, you might decide
that another objective is more important. Constantly switching ideas all
the time \emph{might not get you anywhere}. - Third, how to choose the
time period? In Scrum it's betweeen tbd. But, lots of people are saying
go smaller.

The choice of using gradient descent means that you have given up on
{[}Grand Objectives{]}.

But essentially, we have here the difference between ``Walking towards a
destination'' and ``Walking downhill''.

Or, a planned economy and a market economy. But, we don't live in
\emph{either}: everyone lives in some mixture of the two.

So, is there a synthesis of these two approaches that makes sense?

\hypertarget{risk-first-estimating}{%
\section{Risk-First Estimating}\label{risk-first-estimating}}

One approach

Devops approach.

\end{document}  