\frontmatter

This is part of the risk first series.

sdfds f sd sd f sdf

Published by.

On.

Stuff;

Dedicated to blan

\setcounter{tocdepth}{0}
\tableofcontents

\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

Welcome to Risk-First

Scrum, Waterfall, Lean, Prince2: what do they all have in common?

One perspective is that they are individual
\href{https://en.wikipedia.org/wiki/Software_development_process\#Methodologies}{software
methodologies}, offering different viewpoints on how to build software.

However, here, we are going to consider a second perspective: that
building software is all about \emph{managing risk}, and that these
methodologies are acknowledgements of this fact, and they differ because
they have \emph{different ideas} about which are the most important
\emph{risks to manage}.

\hypertarget{goal}{%
\section{Goal}\label{goal}}

Hopefully, after reading through some of the articles here, you'll come
away with:

\begin{itemize}
\tightlist
\item
  An appreciation of how risk underpins everything we do as developers,
  whether we want it to or not.
\item
  A framework for evaluating
  \href{https://en.wikipedia.org/wiki/Software_development_process\#Methodologies}{software
  methodologies} and choosing the right one for the task-at-hand.
\item
  A recontextualization of the software process as being an exercise in
  mitigating different kinds of risk.
\item
  The tools to help you decide when a methodology is \emph{letting you
  down}, and the vocabulary to argue for when it's a good idea to
  deviate from it.
\end{itemize}

\hypertarget{what-this-is-not}{%
\section{What This is Not}\label{what-this-is-not}}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change \textbf{too fast}.)

Neither is this site isn't going to be an exhaustive guide of every
possible software development practice and methodology. That would just
be too long and tedious.

Neither is this really a practitioner's guide to using any particular
methodology: If you've come here to learn the best way to do
\textbf{Retrospectives}, then you're in the wrong place. There are
plenty of places you can find that information already. Where possible,
this site will link to or reference concepts on Wikipedia or the wider
internet for further reading on each subject.

Lastly, although this is a
\href{https://en.wikipedia.org/wiki/Wiki}{Wiki}, it's not meant to be an
open-ended discussion of software techniques like
\href{http://wiki.c2.com}{Ward's Wiki}. In order to be concise and
useful, discussions need to be carried out by
\href{https://github.com/risk-first/website/issues}{Opening an Issue}.

\mainmatter
\part{Introduction}

\hypertarget{a-simple-scenario}{%
\chapter{A Simple Scenario}\label{a-simple-scenario}}

Hi.

Welcome to the Risk-First Wiki.

I've started this website because, on my career journey, I've noticed
that the way I do things doesn't seem to match up with the way the books
\emph{say} it should be done. And, I found this odd and wanted to
explore it further. Hopefully, you, the reader, will find something of
use in this.

First up, I'm going to introduce a simple model for thinking about risk.

\hypertarget{a-simple-scenario-1}{%
\section{A Simple Scenario}\label{a-simple-scenario-1}}

Lets for a moment forget about software completely, and think about
\emph{any endeavor at all} in life. It could be passing a test, mowing
the lawn or going on holiday. Choose something now. I'll discuss from
the point of view of ``cooking a meal for some friends'', but you can
play along with your own example.

\hypertarget{goal-in-mind}{%
\subsection{Goal In Mind}\label{goal-in-mind}}

Now, in this endeavour, we want to be successful. That is to say, we
have a \textbf{Goal In Mind}: we want our friends to go home satisfied
after a decent meal, and not to feel hungry. As a bonus, we might also
want to spend time talking with them before and during the meal. So, now
to achieve our \textbf{Goal In Mind} we \emph{probably} have to do some
tasks.

If we do nothing, our friends will turn up and maybe there's nothing in
the house for them to eat. Or maybe, the thing that you're going to cook
is going to take hours and they'll have to sit around and wait for you
to cook it and they'll leave before it's ready. Maybe you'll be some
ingredients short, or maybe you're not confident of the steps to prepare
the meal and you're worried about messing it all up.

\hypertarget{attendant-risk}{%
\subsection{Attendant Risk}\label{attendant-risk}}

These \emph{nagging doubts} that are going through your head I'll call
the \textbf{Attendant Risks}: they're the ones that will occur to you as
you start to think about what will happen.

\begin{figure}
\centering
\includegraphics{images/goal_in_mind.png}
\caption{Goal In Mind}
\end{figure}

When we go about preparing this wonderful evening, we can with these
risks and try to mitigate them: shop for the ingredients in advance,
prepare parts of the meal, maybe practice the cooking in advance. Or, we
can wing it, and sometimes we'll get lucky.

How much effort we expend on mitigating \textbf{Attendant Risks} depends
on how great we think they are: for example, if you know it's a 24-hour
shop, you'll probably not worry too much about getting the ingredients
well in advance (although, the shop \emph{could still be closed}).

\hypertarget{hidden-risks}{%
\subsection{Hidden Risks}\label{hidden-risks}}

There are also hidden \textbf{Attendant Risks} that you might not know
about: if you're poaching eggs for dinner, you might know that fresh
eggs poach best. These are the ``Unknown Unknowns'' of
\href{https://en.wikipedia.org/wiki/There_are_known_knowns}{Rumsfeld's
model}.

\begin{figure}
\centering
\includegraphics{images/hidden_risk.png}
\caption{Goal In Mind}
\end{figure}

Different people will evaluate the risks differently. (That is, worry
about them more or less.) They'll also \emph{know} about different
risks. They might have cooked the recipe before, or organised lots more
dinner parties than you.

How we evaluate the risks, and which ones we know about depends on our
\textbf{knowledge} and \textbf{experience}, then. And that varies from
person to person (or team to team). Lets call this our \textbf{Internal
Model}, and it's something we build on and improve with experience (of
organising dinner parties, amongst everything else).

\hypertarget{model-meets-reality}{%
\subsection{Model Meets Reality}\label{model-meets-reality}}

As the dinner party gets closer, we make our preparations, and the
inadequacies of the \textbf{Internal Model} become apparent, and we
learn what we didn't know. The \textbf{Hidden Risks} reveal themselves;
things we were worried about may not materialise, things we thought
would be minor risks turn out to be greater.

Our model is forced into contact with reality, and the model changes.

\begin{figure}
\centering
\includegraphics{images/reality.png}
\caption{Reality}
\end{figure}

If we had a good model, and took the right actions, we should see
positive outcomes. If we failed to mitigate risks, or took inappropriate
actions, we'll probably see negative outcomes.

\hypertarget{on-to-software}{%
\section{On To Software}\label{on-to-software}}

In this website, we're going to look at the risks in the software
process and how these are mitigated by the various methodologies you can
choose from.

Let's examine the scenario of a new software project, and expand on the
simple model being outlined above: instead of a single person, we are
likely to have a team, and our model will not just exist in our heads,
but in the code we write.

On to \textbf{Development Process}

\hypertarget{development-process}{%
\chapter{Development Process}\label{development-process}}

In the \textbf{previous section} we looked at a simple model for risks
on any given activity.

Now, let's look at the everyday process of developing \emph{a new
feature} on a software project, and see how our risk model informs it.

\hypertarget{an-example-process}{%
\section{An Example Process}\label{an-example-process}}

Let's ignore for now the specifics of what methodology is being used -
we'll come to that later. Let's say your team have settled for a process
something like the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Specification}: A new feature is requested somehow, and a
  business analyst works to specify it.
\item
  \textbf{Code And Unit Test}: A developer writes some code, and some
  unit tests.
\item
  \textbf{Integration}: They integrate their code into the code base.
\item
  \textbf{UAT}: They put the code into a User Acceptance Test (UAT)
  environment, and user(s) test it.
\end{enumerate}

\ldots{} All being well, the code is released to production.

Now, it might be waterfall, it might be agile, we're not going to commit
to specifics at this stage. It's probably not perfect, but let's just
assume that \emph{it works for this project} and everyone is reasonably
happy with it.

I'm not saying this is the \emph{right} process, or even a \emph{good}
process: you could add code review, a pilot, integration testing,
whatever. We're just doing some analysis of \emph{what process gives
us}.

\begin{figure}
\centering
\includegraphics{images/dev_process1.png}
\caption{Development Process}
\end{figure}

What's happening here? Why these steps?

\hypertarget{minimizing-risks---overview}{%
\section{Minimizing Risks -
Overview}\label{minimizing-risks---overview}}

I am going to argue that this entire process is \emph{informed by
software risk}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We have \emph{a business analyst} who talks to users and fleshes out
  the details of the feature properly. This is to minimize the risk of
  \textbf{building the wrong thing}.
\item
  We \emph{write unit tests} to minimize the risk that our code
  \textbf{isn't doing what we expected, and that it matches the
  specifications}.
\item
  We \emph{integrate our code} to minimize the risk that it's
  \textbf{inconsistent with the other, existing code on the project}.\\
\item
  We have \emph{acceptance testing} and quality gates generally to
  \textbf{minimize the risk of breaking production}, somehow.
\end{enumerate}

We could skip all those steps above and just do this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Developer gets wind of new idea from user, logs onto production and
  changes some code directly.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/dev_process2.png}
\caption{Development Process}
\end{figure}

We can all see this would be a disaster, but why?

Two reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  You're meeting reality all-in-one-go: all of these risks materialize
  at the same time, and you have to deal with them all at once.
\item
  Because of this, at the point you put code into the hands of your
  users, your \textbf{Internal Model} is at its least-developed. All the
  \textbf{Hidden Risks} now need to be dealt with at the same time, in
  production.
\end{enumerate}

\hypertarget{applying-the-model}{%
\section{Applying the Model}\label{applying-the-model}}

Let's look at how our process should act to prevent these risks
materializing by considering an unhappy path, one where at the outset,
we have lots of \textbf{Hidden Risks} ready to materialize. Let's say a
particularly vocal user rings up someone in the office and asks for new
\textbf{Feature X} to be added to the software. It's logged as a new
feature request, but:

\begin{itemize}
\tightlist
\item
  Unfortunately, this feature once programmed will break an existing
  \textbf{Feature Y}\\
\item
  Implementing the feature will use some api in a library, which
  contains bugs and have to be coded around.\\
\item
  It's going to get misunderstood by the developer too, who is new on
  the project and doesn't understand how the software is used.\\
\item
  Actually, this functionality is mainly served by \textbf{Feature
  Z}\ldots{}
\item
  which is already there but hard to find.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/dev_process_hidden_risks.png}
\caption{Development Process - Hidden Risks}
\end{figure}

This is a slightly contrived example, as you'll see. But let's follow
our feature through the process and see how it meets reality slowly, and
the hidden risks are discovered:

\hypertarget{specification}{%
\subsection{Specification}\label{specification}}

The first stage of the journey for the feature is that it meets the
Business Analyst (BA). The \emph{purpose} of the BA is to examine new
goals for the project and try to integrate them with \emph{reality as
they understands it}. A good BA might take a feature request and vet it
against the internal logic of the project, saying something like:

\begin{itemize}
\tightlist
\item
  ``This feature doesn't belong on the User screen, it belongs on the
  New Account screen''
\item
  ``90\% of this functionality is already present in the Document Merge
  Process''
\item
  ``We need a control on the form that allows the user to select between
  Internal and External projects''
\end{itemize}

In the process of doing this, the BA is turning the simple feature
request \emph{idea} into a more consistent, well-explained
\emph{specification} or \emph{requirement} which the developer can pick
up. But why is this a useful step in our simple methodology? From the
perspective of our \textbf{Internal Model}, we can say that the BA is
responsible for:

\begin{itemize}
\tightlist
\item
  Trying to surface \textbf{Hidden Risks}
\item
  Trying to evaluate \textbf{Apparent Risk} and make it clear to
  everyone on the project.
\end{itemize}

Hopefully, after this stage, our \textbf{Internal Model} might look
something like this:

\begin{figure}
\centering
\includegraphics{images/dev_process_ba.png}
\caption{BA Specification}
\end{figure}

In surfacing these risks, there is another outcome: while
\textbf{Feature X} might be flawed as originally presented, the BA can
``evolve'' it into a specification, and tie it down sufficiently to
reduce the risks. The BA does all this by simply \emph{thinking about
it}, \emph{talking to people} and \emph{writing stuff down}.

This process of evolving the feature request into a requirement is the
BAs job. From our risk-first perspective, it is \emph{taking an idea and
making it meet reality}. Not the \emph{full reality} of production
(yet), but something more limited. After its brush with reality, the
\textbf{goal in mind} has \emph{evolved} from being \textbf{Feature X
(Idea)} to \textbf{Feature X (Specification)}.

\hypertarget{code-and-unit-test}{%
\subsection{Code And Unit Test}\label{code-and-unit-test}}

The next stage for our feature, \textbf{Feature X (Specification)} is
that it gets coded and some tests get written. Let's look at how our
\textbf{goal in mind} meets a new reality: this time it's the reality of
a pre-existing codebase, which has it's own internal logic.

As the developer begins coding the feature in the software, she will
start with an \textbf{Internal Model} of the software, and how the code
fits into it. But, in the process of implementing it, she is likely to
learn about the codebase, and her \textbf{Internal Model} will develop.

To a large extent, this is the whole point of \emph{type safety}: to
ensure that your \textbf{Internal Model} stays consistent with the
reality of the codebase. If you add code that doesn't fit the reality of
the codebase, you'll know about it with compile errors.

The same thing is true of writing unit tests: again you are testing your
\textbf{Internal Model} against the reality of the system being built,
running in your development environment. Hopefully, this will surface
some new hidden risks, and again, because the \textbf{goal in mind} has
met reality, it is changed, to \textbf{Feature X (Code)}.

\begin{figure}
\centering
\includegraphics{images/dev_process_code.png}
\caption{Coding Process}
\end{figure}

\hypertarget{integration}{%
\subsection{Integration}\label{integration}}

Integration is where we run \emph{all} the tests on the project, and
compile \emph{all} the code in a clean environment: the ``reality'' of
the development environment can vary from one developer's machine to
another.

So, this stage is about the developer's committed code meeting a new
reality: the clean build.

At this stage, we might discover the \textbf{Hidden Risk} that we'd
break \textbf{Feature Y}

\begin{figure}
\centering
\includegraphics{images/dev_process_integration.png}
\caption{Integration}
\end{figure}

\hypertarget{uat}{%
\subsection{UAT}\label{uat}}

Is where our feature meets another reality: \emph{actual users}. I think
you can see how the process works by now. We're just flushing out yet
more \textbf{Hidden Risks}:

\begin{figure}
\centering
\includegraphics{images/dev_process_uat.png}
\caption{UAT}
\end{figure}

\hypertarget{observations}{%
\section{Observations}\label{observations}}

A couple of things:

\textbf{First}, the people setting up the development process
\emph{didn't know} about these \emph{exact} risks, but they knew the
\emph{shape that the risks take}. The process builds ``nets'' for the
different kinds of hidden risks without knowing exactly what they are.
Part of the purpose of this site is to help with this and try and
provide a taxonomy for different types of risks.

\textbf{Second}, are these really risks, or are they \emph{problems we
just didn't know about}? I am using the terms interchangeably, to a
certain extent. Even when you know you have a problem, it's still a risk
to your deadline until it's solved. So, when does a risk become a
problem? Is a problem still just a schedule-risk, or cost-risk? It's
pretty hard to draw a line and say exactly.

\textbf{Third}, the real take-away from this is that all these risks
exist because we don't know 100\% how reality is. Risk exists because we
don't (and can't) have a perfect view of the universe and how it'll
develop. Reality is reality, \emph{the risks just exist in our head}.

\textbf{Fourth}, hopefully you can see from the above that really
\emph{all this work is risk management}, and \emph{all work is testing
ideas against reality}.

\hypertarget{conclusion}{%
\section{Conclusion?}\label{conclusion}}

Could it be that \emph{everything} you do on a software project is risk
management? This is an idea explored in \textbf{the next section}.

\hypertarget{all-risk-management}{%
\chapter{All Risk Management}\label{all-risk-management}}

In this section, I am going to introduce the idea that everything you do
on a software project is Risk Management.

In the \textbf{last section}, we observed that all the activities in a
simple methodology had a part to play in exposing different risks. They
worked to manage risk prior to them creating bigger problems in
production.

Here, we'll look at one of the tools in the Project Manager's toolbox,
the \href{http://pmtips.net/blog-new/raid-logs-introduction}{RAID Log},
and observe how risk-centric it is.

\hypertarget{raid-log}{%
\section{RAID Log}\label{raid-log}}

Many project managers will be familiar with the
\href{http://pmtips.net/blog-new/raid-logs-introduction}{RAID Log}. It's
simply four columns on a spreadsheet:

\begin{itemize}
\tightlist
\item
  Risks
\item
  Actions
\item
  Issues
\item
  Decisions
\end{itemize}

Let's try and put the following \textbf{Attendant Risk} into the RAID
Log:

\begin{quote}
Debbie needs to visit the client to get them to choose the logo to use
on the product, otherwise we can't size the screen areas exactly.
\end{quote}

\begin{itemize}
\tightlist
\item
  So, is this an \textbf{action}? Certainly. There's definitely
  something for Debbie to do here.
\item
  Is it an \textbf{issue}? Yes, because it's holding up the screen-areas
  sizing thing.
\item
  Is it a \textbf{decision}? Well, clearly, it's a decision for someone.
\item
  Is it a \textbf{risk}? Probably: Debbie might go to the client and
  they \emph{still} don't make a decision. What then?
\end{itemize}

\hypertarget{lets-go-again}{%
\section{Let's Go Again}\label{lets-go-again}}

This is a completely made-up example, deliberately chosen to be hard to
categorize. Normally, items are more one thing than another. But often,
you'll have to make a choice between two categories, if not all four.

This hints at the fact that at some level it's All Risk:

\hypertarget{every-action-mitigates-risk}{%
\subsection{Every Action Mitigates
Risk}\label{every-action-mitigates-risk}}

The reason you are \emph{taking} an action is to mitigate a risk. For
example, if you're coing up new features in the software, this is
mitigating \textbf{Feature Risk}. If you're getting a business sign-off
for something, this is mitigating a \textbf{Too Many Cooks}-style
\emph{stakeholder risk}.

\hypertarget{every-action-carries-risk.}{%
\subsection{Every Action Carries
Risk.}\label{every-action-carries-risk.}}

\begin{itemize}
\tightlist
\item
  How do you know if the action will get completed?\\
\item
  Will it overrun on time?\\
\item
  Will it lead to yet more actions?
\end{itemize}

Consider \emph{coding a feature} (as we did in the earlier
\textbf{Development Process} section). We saw here how the whole process
of coding was an exercise in learning what we didn't know about the
world, uncovering problems and improving our \textbf{Internal Model}.
That is, flushing out the \textbf{Attendant Risk} of the \textbf{Goal In
Mind}.

And, as we saw in the \textbf{Introduction}, even something
\emph{mundane} like the Dinner Party had risks.

\hypertarget{an-issue-is-just-a-type-of-risk}{%
\subsection{An Issue is Just A Type of
Risk}\label{an-issue-is-just-a-type-of-risk}}

\begin{itemize}
\tightlist
\item
  Because issues need to be solved\ldots{}\\
\item
  And solving an issue is an action\ldots{}
\item
  Which, as we just saw also carry risk.
\end{itemize}

One retort to this might be to say: an issue is a problem I have now,
whereas a risk is a problem that \emph{might} occur. I am going to try
and \emph{break} that mindset in the coming pages, but I'll just start
with this:

\begin{itemize}
\tightlist
\item
  Do you know \emph{exactly} how much damage this issue will do?
\item
  Can you be sure that the issue might not somehow go away?
\end{itemize}

\emph{Issues} then, just seem more ``definite'' and ``now'' than
\emph{risks}, right? This classification is arbitrary: they're all just
part of the same spectrum, so stop agonising over which column to put
them in.

\hypertarget{every-decision-is-a-risk.}{%
\subsection{Every Decision is a Risk.}\label{every-decision-is-a-risk.}}

\begin{itemize}
\tightlist
\item
  By the very nature of having to make a decision, there's the risk
  you'll decide wrongly.
\item
  And, there's the time it takes to make the decision.
\item
  And what's the risk if the decision doesn't get made?
\end{itemize}

\hypertarget{what-to-do}{%
\section{What To Do?}\label{what-to-do}}

It makes it much easier to tackle the RAID log if there's only one list:
all you do is pick the worst risk on the list, and deal with it. (In
\textbf{Risk Theory} we look at how to figure out which one that is).

OK, so maybe that \emph{works} for a RAID log (or a Risk log, since
we've thrown out the others), but does it scale to a whole project?

In the next section, \textbf{Software Project Scenario} I will make a
slightly stronger case for the idea that it does.

\hypertarget{software-project-scenario}{%
\chapter{Software Project Scenario}\label{software-project-scenario}}

Where do the risks of the project lie?

How do we decide what \emph{needs to be done today} on a software
project?

Let's look again at the simple risk framework from the
\textbf{introduction} and try to apply it at the level of the
\emph{entire project}.

\begin{figure}
\centering
\includegraphics{images/reality.png}
\caption{Reality}
\end{figure}

\hypertarget{goal-in-mind-1}{%
\section{Goal In Mind}\label{goal-in-mind-1}}

How should we decide how to spend our time today?

What actions should we take? (In \textbf{Scrum} terminology, what is our
\emph{Sprint Goal}?).

If we want to take the right actions, we need to have a good
\textbf{Internal Model}.

Sometimes, we will know that our model is deficient, and our time should
be spend \emph{improving} it, perhaps by talking to our clients, or the
support staff, or other developers, or reading.

But let's say for example, today our \textbf{Goal In Mind} is to grow
our user base.

\hypertarget{attendant-risks}{%
\section{Attendant Risks}\label{attendant-risks}}

What are the \textbf{Attendant Risks} that come with that goal? Here are
some to get us started:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The users can't access the system
\item
  The data gets lost, stolen.
\item
  The data is wrong or corrupted
\item
  There are bugs that prevent the functionality working
\item
  The functionality isn't there that the user needs (\textbf{Feature
  Risk}).
\item
  Our \textbf{Internal Model} of the market is poor, and we could be
  building the wrong thing.
\end{enumerate}

I'm sure you can think of some more.

\hypertarget{evaluating-the-risks}{%
\section{Evaluating The Risks}\label{evaluating-the-risks}}

Next, we can look at each of these risks and consider the threat they
represent. Usually, when \textbf{evaluating a risk} we consider both
it's \textbf{impact} and \textbf{likelihood}.

The same \textbf{Attendant Risks} will be evaluated differently
depending on the \emph{nature of the project} and the mitigations you
already have in place. For example:

\begin{itemize}
\tightlist
\item
  If they \textbf{can't access it}, does that mean that they're stuck
  unable to get on the train? Or they can't listen to music?\\
\item
  If the \textbf{data is lost}, does this mean that no one can get on
  the plane? Or that the patients have to have their CAT scans done
  again? Or that people's private information is scattered around the
  Internet?
\item
  If the \textbf{data is wrong}, does that mean that the wrong people
  get sent their parcels? Do they receive the wrong orders? Do they end
  up going to the wrong courses?
\item
  If there are \textbf{bugs}, does it mean that their pictures don't end
  up on the internet? Does it mean that they have to restart the
  program? Does it mean that they'll waste time, or that they end up
  thinking they have insurance but haven't?\\
\item
  If there is \textbf{missing functionality}, will they not buy the
  system? Will they use a competitor's product? Will they waste time
  doing things a harder or less optimal way?
\item
  If our ****Internal Model** is wrong**, then is there a chance we are
  building something for a non-existent market? Or annoying our
  customers? Or leaving an opportunity for competitors?
\end{itemize}

\hypertarget{outcomes}{%
\section{Outcomes}\label{outcomes}}

As part of evaluating the risks, we can also \emph{predict} the negative
outcomes if these risks materialise and we don't take action.

\begin{itemize}
\tightlist
\item
  Losing Revenue
\item
  Legal Culpability
\item
  Losing Users
\item
  Bad Reputation
\item
  etc.
\end{itemize}

\hypertarget{a-single-attendant-risk-getting-hacked}{%
\section{A Single Attendant Risk: Getting
Hacked}\label{a-single-attendant-risk-getting-hacked}}

Let's consider a single risk: that the website gets hacked, and
sensitive data is stolen. How we evaluate this risk is going to depend
on a number of factors:

\begin{itemize}
\tightlist
\item
  How many users we have
\item
  The importance of the data
\item
  How much revenue will be lost
\item
  Risk of litigation
\item
  etc.
\end{itemize}

\hypertarget{ashley-maddison}{%
\subsubsection{Ashley Maddison}\label{ashley-maddison}}

We've seen
\href{https://www.acunetix.com/blog/articles/password-hashing-and-the-ashley-madison-hack/}{in
the example of hacks on LinkedIn and Ashley Maddison} that passwords
were not held as hashes in the database. (A practice which experienced
developers mainly would see as negligent).

How does our model explain what happened here?

\begin{itemize}
\tightlist
\item
  It's possible that \emph{at the time of implementing the password
  storage}, hashing was considered, but the evaluation of the risk was
  low: Perhaps, the risk of not shipping quickly was deemed greater. And
  so they ignored this concern.
\item
  It's also possible that for the developers in question this was a
  \textbf{Hidden Risk}, and they hadn't even considered it.
\item
  However, as the number of users of the sites increased, the risk
  increased too, but there was no re-evaluation of the risk otherwise
  they would have addressed it. This was a costly \emph{failure to
  update the \textbf{Internal Model}}.
\end{itemize}

\hypertarget{possible-action}{%
\subsubsection{Possible Action}\label{possible-action}}

When exposing a service on the Internet, it's now a good idea to
\emph{look for trouble}: you should go out and try and improve your
\textbf{Internal Model}.

Thankfully, this is what sites like
\href{https://www.owasp.org/index.php/Top_10-2017_Top_10}{OWASP} are
for: they \emph{tell you about the \textbf{Attendant Risks}} and
further, try to provide some evaluation of them to guide your actions.

\hypertarget{actions}{%
\section{Actions}\label{actions}}

So, this gives us a guide for one potential action we could take
\emph{today}. But on it's own, this isn't helpful: we would need to
consider this action against the actions we could take to mitigate the
other risks. Can we answer this question:

Which actions give us the biggest benefit in terms of mitigating the
\textbf{Attendant Risks}?

That is, we consider for each possible action:

\begin{itemize}
\tightlist
\item
  The Impact and Likelihood of the \textbf{Attendant Risks} it mitigates
\item
  The Cost of the Action
\end{itemize}

For example, it's worth considering that if we're just starting this
project, risks 1-4 are \emph{negligible}, and we're only going to spend
time building functionality or improving our understanding of the
market. (Which makes sense, right?)

\hypertarget{tacit-and-explicit-modelling}{%
\section{Tacit and Explicit
Modelling}\label{tacit-and-explicit-modelling}}

As we saw in the example of the \textbf{Dinner Party}, creating an
internal model is something \emph{we just do}: we have this
functionality in our brains already. When we scale this up to a whole
project team, we can expect the individuals on the project to continue
to do this, but we might also want to consider \emph{explicitly}
creating a \textbf{risk register for the whole project}.

Whether we do this explicitly or not, we are still individually
following this model.

In the next section, we're going to take a quick aside into looking at
some \textbf{Risk Theory}.

\hypertarget{risk-theory}{%
\chapter{Risk Theory}\label{risk-theory}}

Here, I am going to recap on some pre-existing knowledge about risk,
generally, in order to set the scene for the next section on
\textbf{Meeting Reality}.

\hypertarget{risk-registers}{%
\section{Risk Registers}\label{risk-registers}}

In the previous section \textbf{Software Project Scenario} we saw how
you try to look across the \textbf{Attendant Risks} of the project, in
order to decide what to do next.

A \href{https://en.wikipedia.org/wiki/Risk_register}{Risk Register} can
help with this. From Wikipedia:

\begin{quote}
A typical risk register contains:

\begin{itemize}
\tightlist
\item
  A risk category to group similar risks
\item
  The risk breakdown structure identification number
\item
  A brief description or name of the risk to make the risk easy to
  discuss
\item
  The impact (or consequence) if event actually occurs rated on an
  integer scale
\item
  The probability or likelihood of its occurrence rated on an integer
  scale
\item
  The Risk Score (or Risk Rating) is the multiplication of Probability
  and Impact and is often used to rank the risks.
\item
  Common mitigation steps (e.g.~within IT projects) are Identify,
  Analyze, Plan Response, Monitor and Control.
\end{itemize}
\end{quote}

This is Wikipedia's example:

\begin{figure}
\centering
\includegraphics{images/WikipediaRiskRegister2.png}
\caption{Wikipedia Risk Register}
\end{figure}

Some points about this description:

\hypertarget{this-is-a-bells-and-whistles-description}{%
\subsection{This is a Bells-and-Whistles
Description}\label{this-is-a-bells-and-whistles-description}}

Remember back to the Dinner Party example at the start: the Risk
Register happened \emph{entirely in your head}. There is a continuum all
the way from ``in your head'' to Wikipedia's Risk Register description.
Most of the time, it's going to be in your head, or in discussion with
the team, rather than written down.

Most of the value of the \textbf{Risk-First} approach is \emph{in
conversation}. Later, we'll have an example to show how this can work
out.

\hypertarget{probability-and-impact}{%
\subsection{Probability And Impact}\label{probability-and-impact}}

Sometimes, it's better to skip these, and just figure out a Risk Score.
This is because if you think about ``impact'', it implies a definite,
discrete event occurring, or not occurring, and asks you then to
consider the probability of that occurring.

\textbf{Risk-First} takes a view that risks are a continuous quantity,
more like \emph{money} or \emph{water}: by taking an action before
delivering a project you might add a degree of \textbf{Schedule Risk},
but decrease the \textbf{Production Risk} later on by a greater amount.

\hypertarget{graphical-analysis}{%
\section{Graphical Analysis}\label{graphical-analysis}}

The \href{https://en.wikipedia.org/wiki/Risk_register}{Wikipedia page}
also includes this wonderful diagram showing you risks of a poorly run
barbecue party:

\begin{figure}
\centering
\includegraphics{images/WikipediaRiskRegister1.png}
\caption{Wikipedia Risk Register}
\end{figure}

This type of graphic is \emph{helpful} in deciding what to do next,
although personally I prefer to graph the overall \textbf{Risk Score}
against the \textbf{Cost of Mitigation}: easily mitigated, but expensive
risks can therefore be dealt with first (hopefully).

\hypertarget{unknown-unknowns}{%
\section{Unknown Unknowns}\label{unknown-unknowns}}

In Wikipedia's example, this ficticious BBQ has high fire risk, so one
should begin mitigating there.

But, does this feel right? One of the criticisms of the Risk Register
approach is that of \textbf{mistaking the map for the territory}. That
is, mistakenly believing that what's on the Risk Register \emph{is all
there is}.

In the preceding discussions, I have been careful to point out the
existence of \textbf{Hidden Risks} for that very reason. Or, to put
another way:

\begin{quote}
What we don't know is what usually gets us killed - Petyr Baelish
\end{quote}

Donald Rumsfeld's famous
\href{https://en.wikipedia.org/wiki/There_are_known_knowns}{Known
Knowns} is also a helpful conceptualization.

\hypertarget{risk-and-uncertainty}{%
\section{Risk And Uncertainty}\label{risk-and-uncertainty}}

Arguably, this site uses the term `Risk' wrongly: most literature
suggests
\href{https://keydifferences.com/difference-between-risk-and-uncertainty.html}{risk
can be measured} whereas uncertainty represents things that cannot.

I am using \textbf{risk} everywhere because later we will talk about
specific risks (e.g. \textbf{Executable Boundary Risk} or
\textbf{Technical Debt Risk}), and it doesn't feel grammatically correct
to talk about those as \textbf{uncertainties}, especially given the
pre-existing usage in Banking of terms like
\href{https://en.wikipedia.org/wiki/Operational_risk}{Operational risk}
or
\href{https://www.investopedia.com/terms/r/reputational-risk.asp}{Reputational
risk} which are also not really a-priori measurable.

\hypertarget{the-opposite-of-risk-management}{%
\section{The Opposite Of Risk
Management}\label{the-opposite-of-risk-management}}

Let's look at the classic description of Risk Management:

\begin{quote}
Risk Management is the process of thinking out corrective actions before
a problem occurs, while it's still an abstraction.\\
The opposite of risk management is crisis management, trying to figure
out what to do about the problem after it happens. - Waltzing With
Bears, Tom De Marco \& Tim Lister
\end{quote}

This is not how \textbf{Risk-First} sees it:

First, we have the notion that Risks are discrete events, again. Some
risks \emph{are} (like gambling on a horse race), but most
\emph{aren't}. In the \textbf{Dinner Party}, for example, bad
preparation is going to mean a \emph{worse} time for everyone, but how
good a time you're having is a spectrum, it doesn't divide neatly into
just ``good'' or ``bad''.

Second, the opposite of ``Risk Management'' (or trying to minimize the
``Downside'') is either ``Upside Risk Management'', (trying to maximise
the good things happening), or it's trying to make as many bad things
happen as possible. Humans tend to be optimists (especially when there
are lots of \textbf{Hidden Risks}), hence our focus on Downside Risk.
Sometimes though, it's good to stand back and look at a scenario and
think: am I capturing all the Upside Risk here?

Finally, Crisis Management is \emph{still just Risk Management}: the
crisis (Earthquake, whatever) has \emph{happened}. You can't manage it
because it's in the past. All you can do is Risk Manage the future
(minimize further casualties and human suffering, for example).

Yes, it's fine to say ``we're in crisis'', but to assume there is a
different strategy for dealing with it is a mistake: this is the
\href{https://en.wikipedia.org/wiki/Sunk_costs}{Fallacy of Sunk Costs}.

\hypertarget{scale-and-panic-invariance}{%
\section{Scale and Panic Invariance}\label{scale-and-panic-invariance}}

tbd.

\hypertarget{value}{%
\section{Value}\label{value}}

``Upside Risk'' isn't a commonly used term: industry tends to prefer
``value'', as in ``Is this a value-add project?''. There is plenty of
theory surrounding \textbf{Value}, such as Porter's \textbf{Value Chain}
and \textbf{Net Present Value}. This is all fine so long as we remember:

\begin{itemize}
\tightlist
\item
  \textbf{The pay-off is risky}: Since the \textbf{Value} is created in
  the future, we can't be certain about it happening - we should never
  consider it a done-deal. \textbf{Future Value} is always at risk. In
  finance, for example, we account for this in our future cash-flows by
  discounting them according to the risk of default.
\item
  \textbf{The pay-off amount is risky}: Additionally, whereas in a
  financial transaction (like a loan, say), we might know the size of a
  future payment, in IT projects we can rarely be sure that they will
  deliver a certain return. On some fixed-contract projects this
  sometimes is not true: there may be a date when the
  payment-for-delivery gets made, but mostly we'll be expecting an
  uncertain pay-off.
\end{itemize}

\hypertarget{time-value-of-risk}{%
\section{Time Value of Risk}\label{time-value-of-risk}}

In exactly th

\hypertarget{urgency-vs-importance}{%
\section{Urgency vs Importance}\label{urgency-vs-importance}}

--eisenhower's box tbd

\hypertarget{discounting-the-future-to-zero}{%
\section{Discounting the Future To
Zero}\label{discounting-the-future-to-zero}}

\begin{itemize}
\tightlist
\item
  more pressure, heavier discounting pooh bear procrastination
\end{itemize}

\hypertarget{is-this-scientific}{%
\section{Is This Scientific?}\label{is-this-scientific}}

\textbf{Risk-First} is an attempt to provide a practical framework,
rather than a scientifically rigorous analysis. In fact, my view is that
you should \emph{give up} on trying to compute risk numerically. You
\emph{can't} work out how long a software project will take based purely
on an analysis of (say) \emph{function points}. (Whatever you define
them to be).

\begin{itemize}
\tightlist
\item
  First, there isn't enough evidence for an approach like this. We
  \emph{can} look at collected data about IT projects, but
  \textbf{techniques and tools change}.
\item
  Second, IT projects have too many confounding factors, such as
  experience of the teams, technologies used etc. That is, the risks
  faced by IT projects are \emph{too diverse} and \emph{hard to
  quantify} to allow for meaningful comparison from one to the next.
\item
  Third, as soon as you \emph{publish a date} it changes the
  expectations of the project (see \textbf{Student Syndrome}).
\item
  Fourth, metrics get first of all \textbf{misused} and then
  \textbf{gamed}.
\end{itemize}

Reality is messy. Dressing it up with numbers doesn't change that and
you risk \textbf{fooling yourself}. If this is the case, is there any
hope at all in what we're doing? I would argue yes: \emph{forget
precision}. You should, with experience be able to hold up two separate
risks and answer the question, ``is this one bigger than this one?''

Reality is Reality, \textbf{so let's meet it}.

\hypertarget{meeting-reality}{%
\chapter{Meeting Reality}\label{meeting-reality}}

In this section, we will look at how exposing your \textbf{Internal
Model} to reality is in itself a good risk management technique.

\hypertarget{revisiting-the-model}{%
\section{Revisiting the Model}\label{revisiting-the-model}}

In the \textbf{Introduction}, we looked at a basic model for how
\textbf{Reality} and our \textbf{Internal Model} interacted with each
other: we take action based on out \textbf{Internal Model}, hoping to
\textbf{change Reality} with some positive outcome.

And, in \textbf{Development Process} we looked at how we can meet with
reality in \emph{different forms}: Analysis, Testing, Integration and so
on, and saw how the model could work in each stage of a project.

Finally, in \textbf{Software Project Scenario} we looked at how we could
use this model on a day-to-day basis to inform what we should do next.

So, it should be no surprise to see that there is a \emph{recursive}
nature about this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \textbf{actions we take} each day have consequences: they
  \textbf{expose new }Hidden Risks****, which inform our
  \textbf{Internal Model}, and at the same time, they change reality in
  some way (otherwise, what would be the point of doing them?)
\item
  The actions we take towards achieving a \textbf{Goal In Mind} each
  have their \emph{own} \textbf{Goal In Mind}. And because of this, when
  we take action, we have to consider and evaluate the \textbf{Hidden
  Risks} exposed by that action. That is, there are many ways to
  achieving a goal, and these different ways expose different
  \textbf{Hidden Risks}.
\end{enumerate}

So, let's see how this kind of recursion looks on our model. Note that
here, I am showing \emph{just one possible action}, in reality, you'll
have choices.

\includegraphics{images/reality2.png} .

Hopefully, if you've read along so far, this model shouldn't be too hard
to understand. But, how is it helpful?

\hypertarget{navigating-the-risk-landscape}{%
\section{\texorpdfstring{``Navigating the \textbf{Risk
Landscape}''}{``Navigating the Risk Landscape''}}\label{navigating-the-risk-landscape}}

So, we often have multiple ways of achieving a \textbf{Goal In Mind}.

What's the best way?

I would argue that the best way is the one which accrues the \emph{least
risk} to get it done: each action you take in trying to achieve the
overall \textbf{Goal In Mind} will have it's \textbf{Attendant Risks},
and it's the experience you bring to bear on these that will help you
navigate through them smoothly.

Ideally, when you take an action, you are trading off a big risk for a
smaller one. Take Unit Testing for example. Clearly, writing Unit Tests
adds to the amount of development work, so on it's own, it adds
\textbf{Schedule Risk}. However, if you write \emph{just enough} of the
right Unit Tests, you should be short-cutting the time spent finding
issues in the User Acceptance Testing (UAT) stage, so you're hopefully
trading off a larger \textbf{Schedule Risk} from UAT and adding a
smaller risk to \textbf{Development}.

Sometimes, in solving one problem, you can end up somewhere
\emph{worse}: the actions you take to solve a higher-level
\textbf{Attendant Risk} will leave you with a worse \textbf{Attendant
Risks}. Almost certainly, this will have been a \textbf{Hidden Risk}
when you embarked on the action, otherwise you'd not have chosen it.

\hypertarget{a-quick-example}{%
\subsection{A Quick Example}\label{a-quick-example}}

On a recent project in a bank, we had a requirement to store a modest
amount of data and we needed to be able to retrieve it fast. The
developer chose to use \href{https://www.mongodb.com}{MongoDB} for this.
At the time, others pointed out that other teams in the bank had had
lots of difficulty deploying MongoDB internally, due to licensing issues
and other factors internal to the bank.

Other options were available, but the developer chose MongoDB because of
their \emph{existing familiarity} with it: therefore, they felt that the
\textbf{Hidden Risks} of MongoDB were \emph{lower} than the other
options, and disregarded the others' opinions.

The data storage \textbf{Attendant Risk} was mitigated easily with
MongoDB. However, the new \textbf{Attendant Risk} of licensing
bureacracy eventually proved too great, and MongoDB had to be abandoned
after much investment of time.

This is not a criticism of MongoDB: it's simply a demonstration that
sometimes, the cure is worse than the disease. Successful projects are
\emph{always} trying to \emph{reduce} \textbf{Attendant Risks}.

\hypertarget{the-cost-of-meeting-reality}{%
\section{The Cost Of Meeting
Reality}\label{the-cost-of-meeting-reality}}

Meeting reality is \emph{costly}, for example. Going to production can
look like this:

\begin{itemize}
\tightlist
\item
  Releasing software
\item
  Training users
\item
  Getting users to use your system
\item
  Gathering feedback
\end{itemize}

All of these steps take a lot of effort and time. But you don't have to
meet the whole of reality in one go - sometimes that is expensive. But
we can meet it in ``limited ways''.

In all, to de-risk, you should try and meet reality:

\begin{itemize}
\tightlist
\item
  \textbf{Sooner}, so you have time to mitigate the hidden risks it
  uncovers
\item
  \textbf{More Frequently}: so the hidden risks don't hit you all at
  once
\item
  \textbf{In Smaller Chunks}:
\end{itemize}

\hypertarget{yagni}{%
\subsection{YAGNI}\label{yagni}}

As a flavour of what's to come, let's look at
\href{https://www.martinfowler.com/bliki/Yagni.html}{YAGNI}, an acronym
for You Aren't Gonna Need It. Martin Fowler says:

\begin{quote}
Yagni originally is an acronym that stands for ``You Aren't Gonna Need
It''. It is a mantra from ExtremeProgramming that's often used generally
in agile software teams. It's a statement that some capability we
presume our software needs in the future should not be built now because
``you aren't gonna need it''.
\end{quote}

\begin{quote}
This principle was first discussed and fleshed out on
\href{http://wiki.c2.com/?YouArentGonnaNeedIt}{Ward's Wiki}
\end{quote}

The idea makes sense: if you take on extra work that you don't need,
\emph{of course} you'll be accreting \textbf{Attendant Risks}.

But, there is always the opposite opinion:
\href{http://wiki.c2.com/?YouAreGonnaNeedIt}{You Are Gonna Need It}. As
a simple example, we often add log statements in our code as we write
it, though following YAGNI strictly says we should leave it out.

\hypertarget{which-is-right}{%
\subsubsection{Which is right?}\label{which-is-right}}

Now, we can say: do the work \emph{if it mitigates your
\textbf{Attendant Risks}}.

\begin{itemize}
\tightlist
\item
  Logging statements are \emph{good}, because otherwise, you're
  increasing the risk that in production, no one will be able to
  understand \emph{how the software went wrong}.
\item
  However, adding them takes time, which might introduce
  \textbf{Schedule Risk}.
\end{itemize}

So, it's a trade-off: continue adding logging statements so long as you
feel that overall, you're reducing risk.

\hypertarget{do-the-simplest-thing-that-could-possibly-work}{%
\subsection{Do The Simplest Thing That Could Possibly
Work}\label{do-the-simplest-thing-that-could-possibly-work}}

Another mantra from Kent Beck (originator of the \textbf{Extreme
Programming} methodology, is ``Do The Simplest Thing That Could Possibly
Work'', which is closely related to YAGNI and is about looking for
solutions which are simple. Our risk-centric view of this strategy would
be:

\begin{itemize}
\tightlist
\item
  Every action you take on a project has it's own \textbf{Attendant
  Risks}.
\item
  The bigger or more complex the action, the more \textbf{Attendant
  Risk} it'll have.
\item
  The reason you're taking action \emph{at all} is because you're trying
  to reduce risk elsewhere on the project
\item
  Therefore, the biggest payoff is whatever action \emph{works} to
  remove that risk, whilst simultaneously picking up the least amount of
  new \textbf{Attendant Risk}.
\end{itemize}

So, ``Do The Simplest Thing That Could Possibly Work'' is really a
helpful guideline for Navigating the \textbf{Risk Landscape}.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

So, here we've looked at Meeting Reality, which basically boils down to
taking actions to manage risk and seeing how it turns out:

\begin{itemize}
\tightlist
\item
  Each Action you take is a step on the Risk Landscape
\item
  Each Action is a cycle around our model.
\item
  Each cycle, you'll expose new \textbf{Hidden Risks}, changing your
  \textbf{Internal Model}.
\item
  Preferably, each cycle should reduce the overall \textbf{Attendant
  Risk} of the \textbf{Goal}
\end{itemize}

Surely, the faster you can do this, the better? \textbf{Let's
investigate\ldots{}}

\hypertarget{cadence}{%
\chapter{Cadence}\label{cadence}}

Let's go back to the model again, introduced in \textbf{Meeting
Reality}:

\begin{figure}
\centering
\includegraphics{images/reality2.png}
\caption{Reality 2}
\end{figure}

As you can see, it's an idealized \textbf{Feedback Loop}.

How \emph{fast} should we go round this loop? Is there a right answer?
The longer you leave your \textbf{goal in mind}, the longer it'll be
before you find out how it really stacks up against reality.

Testing your \textbf{goals in mind} against reality early and safely is
how you'll manage risk effectively, and to do this, you need to set up
\textbf{Feedback Loops}. e.g.

\begin{itemize}
\tightlist
\item
  \textbf{Bug Reports and Feature Requests} tell you how the users are
  getting on with the software.
\item
  \textbf{Monitoring Tools and Logs} allow you to find out how your
  software is doing in reality.
\item
  \textbf{Dog-Fooding} i.e using the software you write yourself might
  be faster than talking to users.
\item
  \textbf{Continuous Delivery} (CD) is about putting software into
  production as soon as it's written.\\
\item
  \textbf{Integration Testing} is a faster way of meeting \emph{some}
  reality than continually deploying code and re-testing it manually.
\item
  \textbf{Unit Testing} is a faster feedback loop than Integration
  Testing.
\item
  \textbf{Compilation} warns you about logical inconsistencies in your
  code.
\end{itemize}

.. and so on.

\hypertarget{time-reality-trade-off}{%
\subsection{Time / Reality Trade-Off}\label{time-reality-trade-off}}

This list is arranged so that at the top, we have the most visceral,
most \emph{real} feedback loop, but at the same time, the slowest.

At the bottom, a good IDE can inform you about errors in your
\textbf{Internal Model} in real time, by way of highlighting compilation
errors . So, this is the fastest loop, but it's the most \emph{limited}
reality.

Imagine for a second that you had a special time-travelling machine.
With it, you could make a change to your software, and get back a report
from the future listing out all the issues people had faced using it
over its lifetime, instantly.

That'd be neat, eh? If you did have this, would there be any point at
all in a compiler? Probably not, right?

The whole \emph{reason} we have tools like compilers is because they
give us a short-cut way to get some limited experience of reality
\emph{faster} than would otherwise be possible. Because, cadence is
really important: the faster we test our ideas, the more quickly we'll
find out if they're correct or not.

\hypertarget{development-cycle-time}{%
\subsection{Development Cycle Time}\label{development-cycle-time}}

One thing that often astounds me is how developers can ignore the fast
feedback loops at the bottom of the list, because the ones nearer the
top \emph{will do}. In the worst cases, changing two lines of code,
running the build script, deploying and then manually testing out a
feature. And then repeating.

If you're doing it over and over, this is a terrible waste of time. And,
you get none of the benefit of a permanent suite of tests to run again
in the future.

The
\href{http://www.agilenutshell.com/episodes/41-testing-pyramid}{Testing
Pyramid} hints at this truth:

\begin{itemize}
\tightlist
\item
  \textbf{Unit Tests} have a \emph{fast feedback loop}, so have
  \emph{lots of them}.
\item
  \textbf{Integration Tests} have a slightly \emph{slower feedback
  loop}, so have \emph{few of them}. Use them when you can't write unit
  tests (at the application boundaries).
\item
  \textbf{Manual Tests} have a \emph{very slow feedback loop}, so have
  \emph{even fewer of them}. Use them as a last resort.
\end{itemize}

\hypertarget{production}{%
\subsection{Production}\label{production}}

You could take this section to mean that \textbf{Continuous Delivery}
(CD) is always and everywhere a good idea. I \emph{guess} that's not a
bad take-away, but it's clearly more nuanced than that.

Yes, CD will give you faster feedback loops, but getting things into
production is not the whole story: the feedback loop isn't complete
until people have used the code, and reported back to the development
team.

The right answer is to use the fastest feedback loop possible,
\emph{which actually does give you feed back}.

\hypertarget{recap}{%
\section{Recap}\label{recap}}

Let's look at the journey so far:

\begin{itemize}
\item
  In the \textbf{Introduction} we looked at how risk pervades every goal
  we have in life, big or small. We saw that risk stems from the fact
  that our \textbf{Internal Model} of the world couldn't capture
  everything about reality, and so some things were down to chance.
\item
  In the \textbf{Development Process} we looked at how common software
  engineering conventions like Unit Testing, User Acceptance Testing and
  Integration could help us manage the risk of taking an idea to
  production, by \emph{gradually} introducing it to reality in stages.
\item
  In \textbf{It's All Risk Management} we took a leap of faith: Could
  \emph{everything} we do just be risk management? And we looked at the
  RAID log and thought that maybe it could be.
\item
  Next, in \textbf{A Software Project Scenario} we looked at how you
  could treat the project-as-a-whole as a risk management exercise, and
  treat the goals from one day to the next as activities to mitigate
  risk.
\item
  \textbf{Some Risk Theory} was an aside, looking at some terminology
  and the useful concept of a Risk Register.
\item
  Then, generalizing the lessons of the Development Process article, we
  examined the idea that \textbf{Meeting Reality} frequently helps flush
  out \textbf{Hidden Risks} and improve your \textbf{Internal Model}.
\item
  Finally, above, we looked at \textbf{Cadence}, and how feedback loops
  allow you Navigate the Risk Landscape more effectively, by showing you
  more quickly when you're going wrong.
\end{itemize}

What this has been building towards is supplying us with a vocabulary
with which to communicate to our team-mates about which Risks are
important to us, which actions we believe are the right ones, and which
tools we should use.

Let's have a \textbf{look at an example} of how this might work:

\hypertarget{a-conversation}{%
\chapter{A Conversation}\label{a-conversation}}

After so much theory, it seems like it's time to look at how we can
apply these principles in the real world.

The following is based the summary of an issue from just a few weeks
ago. It's heavily edited and anonymized, and I've tried to add the
\textbf{Risk-First} vocabulary along the way, but otherwise, it's real.

Some background: \textbf{Synergy} is an online service with an
app-store, and \textbf{Eve} and \textbf{Bob} are developers working for
\textbf{Large Corporation LTD}, which wants to have an application
accepted into Synergy's app-store.

Synergy's release means that the app-store refresh will happen in a few
weeks, so this is something of a hard deadline: if we miss it, the next
release will be four months away.

\hypertarget{a-risk-conversation}{%
\section{A Risk Conversation}\label{a-risk-conversation}}

\textbf{Eve}: We've got a problem with the Synergy security review.

\textbf{Bob}: Tell me.

\textbf{Eve}: Well, you know Synergy did their review and asked us to
upgrade our Web Server to only allow TLS version 1.1 and greater?

\textbf{Bob}: Yes, I remember: We discussed it as a team and thought the
simplest thing would be to change the security settings on the Web
Server, but we all felt it was pretty risky. We decided that in order to
flush out \textbf{Hidden Risk}, we'd upgrade our entire production site
to use it \emph{now}, rather than wait for the app launch.

\textbf{Eve}: Right, and it \emph{did} flush out \textbf{Hidden Risk}:
some people using Windows 7, downloading Excel spreadsheets on the site,
couldn't download them: for some reason, that combination didn't support
anything greater than TLS version 1.0. So, we had to back it out.

\textbf{Bob}: Ok, well I guess it's good we found out \emph{now}. It
would have been a disaster to discover this after the go-live.

\textbf{Eve}: Yes. So, what's our next-best action to mitigate this?

\textbf{Bob}: Well, we could go back to Synergy and ask them for a
reprieve, but I think it'd be better to mitigate this risk now if we
can\ldots{} they'll definitely want it changed at some point.

\textbf{Eve}: How about we run two web-servers? One for the existing
content, and one for our new Synergy app? We'd have to get a new
external IP address, handle DNS setup, change the firewalls, and then
deploy a new version of the Web Server software on the production boxes.

\textbf{Bob}: This feels like there'd be a lot of \textbf{Attendant
Risk}: and all of this needs to be handled by the Networking Team, so
we're picking up a lot of \textbf{Bureaucratic Risk}. I'm also worried
that there are too many steps here, and we're going to discover loads of
\textbf{Hidden Risks} as we go.

\textbf{Eve}: Well, you're correct on the first one. But, I've done this
before not that long ago for a Chinese project, so I know the process -
we shouldn't run into any new \textbf{Hidden Risk}.

\textbf{Bob}: Ok, fair enough. But isn't there something simpler we can
do? Maybe some settings in the Web Server?

\textbf{Eve}: Well, if we were using Apache, yes, it would be easy to do
this. But, we're using Baroque Web Server, and it \emph{might} support
it, but the documentation isn't very clear.

\textbf{Bob}: Ok, and upgrading it is a \emph{big} risk, right? We'd
have to migrate all of our \textbf{configuration}\ldots{}

\textbf{Eve}: Yes, let's not go there. But if we changing the settings
on Baroque, we have the \textbf{Attendant Risk} that it's not supported
by the software and we're back where we started. Also, if we isolate the
Synergy app stuff now, we can mess around with it at any point in
future, which is a big win in case there are other \textbf{Hidden Risks}
with the security changes that we don't know about yet.

\textbf{Bob}: Ok, I can see that buys us something, but time is really
short and we have holidays coming up.

\textbf{Eve}: Yes. How about for now, we go with the isolated server,
and review next week? If it's working out, then great, we continue with
it. Otherwise, if we're not making progress next week, then it'll be
because our isolation solution is meeting more risk than we originally
thought. We can try the settings change in that case.

\textbf{Bob}: Fair enough, it sounds like we're managing the risk
properly, and because we can hand off a lot of this to the Networking
Team, we can get on with mitigating our biggest risk on the project, the
authentication problem, in the meantime.

\textbf{Eve}: Right. I'll check in with the Networking Team each day and
make sure it doesn't get forgotten.

\hypertarget{aftermath}{%
\section{Aftermath}\label{aftermath}}

Hopefully, this type of conversation will feel familiar. It should.
There's nothing ground-breaking at all in what we've covered so far;
it's more-or-less just Risk Management theory.

If you can now apply it in conversation, like we did above, then that's
one extra tool you have for delivering software.

So with the groundwork out of the way, let's get on to Part 2 and
investigate \textbf{The Risk Landscape}.

\part{Risk}

\reversemarginpar

\hypertarget{risk-landscape}{%
\chapter{Risk Landscape}\label{risk-landscape}}

Risk is messy. It's not always easy to tease apart the different
components of risk and look at them individually. Let's look at a
high-profile recent example to see why.

\hypertarget{financial-crisis}{%
\section{Financial Crisis}\label{financial-crisis}}

In the \href{https://en.wikipedia.org/wiki/Financial_services}{Financial
Services} industry, lots of effort is spend calculating things like: -
\href{https://en.wikipedia.org/wiki/Market_risk}{Market Risk}: the risk
that the amount some asset you hold/borrow/have loaned is going to
change in value. -
\href{https://en.wikipedia.org/wiki/Credit_risk}{Credit Risk}. the risk
that someone who owes you a payment at a specific point in time might
not pay it back.

They get expressed in ways like this:

\begin{quote}
``we have a 95\% chance that today we'll lose less than £100''
\end{quote}

In the financial crisis, though, these models of risk didn't turn out to
be much use. Although there are lots of conflicting explanations of what
happened, one way to look at it is this: - Liquidity difficulties
(i.e.~amount of cash you have for day-to-day running of the bank) caused
some banks to not be able to cover their interest payments. - This
caused credit defaults (the thing that \textbf{Credit Risk} measures
were meant to guard against) even though the banks \emph{technically}
were solvent. - That meant that, in time, banks got bailed out, share
prices crashed and there was lots of
\href{https://en.wikipedia.org/wiki/Quantitative_easing}{Quantitative
Easing}.\\
- All of which had massive impacts on the markets in ways that none of
the \textbf{Market Risk} models foresaw.

All the \textbf{Risks} were
\href{https://www.investopedia.com/terms/c/correlation.asp}{correlated}.
That is, they were affected by the \emph{same underlying events}, or
\emph{each other}.

\hypertarget{the-risk-landscape-again}{%
\section{The Risk Landscape Again}\label{the-risk-landscape-again}}

It's like this with software risks, too, sadly.

In \textbf{Meeting Reality}, we looked at the concept of the
\textbf{Risk Landscape}, and how a software project tries to
\emph{navigate} across this landscape, testing the way as it goes, and
trying to get to a position of \emph{more favourable risk}.

In this section, I am going to try and show you some of the geography of
the \textbf{Risk Landscape}. We know every project is different, so
every \textbf{Risk Landscape} is also different. But, just as I can tell
you that the landscape outside your window will probably will have some
roads, trees, fields, forests, buildings, and that the buildings are
likely to be joined together by roads, I can tell you some general
things about risks too.

In fact, we're going to try and categorize the kinds of things we see on
this risk landscape. But, this isn't going to be perfect: - One risk can
``blend'' into another just like sometimes a ``field'' is also a
``car-park'' or a building might contain some trees (but isn't a
forest).\\
- There is \emph{correlation} between different risks: one risk may
cause another, or two risks may be due to the same underlying cause.\\
- As we saw in \textbf{Part 1}, mitigating one risk can give rise to
another, so risks are often \emph{inversely correlated}.

\hypertarget{three-basic-areas-of-risk}{%
\section{Three Basic Areas Of Risk}\label{three-basic-areas-of-risk}}

\emph{tbd; is this enough?}

\begin{figure}
\centering
\includegraphics{images/types_of_risk.png}
\caption{Risk Types}
\end{figure}

In general, you will definitely have at least 3 main \textbf{areas} of
risk:

\begin{itemize}
\tightlist
\item
  \textbf{Product Risks}: Risks affecting the \emph{product you're
  building}, such as \textbf{Feature Risk} and \textbf{Dependency Risk}
\item
  \textbf{Staff Risks}: Risks to do with the people or organisations
  \emph{building the product}, such as \textbf{Coordination Risk} and
  \textbf{Agency Risk}
\item
  \textbf{Customer Risks}: Risks to do with the \emph{consumers} of the
  product.
\end{itemize}

None of the risk categories we're going to look at fit \emph{exactly}
into these areas, and some of them exist at the \textbf{intersection} of
these types: - \textbf{Feature Risk} is about the \textbf{Customer} and
\textbf{Product} fit. - \textbf{Complexity Risk} is a problem between
the \textbf{Staff} and the \textbf{Product} they are building. -
\textbf{Communication Risk} occurs at the intersection of
\textbf{Customer}, \textbf{Product} and \textbf{Staff}.

\begin{figure}
\centering
\includegraphics{images/types_of_risk2.png}
\caption{Risk Types 2}
\end{figure}

\hypertarget{our-tour-itinerary}{%
\section{Our Tour Itinerary}\label{our-tour-itinerary}}

tbd

\begin{longtable}[]{@{}lll@{}}
\toprule
Risk & Areas &\tabularnewline
\midrule
\endhead
\textbf{Feature Risk} & Customer, Product &\tabularnewline
\textbf{Complexity Risk} & Product, Staff &\tabularnewline
\textbf{Communication Risk} & Customer, Product, Staff &\tabularnewline
\textbf{Dependency Risk} & Product, Customer, Staff &\tabularnewline
\textbf{Software Dependency Risk} & Product, Staff &\tabularnewline
\textbf{Process Risk} & Staff &\tabularnewline
\textbf{Schedule Risk} & Product, Staff &\tabularnewline
\textbf{Boundary Risk} & Product &\tabularnewline
\textbf{Agency Risk} & Staff &\tabularnewline
\textbf{Coordination Risk} & Staff &\tabularnewline
\textbf{Production Risk} & Customer, Product &\tabularnewline
\textbf{Map And Territory Risk} & Staff &\tabularnewline
\bottomrule
\end{longtable}

On each page we'll start by looking at the category of the risk \emph{in
general}, and then break this down into some specific subtypes.

Let's get started with \textbf{Feature Risk}.

\hypertarget{feature-risk}{%
\chapter{Feature Risk}\label{feature-risk}}

\textbf{Feature Risk} is the category of risks to do with features that
have to be in your software.\\
You could also call it \textbf{Functionality Risk}. It is the risk that
you face by \emph{not having features that your clients need}.

\begin{figure}
\centering
\includegraphics{images/generated/feature-risk.png}
\caption{Feature Risk}
\end{figure}

Eventually, this will come down to lost money, business, acclaim, or
whatever else reason you are doing your project for.

In a way, \textbf{Feature Risk} is very fundamental: if there were
\emph{no} feature risk, the job would be done already, either by you, or
by another product.

As a simple example, if your needs are served perfectly by Microsoft
Excel, then you don't have any \textbf{Feature Risk}. However, the day
you find Microsoft Excel wanting, and decide to build an Add-On is the
day when you first appreciate some \textbf{Feature Risk}.

\hypertarget{variations}{%
\section{Variations}\label{variations}}

\hypertarget{feature-fit-risk}{%
\subsection{Feature Fit Risk}\label{feature-fit-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/fit-risk.png}
\caption{Feature Risk}
\end{figure}

This is the one we've just discussed above: the feature that you (or
your clients) want to use in the software \emph{isn't there}. Now, as
usual, you could call this an issue, but we're calling it a
\textbf{Risk} because it's not clear exactly \emph{how many} people are
affected, or how badly.

\begin{itemize}
\tightlist
\item
  This might manifest itself as complete \emph{absence} of something you
  need, e.g ``Where is the word count?''
\item
  It could be that the implementation isn't complete enough, e.g ``why
  can't I add really long numbers in this calculator?''
\end{itemize}

\hypertarget{features-dont-work-properly}{%
\subsection{Features Don't Work
Properly}\label{features-dont-work-properly}}

\begin{figure}
\centering
\includegraphics{images/generated/implementation-risk.png}
\caption{Implementation Risk}
\end{figure}

\textbf{Feature Risk} also includes things that don't work as expected:
That is to say, \href{https://en.wikipedia.org/wiki/Software_bug}{bugs}.
Although the distinction between ``a missing feature'' and ``a broken
feature'' might be worth making in the development team, we can consider
these both the same kind of risk: \emph{the software doesn't do what the
user expects}.

(At this point, it's worth pointing out that sometimes, \emph{the user
expects the wrong thing}. This is a different but related risk, which
could be down to \textbf{Training} or \textbf{Documentation} or simply
\textbf{Poor User Interface} and we'll look at that more in
\textbf{Communication Risk}.)

\hypertarget{regression-risk}{%
\subsection{Regression Risk}\label{regression-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/regression-risk.png}
\caption{Regression Risk}
\end{figure}

\textbf{Regression Risk} is basically risk of breaking existing features
in your software when you add new ones. As with the previous risks, the
eventual result is the same; customers don't have the features they
expect. This can become a problem as your code-base \textbf{gains
Complexity}, as it becomes impossible to keep a complete
\textbf{Internal Model} of the whole thing.

Also, while delivering new features can delight your customers, breaking
existing ones will annoy them. This is something we'll come back to in
\textbf{Reputation Risk}.

\hypertarget{market-risk}{%
\subsection{Market Risk}\label{market-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/market-risk.png}
\caption{Market Risk}
\end{figure}

On the \textbf{Risk Landscape} page I introduced the idea of
\textbf{Market Risk} as being the value that the market places on a
particular asset. Since the product you are building is your asset, it
makes sense that you'll face \textbf{Market Risk} on it:

\begin{quote}
``Market risk is the risk of losses in positions arising from movements
in market prices.'' -
\href{https://en.wikipedia.org/wiki/Market_risk}{Market Risk,
\emph{Wikipedia}}
\end{quote}

I face market risk when I own (i.e.~have a \emph{position} in) some
\href{http://apple.com}{Apple} stock. \href{http://apple.com}{Apple's}'s
stock price will decline if a competitor brings out an amazing product,
or if fashions change and people don't want their products any more.

In the same way, \emph{you} have \textbf{Market Risk} on the product or
service you are building: the \emph{market} decides what it is prepared
to pay for this, and it tends to be outside your control.

\hypertarget{conceptual-integrity-risk}{%
\subsection{Conceptual Integrity Risk}\label{conceptual-integrity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/conceptual-integrity-risk.png}
\caption{Conceptual Integrity Risk}
\end{figure}

Sometimes, users \emph{swear blind} that they need some feature or
other, but it runs at odds with the design of the system, and plain
\emph{doesn't make sense}. Often, the development team can spot this
kind of conceptual failure as soon as it enters the \textbf{Backlog}.
Usually, it's in coding that this becomes apparent.

Sometimes, it can go for a lot longer. I once worked on some software
that was built as a score-board within a chat application. However,
after we'd added much-asked-for commenting and reply features to our
score-board, we realised we'd implemented a chat application
\emph{within a chat application}, and had wasted our time enormously.

Which leads to Greenspun's 10th Rule:

\begin{quote}
``Any sufficiently complicated C or Fortran program contains an ad-hoc,
informally-specified, bug-ridden, slow implementation of half of Common
Lisp.'' -
\href{https://en.wikipedia.org/wiki/Greenspun's_tenth_rule}{Greenspun's
10th Rule, \emph{Wikipedia}}
\end{quote}

This is a particularly pernicious kind of \textbf{Feature Risk} which
can only be mitigated by good \textbf{Design}. Human needs are fractal
in nature: the more you examine them, the more differences you can find.
The aim of a product is to capture some needs at a \emph{general} level:
you can't hope to ``please all of the people all of the time''.

\textbf{Conceptual Integrity Risk} is the risk that chasing after
features leaves the product making no sense, and therefore pleasing
no-one.

\hypertarget{feature-access-risk}{%
\subsection{Feature Access Risk}\label{feature-access-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/feature-access-risk.png}
\caption{Feature Access Risk}
\end{figure}

Sometimes, features can work for some people and not others: this could
be down to
\href{https://en.wikipedia.org/wiki/Accessibility}{Accessibility}
issues, language barriers or localization.

You could argue that the choice of \emph{platform} is also going to
limit access: writing code for XBox-only leaves PlayStation owners out
in the cold. This is \emph{largely} \textbf{Feature Access Risk}, though
\textbf{Dependency Risk} is related here.

\hypertarget{feature-drift-risk}{%
\subsection{Feature Drift Risk}\label{feature-drift-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/feature-drift-risk.png}
\caption{Feature Drift Risk}
\end{figure}

\textbf{Feature Drift} is the tendency that the features people need
\emph{change over time}. For example, at one point in time, supporting
IE6 was right up there for website developers, but it's not really
relevant anymore. Although that change took \emph{many} years to
materialize, other changes are more rapid.

The point is: \textbf{Requirements captured} \emph{today} might not make
it to \emph{tomorrow}, especially in the fast-paced world of IT.

\textbf{Feature Drift Risk} is \emph{not the same thing} as
\textbf{Requirements Drift}, which is the tendency projects have to
expand in scope as they go along. There are lots of reasons they do
that, a key one being the \textbf{Hidden Risks} uncovered on the project
as it progresses.

\hypertarget{fashion}{%
\subsection{Fashion}\label{fashion}}

Fashion plays a big part in IT, as this
\href{https://designers.hubspot.com/blog/the-history-of-web-design-infographic}{infographic
on website design shows}. True, websites have got easier to use as time
has gone by, and users now expect this. Also, bandwidth is greater now,
which means we can afford more media and code on the client side.
However, \emph{fashion} has a part to play in this.

By being \emph{fashionable}, websites are communicating: \emph{this is a
new thing}, \emph{this is relevant}, \emph{this is not terrible}: all of
which is mitigating a \textbf{Communication Risk}. Users are
all-too-aware that the Internet is awash with terrible, abandon-ware
sites that are going to waste their time. How can you communicate that
you're not one of them to your users?

\hypertarget{delight}{%
\subsection{Delight}\label{delight}}

If this breakdown of \textbf{Feature Risk} seems reductive, then try not
to think of it that way: the aim \emph{of course} should be to delight
users, and turn them into fans. That's a laudable \textbf{Goal}, but
should be treated in the usual Risk-First way: \emph{pick the biggest
risk you can mitigate next}.

Consider \textbf{Feature Risk} from both the down-side and the up-side:

\begin{itemize}
\tightlist
\item
  What are we missing?
\item
  How can we be \emph{even better}?
\end{itemize}

Hopefully, this has given you some ideas about what \textbf{Feature
Risk} involves. Hopefully, you might be able to identify a few more
specific varieties. But, it's time to move on and look in more detail at
\textbf{Complexity Risk} and how it affects what we build.

\hypertarget{complexity-risk}{%
\chapter{Complexity Risk}\label{complexity-risk}}

\textbf{Complexity Risk} are the risks to your project due to its
underlying ``complexity''. Over the next few sections, we'll break down
exactly what we mean by complexity, looking at \textbf{Dependency Risk}
and \textbf{Boundary Risk} as two particular sub-types of
\textbf{Complexity Risk}. However, in this section, we're going to be
specifically focusing on \emph{code you write}: the size of your
code-base, the number of modules, the interconnectedness of the modules
and how well-factored the code is.

\begin{figure}
\centering
\includegraphics{images/generated/all-complexity-risk.png}
\caption{Complexity Risks}
\end{figure}

You could think of this section, then, as \textbf{Codebase Risk}: We'll
look at three separate measures of codebase complexity and talk about
\textbf{Technical Debt}, and look at places in which \textbf{Codebase
Risk} is at it's greatest.

\hypertarget{kolmogorov-complexity}{%
\section{Kolmogorov Complexity}\label{kolmogorov-complexity}}

The standard Computer-Science definition of complexity, is
\href{https://en.wikipedia.org/wiki/Kolmogorov_complexity}{Kolmogorov
Complexity}. This is:

\begin{quote}
``\ldots{}is the length of the shortest computer program (in a
predetermined programming language) that produces the object as
output.'' -
\href{https://en.wikipedia.org/wiki/Kolmogorov_complexity}{Kolmogorov
Complexity, Wikipedia}
\end{quote}

This is a fairly handy definition for us, as it means that to in writing
software to solve a problem, there is a lower bound on the size of the
software we write. In practice, this is pretty much impossible to
quantify. But that doesn't really matter: the techniques for
\emph{moving in that direction} are all that we are interested in, and
this basically amounts to compression.

Let's say we wanted to write a javascript program to output this string:

\begin{verbatim}
abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd
\end{verbatim}

We might choose this representation:

\begin{Shaded}
\begin{Highlighting}[]
 
\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                             (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \StringTok{"abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd"}\NormalTok{        (}\DecValTok{45}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                                            (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

\ldots{} which contains \textbf{53} symbols, if you count
\texttt{function}, \texttt{out} and \texttt{return} as one symbol each.

But, if we write it like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                           (}\DecValTok{11}\NormalTok{ symbols)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                             (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return}\NormalTok{ ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\AttributeTok{ABCD}\NormalTok{ (}\DecValTok{21}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                                            (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

With this version, we now have \textbf{40} symbols. And with this
version:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                           (}\DecValTok{11}\NormalTok{ symbols)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                             (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                                   (}\DecValTok{7}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                                            (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

\ldots{} we have \textbf{26} symbols.

\hypertarget{abstraction}{%
\subsection{Abstraction}\label{abstraction}}

What's happening here is that we're \emph{exploiting a pattern}: we
noticed that \texttt{ABCD} occurs several times, so we defined it a
single time and then used it over and over, like a stamp. Separating the
\emph{definition} of something from the \emph{use} of something as we've
done here is called ``abstraction''. We're going to come across it over
and over again in this part of the book, and not just in terms of
computer programs.

By applying techniques such as Abstraction, we can improve in the
direction of the Kolmogorov limit. And, by allowing ourselves to say
that \emph{symbols} (like \texttt{out} and \texttt{ABCD}) are worth one
complexity point, we've allowed that we can be descriptive in our
\texttt{function} name and \texttt{const}. Naming things is an important
part of abstraction, because to use something, you have to be able to
refer to it.

\hypertarget{trade-off}{%
\subsection{Trade-Off}\label{trade-off}}

But we could go further down into
\href{https://en.wikipedia.org/wiki/Code_golf}{Code Golf} territory.
This javascript program plays
\href{https://en.wikipedia.org/wiki/Fizz_buzz}{FizzBuzz} up to 100, but
is less readable than you might hope:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{<}\DecValTok{100}\OperatorTok{;}\NormalTok{)}\VariableTok{document}\NormalTok{.}\AttributeTok{write}\NormalTok{(((}\OperatorTok{++}\NormalTok{i}\OperatorTok{%}\DecValTok{3}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Fizz'}\NormalTok{)}\OperatorTok{+}
\NormalTok{(i}\OperatorTok{%}\DecValTok{5}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Buzz'}\NormalTok{)}\OperatorTok{||}\NormalTok{i)}\OperatorTok{+}\StringTok{"<br>"}\NormalTok{)                                  (}\DecValTok{66}\NormalTok{ symbols)}
\end{Highlighting}
\end{Shaded}

So there is at some point a trade-off to be made between
\textbf{Complexity Risk} and \textbf{Communication Risk}. This is a
topic we'll address more in that section. But for now, it should be said
that \textbf{Communication Risk} is about \emph{misunderstanding}: The
more complex a piece of software is, the more difficulty users will have
understanding it, and the more difficulty developers will have changing
it.

\hypertarget{connectivity}{%
\section{Connectivity}\label{connectivity}}

A second, useful measure of complexity comes from graph theory, and that
is the connectivity of a graph:

\begin{quote}
``\ldots{}the minimum number of elements (nodes or edges) that need to
be removed to disconnect the remaining nodes from each other'' -
\href{https://en.wikipedia.org/wiki/Connectivity_(graph_theory)}{Connectivity,
\emph{Wikipedia}}
\end{quote}

To see this in action, have a look at the below graph:

\begin{figure}
\centering
\includegraphics{images/connectivity_1.png}
\caption{Graph 1}
\end{figure}

It has 10 vertices, labelled \textbf{a} to \textbf{j}, and it has 15
edges (or links) connecting the vertices together. If any single edge
were removed from this diagram, the 10 vertices would still be linked
together. Because of this, we can say that the graph is
\emph{2-connected}. That is, to disconnect any single vertex, you'd have
to remove \emph{at least} two edges.

As a slight aside, let's consider the \textbf{Kolmogorov Complexity} of
this graph, by inventing a mini-language to describe graphs. It could
look something like this:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<}\NormalTok{item}\OperatorTok{>} \OperatorTok{:}\NormalTok{ [}\OperatorTok{<}\NormalTok{item}\OperatorTok{>,}\NormalTok{]}\OperatorTok{*} \OperatorTok{<}\NormalTok{item}\OperatorTok{>}\NormalTok{    # Indicates that the item before the colon }
\NormalTok{                              # has a connection to all the items after the }\VariableTok{colon}\NormalTok{.}
                              
\NormalTok{a}\OperatorTok{:}\NormalTok{ b}\OperatorTok{,}\NormalTok{c}\OperatorTok{,}\NormalTok{d}
\NormalTok{b}\OperatorTok{:}\NormalTok{ c}\OperatorTok{,}\NormalTok{f}\OperatorTok{,}\NormalTok{e}
\NormalTok{c}\OperatorTok{:}\NormalTok{ f}\OperatorTok{,}\NormalTok{d}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}\OperatorTok{,}\NormalTok{j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{g}\OperatorTok{:}\NormalTok{ j}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{i}\OperatorTok{:} \AttributeTok{j}\NormalTok{                                                         (}\DecValTok{39}\NormalTok{ symbols)}
\end{Highlighting}
\end{Shaded}

Let's remove some of those extra links:

\begin{figure}
\centering
\includegraphics{images/connectivity_2.png}
\caption{Graph 2}
\end{figure}

In this graph, I've removed 6 of the edges. Now, we're in a situation
where if any single edge is removed, the graph becomes
\emph{unconnected}. That is, it's broken into distinct chunks. So, it's
\emph{1-connected}.

The second graph is clearly simpler than the first. And, we can show
this by looking at the \textbf{Kolgomorov Complexity} in our little
language:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{g}
\NormalTok{b}\OperatorTok{:}\NormalTok{ f}
\NormalTok{c}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{f}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}
\NormalTok{h}\OperatorTok{:} \AttributeTok{i}\NormalTok{                                                         (}\DecValTok{25}\NormalTok{ symbols)}
\end{Highlighting}
\end{Shaded}

\textbf{Connectivity} is also \textbf{Complexity}. Heavily connected
programs/graphs are much harder to work with than less-connected ones.
Even \emph{laying out} the first graph sensibly is a harder task than
the second (the second is a doddle). But the reason programs with
greater connectivity are harder to work with is that changing one module
potentially impacts many others.

\hypertarget{hierarchies-and-modularization}{%
\section{Hierarchies and
Modularization}\label{hierarchies-and-modularization}}

In the second, simplified graph, I've arranged it as a hierarchy, which
I can do now that it's only 1-connected. For 10 vertices, we need 9
edges to connect everything up. It's always:

\begin{verbatim}
  edges = vertices - 1
\end{verbatim}

Note that I could pick any hierarchy here: I don't have to start at
\textbf{c} (although it has the nice property that it has two roughly
even sub-trees attached to it).

How does this help us? Imagine if \textbf{a} - \textbf{j} were modules
of a software system, and the edges of the graph showed communications
between the different sub-systems. In the first graph, we're in a worse
position: who's in charge? What deals with what? Can I isolate a
component and change it safely? What happens if one component
disappears? But, in the second graph, it's easier to reason about,
because of the reduced number of connections and the new heirarchy of
organisation.

On the downside, perhaps our messages have farther to go now: in the
original \textbf{i} could send a message straight to \textbf{j}, but now
we have to go all the way via \textbf{c}. But this is the basis of
\href{https://en.wikipedia.org/wiki/Modular_programming}{Modularization}
and \href{https://en.wikipedia.org/wiki/Hierarchy}{Hierarchy}.

As a tool to battle complexity, we don't just see this in software, but
everywhere in our lives. Society, business, nature and even our bodies:

\begin{itemize}
\tightlist
\item
  \textbf{Organelles} - such as
  \href{https://en.wikipedia.org/wiki/Mitochondrion}{Mitochondria}.
\item
  \textbf{Cells} - such as blood cells, nerve cells, skin cells in the
  \href{https://en.wikipedia.org/wiki/List_of_distinct_cell_types_in_the_adult_human_body}{Human
  Body}.
\item
  \textbf{Organs} - like hearts livers, brains etc.
\item
  \textbf{Organisms} - like you and me.
\end{itemize}

The great complexity-reducing mechanism of modularization is that
\emph{you only have to consider your local environment}. Elements of the
program that are ``far away'' in the hierarchy can be relied on not to
affect you. This is somewhat akin to the \textbf{Principal Of Locality}:

\begin{quote}
``Spatial locality refers to the use of data elements within relatively
close storage locations.'' -
\href{https://en.wikipedia.org/wiki/Locality_of_reference}{Locality Of
Reference, \emph{Wikipedia}}
\end{quote}

\hypertarget{cyclomatic-complexity}{%
\section{Cyclomatic Complexity}\label{cyclomatic-complexity}}

A variation on this graph connectivity metric is our third measure of
complexity,
\href{https://en.wikipedia.org/wiki/Cyclomatic_complexity}{Cyclomatic
Complexity}. This is:

\begin{verbatim}
Cyclomatic Complexity = edges − vertices + 2P,
\end{verbatim}

Where \textbf{P} is the number of \textbf{Connected Components}
(i.e.~distinct parts of the graph that aren't connected to one another
by any edges).

So, our first graph had a \textbf{Cyclomatic Complexity} of 7.
\texttt{(15\ -\ 10\ +\ 2)}, while our second was 1.
\texttt{(9\ -\ 10\ +\ 2)}.

Cyclomatic complexity is all about the number of different routes
through the program. The more branches a program has, the greater it's
cyclomatic complexity. Hence, this is a useful metric in
\textbf{Testing} and \textbf{Code Coverage}: the more branches you have,
the more tests you'll need to exercise them all.

\hypertarget{more-abstraction}{%
\section{More Abstraction}\label{more-abstraction}}

Although we ended up with our second graph having a \textbf{Cyclomatic
Complexity} of 1 (the minimum), we can go further through abstraction,
because this representation isn't minimal from a \textbf{Kolmogorov
Complexity} point-of-view. For example, we might observe that there are
further similarities in the graph that we can ``draw out'':

\begin{figure}
\centering
\includegraphics{images/connectivity_3.png}
\caption{Complexity 3}
\end{figure}

Here, we've spotted that the structure of subgraphs \textbf{P1} and
\textbf{P2} are the same: we can have the same functions there to
assemble those. Noticing and exploiting patterns of repetition is one of
the fundamental tools we have in the fight against \textbf{Complexity
Risk}.

\hypertarget{complexity-as-mass}{%
\section{Complexity As Mass}\label{complexity-as-mass}}

So, we've looked at some measures of software structure complexity, in
order that we can say ``this is more complex than this''. However, we've
not really said why complexity entails \textbf{Risk}. So let's address
that now by looking at two analogies, \textbf{Mass} and
\textbf{Technical Debt}.

The first way to look at complexity is as \textbf{Mass} or
\textbf{Inertia} : a software project with more complexity has greater
\textbf{Inertia} or \textbf{Mass} than one with less complexity.

Newton's Second Law states:

\begin{quote}
``F = \emph{m}\textbf{a}, ( Force = Mass x Acceleration )'' -
\href{https://en.wikipedia.org/wiki/Newton\%27s_laws_of_motion}{Netwon's
Laws Of Motion, \emph{Wikipedia}}
\end{quote}

That is, in order to move your project \emph{somewhere new}, and make it
do new things, you need to give it a push, and the more \textbf{Mass} it
has, the more \textbf{Force} you'll need to move (accelerate) it.

\textbf{Inertia} and \textbf{Mass} are equivalent concepts in physics:

\begin{quote}
``mass is the quantitative or numerical measure of a body's inertia,
that is of its resistance to being accelerated''. -
\href{https://en.wikipedia.org/wiki/Inertia\#Mass_and_inertia}{Inertia,
\emph{Wikipedia}}
\end{quote}

You could stop here and say that the more lines of code a project
contains, the higher it's mass. And, that makes sense, because in order
to get it to do something new, you're likely to need to change more
lines.

But there is actually some underlying sense in which \emph{this is
real}, as discussed in this
\href{https://www.youtube.com/user/1veritasium}{Veritasium} video. To
paraphrase:

\begin{quote}
``Most of your mass you owe due to E=mc², you owe to the fact that your
mass is packed with energy, because of the \textbf{interactions} between
these quarks and gluon fluctuations in the gluon field\ldots{} what we
think of as ordinarily empty space\ldots{} that turns out to be the
thing that gives us most of our mass.'' -
\href{https://www.youtube.com/watch?annotation_id=annotation_3771848421\&feature=iv\&src_vid=Xo232kyTsO0\&v=Ztc6QPNUqls}{Your
Mass is NOT From the Higgs Boson, \emph{Veritasium}}
\end{quote}

I'm not an expert in physics, \emph{at all}, and so there is every
chance that I am pushing this analogy too hard. But, substituting quarks
and gluons for pieces of software we can (in a very handwaving-y way)
say that more complex software has more \textbf{interactions} going on,
and therefore has more mass than simple software.

The reason I am labouring this analogy is to try and make the point that
\textbf{Complexity Risk} is really fundamental:

\begin{itemize}
\tightlist
\item
  \textbf{Feature Risk}: like \textbf{money}.
\item
  \textbf{Schedule Risk}: like \textbf{time}.
\item
  \textbf{Complexity Risk}: like \textbf{mass}.
\end{itemize}

At a basic level, \textbf{Complexity Risk} heavily impacts on
\textbf{Schedule Risk}: more complexity means you need more force to get
things done, which takes longer.

\hypertarget{technical-debt}{%
\section{Technical Debt}\label{technical-debt}}

The most common way we talk about unnecessary complexity in software is
as \textbf{Technical Debt}:

\begin{quote}
``Shipping first time code is like going into debt. A little debt speeds
development so long as it is paid back promptly with a rewrite\ldots{}
The danger occurs when the debt is not repaid. Every minute spent on
not-quite-right code counts as interest on that debt. Entire engineering
organizations can be brought to a stand-still under the debt load of an
unconsolidated implementation, object-oriented or otherwise.'' --
\href{https://en.wikipedia.org/wiki/Technical_debt}{Ward Cunningham,
1992}
\end{quote}

Building a perfect first-time solution is a waste, because perfection
takes a long time. You're taking on more attendant \textbf{Schedule
Risk} than necessary and \textbf{Meeting Reality} more slowly than you
could.

A quick-and-dirty, over-complex implementation mitigates the same
\textbf{Feature Risk} and allows you to \textbf{Meet Reality} faster
(see \textbf{Prototyping}).

But, having mitigated the \textbf{Feature Risk}, you are now carrying
more \textbf{Complexity Risk} than you necessarily need, and it's time
to think about how to \textbf{Refactor} the software to reduce this risk
again.

\hypertarget{kitchen-analogy}{%
\section{Kitchen Analogy}\label{kitchen-analogy}}

It's often hard to make the case for minimizing \textbf{Technical Debt}:
it often feels that there are more important priorities, especially when
technical debt can be ``swept under the carpet'' and forgotten about
until later. (See \textbf{Discounting The Future}.)

One helpful analogy I have found is to imagine your code-base is a
kitchen. After preparing a meal (i.e.~delivering the first
implementation), \emph{you need to tidy up the kitchen}. This is just
something everyone does as a matter of \emph{basic sanitation}.

Now of course, you could carry on with the messy kitchen. When tomorrow
comes and you need to make another meal, you find yourself needing to
wash up saucepans as you go, or working around the mess by using
different surfaces to chop on.

It's not long before someone comes down with food poisoning.

We wouldn't tolerate this behaviour in a restaurant kitchen, so why put
up with it in a software project?

\hypertarget{feature-creep}{%
\section{Feature Creep}\label{feature-creep}}

In Brooks' essay ``No Silver Bullet -- Essence and Accident in Software
Engineering'', a distinction is made between:

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{Essence}: \emph{the difficulties inherent in the nature of the
  software.}
\item
  \textbf{Accident}: \emph{those difficulties that attend its production
  but are not inherent.}

  \begin{itemize}
  \tightlist
  \item
    \href{https://en.wikipedia.org/wiki/No_Silver_Bullet}{Fred Brooks,
    \emph{No Silver Bullet}}
  \end{itemize}
\end{itemize}
\end{quote}

The problem with this definition is that we are accepting features of
our software as \emph{essential}.

The \textbf{Risk-First} approach is that if you want to mitigate some
\textbf{Feature Risk} then you have to pick up \textbf{Complexity Risk}
as a result. But, that's a \emph{choice you get to make}.

Therefore, \href{https://en.wikipedia.org/wiki/Feature_creep}{Feature
Creep} (or
\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}) is a failure to observe this basic equation: instead of
considering this trade off, you're building every feature possible. This
has an impact on \textbf{Complexity Risk}, which in turn impacts
\textbf{Communication Risk} and also \textbf{Schedule Risk}.

Sometimes, feature-creep happens because either managers feel they need
to keep their staff busy, or the staff decide on their own that they
need to \textbf{keep themselves busy}. But now, we can see that
basically this boils down to bad risk management.

\begin{quote}
``Perfection is Achieved Not When There Is Nothing More to Add, But When
There Is Nothing Left to Take Away'' - Antoine de Saint-Exupery
\end{quote}

\hypertarget{dead-end-risk}{%
\section{Dead-End Risk}\label{dead-end-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/dead-end-risk.png}
\caption{Dead-End Risk}
\end{figure}

\textbf{Dead-End Risk} is where you build functionality that you
\emph{think} is useful, only to find out later that actually, it was a
dead-end, and is superceded by something else.

For example, let's say that the Accounting sub-system needed password
protection (so you built this). Then the team realised that you needed a
way to \emph{change the password} (so you built that). Then, that you
needed to have more than one user of the Accounting system so they would
all need passwords (ok, fine).

Finally, the team realises that actually logging-in would be something
that all the sub-systems would need, and that it had already been
implemented more thoroughly by the Approvals sub-system.

At this point, you realise you're in a \textbf{Dead End}:

\begin{itemize}
\tightlist
\item
  \textbf{Option 1}: You carry on making minor incremental improvements
  to the accounting password system (carrying the extra
  \textbf{Complexity Risk} of the duplicated functionality).
\item
  \textbf{Option 2}: You rip out the accounting password system, and
  merge in the Approvals system, surfacing new, hidden
  \textbf{Complexity Risk} in the process, due to the difficulty in
  migrating users from the old to new way of working.
\item
  \textbf{Option 3}: You start again, trying to take into account both
  sets of requirements at the same time, again, possibly surfacing new
  hidden \textbf{Complexity Risk} due to the combined approach.
\end{itemize}

Sometimes, the path from your starting point to your goal on the
\textbf{Risk Landscape} will take you to dead ends: places where the
only way towards your destination is to lose something, and do it again
another way.

This is because you surface new \textbf{Hidden Risk} along the way. And
the source of a lot of this hidden risk will be unexpected
\textbf{Complexity Risk} in the solutions you choose. This happens a
lot.

\hypertarget{source-control}{%
\subsection{Source Control}\label{source-control}}

\href{https://en.wikipedia.org/wiki/Version_control}{Version Control
Systems} like \href{https://en.wikipedia.org/wiki/Git}{Git} are a useful
mitigation of \textbf{Dead-End Risk}, because it means you can \emph{go
back} to the point where you made the bad decision and go a different
way. Additionally, they provide you with backups against the often
inadvertent \textbf{Dead-End Risk} of someone wiping the hard-disk.

\hypertarget{the-re-write}{%
\subsection{The Re-Write}\label{the-re-write}}

\textbf{Option 3}, Rewriting code or a whole project can seem like a way
to mitigate \textbf{Complexity Risk}, but it usually doesn't work out
too well. As Joel Spolsky says:

\begin{quote}
There's a subtle reason that programmers always want to throw away the
code and start over. The reason is that they think the old code is a
mess. And here is the interesting observation: they are probably wrong.
The reason that they think the old code is a mess is because of a
cardinal, fundamental law of programming:\\
\emph{It's harder to read code than to write it.} -
\href{https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/}{Things
You Should Never Do, Part 1, \emph{Joel Spolsky}}
\end{quote}

The problem that Joel is outlining here is that the developer mistakes
hard-to-understand code for unnecessary \textbf{Complexity Risk}. Also,
perhaps there is \textbf{Agency Risk} because the developer is doing
something that is more useful to him than the project. We're going to
return to this problem in again \textbf{Communication Risk}.

\hypertarget{where-complexity-hides}{%
\section{Where Complexity Hides}\label{where-complexity-hides}}

Complexity isn't spread evenly within a software project. Some problems,
some areas, have more than their fair share of issues. We're going to
cover a few of these now, but be warned, this is not a complete list by
any means:

\begin{itemize}
\tightlist
\item
  Memory Management
\item
  Protocols / Types
\item
  Algorithmic (Space and Time) Complexity
\item
  Concurrency / Mutability
\item
  Networks / Security
\end{itemize}

\hypertarget{memory-management}{%
\subsection{Memory Management}\label{memory-management}}

Memory Management is another place where \textbf{Complexity Risk} hides:

\begin{quote}
``Memory leaks are a common error in programming, especially when using
languages that have no built in automatic garbage collection, such as C
and C++.'' - \href{https://en.wikipedia.org/wiki/Memory_leak}{Memory
Leak, \emph{Wikipedia}}
\end{quote}

\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{Garbage
Collectors} (as found in Javascript or Java) offer you the deal that
they will mitigate the \textbf{Complexity Risk} of you having to manage
your own memory, but in return perhaps give you fewer guarantees about
the \emph{performance} of your software. Again, there are times when you
can't accommodate this \textbf{Performance Risk}, but these are rare and
usually only affect a small portion of an entire software-system.

\hypertarget{protocols-and-types}{%
\subsection{Protocols And Types}\label{protocols-and-types}}

Whenever two components of a software system need to interact, they have
to establish a protocol for doing so. There are lots of different ways
this can work, but the simplest example I can think of is where some
component \textbf{a} calls some function \textbf{b}. e.g:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c) }\OperatorTok{\{}
    \ControlFlowTok{return} \StringTok{"whatever"} \CommentTok{// do something here.}
\OperatorTok{\}}

\KeywordTok{function} \AttributeTok{a}\NormalTok{() }\OperatorTok{\{}
    \KeywordTok{var}\NormalTok{ bOut }\OperatorTok{=} \AttributeTok{b}\NormalTok{(}\StringTok{"one"}\OperatorTok{,} \StringTok{"two"}\OperatorTok{,} \StringTok{"three"}\NormalTok{)}\OperatorTok{;}
    \ControlFlowTok{return} \StringTok{"something "}\OperatorTok{+}\NormalTok{bOut}\OperatorTok{;}   
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

If component \textbf{b} then changes in some backwards-incompatible way,
say:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{,}\NormalTok{ d }\CommentTok{/* new parameter */}\NormalTok{) }\OperatorTok{\{}
    \ControlFlowTok{return} \StringTok{"whatever"} \CommentTok{// do something here.}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then, we can say that the protocol has changed. This problem is so
common, so endemic to computing that we've had compilers that check
function arguments \href{https://en.wikipedia.org/wiki/Compiler}{since
the 1960's}. The point being is that it's totally possible for the
compiler to warn you about when a protocol within the program has
changed.

The same is basically true of
\href{https://en.wikipedia.org/wiki/Data_type}{Data Types}: whenever we
change the \textbf{Data Type}, we need to correct the usages of that
type. Note above, I've given the \texttt{javascript} example, but I'm
going to switch to \texttt{typescript} now:

\begin{verbatim}
interface BInput {
    a: string,
    b: string, 
    c: string,
    d: string
}

function b(in: BInput): string {
    return "whatever" // do something here.
}
\end{verbatim}

Now, of course, there is a tradeoff: we \emph{mitigate}
\textbf{Complexity Risk}, because we define the protocols / types
\emph{once only} in the program, and ensure that usages all match the
specification. But the tradeoff is (as we can see in the
\texttt{typescript} code) more \emph{finger-typing}, which some people
argue counts as \textbf{Schedule Risk}.

Nevertheless, compilers and type-checking are so prevalent in software
that clearly, you have to accept that in most cases, the trade-off has
been worth it: Even languages like \href{https://clojure.org}{Clojure}
have been retro-fitted with
\href{https://github.com/clojure/core.typed/wiki/User-Guide}{type
checkers}.

We're going to head into much more detail on this in the section on
\textbf{Protocol Risk}.

\hypertarget{space-and-time-complexity}{%
\subsection{Space and Time Complexity}\label{space-and-time-complexity}}

So far, we've looked at a couple of definitions of complexity in terms
of the codebase itself. However, in Computer Science there is a whole
branch of complexity theory devoted to how the software \emph{runs},
namely \href{https://en.wikipedia.org/wiki/Big_O_notation}{Big O
Complexity}.

Once running, an algorithm or data structure will consume space or
runtime dependent on it's characteristics. As with
\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{Garbage
Collectors}, these characteristics can introduce \textbf{Performance
Risk} which can easily catch out the unwary. By and large, using
off-the-shelf data structures and algorithms helps, but you still need
to know their performance characteristics.

The \href{http://bigocheatsheet.com}{Big O Cheatsheet} is a wonderful
resource to investigate this further.

\hypertarget{concurrency-mutability}{%
\subsection{Concurrency / Mutability}\label{concurrency-mutability}}

Although modern languages include plenty of concurrency primitives,
(such as the
\href{https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/package-summary.html}{java.util.concurrent}
libraries), concurrency is \emph{still} hard to get right.

\href{https://en.wikipedia.org/wiki/Race_condition}{Race conditions} and
\href{https://en.wikipedia.org/wiki/Deadlock}{Deadlocks} \emph{thrive}
in over-complicated concurrency designs: complexity issues are magnified
by concurrency concerns, and are also hard to test and debug.

Recently, languages such as \href{https://clojure.org}{Clojure} have
introduced
\href{https://en.wikipedia.org/wiki/Persistent_data_structure}{persistent
collections} to alleviate concurrency issues. The basic premise is that
any time you want to \emph{change} the contents of a collection, you get
given back a \emph{new collection}. So, any collection instance is
immutable once created. The tradeoff is again attendant
\textbf{Performance Risk} to mitigate \textbf{Complexity Risk}.

An important lesson here is that choice of language can reduce
complexity: and we'll come back to this in \textbf{Software Dependency
Risk}.

\hypertarget{networking-security}{%
\subsection{Networking / Security}\label{networking-security}}

The last area I want to touch on here is networking. There are plenty of
\textbf{Complexity Risk} perils in \emph{anything} to do with networked
code, chief amongst them being error handling and (again)
\textbf{protocol evolution}.

In the case of security considerations, exploits \emph{thrive} on the
complexity of your code, and the weaknesses that occur because of it. In
particular, Schneier's Law says, never implement your own crypto scheme:

\begin{quote}
``Anyone, from the most clueless amateur to the best cryptographer, can
create an algorithm that he himself can't break. It's not even hard.
What is hard is creating an algorithm that no one else can break, even
after years of analysis.'' -
\href{https://en.wikipedia.org/wiki/Bruce_Schneier\#Cryptography}{Bruce
Schneier, 1998}
\end{quote}

Luckily, most good languages include crypto libraries that you can
include to mitigate these \textbf{Complexity Risks} from your own
code-base.

This is a strong argument for the use of libraries. But, when should you
use a library and when should you implement yourself? This is again
covered in the section on \textbf{Software Dependency Risk}.

tbd - next section.

\hypertarget{communication-risk}{%
\chapter{Communication Risk}\label{communication-risk}}

\textbf{Communication Risk} is the risk of communication between
entities \emph{going wrong}, due to loss or misunderstanding. Consider
this: if we all had identical knowledge, there would be no need to do
any communicating at all, and therefore and also no
\textbf{Communication Risk}.

\begin{figure}
\centering
\includegraphics{images/generated/communication-risk.png}
\caption{Communication Risk}
\end{figure}

But, people are not all-knowing oracles. We rely on our \emph{senses} to
improve our \textbf{Internal Models} of the world. There is
\textbf{Communication Risk} here - we might overlook something vital
(like an oncoming truck) or mistake something someone says (like ``Don't
cut the green wire'').

\textbf{Communication Risk} isn't just for people; it affects computer
systems too.

\hypertarget{a-model-of-communication}{%
\section{A Model Of Communication}\label{a-model-of-communication}}

In 1948, Claude Shannon proposed this definition of communication:

\begin{quote}
``The fundamental problem of communication is that of reproducing at one
point, either exactly or approximately, a message selected at another
point.'' -
\href{https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication}{A
Mathematical Theory Of Communication, \emph{Claude Shannon}}
\end{quote}

And from this same paper, we get the following (slightly adapted) model.

\begin{figure}
\centering
\includegraphics{images/communication_1.png}
\caption{Communication Model}
\end{figure}

We move from top-left (``I want to send a message to someone'') to
bottom left, clockwise, where we hope the message has been understood
and believed. (I've added this last box to Shannon's original diagram.)

One of the chief concerns in Shannon's paper is the step between
\textbf{Transmission} and \textbf{Reception}. He creates a theory of
information (measured in \textbf{bits}), the upper-bounds of information
that can be communicated over a channel and ways in which
\textbf{Communication Risk} between these processes can be mitigated by
clever \textbf{Encoding} and \textbf{Decoding} steps.

But it's not just transmission. \textbf{Communication Risk} exists at
each of these steps. Let's imagine a short exchange where someone,
\textbf{Alice} is trying to send a message to \textbf{Bob}:

\begin{itemize}
\tightlist
\item
  \textbf{Alice} might be \textbf{motivated} to send a message to tell
  \textbf{Bob} something, only to find out that he already knew it\_, or
  it wasn't useful information for them.
\item
  In the \textbf{composition} stage, \textbf{Alice} might mess up the
  \emph{intent} of the message: instead of ``Please buy chips'' she
  might say, ``Please buy chops''.
\item
  In the \textbf{encoding} stage, \textbf{Alice} might not speak clearly
  enough to be understood, and\ldots{}
\item
  In the \textbf{transmission} stage, \textbf{Alice} might not say it
  loudly enough for \textbf{Bob} to\ldots{}
\item
  \textbf{receive} the message clearly (maybe there is background
  noise).
\item
  Having heard \textbf{Alice} say something, can \textbf{Bob}
  \textbf{decode} what was said into a meaningful sentence?
\item
  Then, assuming that, will they \textbf{interpret} correctly which type
  of chips (or chops) \textbf{Alice} was talking about? Does ``Please
  buy chips'' convey all the information they need?
\item
  Finally, assuming \emph{everything else}, will \textbf{Bob} believe
  the message? Will they \textbf{reconcile} the information into their
  \textbf{Internal Model} and act on it? Perhaps not, if \textbf{Bob}
  thinks that there are chips at home already.
\end{itemize}

\hypertarget{approach-to-communication-risk}{%
\section{Approach To Communication
Risk}\label{approach-to-communication-risk}}

There is a symmetry about the steps going on in Shannon's diagram, and
we're going to exploit this in order to break down \textbf{Communication
Risk} into it's main types.

\begin{figure}
\centering
\includegraphics{images/communication_2.png}
\caption{Communication Risk 2}
\end{figure}

To get inside \textbf{Communication Risk}, we need to understand
\textbf{Communication} itself, whether between \emph{machines},
\emph{people} or \emph{products}: we'll look at each in turn. In order
to do that, we're going to examine four basic concepts in each of these
settings:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Communication_channel}{Channels},
  the medium via which the communication is happening.
\item
  \href{https://en.wikipedia.org/wiki/Communication_protocol}{Protocols}
  - the systems of rules that allow two or more entities of a
  communications system to transmit information.
\item
  \href{https://en.wikipedia.org/wiki/Message}{Messages}: The
  information we want to convey.
\item
  \textbf{Internal Models}: the sources and destinations for the
  messages. Updating internal models (whether in our heads or machines)
  is the reason why we're communicating.
\end{itemize}

And, as we look at these four areas, we'll consider the
\textbf{Attendant Risks} of each.

\hypertarget{channels}{%
\section{Channels}\label{channels}}

There are lots of different types of media for communicating (e.g.~TV,
Radio, DVD, Talking, Posters, Books, Phones, The Internet, etc. ) and
they all have different characteristics. When we communicate via a given
medium, it's called a \emph{channel}.

The channel \emph{characteristics} depend on the medium, then. Some
obvious ones are cost, utilisation, number of people reached, simplex or
duplex (parties can transmit and receive at the same time), persistence
(a play vs a book, say), latency (how long messages take to arrive) and
bandwidth (the amount of information that can be transmitted in a period
of time).

Channel characteristics are important: in a high-bandwidth, low-latency
situation, \textbf{Alice} and \textbf{Bob} can \emph{check} with each
other that the meaning was transferred correctly. They can discuss what
to buy, they can agree that \textbf{Alice} wasn't lying or playing a
joke.

The channel characteristics also imply suitability for certain
\emph{kinds} of messages. A documentary might be a great way of
explaining some economic concept, whereas an opera might not be.

\hypertarget{channel-risk}{%
\section{Channel Risk}\label{channel-risk}}

Shannon discusses that no channel is perfect: there is always the
\textbf{risk of noise} corrupting the signal. A key outcome from
Shannon's paper is that there is a tradeoff: within the capacity of the
channel (the \textbf{Bandwidth}), you can either send lots of
information with \emph{higher} risk that it is wrong, or less
information with \emph{lower} risk of errors. And, rather like the
\textbf{Kolgomorov complexity} result, the more \emph{randomness} in the
signal, the less compressible it is, and therefore the more \emph{bits}
it will take to transmit.

\begin{figure}
\centering
\includegraphics{images/generated/channel-risk.png}
\caption{Channel Risk}
\end{figure}

But channel risk goes wider than just this mathematical example:
messages might be delayed or delivered in the wrong order, or not be
acknowledged when they do arrive. Sometimes, a channel is just an
inappropriate way of communicating. When you work in a different
time-zone to someone else on your team, there is \emph{automatic}
\textbf{Channel Risk}, because instantaneous communication is only
available for a few hours' a day.

When channels are \textbf{poor-quality}, less communication occurs.
People will try to communicate just the most important information. But,
it's often impossible to know a-priori what constitutes ``important''.
This is why \textbf{Extreme Programming} recommends the practice of
\textbf{Pair Programming} and siting all the developers together:
although you don't know whether useful communication will happen, you
are mitigating \textbf{Channel Risk} by ensuring high-quality
communication channels are in place.

At other times, channels can contain so much information that we can't
hope to receive all the messages. In these cases, we don't even observe
the whole channel, just parts of it. For example, you might have a few
YouTube channels that you subscribe to, but hundreds of hours of video
are being posted on YouTube every second, so there is no way you can
keep up with all of it.

\begin{figure}
\centering
\includegraphics{images/communication_channels.png}
\caption{Communication Channels}
\end{figure}

\hypertarget{marketing-communications}{%
\subsubsection{Marketing
Communications}\label{marketing-communications}}

When we are talking about a product or a brand, mitigating
\textbf{Channel Risk} is the domain of
\href{https://en.wikipedia.org/wiki/Marketing_communications}{Marketing
Communications}. How do you ensure that the information about your
(useful) project makes it to the right people? How do you address the
right channels?

This works both ways. Let's looks at some of the \textbf{Channel Risks}
from the point of view of a hypothetical software tool, \textbf{D},
which would really useful in my software:

\begin{itemize}
\tightlist
\item
  The concept that there is such a thing as \textbf{D} which solves my
  problem isn't something I'd even considered.\\
\item
  I'd like to use something like \textbf{D}, but how do I find it?\\
\item
  There are multiple implementations of \textbf{D}, which is the best
  one for the task?
\item
  I know \textbf{D}, but I can't figure out how to solve my problem in
  it.
\item
  I've chosen \textbf{D}, I now need to persuade my team that \textbf{D}
  is the correct solution\ldots{}
\item
  \ldots{} and then they also need to understand \textbf{D} to do their
  job too.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/communication_marketing.png}
\caption{Communication Marketing}
\end{figure}

\textbf{Internal Models} don't magically get populated with the
information they need: they fill up gradually, as shown in this diagram.
Popular products and ideas \emph{spread}, by word-of-mouth or other
means. Part of the job of being a good technologist is to keep track of
new \textbf{Ideas}, \textbf{Concepts} and \textbf{Options}, so as to use
them as \textbf{Dependencies} when needed.

\hypertarget{protocols}{%
\section{Protocols}\label{protocols}}

In this section, I want to examine the concept of
\href{https://en.wikipedia.org/wiki/Communication_protocol}{Communication
Protocols} and how they relate to \textbf{Abstraction}.

So, to do this, let's look in a bit of detail at how web pages are
loaded. When considering this, we need to broaden our terminology.
Although so far we've talked about \textbf{Senders} and
\textbf{Receivers}, we now need to talk from the point of view of
who-depends-on-who. If you're \emph{depended on}, then you're a
``Server'', whereas if you require communication with something else,
you're a ``Client''. Thus, clients depend on servers in order to load
pages.

This is going to involve (at least) six separate protocols, the top-most
one being the
\href{https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol}{HTTP
Protocol}. As far as the HTTP Protocol is concerned, a \emph{client}
makes an \texttt{HTTP\ Request} at a specific URL and the
\texttt{HTTP\ Response} is returned in a predictable format that the
browser can understand.

Let's have a quick look at how that works with a \texttt{curl} command,
which allows me to load a web page from the command line. We're going to
try and load Google's preferences page, and see what happens. If I type:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>} \ExtensionTok{curl}\NormalTok{ -v http://google.com/preferences      # -v indicates verbose}
\end{Highlighting}
\end{Shaded}

\hypertarget{dns---domain-name-system}{%
\subsection{1. DNS - Domain Name
System}\label{dns---domain-name-system}}

Then, the first thing that happens is this:

\begin{verbatim}
* Rebuilt URL to: http://google.com/
*   Trying 216.58.204.78...
\end{verbatim}

At this point, curl has used
\href{https://en.wikipedia.org/wiki/Domain_Name_System}{DNS} to
\emph{resolve} the address ``google.com'' to an IP address. This is some
\textbf{Abstraction}: instead of using the machine's
\href{https://en.wikipedia.org/wiki/IP_address}{IP Address} on the
network, \texttt{216.58.204.78}, I can use a human-readable address,
\texttt{google.com}. The address \texttt{google.com} doesn't necessarily
resolve to that same address each time: \emph{They have multiple IP
addresses for \texttt{google.com}}. But, for the rest of the
\texttt{curl} request, I'm now set to just use this one.

\hypertarget{ip---internet-protocol}{%
\subsection{2. IP - Internet Protocol}\label{ip---internet-protocol}}

But this hints at what is beneath the abstraction: although I'm loading
a web-page, the communication to the Google server happens by
\href{https://en.wikipedia.org/wiki/Internet_Protocol}{IP Protocol} -
it's a bunch of discrete ``packets'' (streams of binary digits). You can
think of a packet as being like a real-world parcel or letter.

Each packet consists of two things:

\begin{itemize}
\tightlist
\item
  An address, which tells the network components (such as routers and
  gateways) where to send the packet, much like you'd write the address
  on the outside of a parcel.
\item
  The \emph{payload}, the stream of bytes for processing at the
  destination. Like the contents of the parcel.
\end{itemize}

But, even this concept of ``packets'' is an \textbf{Abstraction}.
Although all the components of the network interoperate with this
protocol, we might be using Wired Ethernet, or WiFi, 4G or
\emph{something else}.

\hypertarget{wifi-protocol}{%
\subsection{3. 802.11 - WiFi Protocol}\label{wifi-protocol}}

I ran this at home, using WiFi, which uses
\href{https://en.wikipedia.org/wiki/IEEE_802.11}{IEEE 802.11 Protocol},
which allows my laptop to communicate with the router wirelessly, again
using an agreed, standard protocol. But even \emph{this} isn't the
bottom, because this is actually probably specifying something like
\href{https://en.wikipedia.org/wiki/MIMO-OFDM}{MIMO-OFDM}, giving
specifications about frequencies of microwave radiation, antennas,
multiplexing, error-correction codes and so on. And WiFi is just the
first hop: after the WiFi receiver, there will be protocols for
delivering the packets via the telephony system.

\hypertarget{tcp---transmission-control-protocol}{%
\subsection{4. TCP - Transmission Control
Protocol}\label{tcp---transmission-control-protocol}}

Anyway, the next thing that happens is this:

\begin{verbatim}
* TCP_NODELAY set
* Connected to google.com (216.58.204.78) port 80 (#0)
\end{verbatim}

The second obvious \textbf{Abstraction} going on here is that
\texttt{curl} now believes it has a
\href{https://en.wikipedia.org/wiki/Transmission_Control_Protocol}{TCP}
connection. The TCP connection abstraction gives us the surety that the
packets get delivered in the right order, and retried if they go
missing. Effectively it \emph{guarantees} these things, or that it will
have a connection failure if it can't keep it's guarantee.

But, this is a fiction - TCP is built on the IP protocol, packets of
data on the network. So there are lots of packets floating around which
say ``this connection is still alive'' and ``I'm message 5 in the
sequence'' and so on in order to maintain this fiction. But that means
that the HTTP protocol can forget about this complexity and work with
the fiction of a connection.

\hypertarget{http---hypertext-transfer-protocol}{%
\subsection{5. HTTP - Hypertext Transfer
Protocol}\label{http---hypertext-transfer-protocol}}

Next, we see this:

\begin{verbatim}
> GET /preferences HTTP/1.1     (1)
> Host: google.com              (2)
> User-Agent: curl/7.54.0       (3)
> Accept: */*                   (4)
>                               (5)
\end{verbatim}

This is now the HTTP protocol proper, and these 5 lines are sending
information \emph{over the connection} to the Google server.

\begin{itemize}
\tightlist
\item
  \texttt{(1)} says what version of HTTP we are using, and the path
  we're loading (\texttt{/preferences} in this case).\\
\item
  \texttt{(2)} to \texttt{(4)} are \emph{headers}. They are name-value
  pairs, separated with a colon. The HTTP protocol specifies a bunch of
  these names, and later versions of the protocol might introduce newer
  ones.\\
\item
  \texttt{(5)} is an empty line, which indicates that we're done with
  the headers, please give us the response. And it does:
\end{itemize}

\begin{verbatim}
< HTTP/1.1 301 Moved Permanently                                      
< Location: http://www.google.com/preferences
< Content-Type: text/html; charset=UTF-8
< Date: Sun, 08 Apr 2018 10:24:34 GMT
< Expires: Tue, 08 May 2018 10:24:34 GMT
< Cache-Control: public, max-age=2592000
< Server: gws
< Content-Length: 230
< X-XSS-Protection: 1; mode=block
< X-Frame-Options: SAMEORIGIN
< 
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>301 Moved</TITLE></HEAD><BODY>
<H1>301 Moved</H1>
The document has moved
</BODY></HTML>
* Connection #0 to host google.com left intact
\end{verbatim}

There's a lot going on here, but we can break it down really easily into
3 chunks:

\begin{itemize}
\tightlist
\item
  The first line is the
  \href{https://en.wikipedia.org/wiki/List_of_HTTP_status_codes}{HTTP
  Status Code}. \texttt{301} is a code meaning that the page has moved.
\item
  The next 9 lines are HTTP headers again (name-value pairs). The
  \texttt{Location:} directive tells us where the page has moved to.
  Instead of trying \texttt{http://google.com/preferences}, we should
  have used \texttt{http://www.google.com/preferences}.
\item
  The lines starting \texttt{\textless{}HTML\textgreater{}} are now some
  HTML to display on the screen to tell the user that the page has
  moved.
\end{itemize}

\hypertarget{html---hypertext-markup-language}{%
\subsection{6. HTML - Hypertext Markup
Language}\label{html---hypertext-markup-language}}

Although \href{https://en.wikipedia.org/wiki/HTML}{HTML} is a language,
a language is also a protocol. (After all, language is what we use to
encode our ideas for transmission as speech.) In the example we gave,
this was a very simple page telling the client that it's looking in the
wrong place. In most browsers, you don't get to see this: the browser
will understand the meaning of the \texttt{301} error and redirect you
to the location.

Let's look at all the protocols we saw here:

\begin{figure}
\centering
\includegraphics{images/communication_protocols.png}
\caption{Protocol Stack}
\end{figure}

Each protocol ``passes on'' to the next one in the chain. On the left,
we have the representation most suitable for the \emph{messages}: HTTP
is designed for browsers to use to ask for and receive web pages. As we
move right, we are converting the message more and more into a form
suitable for the \textbf{Channel}: in this case, microwave transmission.

By having a stack of protocols, we are able to apply \textbf{Separation
Of Concerns}, each protocol handling just a few concerns:

\begin{itemize}
\tightlist
\item
  \texttt{HTML} Abstraction: A language for describing the contents of a
  web-page.
\item
  \texttt{HTTP} Abstraction: Name-Value pairs, agreed on by both
  \texttt{curl} and Google, URLs and error codes.
\item
  \texttt{DNS} Abstraction: Names of servers to IP Addresses.
\item
  \texttt{TCP} Abstraction: The concept of a ``connection'' with
  guarantees about ordering and delivery.
\item
  \texttt{IP} Abstraction: ``Packets'' with addresses and payloads.
\item
  \texttt{WiFi} Abstraction: ``Networks'', 802.11 flavours.
\item
  Transmitters, Antennas, error correction codes, etc.
\end{itemize}

\texttt{HTTP} ``stands on the shoulders of giants''. Not only does it
get to use pre-existing protocols like \texttt{TCP} and \texttt{DNS} to
make it's life easier, it got \texttt{802.11} ``for free'' when this
came along and plugged into the existing \texttt{IP} protocol. This is
the key value of abstraction: you get to piggy-back on \emph{existing}
patterns, and use them yourself.

The protocol mediates between the message and the channel. Where this
goes wrong, we have \textbf{Protocol Risk}. This is a really common
issue for IT systems, but also sometimes for human communication too.

\hypertarget{protocol-risk}{%
\section{Protocol Risk}\label{protocol-risk}}

Generally, any time where you have different parts of a system
communicating with each other, and one part can change incompatibly with
another you have \textbf{Protocol Risk}.

\begin{figure}
\centering
\includegraphics{images/generated/all-protocol-risk.png}
\caption{Protocol Risk}
\end{figure}

Locally, (within our own project), where we have control, we can
mitigate this risk using compile-time checking (as discussed already in
\textbf{Complexity Risk}), which essentially forces all clients and
servers to agree on protocol. But, the wider the group that you are
communicating with, the less control you have and the more chance there
is of \textbf{Protocol Risk}.

Let's look at some types of \textbf{Protocol Risk}:

\hypertarget{protocol-incompatibility-risk}{%
\subsection{Protocol Incompatibility
Risk}\label{protocol-incompatibility-risk}}

The people you find it \emph{easiest} to communicate with are your
friends and family, those closest to you. That's because you're all
familiar with the same protocols. Someone from a foreign country,
speaking a different language and having a different culture, will
essentially have a completely incompatible protocol for spoken
communication to you.

Within software, there are also competing, incompatible protocols for
the same things, which is maddening when your protocol isn't supported.
Although the world seems to be standardizing, there used to be
\emph{hundreds} of different image formats. Photographs often use
\href{https://en.wikipedia.org/wiki/TIFF}{TIFF},
\href{https://en.wikipedia.org/wiki/Raw_image_format}{RAW} or
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG}, whilst we also have
\href{https://en.wikipedia.org/wiki/Scalable_Vector_Graphics}{SVG} for
vector graphics, \href{https://en.wikipedia.org/wiki/GIF}{GIF} for
images and animations and
\href{https://en.wikipedia.org/wiki/Portable_Network_Graphics}{PNG} for
other bitmap graphics.

\hypertarget{protocol-versioning-risk}{%
\subsection{Protocol Versioning Risk}\label{protocol-versioning-risk}}

Even when systems are talking the same protocol, there can be problems.
When we have multiple, different systems owned by different parties, on
their own upgrade cycles, we have \textbf{Protocol Versioning Risk}: the
risk that either client or server could start talking in a version of
the protocol that the other side hasn't learnt yet. There are various
mitigating strategies for this. We'll look at two now: \textbf{Backwards
Compatibility} and \textbf{Forwards Compatibility}.

\hypertarget{backward-compatibility}{%
\subsubsection{Backward Compatibility}\label{backward-compatibility}}

Backwards Compatibility mitigates \textbf{Protocol Versioning Risk}.
Quite simply, this means, supporting the old format until it falls out
of use. If a server is pushing for a change in protocol it either must
ensure that it is Backwards Compatible with the clients it is
communicating with, or make sure they are upgraded concurrently. When
building \textbf{web services}, for example, it's common practice to
version all apis so that you can manage the migration. Something like
this:

\begin{itemize}
\tightlist
\item
  Server publishes \texttt{/api/v1/something}.
\item
  Clients use \texttt{/api/v1/something}.
\item
  Server publishes \texttt{/api/v2/something}.
\item
  Clients start using \texttt{/api/v2/something}.
\item
  Clients (eventually) stop using \texttt{/api/v2/something}.
\item
  Server retires \texttt{/api/v2/something} API.
\end{itemize}

\hypertarget{forward-compatibility}{%
\subsubsection{Forward Compatibility}\label{forward-compatibility}}

\texttt{HTML} and \texttt{HTTP} provide ``graceful failure'' to mitigate
\textbf{Protocol Risk}: while its expected that all clients can parse
the syntax of \texttt{HTML} and \texttt{HTTP}, it's not necessary for
them to be able to handle all of the tags, attributes and rules they
see. The specification for both these standards is that if you don't
understand something, ignore it. Designing with this in mind means that
old clients can always at least cope with new features, but it's not
always possible.

\texttt{JavaScript} \emph{can't} support this: because the meaning of
the next instruction will often depend on the result of the previous
one.

Does human language support this? To some extent! New words are added to
our languages all the time. When we come across a new word, we can
either ignore it, guess the meaning, ask or look it up. In this way,
human language has \textbf{Forward Compatibility} features built in.

\hypertarget{protocol-implementation-risk}{%
\subsection{Protocol Implementation
Risk}\label{protocol-implementation-risk}}

A second aspect of \textbf{Protocol Risk} exists in heterogenous
computing environments, where protocols have been independently
implemented based on standards. For example, there are now so many
different browsers, all supporting different levels of \texttt{HTTP},
\texttt{HTML} and \texttt{JavaScript} that it becomes impossible to test
comprehensively over all the different versions. To mitigate as much
\textbf{Protocol Risk} as possible, generally we run tests in a subset
of browsers, and use a lowest-common-denominator approach to choosing
protocol and language features.

\begin{figure}
\centering
\includegraphics{images/communication_protocols_risks.png}
\caption{Communication Protocols Risks}
\end{figure}

\hypertarget{messages}{%
\section{Messages}\label{messages}}

Although Shannon's Communication Theory is about transmitting
\textbf{Messages}, messages are really encoded \textbf{Ideas} and
\textbf{Concepts}, from an \textbf{Internal Model}.

\begin{figure}
\centering
\includegraphics{images/generated/all-message-risk.png}
\caption{Message Risk}
\end{figure}

\hypertarget{internal-model-assumption-risk}{%
\subsection{Internal Model Assumption
Risk}\label{internal-model-assumption-risk}}

When we construct messages in a conversation, we have to make judgements
about what the other person already knows. When talking to children,
it's often hard work because they \emph{assume} that you have knowledge
of everything they do. This is called
\href{https://en.wikipedia.org/wiki/Theory_of_mind}{Theory Of Mind}: the
appreciation that your knowledge is different to other people's, and
adjusting you messages accordingly.

When teaching, this is called
\href{https://en.wikipedia.org/wiki/Curse_of_knowledge}{The Curse Of
Knowledge}: teachers have difficulty understanding students' problems
\emph{because they already understand the subject}. For example, if I
want to tell you about a new
\href{https://en.wikipedia.org/wiki/JDBC_driver}{JDBC Driver}, this
pre-assumes that you know what JDBC is: the message has a dependency on
prior knowledge.

\hypertarget{message-dependency-risk}{%
\subsection{Message Dependency Risk}\label{message-dependency-risk}}

A second, related problem is actually \textbf{Dependency Risk}, which is
covered more thoroughly in the next section. Often, messages assume that
you have followed everything up to that point already, otherwise again,
your \textbf{Internal Model} will not be rich enough to understand the
new messages.

This happens when messages get missed, or delivered out of order. In the
past, TV shows were only aired once a week at a particular time. So
writers were constrained plot-wise by not knowing whether their audience
would have seen the previous week's episode. Therefore, often the state
of the show would ``reset'' week-to-week, allowing you to watch it in
\emph{any} order.

The same \textbf{Message Dependency Risk} exists for computer software:
if there is replication going on between instances of an application,
and one of the instances misses some messages, you end up with a
``\href{https://en.wikipedia.org/wiki/Split-brain_(computing)}{Split
Brain}'' scenario, where later messages can't be processed because they
refer to an application state that doesn't exist. For example, a message
saying:

\begin{verbatim}
Update user 53's surname to 'Jones'
\end{verbatim}

only makes sense if the application has previously had the message

\begin{verbatim}
Create user 53 with surname 'Smith'
\end{verbatim}

\hypertarget{abstraction-and-misinterpretation-risk}{%
\subsection{Abstraction and Misinterpretation
Risk}\label{abstraction-and-misinterpretation-risk}}

People don't rely on rigorous implementations of abstractions like
computers do; we make do with fuzzy definitions of concepts and ideas.
We rely on \textbf{Abstraction} to move between the name of a thing and
the \emph{idea of a thing}.

While machines only process \emph{information}, people's brains run on
concepts and ideas. For people, abstraction is critical: nothing exists
unless we have a name for it. Our world is just atoms, but we don't
think like this. \emph{The name is the thing}.

\begin{quote}
``The famous pipe. How people reproached me for it! And yet, could you
stuff my pipe? No, it's just a representation, is it not? So if I had
written on my picture ``This is a pipe'', I'd have been lying!'' -
\href{https://en.wikipedia.org/wiki/The_Treachery_of_Images}{Rene
Magritte, of \emph{The Treachery of Images}}
\end{quote}

This brings about \textbf{Misinterpretation Risk}: names are not
\emph{precise}, and concepts mean different things to different people.
We can't be sure that people have the same meaning for concepts that we
have.

\hypertarget{abstraction-and-invisibility-risk}{%
\subsection{Abstraction and Invisibility
Risk}\label{abstraction-and-invisibility-risk}}

Another cost of \textbf{Abstraction} is \textbf{Invisibility Risk}.
While abstraction is a massively powerful technique, (as we saw above in
the section on \textbf{Protocols}, it allows things like the Internet to
happen) it lets the function of a thing hide behind the layers of
abstraction and become invisible.

\hypertarget{invisibility-risk-in-software}{%
\subsubsection{Invisibility Risk In
Software}\label{invisibility-risk-in-software}}

As soon as you create a function, you are doing abstraction. You are
saying: ``I now have this operation. The details, I won't mention again,
but from now on, it's called \textbf{f}'' And suddenly, ``\textbf{f}''
hides. It is working invisibly. Things go on in \textbf{f} that people
don't necessarily need to understand. There may be some documentation,
or tacit knowledge around what \textbf{f} is, and what it does, but it's
not necessarily right. Referring to \textbf{f} is a much simpler job
than understanding \textbf{f}.

We try to mitigate this via (for the most part) documentation, but this
is a terrible deal: because we can't understand the original,
(un-abstracted) implementation, we now need to write some simpler
documentation, which \emph{explains} the abstraction, in terms of
further abstractions, and this is where things start to get murky.

\textbf{Invisibility Risk} is mainly \textbf{Hidden Risk}. (Mostly,
\emph{you don't know what you don't know}.) But you can carelessly
\emph{hide things from yourself} with software:

\begin{itemize}
\tightlist
\item
  Adding a thread to an application that doesn't report whether it's
  worked, failed, or is running out of control and consuming all the
  cycles of the CPU.
\item
  Redundancy can increase reliability, but only if you know when servers
  fail, and fix them quickly. Otherwise, you only see problems when the
  last server fails.
\item
  When building a webservice, can you assume that it's working for the
  users in the way you want it to?
\end{itemize}

When you build a software service, or even implement a thread, ask
yourself: ``How will I know next week that this is working properly?''
If the answer involves manual work and investigation, then your
implementation has just cost you in \textbf{Invisibility Risk}.

\hypertarget{invisibility-risk-in-conversation}{%
\subsubsection{Invisibility Risk In
Conversation}\label{invisibility-risk-in-conversation}}

\textbf{Invisibility Risk} is risk due to information not sent. But
because humans don't need a complete understanding of a concept to use
it, we can cope with some \textbf{Invisibility Risk} in communication,
and this saves us time when we're talking. It would be \emph{painful} to
have conversations if, say, the other person needed to understand
everything about how cars worked in order to discuss cars.

For people, \textbf{Abstraction} is a tool that we can use to refer to
other concepts, without necessarily knowing how the concepts work. This
divorcing of ``what'' from ``how'' is the essence of abstraction and is
what makes language useful.

The debt of \textbf{Invisibility Risk} comes due when you realise that
\emph{not} being given the details \emph{prevents} you from reasoning
about it effectively. Let's think about this in the context of a project
status meeting, for example:

\begin{itemize}
\tightlist
\item
  Can you be sure that the status update contains all the details you
  need to know?
\item
  Is the person giving the update wrong or lying?
\item
  Do you know enough about the details of what's being discussed in
  order to make informed decisions about how the project is going?
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/communication_messages.png}
\caption{Message Risk}
\end{figure}

\hypertarget{internal-models}{%
\section{Internal Models}\label{internal-models}}

So finally, we are coming to the root of the problem: communication is
about transferring ideas and concepts from one \textbf{Internal Model}
to another.

\begin{figure}
\centering
\includegraphics{images/generated/all-internal-model-risk.png}
\caption{Internal Model Risk}
\end{figure}

The communication process so far has been fraught with risks, but we
have a few more to come.

\hypertarget{trust-risk-belief-risk}{%
\subsection{Trust Risk \& Belief Risk}\label{trust-risk-belief-risk}}

Although protocols can sometimes handle security features of
communication (such as
\href{https://en.wikipedia.org/wiki/Authentication}{Authentication} and
preventing
\href{https://en.wikipedia.org/wiki/Man-in-the-middle_attack}{man-in-the-middle
attacks}), trust goes further than this, intersecting with
\textbf{Agency Risk}: can you be sure that the other party in the
communication is acting in your best interests?

Even if the receiver trusts the communicator, they may not trust the
message. Let's look at some reasons for that:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/World_view}{Weltanschauung (World
  View)}: The ethics, values and beliefs in the receiver's
  \textbf{Internal Model} may be incompatible to those from the
  sender.\\
\item
  \href{https://en.wikipedia.org/wiki/Relativism}{Relativism} is the
  concept that there are no universal truths. Every truth is from a
  frame of reference. For example, what constitutes \emph{offensive
  language} is dependent on the listener.
\item
  \href{https://en.wikipedia.org/wiki/Psycholinguistics}{Psycholinguistics}
  is the study of humans aquire languages. There are different languages
  and dialects, (and \emph{industry dialects}), and we all understand
  language in different ways, take different meanings and apply
  different contexts to the messages.
\end{itemize}

From the point-of-view of \textbf{Marketing Communications} choosing the
right message is part of the battle. You are trying to communicate your
idea in such a way as to mitigate \textbf{Belief Risk} and \textbf{Trust
Risk}.

\hypertarget{learning-curve-risk}{%
\subsection{Learning-Curve Risk}\label{learning-curve-risk}}

If the messages we are receiving force us to update our \textbf{Internal
Model} too much, we can suffer from the problem of ``too steep a
\href{https://en.wikipedia.org/wiki/Learning_curve}{Learning Curve}'' or
``\href{https://en.wikipedia.org/wiki/Information_overload}{Information
Overload}'', where the messages force us to adapt our \textbf{Internal
Model} too quickly for our brains to keep up.

Commonly, the easiest option is just to ignore the information channel
completely in these cases.

\hypertarget{reading-code}{%
\subsection{Reading Code}\label{reading-code}}

It's often been said that code is \emph{harder to read than to write}:

\begin{quote}
``If you ask a software developer what they spend their time doing,
they'll tell you that they spend most of their time writing code.
However, if you actually observe what software developers spend their
time doing, you'll find that they spend most of their time trying to
understand code.'' -
\href{https://blog.codinghorror.com/when-understanding-means-rewriting/}{When
Understanding Means Rewriting, \emph{Coding Horror}}
\end{quote}

By now it should be clear that it's going to be \emph{both} quite hard
to read and write: the protocol of code is actually designed for the
purpose of machines communicating, not primarily for people to
understand. Making code human readable is a secondary concern to making
it machine readable.

But now we should be able to see the reasons it's harder to read than
write too:

\begin{itemize}
\tightlist
\item
  When reading code, you are having to shift your \textbf{Internal
  Model} to wherever the code is, accepting decisions that you might not
  agree with and accepting counter-intuitive logical leaps. i.e.
  \textbf{Learning Curve Risk}. \emph{(cf.
  \href{https://en.wikipedia.org/wiki/Principle_of_least_astonishment}{Principle
  of Least Surprise})}
\item
  There is no \textbf{Feedback Loop} between your \textbf{Internal
  Model} and the \textbf{Reality} of the code, opening you up to
  \textbf{Misinterpretation Risk}. When you write code, your compiler
  and tests give you this.
\item
  While reading code \emph{takes less time} than writing it, this also
  means the \textbf{Learning Curve} is steeper.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/communication_internalmodel.png}
\caption{Internal Model Risks}
\end{figure}

\hypertarget{communication-risk-wrap-up}{%
\section{Communication Risk Wrap Up}\label{communication-risk-wrap-up}}

So, here's a summary of where we've arrived with our model of
communication risk:

\begin{figure}
\centering
\includegraphics{images/communication_3.png}
\caption{Communication 2}
\end{figure}

Since the purpose of Communication is to \emph{coordinate our actions},
next it's time to look at \textbf{Coordination Risk}.

\hypertarget{coordination-risk}{%
\chapter{Coordination Risk}\label{coordination-risk}}

\textbf{Coordination Risk} is the risk that, despite a group of people
(or processes) having the same \textbf{Goal In Mind} they can fail to
coordinate on a way to meet this goal and end up making things worse.
\textbf{Coordination Risk} is embodied in the phrase ``Too Many Cooks
Spoil The Broth'': more people, opinions or actors often make results
worse.

In this section, we're going to work on the assumption that everyone has
a common \textbf{Goal}, but in reality, people often have their own
agendas. We'll come to that in the section on \textbf{Agency Risk}
later.

\hypertarget{more-communication-risk}{%
\section{More Communication Risk?}\label{more-communication-risk}}

You might think that this is just another type of \textbf{Communication
Risk} problem, and that's often a part of it, but even with synchronized
\textbf{Internal Models}, coordination risk can occur. Imagine the
example of people all trying to madly leave a burning building. They all
have the same information (the building is on fire). If they coordinate,
and leave in an orderly fashion, they might all get out. If they don't,
and there's a scramble for the door, more people might die.

Alternatively, even with a cluster of stateless server processes, some
coordination is required to decide which server processes which request.

But generally, \textbf{Coordination Risk} occurs most commonly where
people have different ideas about how to achieve a goal, and they have
different ideas because they have different evaluations of the
\textbf{Attendant Risk}. As we saw in the section on
\textbf{Communication Risk}, we can only hope to synchronize
\textbf{Internal Models} if there are high-bandwidth \textbf{Channels}
available for communication.

\hypertarget{decision-making}{%
\section{Decision Making}\label{decision-making}}

So \textbf{Coordination Risk} is worse on projects with more members,
and worse in organizations with more staff. If you are engaged in a solo
project, do you suffer from \textbf{Coordination Risk} at all? Maybe:
sometimes, you can feel ``conflicted'' about the best way to solve a
problem. And weirdly, usually \emph{not thinking about it} helps.
Sleeping too. (Rich Hickey calls this ``\textbf{Hammock Based
Development}''). This is probably because, unbeknownst to you, your
subconscious is furiously communicating internally, trying to resolve
these conflicts itself, and will let you know when it's come to a
resolution.

So, \textbf{Coordination Risk} is at it's core about resolving
\textbf{Internal Model} conflicts, and arriving at consensus.

\textbf{Vroom and Yetton} introduced a model of group decision making
which looks something like this:

!image tbd

On the left, you have the \emph{least} consultative styles, and on the
right, the \emph{most}. On the left, decisions are made with just the
leader's \textbf{Internal Model} but moving right, the \textbf{Internal
Models} of the rest of the team are increasingly brought into play.

The decisions on the left are faster, but don't do much for mitigating
\textbf{Coordination Risk}. The ones on the right take longer,
(incurring \textbf{Schedule Risk}) but mitigate more
\textbf{Coordination Risk}. Group decision-making inevitably involves
everyone \emph{learning}, and improving their \textbf{Internal Models}.

The trick is to be able to tell which approach is suitable at which
time. Everyone is expected to make decisions \emph{within their realm of
expertise}: you can't have developers continually calling meetings to
discuss whether they should be using an \textbf{Abstract Factory} or a
{[}Factory Method{]}, this would waste time. The critical question is
therefore, ``what's the biggest risk?'' - Is the \textbf{Coordination
Risk} greater? Are we going to suffer \textbf{Dead End Risk} if the
decision is made wrongly? What if people don't agree with it? Poor
leadership has an impact on \textbf{Morale} too. - Is the
\textbf{Schedule Risk} greater? If you have a 1-hour meeting with eight
people to decide a decision, that's \emph{one man day} gone right there:
group decision making is \emph{expensive}.

\hypertarget{with-processes}{%
\subsection{With Processes}\label{with-processes}}

Almost the same model can be used with software processes.

tbd: use bitcoin as an example here.

\hypertarget{specialization-abstraction-risk}{%
\section{Specialization / Abstraction
Risk}\label{specialization-abstraction-risk}}

One common way groups and larger organizations aim to mitigate
\textbf{Coordination Risk} is via \textbf{Abstraction}: teams and
organizations can be arranged along functional lines, with
\emph{interfaces} between their different parts. This means the
different functions can \emph{use} each other without
\emph{understanding} each other.

On a team level, this might mean that you have one developer doing
``UI'', another working on ``billing'' and so on. In a larger
organisation you might have a ``marketing'' team or ``accounts'' team,
or divisions by product.

As we saw before \textbf{Abstraction brings it's own risks}. A key one
being that if team members are specialized, you can end up with
``bottlenecks'' in an organisation (see \textbf{Critical Chain}). This
is covered in more detail in the \textbf{Dependency Risk} section.

Bottlenecks in one part of a team mean that other members will be
under-utilised. This is the trade-off between \textbf{Fungibility}
(people are jack-of-all-trades) and \textbf{Specialization} (people
understand one small area well). Specialism pays off except in highly
dynamic situations, where it becomes necessary for people to re-skill,
with attendant \textbf{Learning Curve Risk}. But software is
\emph{often} highly dynamic: \textbf{Extreme Programming} avoids
specialization with it's insistence on \textbf{Pair Programming}, for
example.

Specialization is a type of complexity too: a homogeneous team of people
presents fewer \textbf{Scheduling} problems, and

Another advantage to specialization is that people have domains of
responsibility, which makes the \textbf{Decision Making} approach easier
to choose. Individuals and teams generally know when a decision can't be
made at their level, and that they need to escalate.

\hypertarget{staff-risk}{%
\section{Staff Risk}\label{staff-risk}}

If \textbf{Coordination Risk} is about trying to mitigate differences in
\textbf{Internal Models}, then it's worth considering how varied
people's models can be: - Different skill levels - Different experiences
- Expertise in different areas - Preferences - Personalities

The job of harmonzing this on a project would seem to fall to the team
leader, but actually people are self-organising to some extent. This
process is called \textbf{Team Development}, after \textbf{Tuckman}, and
can be encouraged with orthogonal practices such as \textbf{Team
Building exercises} (generally, submitting everyone to extreme
experiences in order to bond them together).

With enough communication bandwidth and entente, a team motivated will
self-organise code reviews, information exchange and improve their
practices. But \textbf{Staff Risks} sometimes cannot be resolved without
escalation:

\begin{itemize}
\tightlist
\item
  People leave, taking their \textbf{Internal Models} and expertise with
  them \textbf{Key Man Risk}.
\item
  People often require external training, to understand new tools and
  techniques \textbf{Learning-Curve Risk}
\item
  People can get protective about their knowledge in order to protect
  their jobs \textbf{Agency Risk}.
\item
  Where there are mixed ability levels, senior developers might not help
  juniors as it ``slows them down''
\item
  People don't get on.
\end{itemize}

\ldots{} and so on.

Experiments showed that rather than t

Resource Coordination Risk

split brain (left hand right hand)

People change their minds when they have evidence of new information,
and quickly forget what they \emph{previously thought} about things.

geographic risk

large organisation risks?

\hypertarget{dependency-risk}{%
\chapter{Dependency Risk}\label{dependency-risk}}

\textbf{Dependency Risk} is the risk you take on whenever you have a
dependency on something (or someone) else. One simple example could be
that the software service you write might depend on a server to run on.
If the server goes down, the service goes down too. In turn, the server
depends on electricity from a supplier, as well as a network connection
from a provider. If either of these dependencies aren't met, the service
is out of commission.

Dependencies can be on \emph{events}, \emph{people}, \emph{teams},
\emph{software}, \emph{services}, \emph{processes}: pretty much
\emph{anything}. Dependencies add risk to any project because the
reliability of the project itself is now a function involving the
reliability of the dependency.

In order to avoid repetition, and also to break down this large topic,
we're going to look at this over 4 sections.\\
- This first section will look at dependencies \emph{in general}, and
some of the variations on \textbf{Dependency Risk}. - Then, we'll move
on to look specifically at \textbf{Software Dependency Risk}, covering
using libraries, software services and building on top of the work of
others. - Then, we'll take a look at \textbf{Process Risk}, which is
still \textbf{Dependency Risk}, but we'll be considering more
organisational factors and how bureaucracy comes into the picture.\\
- Then, we'll look at some of the specific problems around working with
other people or businesses in \textbf{Agency Risk}.

\hypertarget{why-have-dependencies}{%
\section{Why Have Dependencies?}\label{why-have-dependencies}}

\hypertarget{reliability}{%
\section{Reliability}\label{reliability}}

Reliability of an overall system is constrained by the reliability

tbd. split this out into a section. there's so much more here.

Is it a known unknown? You know you might be going the wrong way.

Muneer building the extractor, using ASP.net.. turned out we don't
deploy .net/ASP only Java

\hypertarget{events}{%
\section{Events}\label{events}}

The simplest type of \textbf{Dependency Risk} is around events. For
example, ``I can't start shopping until the supermarket opens at 9am'',
or ``I must catch my bus to work at 7:30am''. In the first example, you
can't \emph{start} something until a particular event happens. In the
latter example, you must \emph{be ready} for an event at a particular
time.

When we have a dependency on an event, we depend on the reliability of
that event occurring when it says it will occur. We pick up
\textbf{Schedule Risk} when it doesn't.

Both of these types of risk can be mitigated with \emph{slack}. That is,
ensuring that the exact time of the event isn't critical to your plans:
Don't build into your plans a \emph{need} to start shopping at 9am.
Arrive at the bus-stop \emph{early} in order to mitigate your own
\textbf{Schedule Risk}.

\textbf{Schedule Risk} becomes very hard to manage when you have to
coordinate actions with lots of tightly-constrained events. Rehearsal?

Sometimes, events are a mitigation for \textbf{Coordination Risk}.
Having a fixed time for doing something mitigates \textbf{Coordination
Risk} by turning it into \textbf{Schedule Risk}. Agreeing a date for a
product launch, for example, allows lots of teams to coordinate their
activities.

\hypertarget{people-and-teams}{%
\section{People and Teams}\label{people-and-teams}}

Often, events are outside of our control, and we just have to plan
around them. But usually events occur at certain times because people
have chosen them to, in order to manage \textbf{Coordination Risk}.

\hypertarget{types-of-dependency-risk}{%
\section{Types Of Dependency Risk}\label{types-of-dependency-risk}}

So, let's look at the different kinds of \textbf{Dependency Risk} we
meet. Luckily, we've actually already come across most of this stuff
before: there's a lot of overlap between the risks due to dependencies,
and the risks we've already seen. It looks something like this:

\begin{figure}
\centering
\includegraphics{images/venn_dependency_risk.JPG}
\caption{Venn Dependency Risk}
\end{figure}

So, we're going to focus on
\protect\hyperlink{dependency-risk}{Dependency Risk} from 5 different
perspectives:

\begin{itemize}
\tightlist
\item
  \textbf{Reliability Risk}
\item
  \textbf{Communication Risk}
\item
  \textbf{Scheduling Risk}
\item
  \textbf{Complexity Risk}
\item
  \textbf{Dead-End Risk}
\end{itemize}

\textbf{Reliability Risk} is the new one here, so let's look at that
first.

\hypertarget{reliability-risk}{%
\subsection{Reliability Risk}\label{reliability-risk}}

\begin{itemize}
\item
  If a component \textbf{A} uses component \textbf{B}, unless there is
  some extra redundancy around \textbf{B}, then \textbf{A} \_can't be
  more reliable than \textbf{B}.
\item
  Are there bugs in \textbf{B} that are going to prevent it working
  correclty in all circumstances?
\end{itemize}

(This might sound unlikely, but I've made several career decisions off
the back of this)

Dependency and reliability

Pinto https://en.wikipedia.org/wiki/Reliability\_engineering

FECMA FEMA
https://en.wikipedia.org/wiki/Failure\_mode\_and\_effects\_analysis

Diagram of a distributed software system - where can failures hide?

SPOFs.

\hypertarget{communication-risk-1}{%
\subsection{Communication Risk}\label{communication-risk-1}}

We've already looked at communication risk\ldots{} tbd.

\begin{itemize}
\tightlist
\item
  The concept that there is a module \textbf{D} which solves my problem
  isn't something I'd even considered.\\
\item
  I'd like to have a dependency on some module \textbf{D}, but I don't
  even know what to search for.\\
\item
  I'd like to have a dependency on some module \textbf{D}, but there are
  multiple candidates for this dependency, and I don't know the ``best''
  one.
\item
  Or, I know \textbf{D}, but I can't figure out how to solve my problem
  in it.
\item
  Or, given that I've chosen \textbf{D}, I now need to persuade my team
  that \textbf{D} is the correct solution\ldots{}
\item
  \ldots{} and then they also need to understand \textbf{D} to do their
  job too.
\end{itemize}

(But: is understanding \textbf{D} more trouble than understanding ?)

I didn't even know I was missing Redux until I'd heard of it.

\hypertarget{scheduling-risk}{%
\subsection{Scheduling Risk}\label{scheduling-risk}}

\begin{figure}
\centering
\includegraphics{images/dependency_depends.png}
\caption{Dependency}
\end{figure}

If a component \textbf{A} of our project \emph{depends} on \textbf{B}
for some kind of processing, you might not be able to complete
\textbf{A} before writing \textbf{B}. This makes \emph{scheduling} the
project harder, and if component \textbf{A} is a risky part of the
project, then the chances are you'll want to mitigate risk there first.
There are a couple of ways to do this:

\begin{itemize}
\tightlist
\item
  \textbf{Standards}: If component \textbf{B} is a database, a queue,
  mail gateway or something else with a standard interface, then you're
  in luck. Write \textbf{A} to those standards, and find a cheap, simple
  implementation to test with. This gives you time to sort out exactly
  what implementation of \textbf{B} you're going for. This is not a
  great long-term solution, because obviously, you're not using the
  \emph{real} dependency- you might get surprised when the behaviour of
  the real component is subtly different. But it can reduce
  \textbf{Schedule Risk} in the short-term.
\item
  \textbf{Coding To Interfaces}: If standards aren't an option, but the
  surface area of \textbf{B} that \textbf{A} uses is quite small and
  obvious, you can write a small interface for it, and work behind that,
  using a \href{https://en.wikipedia.org/wiki/Mock_object}{Mock} for
  \textbf{B} while you're waiting for finished component. Write the
  interface to cover only what \textbf{A} \emph{needs}, rather than
  everything that \textbf{B} \emph{does} in order to minimize the risk
  of \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{Leaky
  Abstractions}.
\item
  \textbf{Do The Homework}: Accept that \textbf{B} is going to bite you
  and try to make the decision now. Pick the best 3rd-party component
  you can find (preferably on a trial basis), whilst being aware that
  you might get it wrong and need to change later. Write \textbf{Tests}
  to alleviate \textbf{Communication Risk} now, and then to use to
  evaluate alternatives if need be.
\end{itemize}

\hypertarget{dead-end-risk-1}{%
\subsection{Dead-End Risk}\label{dead-end-risk-1}}

First, when you choose a new component to depend on, you can't be
certain that it's going to work out in your favour. There's \textbf{Dead
End Risk} to find other people using the dependency in the same way as
you, or alternatively by \textbf{Prototyping} hard in order to uncover
as much of the \textbf{Hidden Risk} as possible.

Second, you can't always be sure that a dependency now will always have
the same guarantees in the future: - \textbf{Ownership changes} (e.g.
\href{http://oracle.com}{Oracle} buys \href{http://sun.com}{Sun} who own
\href{https://en.wikipedia.org/wiki/Java_\%28programming_language\%29}{Java}
for example) - \textbf{Licensing changes}. (e.g.
\href{http://oracle.com}{Oracle} buys \textbf{Tangosol} who make
\href{https://en.wikipedia.org/wiki/Oracle_Coherence}{Coherence} for
example) - Security updates not applied. - \textbf{Better alternatives
become available}: As a real example of this, I began a project in 2016
using \textbf{Apache Solr}. However, in 2018, I would probably use
\href{https://en.wikipedia.org/wiki/Elasticsearch}{ElasticSearch}. In
the past, I've built websites using \textbf{Drupal} and then later
converted them to use \textbf{Wordpress}.

Some predictors:

\begin{itemize}
\item
  Or they produce a new version which is incompatible with your old
  version, forcing you to upgrade? (libraries, webservices)
\item
  Dependency Change - REST endpoints, etc. Semantic versioning . Hickey
\end{itemize}

\hypertarget{complexity-risk-1}{%
\subsection{Complexity Risk}\label{complexity-risk-1}}

I don't know whether a library is actually going to reduce my
\textbf{Codebase Risk} or make it worse.

Although

These stem from

\begin{itemize}
\item
  Jar hell: are you bringing in more stuff than is helping you? Are you
  really overall decreasing complexity on the project or making it
  worse? {[}Versioning Risk{]}( (testing jars vs runtime jars. how
  integrated is the jar in question? Is it everywhere, or is it behind
  an interface?
\item
  Shipped size complexity - Spring. Sometimes, you just end up with a
  ton of jars, even when they don't collide on version numbers.
  (Kolmogorov Complexity?)
\item
  Big O Complexity Again (Complexity-Risk)
\end{itemize}

Example

In a project at work, coming across use of Hazlecast to cache the
session IDs. But, the app is only used once every month, and session IDs
can be obtained in milliseconds. Why cache them? By doing this, you have
introduced extra dependency risk, cache invalidation risks, networking
risks, synchronisation risks and so on, for actually no benefit at all.
Unless, it's CV building.

Sometimes, the amount of code and complexity \emph{goes up}: Spring
Templates example: really hard to debug, more code. But, better? No
chance of injection attacks.

\hypertarget{choosing-and-using-a-library}{%
\section{Choosing And Using A
Library}\label{choosing-and-using-a-library}}

m\&t risk, obvs. but 1. Is it alive? 2. Is it open source? 3. Well
trafficked 4. Namespace 5. Look at the source 6. Alternatives available?
7. Traction (vs.~expected traction)

Trying things out usually has a low Dead end Risk vs coding yourself,
and you can usually try several

\begin{itemize}
\tightlist
\item
  number of dependencies it has
\end{itemize}

Write as little code as possible.

-- we don't use bounded rationality.

how to choose libraries

-- the dependency you already have (e.g.~spring)

\hypertarget{choosing-libraries}{%
\section{Choosing Libraries}\label{choosing-libraries}}

\begin{itemize}
\tightlist
\item
  3rd party contractors
\end{itemize}

dependencies between teams

dependencies between modules Dependency Mismatch gantt charts

Visibility Risk

Silo thinking

Lots of beginners don't see dependency risk: they have the dependencies
round the wrong way in their heads. eg. sunny with jenkins and
environment variables. You can't solve a problem if you are working down
the line of dependencies but your issue is with an earlier one

counterparty risk insurance

dependency ijection - invisibile dependencies

reliability risk

Dealing with Dependency Risk is what project managers do

\hypertarget{process-risk}{%
\chapter{Process Risk}\label{process-risk}}

\textbf{Process Risk}, as we will see, is the risk you take on whenever
you embark on a process. This is the final part of our analysis of
different \textbf{Dependency Risks}, so at the end of this section we're
going to summarise what we've learned about \textbf{Dependency Risk} so
far.

But first, what exactly is a process?

tbd. definition

\hypertarget{elaboration}{%
\section{Elaboration}\label{elaboration}}

In the software development world, and the business world generally,
processes usually involve \emph{forms}. If you're filling out a form
(whether on paper or on a computer) then you're involved in a process of
some sort, whether an ``Account Registration'' process, ``Loan
Application'' process or ``Consumer Satisfaction Survey'' process.

Later in this section we'll look at

\hypertarget{the-purpose-of-process}{%
\section{The Purpose Of Process}\label{the-purpose-of-process}}

Process exists to mitigate other kinds of risk, and for this reason,
we'll be looking at them again in \textbf{Practices}. In this section,
we'll look mainly at how you can deal with \textbf{Process Risk} where
you are a client of the process. However, in the later section we'll
look at how you can use process design to your advantage mitigating risk
on your own project.

But until we get there, let's look at some examples of how process can
mitigate other risks:

\begin{itemize}
\tightlist
\item
  \textbf{Coordination Risk}: You can often use process to help people
  coordinate. For example, a production Line is a process where work
  being done by one person is pushed to the next person when it's done.
  A meeting booking process ensures that people will all attend a
  meeting together at the same place and time, and that a room is
  available for it.
\item
  \textbf{Dependency Risk}: You can use processes to make dependencies
  explicit and mitigate dependency risk. For example, a process for
  hiring a car will make sure there is a car available at the time you
  need it. Alternatively, if we're processing a loan application, we
  might need evidence of income or bank statements. We can push this
  \protect\hyperlink{dependency-risk}{Dependency Risk} onto the person
  asking for the loan, by making it part of the process and not
  accepting the application until this has been provided.
\item
  \textbf{Complexity Risk}: Working within a process can reduce the
  amount of Complexity you have to deal with. We accept that processes
  are going to slow us down, but we appreciate the reduction in risk
  this brings. (They allow us to trade Complexity for schedule risk).
  For example, setting up a server might be complex, but filling in a
  form to do the job might simplify things. Clearly, the complexity
  hasn't gone away, but it's hidden within the process. Process
  therefore can provide \protect\hyperlink{abstraction}{Abstraction}.
\item
  \textbf{Operational Risk}: Operational Risk is the risk of people not
  doing their job properly (tbd). But, by having a process, (and asking,
  did this person follow the process?) you can draw a distinction
  between a process failure and a personnel failure. For example, making
  a loan to a money launderer \emph{could} be a failure of the loan
  agent. But, if they followed the \emph{process}, it's a failure of the
  Process itself.
\end{itemize}

\hypertarget{evolution-of-business-process}{%
\section{Evolution Of Business
Process}\label{evolution-of-business-process}}

Before we get to examining different \emph{Process Risks}, let's
consider how processes form. Specifically, we're going to look at
\emph{Business Process}:

tbd

Business Processes often arise in response to an unmet need within an
organisation. And, as we said above, they are usually there to mitigate
other risks. Let's look at an example lifecycle of how that can happen:

tbd image.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Person \texttt{B} in a company starts doing \texttt{A}. A is really
  useful! B gets busy. No one cares. But then, B goes on holiday. A
  doesn't get done, and people now care: the \textbf{Dependency Risk} is
  apparent.
\end{enumerate}

tbd

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Either, B co-opts other people to help, gets given a team (T), or
  someone else forms a team T containing B to get the job done
  ``properly''. T has control of A (it might be a resource, some source
  of complexity, whatever). However, it needs to supply the company with
  A reliably and responsibly, otherwise there will be problems. They
  can't simply sit on the resource and do nothing, but at the same time,
  so they try and please all of their clients as far as possible. This
  is a good deal for their clients, but they end up absorbing a lot of
  risk.
\end{enumerate}

tbd

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  T organises bureaucratically, so that there is a controlled process
  (P) by which A can get done. Like a cell, they have arranged a
  protective barrier around themselves, the strength of which depends on
  the power conferred to them by control of A. P probably involves
  filling in a form (or following some other \textbf{Protocol}). They
  can now deal with requests on a first-come-first-served basis:
  {[}Resource Risk{]} and \protect\hyperlink{dependency-risk}{Dependency
  Risk} are externalized.
\end{enumerate}

tbd

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  But, there are abuses of A: people either misuse it, or use it too
  much. People do things in the wrong order. T reacts and sets up
  sign-off, authorization or monetary barriers around B, increasing the
  bureauratic load involved in using A. But, also by requiring these
  things, they move risk \emph{out of} their team.
\end{enumerate}

tbd

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  There are further abuses of A: bureaucratic load increases to match,
  increasing the amount of \emph{process} to use A. This corresponds to
  greater \textbf{Process Risk} for clients of T.
\end{enumerate}

tbd

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Person C, who has experience working with team T acts as a middleman
  for customers requiring some variant of A. They are able to help
  navigate the bureaucratic process (deal with Process Risk). The cycle
  potentially starts again, except with process risk being dealt with by
  someone else.
\end{enumerate}

In each step, you can see how the organisation evolves to mitigate risk
around the use (and misuse) of \texttt{A}: First, \textbf{Dependency
Risk}, then \textbf{Coordination Risk}, then \textbf{Dependency Risk}
and finally, the \textbf{Process Risk} of the process that was created
to mitigate everything else. This is an example of \emph{Process
following Strategy}:

\begin{quote}
In this conception, you can see how the structure of an organisation
(the teams and processes within it, the heirarchy of control) will
`evolve' from the resources of the organisation and the strategy it
pursues. Processes evolve to meet the needs of the organisation,
\end{quote}

\begin{itemize}
\tightlist
\item
  {[}MInzberg, strategy safari{]}
\end{itemize}

In each step, the actors involved have been acting in good faith: they
are working to mitigate risk in the organisation. The \textbf{Process
Risk} that accretes along the way is an \emph{unintended consequence}:
There is no guarantee that the process that arises will be humane and
intuitive. Many organisational processes end up being baroque or
Kafkaesque, forcing unintuitive contortions on their users. Dealing with
complex processes is a \textbf{Communication Risk} because you have to
translate your requirements into the language of the process.

But {[}Parkinson's Law{]} takes this one step further: the human actors
shaping the organisation will abuse their positions of power in order to
further their own careers (this is \textbf{Agency Risk}, which we will
come to in a future section):

tbd - parkinson's law

\hypertarget{an-example---release-process}{%
\section{An Example - Release
Process}\label{an-example---release-process}}

For many years I have worked in the Finance Industry, and it's given me
time to observe how, across an entire industry, process can evolve, both
in response to regulatory pressure but also because of organisational
maturity, and mitigating risks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initially, I could release software by logging onto the production
  accounts with a password that everyone knew, and deploy software or
  change data in the database.\\
\item
  The first issue with this is bad actors. How could you know that the
  numbers weren't being altered in the databases? Production auditing
  came in so that at least you could tell \emph{who was changing what},
  in order to point the blame later.
\item
  But, there was still plenty of scope for deliberate or accidental
  damage. I personally managed to wipe production data on one occasion
  by mistaking it for a development environment. Eventually, passwords
  were taken out of the hands of developers and you needed approval to
  ``break glass'' to get onto production.\\
\item
  Change Requests were introduced. This is another approval process
  which asks you to describe what you want to change in production, and
  why you want to change it. In most places, this was quite an onerous
  process, so the unintended consequence was that release cadence was
  reduced.
\item
  The change request software is generally awful, making the job of
  raising change requests tedious and time-consuming. Therefore,
  developers would \emph{automate} the processes for release, sometimes
  including the process to write the change request. This allowed them
  to improve release cadence, at the expense of owning more code.
\item
  Auditors didn't like the fact that this automation existed, because
  effectively, that meant that developers could get access to production
  with the press of a button, effectively taking you back to step 1. So
  auditing of Change Requests had to happen.
\end{enumerate}

\ldots{} and so on. tbd.

\hypertarget{process-risks}{%
\section{Process Risks}\label{process-risks}}

\textbf{Process Risk}, then, is a type of \textbf{Dependency Risk},
where you are relying on a process. In a way, it's no different from any
other kind of \protect\hyperlink{dependency-risk}{Dependency Risk}. But
\protect\hyperlink{process-risk}{Process Risk} manifests itself in
fairly predictable ways:

\begin{itemize}
\tightlist
\item
  \textbf{Reliability Risk}: If \emph{people} are part of the process,
  there's the chance that they forget to follow the process itself, and
  miss steps or forget your request completely. The reliability is
  related to the amount of
  \protect\hyperlink{complexity-risk-1}{Complexity Risk} the process is
  absorbing.
\item
  {[}Visibility Risk{]}: Usually, processes (like other dependencies)
  trade \protect\hyperlink{complexity-risk-1}{Complexity Risk} for
  visibility: it's often not possible to see how far along a process is
  to completion. Sometimes, you can do this to an extent. For example,
  when I send a package for delivery, I can see roughly how far it's got
  on the tracking website. But, this is still less-than-complete
  information, and is a representation of reality.\\
\item
  Process Fit Risk/ \textbf{Dead-End Risk}: You have to be careful to
  match the process to the outcome you want. Much like choosing a
  \textbf{Software Dependency}, initiating a process has no guarantee
  that your efforts won't be wasted and you'll be back where you started
  from. The chances of this happening increase as you get further from
  the standard use-case for the process, and the sunk cost increases
  with the length of time the process takes to report back.
\item
  \textbf{Agency Risk}: Due to Parkinson's Law, above.
\end{itemize}

\hypertarget{operational-risk}{%
\section{Operational Risk}\label{operational-risk}}

When processes fail, this is called \emph{Operational Risk}:

tbd - Wikipedia definition

This is a very specific name for
\protect\hyperlink{reliability-risk}{Reliability Risk} with regard to
processes. In the UK each year, X number of people are killed in car
accidents. If you regard driving a car from A to B as a process, then
you could say that car accidents are
\protect\hyperlink{operational-risk}{Operational Risk}. Why do we
tolerate such costly operational risk in the UK. Could it be reduced?
Well, yes. There are lots of ways. One way is that we could just reduce
the speed limit.

It is interesting that we \emph{don't} do that: although we know the
driving process fails, and fails in a way that is costly to human lives,
as a society we value the freedom, the economic efficiency and time
savings that come from not mitigating this operational risk. Changing
the speed limit would have it's own risks, of course: there would be a
complicated transition to manage. However, if ten times as many people
were killed in car accidents, and it was shown that reducing the speed
limit would help, maybe it would be done. The
\protect\hyperlink{operational-risk}{Operational Risk} would outweigh
the \textbf{Schedule Risk}.

The point of this is that we \emph{accept}
\protect\hyperlink{operational-risk}{Operational Risk} as we go.
However, if opportunities rise to mitigate it, which don't leave us with
a net risk increase elsewhere, we'll make those improvements.

\hypertarget{feedback-loops}{%
\section{Feedback Loops}\label{feedback-loops}}

\protect\hyperlink{operational-risk}{Operational Risk} is usually
incurred for outliers: processes tend to work well for the common cases,
because \emph{practice makes perfect}. Processes are really tested when
unusual situations occur. Having mechanisms to deal with edge-cases can
incur \protect\hyperlink{complexity-risk-1}{Complexity
Risk}Complexity-Risk), so often it's better to try and have clear
boundaries of what is ``in'' and ``out'' of the process' domain.

Sometimes, processes are \emph{not} used commonly. How can we rely on
them anyway? Usually, the answer is to build in extra feedback loops
anyway:

\begin{itemize}
\tightlist
\item
  Testing that backups work, even when no backup is needed.
\item
  Running through a disaster recovery scenario at the weekend.
\item
  Increasing the release cadence, so that we practice the release
  process more.
\end{itemize}

The feedback loops allow us to perform \textbf{Retrospectives and
Reviews} to improve our processes.

\hypertarget{sign-offs}{%
\section{Sign-Offs}\label{sign-offs}}

Often, Processes will include sign-off steps. The Sign-Off is an
interesting mechanism: by signing off on something for the business,
people are usually in some part staking their reputation on something
being right. Therefore, you would expect that sign-off involves a lot of
\textbf{Agency Risk}: people don't want to expose themselves in
career-limiting ways. Therefore, the bigger the risk they are being
asked to swallow, the more cumbersome and protracted the sign off
process. Often, Sign Offs boil down to a balance of risk for the signer:
on the one hand, personal risk from signing off, on the other, the risk
of upsetting the rest of the staff waiting for the sign-off, and the
{[}Dead End Risk{]} of all the effort gone into getting the sign off if
they don't.

This is a nasty situation, but there are a couple of ways to de-risk
this: - break signoffs down into bite-size chunks of risk that are
acceptable to those doing the sign-off.\\
- Agree far-in-advance the sign-off criteria. As discussed in
\textbf{Risk Theory}, people have a habit of heavily discounting future
risk, and it's much easier to get agreement on the criteria than it is
to get the sign-off.

\hypertarget{dependencies---a-quick-review}{%
\section{Dependencies - A Quick
Review}\label{dependencies---a-quick-review}}

Dependency of any kind is a choice in which you are trying to choosing a
position of lower \textbf{Attendant Risk} than you would have without
the dependency.

So, we've looked at different types of dependencies.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.15\columnwidth}\raggedright
What does the risk look like?\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedright
Software Dependency\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\raggedright
Process\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedright
Event\strut
\end{minipage} & \begin{minipage}[b]{0.21\columnwidth}\raggedright
Person\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\href{}{Dependency Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\href{}{Software Dependency Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\href{}{Process Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\href{}{Deadline Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
{[}Key-Man Risk{]}{[}5{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
----------------------------------\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
--------------------\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
-------------------------------\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
Risks Mitigated\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
{[}Complexity Risk{]}{[}6{]} from having\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
{[}Complexity Risk{]}{[}6{]}\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
{[}Coordination Risk{]}{[}7{]}\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
{[}Resource Coordination Risk{]}{[}8{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
to do the process yourself\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
----------------------------------\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
--------------------\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
-------------------------------\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\protect\hyperlink{communication-risk-1}{Communication Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
Understanding the API, using it\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Filling in forms\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Communicating the\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
- Being misunderstood\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
wrongly.\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
right place and time\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
- Instructions not followed\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
to everyone\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
----------------------------------\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
--------------------\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
-------------------------------\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
{[}Invisibility Risk{]}\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
Understanding the API, but not the\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
You don't know how\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
- Will people show up?\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
implementation. Debugging\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
far along the work\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
- Will it be what you\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
is harder.\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
might be\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
expect?\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
----------------------------------\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
--------------------\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
-------------------------------\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\protect\hyperlink{feature-risk}{Feature Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
The product might not work how you\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Might not\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
Is this:\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
Do the available staff have\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
expected. If features are missing\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
cater to your exact\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
-What you want\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
the skills you need?\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
you might be stuck.\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
use case\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
-When you want it?\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
----------------------------------\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
--------------------\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
----------------------\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
-------------------------------\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
{[}Dead End Risk{]}\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{schedule-risk}{%
\chapter{Schedule Risk}\label{schedule-risk}}

\textbf{Schedule Risk} is the fundamental risk you face because of
\emph{lack of time}.

You could also call this \textbf{Chronological Risk} or just
\textbf{Time Risk} if you wanted to.

\textbf{Schedule Risk} is very pervasive, and really underlies
\emph{everything} we do. People \emph{want} things, but they \emph{want
them at a certain time}. We need to eat and drink every day, for
example. We might value having a great meal, but not if we have to wait
three weeks for it.

And let's go completely philosophical for a second: If you were
completely immortal, you'd probably not feel the need to buy
\emph{anything}. You'd clearly have no \emph{needs}, and anything you
wanted, you could create yourself within your infinite time-budget.
Rocks don't need money, after all.

Let's look at some specific kinds of \textbf{Schedule Risk}.

\hypertarget{opportunity-risk}{%
\section{Opportunity Risk}\label{opportunity-risk}}

\textbf{Opportunity Risk} is really the concern that whatever we do, we
have to do it \emph{in time}. If we wait too long, we'll miss the
\href{https://en.wikipedia.org/wiki/Window_of_opportunity}{Window Of
Opportunity} for our product or service.

Any product idea is necessarily of it's time: the \textbf{Goal In Mind}
will be based on observations from a particular \textbf{Internal Model},
reflecting a view on reality at a specific \emph{point in time}.

How long will that remain true for? This is your \emph{opportunity}: it
exists apart from any deadlines you set yourself, or funding deadlines.
It's purely, ``how long will this idea be worth doing?''

With any luck, decisions around \emph{funding} your project will be tied
into this, but it's not always the case. It's very easy to undershoot or
overshoot the market completely and miss the window of opportunity.

\hypertarget{the-ipad}{%
\subsection{The iPad}\label{the-ipad}}

For example, let's look at the
\href{https://en.wikipedia.org/wiki/History_of_tablet_computers}{iPad},
which was introduced in 2010 and was hugely successful.

This was not the first tablet computer. Apple had already tried to
introduce the \href{https://en.wikipedia.org/wiki/Apple_Newton}{Newton}
in 1989, and Microsoft had released the
\href{https://en.wikipedia.org/wiki/Microsoft_Tablet_PC}{Tablet PC} in
1999. But somehow, they both missed the
\href{https://en.wikipedia.org/wiki/Window_of_opportunity}{Window Of
Opportunity}. Possibly, the window existed because Apple had changed
changed the market with their release of the iPhone, which left people
open to the idea of a tablet being ``just a bigger iPhone''.

But maybe now, the iPad's window is closing? We have more \emph{wearable
computers} like the Apple Watch, and voice-controlled devices like
Alexa, Cortana and (cough) Siri. Peak iPad was in 2014, according to
\href{https://www.statista.com/statistics/269915/global-apple-ipad-sales-since-q3-2010/}{this
graph}.

So, it seems Apple timed the iPad to hit the peak of the Window of
Opportunity.

But, even if you time the Window Of Opportunity correctly, you might
still have the rug pulled from under your feet due to a different kind
of \textbf{Schedule Risk}.

\hypertarget{deadline-risk}{%
\section{Deadline Risk}\label{deadline-risk}}

Often when running a software project, you're given a team of people and
told to get something delivered by a certain date. i.e.~you have an
artificially-imposed \textbf{Deadline} on delivery.

What happens if you miss the deadline? It could be: - The funding on the
project runs out, and it gets cancelled. - You have to go back to a
budgeting committee, and get more money. - The team gets replaced,
because of lack of faith.

.. or something else.

Deadlines can be set by an authority in order to \emph{sharpen focus}
and reduce \textbf{Coordination Risk}. This is how we arrive at tools
like \href{https://en.wikipedia.org/wiki/SMART_criteria}{SMART
Objectives} and
\href{https://en.wikipedia.org/wiki/Performance_indicator}{KPI's (Key
Performance Indicators)}. Time scales change the way we evaluate goals,
and the solutions we choose. In JFK's quote:

\begin{quote}
``First, I believe that this nation should commit itself to achieving
the goal, before this decade is out, of landing a man on the moon and
returning him safely to the Earth.'' - John F. Kennedy, 1961
\end{quote}

The 9-year timespan came from an authority figure (the president) and
helped a huge team of people coordinate their efforts and arrive at a
solution that would work within a given time-frame. Compare with this
quote:

\begin{quote}
``I love deadlines. I love the whooshing noise they make as they go
by.'' - Douglas Adams
\end{quote}

As a successful author, Douglas Adams \emph{didn't really care} about
the deadlines his publisher's gave him. The \textbf{Deadline Risk} was
minimal for him, because the publisher wouldn't be able to give his
project to someone else to complete.

Sometimes, deadlines are set in order to \emph{coordinate work between
teams}. The classic example being in a battle, to coordinate attacks.
When our deadlines are for this purpose, we're heading towards
\textbf{Coordination Risk} territory.

\hypertarget{funding-risk}{%
\section{Funding Risk}\label{funding-risk}}

On a lot of software projects, you are ``handed down'' deadlines from
above, and told to deliver by a certain date or face the consequences.
But sometimes you're given a budget instead, which really just adds
another layer of abstraction to the \textbf{Schedule Risk}: That is, do
I have enough funds to cover the team for as long as I need them?

This grants you some leeway as now you have two variables to play with:
the \emph{size} of the team, and \emph{how long} you can run it for. The
larger the team, the shorter the time you can afford to pay for it.

In startup circles, this ``amount of time you can afford it'' is called
the ``runway'': you have to get the product to ``take-off'' before the
runway ends. So you could term this component as \textbf{Runway Risk}.

Startups often spend a lot of time courting investors in order to get
funding and mitigate this type of \textbf{Schedule Risk}. But, this
activity comes at the expense of \textbf{Opportunity Risk} and
\textbf{Feature Risk}, as usually the same people are trying to raise
funds as build the project itself.

\hypertarget{staff-risk-turnover-risk}{%
\section{Staff Risk / Turnover Risk}\label{staff-risk-turnover-risk}}

If a startup has a \textbf{Runway}, then the chances are that the
founders and staff do too, as this article
\href{https://www.entrepreneur.com/article/223135}{explores}. It
identifies the following risks:

\begin{itemize}
\tightlist
\item
  Company Cash: The \textbf{Runway} of the startup itself
\item
  Founder Cash: The \textbf{Runway} for a founder, before they run out
  of money and can't afford their rent.
\item
  Team Cash: The \textbf{Runway} for team members, who may not have the
  same appetite for risk as the founders do.
\end{itemize}

You need to consider how long your staff are going to be around,
especially if you have \textbf{Key Man Risk} on some of them. You also
can't rely on getting the \textbf{best staff for failing projects}.

\hypertarget{student-syndrome}{%
\section{Student Syndrome}\label{student-syndrome}}

\href{https://en.wikipedia.org/wiki/Student_syndrome}{Student Syndrome}
is, according to Wikipedia:

\begin{quote}
``Student syndrome refers to planned procrastination, when, for example,
a student will only start to apply themselves to an assignment at the
last possible moment before its deadline.'' -
\emph{\href{https://en.wikipedia.org/wiki/Student_syndrome}{Wikipedia}}
\end{quote}

Arguably, there is good psychological, evolutionary and risk-based
reasoning behind procrastination: the further in the future the
\textbf{Deadline Risk} is, the more we discount it. If we're only ever
mitigating our \emph{biggest risks}, then deadlines in the future don't
matter so much, do they? And, putting efforts into mitigating future
risks that \emph{might not arise} is wasted effort.

Or at least, that's the argument. If you're \textbf{Discounting the
Future To Zero} then you'll be pulling all-nighters in order to deliver
any assignment.

So, the problem with \textbf{Student Syndrome} is that the \emph{very
mitigation} for \textbf{Schedule Risk} (allowing more time) is an
\textbf{attendant risk} that \emph{causes} \textbf{Schedule Risk}:
you'll work towards the new, generous deadline more slowly, and you'll
end up revealing \textbf{Hidden Risk} \emph{later} than you would have
with the original, pressing deadline \ldots{} and you end up being late
because of them.

We'll look at mitigations for this in \textbf{Prioritisation}.

\hypertarget{red-queen-risk}{%
\section{Red-Queen Risk}\label{red-queen-risk}}

A more specific formulation of \textbf{Schedule Risk} is \textbf{Red
Queen Risk}, which is that whatever you build at the start of the
project will go slowly more-and-more out of date as the project goes on.

This is named after the Red Queen quote from Alice in Wonderland:

\begin{quote}
``My dear, here we must run as fast as we can, just to stay in place.
And if you wish to go anywhere you must run twice as fast as that.'' -
\href{https://www.goodreads.com/quotes/458856-my-dear-here-we-must-run-as-fast-as-we}{Lewis
Carroll, \emph{Alice in Wonderland}}
\end{quote}

The problem with software projects is that tools and techniques change
\emph{really fast}. In 2011, 3DRealms released Duke Nukem Forever after
\href{https://en.wikipedia.org/wiki/Duke_Nukem_Forever}{15 years in
development}, to negative reviews:

\begin{quote}
``\ldots{} most of the criticism directed towards the game's long
loading times, clunky controls, offensive humor, and overall aging and
dated design.'' -
\emph{\href{https://en.wikipedia.org/wiki/Duke_Nukem_Forever}{Duke Nukem
Forever, Wikipedia}}
\end{quote}

Now, they didn't \emph{deliberately} take 15 years to build this game
(lots of things went wrong). But, the longer it took, the more their
existing design and code-base were a liability rather than an asset.

Personally, I have suffered the pain on project teams where we've had to
cope with legacy code and databases because the cost of changing them
was too high. And any team who is stuck using
\href{https://en.wikipedia.org/wiki/Visual_Basic}{Visual Basic 6.0} is
here. It's possible to ignore \textbf{Red Queen Risk} for a time, but
this is just another form of \textbf{Technical Debt} which eventually
comes due.

\hypertarget{schedule-risk-and-feature-risk}{%
\section{Schedule Risk and Feature
Risk}\label{schedule-risk-and-feature-risk}}

In the section on \textbf{Feature Risk} we looked at \textbf{Market
Risk}, the idea that the value of your product is itself at risk from
the morés of the market, share prices being the obvious example of that
effect. In Finance, we measure this using \emph{money}, and we can put
together probability models based on how much money you might make or
lose.

With \textbf{Schedule Risk}, the underlying measure is \emph{time}:\\
- ``If I implement feature X, I'm picking up something like 5 days of
\textbf{Schedule Risk}.'' - ``If John goes travelling that's going to
hit us with lots of \textbf{Schedule Risk} while we train up Anne.''

\ldots{} and so on. Clearly, in the same way as you don't know exactly
how much money you might lose or gain on the stock-exchange, you can't
put precise numbers on \textbf{Schedule Risk} either.

Having looked at both Time and Money components of risk, let's look at
something equally fundamental, \textbf{Complexity Risk}.

beating rush hour

\hypertarget{agency-risk}{%
\chapter{Agency Risk}\label{agency-risk}}

\marginpar{
  \includegraphics{images/generated/agency-risk.png}
}

\textbf{Coordinating a team} is difficult enough when everyone on the
team has a single \textbf{Goal}. But, people have their own goals, too.
Sometimes, the goals harmlessly co-exist with the team's goal, but other
times they don't.

This is \textbf{Agency Risk}. This term comes from finance and refers to
the situation where you (the ``principal'') entrust your money to
someone (the ``agent'') in order to invest it, but they don't
necessarily have your best interests at heart. They may instead elect to
invest the money in ways that help them, or outright steal it.

\begin{quote}
``This dilemma exists in circumstances where agents are motivated to act
in their own best interests, which are contrary to those of their
principals, and is an example of moral hazard.'' -
\href{https://en.wikipedia.org/wiki/Principal–agent_problem}{Principal-Agent
Problem, \emph{Wikipedia}}
\end{quote}

The less visibility you have of the agent's activities, the bigger the
risk. However, the whole \emph{point} of giving the money to the agent
was that you would have to spend less time and effort managing it. Hence
the dilemma. So, \textbf{Agency Risk} flourishes where there is
\textbf{Invisibility Risk}.

\textbf{Agency Risk} clearly includes the behaviour of
\href{https://en.wiktionary.org/wiki/bad_actor}{Bad Actors}. But, this
is a very strict definition of \textbf{Agency Risk}. In software
development, we're not lending each other money, but we are being paid
by the project sponsor, so they are assuming \textbf{Agency Risk} by
employing us.

Let's look at some examples of borderline \textbf{Agency Risk}
situations, in order to sketch out where the domain of this risk lies.

\hypertarget{cv-building}{%
\section{CV Building}\label{cv-building}}

This is when someone decides that the project needs a dose of ``Some
Technology X'', but in actual fact, this is either completely unhelpful
to the project (incurring large amounts of \textbf{Complexity Risk}), or
merely less useful than something else.

It's very easy to spot CV building: look for choices of technology that
are incongruently complex compared to the problem they solve, and then
challenge by suggesting a simpler alternative.

\hypertarget{consultancies}{%
\section{Consultancies}\label{consultancies}}

When you work with an external consultancy, there is \emph{always} more
\textbf{Agency Risk} than with a direct employee. This is because as
well as your goals and the employee's goals, there is also the
consultancy's goals.

This is a good argument for not using consultancies, but sometimes the
technical expertise they bring can outweigh this risk.

Also, try to look for \emph{hungry} consultancies: if you being a happy
client is valuable to them, they will work at a discount (either working
cheaper, harder or longer or more carefully) as a result.

\hypertarget{the-hero}{%
\section{The Hero}\label{the-hero}}

\begin{quote}
``The one who stays later than the others is a hero.'' -
\href{http://wiki.c2.com/?HeroCulture}{Hero Culture, \emph{Ward's Wiki}}
\end{quote}

Heroes put in more hours and try to rescue projects single-handedly,
often cutting corners like team communication and process in order to
get there.

Sometimes, projects don't get done without heroes. But other times, the
hero has an alternative agenda than just getting the project done:

\begin{itemize}
\tightlist
\item
  A need for control, and for their own vision.
\item
  A preference to work alone.
\item
  A desire for recognition and acclaim from colleagues.
\item
  For the job security of being a
  \href{https://en.wikipedia.org/wiki/Key_person_insurance}{Key Man}.
\end{itemize}

A team \emph{can} make use of heroism, but it's a double-edged sword.
The hero can becomes \textbf{a bottleneck} to work getting done, and
because want to solve all the problems themselves, they
\textbf{under-communicate}.

\hypertarget{devil-makes-work}{%
\section{Devil Makes Work}\label{devil-makes-work}}

Heroes can be useful, but \emph{underused} project members are a
nightmare. The problem is, people who are not fully occupied begin to
worry that actually, the team would be better off without them, and then
wonder if their jobs are at risk.

The solution to this is ``busy-work'': finding tasks that, at first
sight, look useful, and then delivering them in an over-elaborate way
(\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}) that'll keep them occupied. This will leave you with more
\textbf{Complexity Risk} than you had in the first place.

Even if they don't worry about their jobs, doing this is a way to stave
off \emph{boredom}.

\hypertarget{pet-projects}{%
\section{Pet Projects}\label{pet-projects}}

\begin{quote}
A project, activity or goal pursued as a personal favourite, rather than
because it is generally accepted as necessary or important. -
\href{https://en.wiktionary.org/wiki/pet_project}{Pet Project,
\emph{Wiktionary}}
\end{quote}

Sometimes, budget-holders have projects they value more than others
without reference to the value placed on them by the business. Perhaps
the project has a goal that aligns closely with the budget holder's
passions, or its related to work they were previously responsible for.

Working on a pet project usually means you get lots of attention (and
more than enough budget), but due to \textbf{Map and Territory Risk}, it
can fall apart very quickly under scrutiny.

\hypertarget{morale-risk}{%
\section{Morale Risk}\label{morale-risk}}

\begin{quote}
Morale, also known as Esprit de Corps is the capacity of a group's
members to retain belief in an institution or goal, particularly in the
face of opposition or hardship -
\href{https://en.wikipedia.org/wiki/Morale}{Morale, \emph{Wikipedia}}
\end{quote}

\begin{figure}
\centering
\includegraphics{images/generated/morale-risk.png}
\caption{Morale Risk}
\end{figure}

Sometimes, the morale of the team or individuals within it dips, leading
to lack of motivation. \textbf{Morale Risk} is a kind of \textbf{Agency
Risk} because it really means that a team member or the whole team isn't
committed to the \textbf{Goal}, may decide their efforts are best spent
elsewhere. \textbf{Morale Risk} might be caused by:

\begin{itemize}
\tightlist
\item
  External factors: Perhaps the employees' dog has died, or they're
  simply tired of the industry, or are not feeling challenged.
\item
  If the team don't believe a goal is achievable, they won't commit
  their full effort to it. This might be due to to a difference in the
  evaluation of the risks on the project between the team members and
  the leader.
\item
  If the goal isn't considered sufficiently worthy, or the team isn't
  sufficiently valued.
\item
  In military science, a second meaning of morale is how well supplied
  and equipped a unit is. This would also seem like a useful reference
  point for IT projects. If teams are under-staffed or under-equipped,
  this will impact on motivation too.
\end{itemize}

\hypertarget{hubris-ego}{%
\section{Hubris \& Ego}\label{hubris-ego}}

It seems strange that humans are over-confident. You would have thought
that evolution would drive out this trait but apparently it's not so:

\begin{quote}
``Now, new computer simulations show that a false sense of optimism,
whether when deciding to go to war or investing in a new stock, can
often improve your chances of winning.'' -
\href{https://news.nationalgeographic.com/news/2011/09/110914-optimism-narcissism-overconfidence-hubris-evolution-science-nature/}{Evolution
of Narcissism, \emph{National Geographic}}
\end{quote}

In any case, humans have lots of self-destructive tendencies that
\emph{haven't} been evolved away, and we get by.

Development is a craft, and ideally, we'd like developers to take pride
in their work. Too little pride means lack of care, but too much pride
is \emph{hubris}, and the belief that you are better than you really
are. Who does hubris benefit? Certainly not the team, and not the goal,
because hubris blinds the team to hidden risks that they really should
have seen.

Although over-confidence might be a useful trait when bargaining with
other humans, the thesis of everything so far is that \textbf{Meeting
Reality} will punish your over-confidence again and again.

Perhaps it's a little unfair to draw out one human characteristic for
attention. After all, we are
\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{riddled
with biases}. There is probably an interesting article to be written
about the effects of different biases on the software development and
project management processes. This task is left as an exercise for the
reader.

tbd chapter link

\hypertarget{map-and-territory-risk}{%
\chapter{Map And Territory Risk}\label{map-and-territory-risk}}

As we discussed in the section on \textbf{Abstraction Risk}, our
understanding of the world is entirely informed by the names we give
things and the abstractions we create.

\textbf{Map And Territory Risk} is the recognition that there is a
danger that we come to believe the abstractions are more real than
reality itself. It comes from the expression ``Confusing the Map for the
Territory''. That is believing the abstraction is reality, instead of
reality itself.

\begin{figure}
\centering
\includegraphics{images/sat_nav.png}
\caption{Sat Nav Crash - Telegraph Newspaper}
\end{figure}

In the picture shown here, the driver \emph{trusted} the SatNav to such
an extent that he didn't pay attention to the road-signs around him, and
ended up getting stuck.

This wasn't borne of stupidity, but experience: \emph{so many times} the
SatNav had been right, that the driver stopped questioning its
fallibility. But SatNavs are pretty reliable, this is kind of excusable.
People are happy to make this mistake with far less reliable systems
because often it's a shortcut to having to do any real thinking.

\hypertarget{metrics}{%
\section{Metrics}\label{metrics}}

The simplest type of \textbf{Map And Territory Risk} occurs like this:
someone finds a useful new metric that helps in evaluating performance.
It might be:

\begin{itemize}
\tightlist
\item
  \textbf{SLOC (Source Lines Of Code)}: i.e.~the number of lines of code
  each developer writes per day/week whatever.
\item
  \textbf{Function Points}: the number of function points a person on
  the team completes, each sprint.
\item
  \textbf{Code Coverage}: the number of lines of code exercised by unit
  tests
\item
  \textbf{Response Time}: the time it takes to respond to an emergency
  call, say
\item
  \textbf{Release cadence}: number of releases a team performs, per
  month, say.
\end{itemize}

With some skill, they may be able to \emph{correlate} this metric
against some other more abstract measure of success. For example: -
``quality is correlated with more releases'' - ``user-satisfaction is
correlated with SLOC'' - ``response time is correlated with revenue''

Because the \emph{thing on the left} being is immediate and easier to
measure than \emph{the thing on the right}, it becomes used as a proxy
(or, Map) for the thing they are really interested in (the Territory).

But \emph{correlation} doesn't imply \emph{causation}. The cause might
be different:\\
- quality and number of releases might both be down to the simplicity of
the product. - user satisfaction and SLOC might both be down to the
calibre of the developers. - response time and revenue might both be
down to clever team planning.

When you have easy go-to metrics based on accidental or incidental
correlations, \textbf{Hidden Risk} mounts up. By relying on the metrics,
you're not really \emph{seeing} the reality. The devil is in the detail.

\hypertarget{drinking-the-kool-aid}{%
\section{Drinking The Kool-Aid}\label{drinking-the-kool-aid}}

The next problem comes when metrics start being used for more than just
indicators, but as measures of performance or targets: - If a team is
\emph{told} to do lots of releases, they will perform lots of releases
\emph{at the expense of something else}. - If team members are promoted
according to SLOC, they will make sure their code takes up as many lines
as possible. - In the UK, when ambulances were asked to respond to all
emergency calls within a short window, cars and bicycles were employed
as ambulances too {[}tbd{]}.

You are probably nodding your head at these examples. \emph{Of course}
SLOC is a terrible measure performance! We're not that stupid anymore.
The problem is, it's not so much the \emph{choice} of metric, but the
fact that \emph{all} metrics merely approximate reality with a few
numbers.

The map is \emph{always} simpler than the territory, therefore there can
be no perfect metrics.

\hypertarget{the-onion-of-bullshit}{%
\section{The Onion Of Bullshit}\label{the-onion-of-bullshit}}

\textbf{Map-And-Territory Risk} ``trickles down'' through an
organisation, in what I term ``The Onion Of Bullshit''. In which
successive layers of the organisational heirarchy imposed worse and
worse. Here's how this came about in a bank I worked at:

\begin{itemize}
\tightlist
\item
  My team had been tasked with building automated ``smoke tests'' of an
  application. But this was bullshit. We only needed to build these
  \emph{at all} because the application was so complex. The reason it
  was so complex was\ldots{}
\item
  The application was being designed within a ``Framework'' constructed
  by the department. However, the framework was only being used by this
  one application. Building a ``reuasable'' framework which is only used
  by a single application is bullshit. But, we had to do this
  because\ldots{}
\item
  The organisational structure was created along a ``matrix'', with
  ``business function'' on one axis and ``functional area'' on another.
  Although we were only building the application for a single business
  function, it was expected to cater with all the requirements from the
  an entire ``functional area''. This was bullshit too, because
\item
  The matrix structure was largely the legacy of a recent merger with
  another department. As \textbf{Conway's Law} predicts, our software
  therefore had to reflect this structure. But this was bullshit because
\item
  The matrix structure didn't represent reality in any useful way. It
  was designed to pacify the budget committee at the higher level, and
  try to demonstrate attributes such as \emph{control} and
  \emph{governance}. But this was bullshit too, because
\item
  The budget that was given to our department (Risk) was really based on
  how much fear the budget holders currently had of the market
  regulators. But this was bullshit too, because
\item
  At a higher level, the executives had realised that Investment Banking
  wasn't one of the banks strategic strengths, and was working to close
  it all down anyway.
\end{itemize}

When faced with so many mis-aligned objectives, it seemed completely
hopeless to concentrate on the task at hand. But then, my colleague
Gavin was able to nihilistically complete the onion by adding a final
layer:

\begin{itemize}
\tightlist
\item
  It's all about chasing money, which is bullshit, because life is
  bullshit.
\end{itemize}

It feels like there's no way back from that. All of life might well be a
big \textbf{Map and Territory} illusion. But let's analyse just a bit: -
At each layer of the onion, the objectives changed. But, they impacted
on the objectives of the layer below. - Therefore, it seems like the
more layers you have, the less likely it is that your objectives become
inconsistent between the lower and higher levels. - On a new project, it
seems like a good idea to model this stuff: does the objective of the
work you're about to undertake ``align'' with the objectives at a higher
level? If not, the project might well be quite temporary: Before I left,
I was able to eject most of the ``framework'' elements of the project,
and massively simplify the architecture, thus obviating the need for the
smoke tests.

So far, we've considered what happens when a team \emph{has been told}
to optimise around a particular objective. But it's not a great stretch
from here to a point where people are optimising the metric at the
expense of doing what they know is best for the project. Or, optimising
a metric for personal gain because that metric is more visible than
other (perhaps more important) qualities. This is \textbf{Agency Risk}
which we'll look at in the next section.

\hypertarget{inadequate-equilibria}{%
\section{Inadequate Equilibria}\label{inadequate-equilibria}}

\textbf{Inadequate Equilibria} is a book by Eleizer Yudkovsky, who looks
at how \textbf{Map and Territory Risk} can break not just departments,
but entire societal systems. Here is one example involving
\emph{academics} and \emph{grantmakers} in academia:

\begin{itemize}
\tightlist
\item
  It's not very apparent which scientists are better than which other
  scientists.
\item
  One proxy is what they've published (scientific papers) and where
  they've published (journals).
\item
  Universities want to attract research grants, and the best way to do
  this is to have the best scientists.
\item
  Because ``best'' isn't measureable, they use the proxy.
\item
  Therefore, immense power rests in the hands of the journals, since
  they can control the money-proxy.
\item
  Therefore, journals are able to charge large amounts of money to
  universities for subscriptions.
\end{itemize}

So, publication in prestigious journals is a \emph{metric} which is open
to abuse, as we saw earlier.

tbd

\hypertarget{head-in-the-sand}{%
\section{Head In The Sand}\label{head-in-the-sand}}

Introduce Rapid Development example here?

how to pick projects

how to spot vanity projects

how to spot where the Goal In Mind is hopelessly ill-thought-through.
following the rules more important than getting things done.

Head in the sand

Bullshit jobs

\hypertarget{biases}{%
\section{Biases}\label{biases}}

Why is this relevant?

human biases.

\begin{itemize}
\item
  showing progress
\item
  the release
\item
  less wrong
\end{itemize}

Is this really a risk?? Why is this here? To shore up the scheduling
thing?

Do biases go in here? YES!!

\part{Practices}

\hypertarget{coding}{%
\chapter{Coding}\label{coding}}

\hypertarget{what-is-it}{%
\section{What Is It}\label{what-is-it}}

\textbf{Coding} is the main practice that identifies us as working on a
\emph{software project}: Actually entering instructions in a language
that the computer will understand, be it Java, C++, Matlab, Excel or
\emph{whatever}. It is transferring the ideas in your head into steps
that the computer can understand, or, as Wikipedia has it:

\begin{quote}
``\ldots{}actual writing of source code.'' --
\href{https://en.wikipedia.org/wiki/Computer_programming}{Wikipedia,
\emph{Computer Programming}}
\end{quote}

Often, this can be called ``programming'', ``hacking'' or
``development'', although that latter term tends to connotate more than
just programming work, such as \textbf{Requirements Capture} or
\textbf{Documentation}, but we're considering those separately on
different pages.

\hypertarget{how-it-works}{%
\section{How It Works}\label{how-it-works}}

In \textbf{Development Process} we introduced the following diagram to
show what is happening when we do some coding. Let's generalize a bit
from this diagram:

\begin{itemize}
\tightlist
\item
  We start with a \textbf{Goal In Mind} to implement \emph{something}.
\item
  We build an \textbf{Internal Model} of how we're going to meet this
  goal (though coding, naturally)
\item
  Then, we find out how well our idea stands up when we \textbf{Meet
  Reality} and try it out in our code-test-run-debug cycle.
\item
  As we go, the main outcome is that we change reality, and create code,
  but along the way, we discover where our \textbf{Internal Model} was
  wrong, in the form of surfacing \textbf{Hidden Risks}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/dev_process_code.png}
\caption{Coding}
\end{figure}

\hypertarget{examples}{%
\section{Examples}\label{examples}}

As with any \textbf{Practice}, we are coding to minimize
\textbf{Attendant Risks}. We might want\ldots{}

\begin{itemize}
\tightlist
\item
  \textbf{To Build} or improve some features which our clients will find
  useful. - \emph{\textbf{Feature Risk}}
\item
  \textbf{To Automate} some process that takes too long or is too
  arduous. - \emph{\textbf{Process Risk}}
\item
  \textbf{To Explore} how our tools, systems or dependencies work (also
  called \href{https://en.wikipedia.org/wiki/Hacking}{Hacking}). -
  \emph{\textbf{Dependency Risk}}
\item
  \textbf{To Refactor} our codebase, to reduce complexity. -
  \emph{\textbf{Complexity Risk}}
\item
  \textbf{To Clarify} our product, making our software more
  \emph{presentable} and \emph{easier to understand}. -
  \emph{\textbf{Communication Risk}}
\end{itemize}

\ldots{} and so on. As usual, the advice is to \emph{reduce risk} in the
most meaningful way possible, all the time. This might involve coding
\emph{or it might not}.

\hypertarget{where-its-used}{%
\section{Where It's Used}\label{where-its-used}}

Since the focus of this site is on \emph{software methodologies}, you
shouldn't be surprised to learn that \emph{all} of the methodologies use
\textbf{Coding} as a central focus.

\hypertarget{variations-1}{%
\section{Variations}\label{variations-1}}

\hypertarget{building-features}{%
\subsection{Building Features}\label{building-features}}

Most commonly, the reason we are \textbf{Coding} is same as the one in
the \textbf{Development Process} page: we want to put features in the
hands of our customers.

That is, we believe our clients don't have the features they need to see
in the software, and we have \textbf{Feature Risk}.

By coding, we are mitigating \textbf{Feature Risk} in exchange for
\textbf{Complexity Risk} in terms of the extra code we now have on the
project, and \textbf{Schedule Risk}, because by spending time or money
coding we now have less time or money to do other things. Bill Gates
said:

\begin{quote}
``Measuring programming progress by lines of code is like measuring
aircraft building progress by weight.'' - Bill Gates
\end{quote}

And you can see \emph{why} this is true: the more code you write, the
more \textbf{Complexity Risk} you now have on the project, and the more
\textbf{Dead End Risk} you've picked up in case it's wrong. This is why
\textbf{The Agile Manifesto} stresses:

\begin{quote}
``Simplicity -the art of maximizing the amount of work not done- is
essential.'' \href{http://agilemanifesto.org/}{Agile Manifesto}
\end{quote}

\hypertarget{prototyping}{%
\subsection{Prototyping}\label{prototyping}}

Users often have trouble \emph{conceiving} of what they want in
software, let alone \emph{explaining} that to developers in any
meaningful way.

Let's look at how that can happen.

Imagine for a moment, that there was such a thing as \textbf{The Perfect
Product}, and a \textbf{User} wants to build it with a \textbf{Coder}: -
The \textbf{Perfect Product} might be \emph{conceptually elusive}, and
it might take several attempts for the \textbf{User} to find it's form.
\emph{\textbf{Conceptual Integrity Risk}} - It might be hard for the
\textbf{User} to \emph{communicate} the idea of it in writing or words:
where do the buttons go? What do they do? What are the key abstractions?
\emph{\textbf{Communication Risk}} - It might be hard too, for the
\textbf{Coder} to work with this description. Since his \textbf{Internal
Model} is different from the \textbf{User}'s, they have different ideas
about the \emph{meaning} of what the \textbf{User} is communicating.
\emph{\textbf{Communication Risk}} - Then, implementing the idea of
whatever is in the \textbf{Coder}'s \textbf{Internal Model} takes
\emph{effort}, and therefore involves \textbf{Schedule Risk}. - Finally,
we have a feedback loop, so the \textbf{User} can improve their
\textbf{Internal Model} and see the previously unforeseen \textbf{Hidden
Risks}. - Then, you can go round again.

\begin{figure}
\centering
\includegraphics{images/coding_communication_risk.png}
\caption{Coding Communication Risks}
\end{figure}

The problem here is that this is a very \emph{protracted feedback loop}.
This is mitigated by prototyping, because that's all about shortening
the feedback loop as far as possible:\\
- By working together, you mitigate \textbf{Communication Risk}. - By
focusing on one or two elements (such as UI design), you can minimize
\textbf{Schedule Risk}. - By having a tight feedback loop, you can focus
on \emph{iteration}, try lots of ideas, and work through
\textbf{Conceptual Integrity Risk}.

One assumption of Prototyping is that \textbf{Users} can iterate towards
\textbf{The Perfect Product}. But it might not be so: the Conceptual gap
between their own ideas and what they really \emph{need} might prove too
great.

After all, bridging this gap is the job of the \textbf{Designer}:

\begin{quote}
``It's really hard to design products by focus groups. A lot of times,
people don't know what they want until you show it to them.'' --- Steve
Jobs
\end{quote}

\hypertarget{skunkworks}{%
\subsection{SkunkWorks}\label{skunkworks}}

The \href{https://en.wikipedia.org/wiki/Skunk_Works}{SkunkWorks}
approach is one small step up from \textbf{Prototyping}. Wikipedia
describes this as:

\begin{quote}
A group within an organization given a high degree of autonomy and
unhampered by bureaucracy, with the task of working on advanced or
secret projects
\end{quote}

The idea here is \emph{again} to minimize the length of the feedback
loop, and focus on \textbf{Design} to combat \textbf{Conceptual
Integrity Risk}. It was in this kind of small, secret team that the
\href{https://www.networkworld.com/article/2159873/smartphones/apple-s-iphone--the-untold-story.html}{iPhone
was invented}.

To give some idea of the \textbf{Conceptual Integrity Risk} involved,
initially, the team were building a \emph{tablet} using the multi-touch
technology that the iPhone introduced to the world, but pivoted towards
the phones after the failure of the ``Apple Phone'' collaboration with
Motorola.

Scott Forstall picked a small, secret team from within the ranks of
Apple. By doing this, he mitigated \textbf{Communication Risk} and
\textbf{Coordiation Risk} \emph{within his team}, but having fewer
people in the room meant more \textbf{Throughput Risk}.

By having more people involved, the feedback loop will be longer than
the two-man prototyping team, but that's the tradeoff you get for
mitigating those other risks.

\hypertarget{specialization}{%
\subsection{Specialization}\label{specialization}}

One of the problems with a \textbf{SkunkWorks} approach is that you end
up with more \textbf{Coordination Risk} than you'd like, as your
different skunk-teams end up with different \textbf{Internal Models} and
different \textbf{Goals}.

In large companies, this is called
\href{https://en.wikipedia.org/wiki/Information_silo}{Silo Mentality} -
the tendency for lines of business to stop communicating and sharing
with one another. As you can imagine, this leads to a more
\textbf{Complex} and \textbf{bureaucratic} structure than would be
optimal.

But this can happen within a single coding team, too: by splitting up
and working on different pieces of functionality within a project, the
team \emph{specialises} and becomes expert in the parts it has worked
on. This means the team members have different \textbf{Internal Models}
of the codebase.

This is \emph{perfectly normal}: we \emph{need} people to have different
opinions and points-of-view. We \emph{need} specialisation, it's how
humanity has
\href{https://en.wikipedia.org/wiki/Division_of_labour}{ended up on
top}. It's better to have a team who, between them all, know a codebase
really well, than a group of people who know it poorly.

The reason for this is explained again by the first diagram in this
section: the closer our \textbf{Internal Model} matches
\textbf{Reality}, the fewer \textbf{Hidden Risks} we will meet, and the
easier we'll have it.

The downside of specialization is \textbf{Coordination Risk}:\\
- If your payroll expert is off ill for a week, progress on that stops.
- Work is rarely evenly spread out amongst the different components of a
project for long. - If work temporarily dries up on a specific
component, what do the component owners do in the meantime? - What if
the developer of a particular component makes \emph{the wrong
assumptions} about other parts of the system or tool-set?

\hypertarget{pair-programming-mob-programming}{%
\subsection{Pair Programming / Mob
Programming}\label{pair-programming-mob-programming}}

In the main, \textbf{Review} is the main way to mitigate
\textbf{Coordination Risk}. For example: - \textbf{Code Reviews} -
\textbf{Stand Up Meetings} - \textbf{Presentations \& Demos} -
\textbf{Training}

\textbf{Pair Programming} however \emph{combines} the review with the
process of coding: there are now two heads at each terminal. What does
this achieve?\\
- Clearly, we mitigate \textbf{Key-Man Risk} as we've got two people
doing every job.\\
- Knowledge is transferred at the same time, too, mitigating
\textbf{Specialist Risk}.\\
- Proponents also argue that this mitigates \textbf{Complexity Risk}, as
the software will be better quality. - Since the pair spend \emph{so
much time together}, the communication is very \emph{high bandwidth}, so
this mitigates \textbf{Communication Risk}

But, conversely, there is a cost to \textbf{Pair Programming}: - Having
two people doing the job \emph{one person could do} intimates
\textbf{Schedule Risk}. - Could the same \textbf{Complexity Risk} be
mitigated just with more regular \textbf{Code Reviews}? - Sometimes,
asking members of a team to work so closely together is a recipe for
disaster. \textbf{Team Risk} - Not every pair programmer ``shares'' the
keyboard time evenly, especially if ability levels aren't the same. -
There is only one \textbf{Feedback loop}, so despite the fact you have
two people, you can only \textbf{Meet Reality} serially.

\textbf{Mob Programming} goes one stage further and suggests that we can
write better software with \emph{even more people around the keyboard}.
So, what's the right number? Clearly, the usual trade-off applies: are
you \emph{mitigating} more risk than you're \emph{gaining}?

\hypertarget{offshoring-remote-teams}{%
\subsection{Offshoring / Remote Teams}\label{offshoring-remote-teams}}

\textbf{Pairing} and \textbf{Mobbing} as mitigations to
\textbf{Coordination Risk} are easiest when developers are together in
the same room. But it doesn't always work out like this. Teams spread in
different locations and timezones naturally don't have the same
\textbf{communication bandwidth} and you \emph{will} have more issues
with \textbf{Coordination Risk}.

In the extreme, I've seen situations where the team at one location has
decided to ``suck up'' the extra development effort themselves rather
than spend time trying to bring a new remote team up-to-speed. More
common is for one location to do the development, while another gets the
\textbf{Support} duties.

When this happens, it's because somehow the team feel that
\textbf{Coordination Risk} is more unmanageable than \textbf{Schedule
Risk}.

There are some mitigations here: video-chat, moving staff from
location-to-location for face-time, frequent \textbf{show-and-tell}, or
simply modularizing accross geographic boundaries, in respect of
\textbf{Conway's Law}:

\begin{quote}
``organizations which design systems \ldots{} are constrained to produce
designs which are copies of the communication structures of these
organizations.''
- \emph{\href{https://en.wikipedia.org/wiki/Conway\%27s_law}{M. Conway}}
\end{quote}

When we add \textbf{Outsourcing} into the mix, we also have to consider
\textbf{Agency Risk}: the consultancy you've hired is \emph{definitely}
more interested in keeping themselves solvent than solving your business
problems.

\hypertarget{team-size}{%
\subsection{Team Size}\label{team-size}}

As team sizes grow, \textbf{Coordination Risk} grows fast.

To see this, let's consider a made-up situation where all the developers
are equal, and we can mitigate \textbf{Coordination Risk} at the cost of
a 1-hour presentation each per week.

How many man-hours of presentations do we need?

\begin{longtable}[]{@{}lll@{}}
\toprule
Team Size & Hours Of Presentations & Man-Hours In
Presentations\tabularnewline
\midrule
\endhead
1 & 0 & 0\tabularnewline
2 & 2 & 4\tabularnewline
3 & 3 & 9\tabularnewline
4 & 4 & 16\tabularnewline
5 & 5 & 25\tabularnewline
6 & 6 & 36\tabularnewline
7 & 7 & 49\tabularnewline
\bottomrule
\end{longtable}

Adding the 7th person to the team (ceteris paribus) does absolutely
\emph{nothing} for productivity, it makes matters worse. Assuming
everyone works a 40-hour week, we're now 9 hours worse off than before.

This is a \emph{toy example}, but is it better or worse than this in
reality? If the new developers are arriving on an existing project, then
1 hour-per-week of training by the existing team members might be
conservative.

This is why we get
\href{https://en.wikipedia.org/wiki/Brooks\%27s_law}{Brooks' Law}:

\begin{quote}
``adding human resources to a late software project makes it later''. -
\href{https://en.wikipedia.org/wiki/Brooks\%27s_law}{Fred Brooks,
\emph{The Mythical Man-Month}}
\end{quote}

You can see that this law is founded in an appreciation of
\textbf{Coordination Risk}. But the argument from \textbf{Coordination
Risk} \emph{adds nuance}, and explains when this is true and when it
isn't.

\hypertarget{too-many-cooks}{%
\subsection{Too Many Cooks}\label{too-many-cooks}}

Sometimes, you have \emph{too many developers} on a project. This is not
a blessing. As with \textbf{Student Syndrome}, having too many resources
means that:

\begin{quote}
``Work expands so as to fill the time available for it's completion'' -
\textbf{Parkinson's Law}
\end{quote}

One of the reasons for this is that \emph{Developers love to develop}
and it is, after all, their job. If they \emph{aren't} developing, then
are they still needed? This is \textbf{Agency Risk}: people who are
worried about their jobs will often try to \emph{look busy}, and if that
means creating some drama on the project, then so be it.

Sadly, this usually occurs when a successful project is nearing
delivery. Ideally, you want to be \emph{decreasing} the amount of change
on a project as it gets closer to key \textbf{Delivery Dates}. This is
because the risk of \textbf{Missing the Date} is greater than the risk
of \textbf{some features not being ready}.

In the past, I've found it helpful to down-size the team by temporarily
moving developers into other less-fortunate teams, reducing both
\textbf{Coordination Risk} and \textbf{Agency Risk} at the same time.

This can require some guts to do: you have to overcome your own ego
(wanting to run a big team) for the sake of your project.

\hypertarget{automating}{%
\subsection{Automating}\label{automating}}

One of the key ways to measure whether your team is doing \emph{useful
work} is to look at whether, in fact, it can be automated. And this is
the spirit of \textbf{DevOps} - the idea that people in general are poor
at repeatable tasks, and anything people do repeatedly \emph{should} be
automated.

Repetitive work of any kind is a \textbf{Process Risk}, and can be
mitigated at the expense of attendant \textbf{Complexity Risk} and
\textbf{Schedule Risk}.

Since this is a trade-off, you have to be careful about how you
\emph{weigh} the \textbf{Process Risk}: clearly, it exists \emph{into
the future}.

You are making a bet that acting now will pay off in decreased
\textbf{Process Risk} over the lifetime of the project. This is a hard
thing to judge: - How much \textbf{Process Risk} are we carrying,
week-to-week? (A good way to answer this is to look at past failures). -
How much \textbf{Complexity Risk} will we pick up? - How much
\textbf{Schedule Risk} (in spent developer effort) will we pick up? -
How long will the mitigation last before the process changes again?

\hypertarget{tool-use}{%
\subsection{Tool Use}\label{tool-use}}

In general, unless the problem is somehow \emph{specific to your
circumstances} it may well be better to skip direct coding and pick up
some new tools to help with the job.

Tools are a different trade off to automation. You are mitigating
\textbf{Process Risk} or \textbf{Feature Risk} in return for: - New
\textbf{Dependency Risk} on the new tool. - \textbf{Communication Risk}
because now the team has to understand the tool. - \textbf{Schedule
Risk} in the time it takes to learn and integrate the tool. -
\textbf{Complexity Risk} because your project necessarily becomes more
complex for the addition of the tool.

Tools in general are \emph{good} and \emph{worth using} if they offer
you a better risk return than you would have had from not using them.

But, this is a low bar - some tools offer \emph{amazing} returns on
investment. The \textbf{Silver Bullets} article describes in general
some of these: - Assemblers - Compilers - Garbage Collection - Type
Systems - Libraries - Build Tools - etc.

A \emph{really good tool} offers such advantages that not using it
becomes \emph{unthinkable}: Linux is heading towards this point. For
Java developers, the JVM is there already.

Picking new tools and libraries should be done \textbf{very carefully}:
you may be stuck with your choices for some time. Here is a
\textbf{short guide that might help}.

\hypertarget{refactoring}{%
\subsection{Refactoring}\label{refactoring}}

The term ``refactoring'' probably stems from the mathematical concept of
\emph{(Factorization){[}https://en.wikipedia.org/wiki/Factorization{]}}.
Factorizing \emph{polynomial equations} or \emph{numbers} means to
identify and make clear their distinct components.

tbd: SoC

Most coders use the phrase ``refactoring'', and intuitively understand
what it is. It shouldn't have been hard to find a clear explanation for
this page, but sadly it was. There are some very woolly definitions of
``refactoring'' around, such as:

\begin{quote}
``\textbf{Refactoring (n)}: a change made to the internal structure of
software to make it easier to understand and cheaper to modify without
changing its observable behavior''" --
\href{https://www.refactoring.com}{Refactoring.com}
\end{quote}

What do ``easier to understand'' (which makes sense) and ``cheaper to
modify'' mean? Let's try and be more specific. With Refactoring, we are
trying to:

\begin{itemize}
\tightlist
\item
  Mitigate \textbf{Communication Risk} by making the \emph{intent} of
  the software clearer. This can be done by breaking down larger
  functions and methods into smaller ones with helpful names, and naming
  elements of the program clearly, and
\item
  Mitigate \textbf{Complexity Risk} by employing \emph{abstraction} and
  \emph{modularization} to remove duplication and reduce cross-cutting
  concerns. By becoming less complex, the code has less
  \textbf{Inertia}.
\end{itemize}

On \textbf{Refactoring}, Kent Beck says:

\begin{quote}
``If a programmer sees a one-minute ugly way to get a test working and a
ten-minute way to get it working with a simpler design, the correct
choice is to spend the ten minutes.'' -- Kent Beck, \emph{Extreme
Programming Explained}
\end{quote}

This is a bold, not-necessarily-true assertion. How does that ratio
stack up when applied to \emph{hours} or \emph{days}? But you can see
how it's motivated: Kent is saying that the nine extra minutes of
\textbf{Schedule Risk} are \emph{nothing} compared to the carry cost of
\textbf{Complexity Risk} on the project.

\hypertarget{risks-mitigated-attendant-risks}{%
\section{Risks Mitigated / Attendant
Risks}\label{risks-mitigated-attendant-risks}}

tbdd

\hypertarget{attendant-risks-1}{%
\section{Attendant Risks}\label{attendant-risks-1}}

tbd

\hypertarget{see-also}{%
\section{See Also}\label{see-also}}

\hypertarget{design}{%
\chapter{Design}\label{design}}

\hypertarget{what-is-it-1}{%
\section{What Is It}\label{what-is-it-1}}

Design is what you do every time you think of an action to mitigate a
risk. And \textbf{Big Design Up Front} is where you do a lot of it in
one go, for example:

\begin{itemize}
\tightlist
\item
  Where you think about the design of all (or a set of) the requirements
  in one go, in advance.
\item
  Where you consider a \emph{set of \textbf{Attendant Risks}} all at the
  same time.
\end{itemize}

Compare with ``little'' design, where we consider just the \emph{next}
requirement, or the \emph{most pressing} risk.

Although it's fallen out of favour in Agile methodologies, there are
benefits to doing this \emph{sometimes}.

\hypertarget{how-it-works-1}{%
\section{How It Works}\label{how-it-works-1}}

As we saw in \textbf{Meet Reality}, ``Navigating the \textbf{Risk
Landscape}'', meant going from a position of high risk, to a position of
lower risk. \textbf{Agile Design} is much like \textbf{Gradient
Descent}: each day, one small step after another \emph{downwards in
risk} on the \textbf{Risk Landscape}.

But the problem with this is you can get trapped in a \textbf{Local
Minima}, where there are \emph{no} easy steps to take to get you to
where you want to be. Here is a \textbf{real life example}. This is
\textbf{Dead End Risk}.

In these cases, you have to \emph{widen your horizon} and look at where
you want to go: and this is the process of \emph{design}. You're not
necessarily now taking steps on the \textbf{Risk Landscape}, but
imagining a place on the \textbf{Risk Landscape} where you want to be,
and checking it against your \textbf{Internal Model} for validity.

\hypertarget{examples-1}{%
\section{Examples}\label{examples-1}}

\hypertarget{feedback-loops-mitigated-risks}{%
\section{Feedback Loops \& Mitigated
Risks}\label{feedback-loops-mitigated-risks}}

The feedback loop for any design is \textbf{Review and Sign Off}.

\hypertarget{too-many-cooks-1}{%
\subsection{\texorpdfstring{\textbf{Too Many
Cooks}}{Too Many Cooks}}\label{too-many-cooks-1}}

By allowing lots of stakeholders to review and \textbf{agree to a
design}, or select from alternatives, we try to reconcile the needs of
lots of stakeholders \emph{early on} in a project.

\hypertarget{visibility-risk}{%
\subsection{\texorpdfstring{\textbf{Visibility
Risk}}{Visibility Risk}}\label{visibility-risk}}

To allow for \emph{discussion and understanding} of the project between
multiple parties. This may extend to design being \emph{marketing
material} to help explain the project to potential clients or
budget-holders.

\hypertarget{technical-debt-1}{%
\subsection{\texorpdfstring{\textbf{Technical-Debt}}{Technical-Debt}}\label{technical-debt-1}}

To ensure an overall aesthetic or architectural integrity, avoiding the
\textbf{Technical-Debt} that you might accrue by building the wrong
things first.

\hypertarget{dead-end-risk-2}{%
\subsection{\texorpdfstring{\textbf{Dead End
Risk}}{Dead End Risk}}\label{dead-end-risk-2}}

Often, by thinking big-picture we can avoid building components that
\emph{seem} like a good next step, but actually aren't.

\hypertarget{attendant-risks-2}{%
\section{Attendant Risks}\label{attendant-risks-2}}

Building architects appreciate that their \emph{plans might change}:
Roman ruins might be discovered underneath the site, or the supporting
wall might not be as sound as originally thought. The more effort you
put into a design, the more will be wasted if it's wrong. So, how deep
should you go? The answer as usual, is keep designing while it is
reducing your overall project risk.

\begin{itemize}
\tightlist
\item
  The design might itself take a long time to complete \textbf{Schedule
  Risk}.
\item
  People \emph{stop thinking} \textbf{once they have a design}, even
  when reality \emph{obviously} deviates from what the design assumed.
  But the whole point of a plan is that it's easier to change than the
  thing you are doing the plan for.\\
\item
  If your plan starts to become as detailed as the code would be (but
  doesn't run) then you've made the mistake of \emph{overspecification},
  and you are creating \textbf{Technical Debt}.
\end{itemize}

\begin{quote}
Everyone has a great plan until they get hit in the nose - Mike Tyson
Fail to plan and you plan to fail - Eisenhower?
\end{quote}

Risk first design example ; building the research indexer

\hypertarget{prioritisation}{%
\chapter{Prioritisation}\label{prioritisation}}

\hypertarget{what-is-it-2}{%
\section{What Is It}\label{what-is-it-2}}

Prioritisation is a key process in trying to focus on building
\emph{useful} stuff first. It could look like:

\begin{itemize}
\tightlist
\item
  \textbf{A Sprint Planning Meeting}: Deciding on the most important
  things for the team to build in a time period.
\item
  \textbf{Phased Delivery}: Breaking a large project into smaller-scoped
  projects.
\item
  \textbf{A Backlog}: Having tasks or stories in delivery order in a
  queue.
\item
  \textbf{Task Decomposition}: Breaking down larger units of a task into
  smaller items. Often, \textbf{Requirements} come \emph{bundled
  together} and need to be broken down so that we work on just the most
  vital parts, as in
\item
  \textbf{Identifying the MVP}: Trying to cast out \emph{all}
  non-essential functionality.
\end{itemize}

\textbf{Prioritisation} relies on not delivering all the functionality
in one go. But it tends to be a spectrum:

\begin{itemize}
\tightlist
\item
  \textbf{Big Bang}: Delivering all the functionality in a single go.
\item
  \textbf{Cycles, or Phases}: Splitting a large project into smaller
  chunks.
\item
  \textbf{Sprints}: Delivering with a fixed cadence, e.g.~every month or
  week.
\item
  \textbf{Continuous Delivery}: Delivering functionality
  one-piece-at-a-time.
\end{itemize}

Usually, risk is mitigated by \textbf{Prioritisation}. But sometimes,
it's not appropriate: When Finland changed from driving on the right
side of the road to the left, (in order to be in line with the rest of
Europe) the changeover \emph{had} to be \textbf{Big Bang} and the whole
country changed \textbf{overnight}.

\hypertarget{how-it-works-2}{%
\section{How It Works}\label{how-it-works-2}}

There are several ways you can prioritise work:

\begin{itemize}
\tightlist
\item
  \textbf{Largest Mitigation First}: What's the thing we can do right
  now to reduce our \textbf{Attendant Risk} most? This is sometimes hard
  to quantify, given \textbf{Hidden Risk}, so maybe an easier metric
  is\ldots{}
\item
  \textbf{Biggest Win}: What's the best thing we can do right now to
  reduce \textbf{Attendant Risk} for least additional
  \textbf{Schedule-Risk}? (i.e.~simply considering how much \emph{work}
  is likely to be involved)
\item
  \textbf{Dependency Order}: Sometimes, you can't build Feature A until
  Feature B is complete. Prioritisation helps to identify and mitigate
  \textbf{Dependency Risk}.
\end{itemize}

By prioritising, you get to \textbf{Meet Reality} \emph{sooner} and
\emph{more frequently} and in \emph{small chunks}.

\hypertarget{feedback-loops-risks-mitigated}{%
\section{Feedback Loops \& Risks
Mitigated}\label{feedback-loops-risks-mitigated}}

\hypertarget{review}{%
\subsection{\texorpdfstring{\textbf{Review}}{Review}}\label{review}}

This one way in which a particular prioritisation \textbf{Meets Reality}

\begin{itemize}
\tightlist
\item
  Developers might tell you that the ordering incurs \textbf{Dependency
  Risk} or \textbf{Coordination Risk} if everyone is going to end up
  working on the same components.
\item
  Product Owners might tell you that you're not tackling the right
  \textbf{Feature Risk}.
\item
  If you're trying to work out what the \textbf{MVP} is, prioritisation
  might help your investors determine whether the project is worth
  \textbf{funding}.
\end{itemize}

\hypertarget{production-risk}{%
\subsection{\texorpdfstring{\textbf{Production
Risk}}{Production Risk}}\label{production-risk}}

Breaking a large delivery down into lots of small releases has an impact
on \textbf{Production Risk}:

\begin{itemize}
\tightlist
\item
  Usually, lots of small releases allows you to \emph{practice} the
  release process while the project is relatively unimportant. This
  experience allows you to figure out automation and reduce the
  \textbf{Process Risk} of releasing too.
\item
  Smaller, higher-cadence releases also reduce \textbf{Visibility Risk},
  because users don't have large amounts of change to get accustomed to
  all-in-one-go.
\end{itemize}

\hypertarget{schedule-risk-1}{%
\subsection{\texorpdfstring{\textbf{Schedule
Risk}}{Schedule Risk}}\label{schedule-risk-1}}

If you're able to do \textbf{Continuous Delivery}, and have de-risked
the release process, then you can eliminate some \textbf{Schedule Risk},
because you'll know you can hit any date with \emph{something}. The
risks of what you deliver on that date are then
\protect\hyperlink{feature-risk}{Feature Risk} rather than
\textbf{Schedule Risk}.

\hypertarget{attendant-risks-3}{%
\section{Attendant Risks}\label{attendant-risks-3}}

\hypertarget{dependency-risk-1}{%
\subsection{\texorpdfstring{\textbf{Dependency
Risk}}{Dependency Risk}}\label{dependency-risk-1}}

The biggest risk to phased delivery is that you try and build
functionality \textbf{now} that actually relies on things scheduled to
be built \textbf{later}.

\hypertarget{schedule-risk-2}{%
\subsection{\texorpdfstring{\textbf{Schedule
Risk}}{Schedule Risk}}\label{schedule-risk-2}}

Sometimes, releases have a \emph{cost} associated with them in terms of
time and bureaucracy to perform them. Obviously, then, the more releases
you'll do, the less time you'll spend doing \emph{other stuff}, like
building functionality. The trick to doing frequent releases is
therefore to ensure they are \emph{low cost}, and this means
\textbf{automation}. But, building automation adds schedule risk too.

\hypertarget{complexity-risk-2}{%
\subsection{\texorpdfstring{\textbf{Complexity
Risk}}{Complexity Risk}}\label{complexity-risk-2}}

If you are replacing an old system with a new one, incrementally
replacing functionality is a good way to go when the system is complex.
However, this means that you're going to have two systems running at the
same time, which is inevitably \textbf{more complex} than just one
system.

\hypertarget{planning}{%
\subsection{PLanning}\label{planning}}

\begin{itemize}
\tightlist
\item
  also gannt chart
\item
  critical path
\item
  roadmap
\item
  dependency analysis
\end{itemize}

Discuss the tool Duncan and I used to determine whether a release date
was feasible.

\begin{itemize}
\tightlist
\item
  planning using risk
\end{itemize}

https://en.wikipedia.org/wiki/Planning\_fallacy

-- estimating: holding the risks in your hand and saying, which is
heavier?

Risk first planning: break down the goal into the biggest risks3

\hypertarget{requirements-capture}{%
\chapter{Requirements Capture}\label{requirements-capture}}

\hypertarget{what-is-it-3}{%
\section{What Is It}\label{what-is-it-3}}

\textbf{Requirements Capture} is not a single technique, but a broad
category of techniques such as:

\begin{itemize}
\tightlist
\item
  \textbf{Interviews}
\item
  Focus Groups
\item
  User Stories
\item
  Use Cases
\end{itemize}

\hypertarget{how-it-works-3}{%
\section{How It Works}\label{how-it-works-3}}

Whatever exact methodology you are using, the aim is to meet
\textbf{stakeholders} and try to capture their \textbf{Internal Models}
in written form. This has a few effects:

\begin{itemize}
\tightlist
\item
  The \textbf{Internal Models} of the development team can be enriched
  with this new information.
\item
  You are capturing at a moment-in-time what people \emph{thought}.\\
\item
  As with any \textbf{Documentation}, you can to some extent reconcile
  the \textbf{Internal Models} of a wide variety of stakeholders and
  implementers.
\end{itemize}

\hypertarget{variations-2}{%
\section{Variations}\label{variations-2}}

\hypertarget{structured-requirements}{%
\subsection{Structured Requirements}\label{structured-requirements}}

\hypertarget{use-cases}{%
\subsection{Use Cases}\label{use-cases}}

See also: \textbf{Terms Of Reference}

\hypertarget{feedback-loops-risks-mitigated-1}{%
\section{Feedback Loops / Risks
Mitigated}\label{feedback-loops-risks-mitigated-1}}

Requirements Capture is itself a process of \textbf{Meeting Reality},
and in a limited way: rather than speculatively building a piece of
software and trying it out on the world, Requirements Capture allows us,
cheaply, to go and see what the world \emph{thinks} it wants, which is
much \emph{cheaper}, but perhaps less accurate.

\hypertarget{feature-risk-1}{%
\subsection{\texorpdfstring{\textbf{Feature-Risk}}{Feature-Risk}}\label{feature-risk-1}}

\emph{Asking people what they want} is often a way to reduce
\textbf{Feature Risk} by stopping you building the wrong thing.

\hypertarget{section}{%
\subsection{{[}}\label{section}}

The feedback loop for any design is \emph{review}. You can also follow
review with \textbf{Sign Off}.

\hypertarget{attendant-risks-4}{%
\section{Attendant Risks}\label{attendant-risks-4}}

Steve Jobs - people don't know what they want until they see it.

Elizer Yodowski - what exactly is a MVP.

\hypertarget{testing}{%
\chapter{Testing}\label{testing}}

\hypertarget{what-is-it-4}{%
\section{What Is It}\label{what-is-it-4}}

Most forms of testing are about isolating a particular
\emph{characteristic} of your system, and exploring it from a risk
perspective. It could be:

\begin{itemize}
\tightlist
\item
  \textbf{Performance Testing} addresses the risk of \textbf{not being
  able to support all the users}
\item
  \textbf{Usability Testing} tries to see whether people struggle to
  make sense of your software, usually because the assumptions of their
  \textbf{Internal Models} differ from those embedded in the system, or
  that the system isn't adequately \textbf{transparent} about it's own
  model.
\item
  \textbf{Security Testing} addresses the risk that your software could
  be used against you or its users \textbf{by hackers}.
\item
  \textbf{Integration Testing}: Where we test how the software works
  as-a-whole, and test that it will work \textbf{with other systems}
\item
  \textbf{Corridor Testing}: Asking a few, random people to use the
  system-under-test, in order to see \textbf{if it confuses them, or
  not}.
\item
  \textbf{User Acceptance Testing}: Asking users to review new features,
  and make sure that they actually \textbf{do what is required}
\item
  \textbf{Regression Testing}: Making sure changes in new versions of
  the system haven't \textbf{broken functionality}
\end{itemize}

\hypertarget{how-it-works-4}{%
\section{How It Works}\label{how-it-works-4}}

\begin{figure}
\centering
\includegraphics{images/dev_process_test.png}
\caption{Testing Process}
\end{figure}

The whole purpose of testing is to \textbf{meet reality} early, ahead of
putting software in front of real users, where you face
\textbf{Production Risks}, like reputation damage and financial
penalties.

Given this, the best approach to test planning should be risk-based:
consider which risks you want to mitigate, and test accordingly:

\begin{itemize}
\tightlist
\item
  Identify Risks
\item
  Evaluate Risks
\item
  Prioritise Risks
\item
  Plan tests from the top of the priority list down.
\end{itemize}

\hypertarget{examples-2}{%
\section{Examples}\label{examples-2}}

This should work at \emph{every level} within a project. If you are
building a new feature, you should consider:

\begin{itemize}
\tightlist
\item
  Is it going to connect to third-party systems? If so, I should build
  \href{https://en.wikipedia.org/wiki/System_integration_testing}{System
  Integration Tests} to cover the \textbf{Dependency Risk} associated
  with this, and the chance that in the future, the interface will
  change.
\item
  Does my code do what I expect? I probably should build a
  \href{https://en.wikipedia.org/wiki/Unit_testing}{Unit Test} to
  mitigate \textbf{Complexity Risk}.
\item
  Will users understand the software I build for them? I should probably
  do some
  \href{https://en.wikipedia.org/wiki/Software_testing\#Beta_testing}{Beta
  Testing} or
  \href{https://www.usability.gov/what-and-why/glossary/corridor-testing.html}{Corridor
  Testing} to mitigate \textbf{Visiblity Risk}.
\item
  To go live, am I going to need some piece of real-world paperwork?
  Test the process ahead-of-time to expose all the \textbf{Hidden Risks}
\end{itemize}

\hypertarget{where-its-used-1}{%
\section{Where It's Used}\label{where-its-used-1}}

\begin{itemize}
\tightlist
\item
  \textbf{Waterfall} initially was conceived with a long, manual testing
  phase to be performed on the \emph{whole system} after development
\item
  \textbf{Extreme Programming} championed the use of
  \href{https://en.wikipedia.org/wiki/Unit_testing}{Unit Tests} in order
  to test individual subsystems, as well as having an \textbf{On-Site
  Customer} to act as a testing resource when needed.
\end{itemize}

\hypertarget{variations-3}{%
\section{Variations}\label{variations-3}}

\hypertarget{automated-tests}{%
\subsection{Automated Tests}\label{automated-tests}}

Often, the decision of whether to automate a test will be based on
whether or not it can be expressed \emph{objectively}. For example,
checking that a REST endpoint ``returns the right error code'' is
\emph{objective}, and is therefore a candidate for automation.

Automated tests look roughly the same, irrespective of the scope they
are trying to test.\\
- We have a \textbf{System Under Test}, which may be a single class, or
a whole executable.\\
- We have some \textbf{Input Conditions} for the test, and some
\textbf{Expectations}. - When the test is executed, we compare the
actual outputs with the expected ones, giving us \textbf{The Result}.

\begin{figure}
\centering
\includegraphics{images/testing_process.png}
\caption{Testing Process}
\end{figure}

A useful way to think about automated testing is that it turns the
\textbf{System Under Test} into a
\href{https://en.wikipedia.org/wiki/Pure_function}{Pure Function}: This
means that for a specific set of inputs, the system will produce a
specific output, reliably, every time.

Getting complex systems to behave as pure functions can be costly, but
there are techniques to help with this such as
\href{https://en.wikipedia.org/wiki/Mock_object}{Mocking}. However, if
you try to devise as much of your software in a pure-functional way to
start with, automated testing is much easier.

\textbf{Automated Testing} has an interesting effect on managing
\textbf{Complexity Risk}: Although you may initially write a Unit Test
(say) to mitigate the risk of \textbf{having implemented a feature
wrongly}, you are also given insurance against future change breaking
that feature. That is to say, they are \emph{regression tests}. However,
implementing tests like this is better than building regression tests,
\textbf{as discussed here}.

-- how do automated tests mitigate complexity risk?

\hypertarget{manual-tests}{%
\subsection{Manual Tests}\label{manual-tests}}

\textbf{Manual Testing} is, at some level, essential if your product is
to be used by humans. Although UI-Automation tools such as
\href{https://docs.seleniumhq.org}{Selenium} allow you to script browser
interactions, they cannot reliably catch every problem.

For example, ensuring the UI ``looks ok and doesn't glitch'' is entirely
\emph{subjective}: you'll need to express this in a manual test. Manual
Tests are often described in
\href{https://en.wikipedia.org/wiki/Test_plan}{Test Plans} and
\href{https://en.wikipedia.org/wiki/Test_script}{Test Scripts} in order
to ensure repeatability, and manage \textbf{Process Risk}.

Since manual tests carry much higher per-use cost to run, there is a
tendency to want to save this cost by doing \emph{fewer releases}. After
all, fewer releases means less manual testing, but this may increase
\textbf{Process Risk}.

How do you decide whether to keep a test manual, or automate? The more
\emph{automated} a test is, the more cheaply it can be re-used. However,
the process of automation can take longer, and so adds \textbf{Schedule
Risk}. Whether or not it's worth automating is to some extend going to
depend on how much you \textbf{value future time}.

\hypertarget{white-box-and-black-box-testing}{%
\subsection{White-Box and Black-Box
Testing}\label{white-box-and-black-box-testing}}

In the initial conception,
\href{https://en.wikipedia.org/wiki/Black-box_testing}{Black-Box
Testing} ignores the \emph{implementation details} of a component and
tests the interface only.

White-box testing however considers the components within the box, and
how they interact with one another in order to define the tests. This is
\emph{fair enough} if, for some reason, you are unable to test the
components individually for some reason: knowing how something is
implemented gives you an insight into \emph{where the bugs will hide},
and therefore, where the risks lie.

\hypertarget{testing-level}{%
\subsection{Testing Level}\label{testing-level}}

However, if possible, it's better to break open the white box and test
the components \emph{themselves}. This means you end up having
``higher'' and ``lower'' level tests, depending on the scope of the
\textbf{System Under Test}. There are several advantages to this:

\begin{itemize}
\tightlist
\item
  First, tests become less ``brittle'': the smaller the \textbf{System
  Under Test}, the less \textbf{Context} it needs to operate, therefore
  the more insulated it is to changes in other parts of the system. As a
  counter-example, if \emph{all} of your tests run over the whole
  system, and the authentication system changes, does that break all the
  tests? This is an argument from \textbf{Complexity-Risk}.
\item
  Tests at the ``whole system'' level are usually longer-running since
  they require starting up the whole system, and also require more data
  and context to run. This is an argument both from
  \textbf{Complexity-Risk} and \textbf{Process Risk}.
\end{itemize}

Expanding on this then, the
\href{https://martinfowler.com/bliki/TestPyramid.html}{Testing Pyramid}
idea is that lower level, automated tests which run quickly should be
common, while there should be fewer of the more expensive ``whole
system'' level tests.

\begin{figure}
\centering
\includegraphics{images/testing_pyramid.png}
\caption{Testing Pyramid}
\end{figure}

Finally, since manual tests are run by people (who are comparatively
slow and costly), these should be the \emph{rarest} kind of test.

\hypertarget{testing-team}{%
\subsection{Testing Team}\label{testing-team}}

Sometimes, testing is handled by external teams (possibly in other
locales). This is often done as a \textbf{cost-saving measure}, but
comes with some penalties such as: - Increased \textbf{Bureacratic Risk}
in terms of having to engage with an external company. - \textbf{Agency
Risk} because the testing team are a \emph{business in their own right},
who might be more interested in the goal of making money from you than
shipping your product. - Obvious \textbf{Coordination Risk} in trying to
arrange work in other teams, buildings, timezones or countries, and not
having control on exactly which staff are dealing with your product. -
\textbf{Visibility Risk} because at some level, the testing team need to
understand \emph{what your software is for}.

\hypertarget{test-driven-development}{%
\subsection{Test-Driven Development}\label{test-driven-development}}

Also called test-first development, the idea here (from \textbf{Extreme
Programming}) is that you write the tests before the code, in order that
you think up-front about the requirements of the software you are
writing. The aim of this is to minimize \textbf{Complexity Risk} via
preventing developers from
\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}, and getting them to do \textbf{The Simplest Thing That Can
Possibly Work}.

Additionally, by having test \emph{fail} before they \emph{pass}, you
mitigate the risk of writing a ``null'' test (see below).

\hypertarget{code-coverage}{%
\subsection{Code Coverage}\label{code-coverage}}

Code Coverage tools are a useful way of showing you which parts of your
software might contain bugs due to lack of testing, which is really
useful in the \textbf{Risk Evaluation} phase of test-planning.

Sometimes code coverage spawns its own \textbf{Map And Territory Risks}
though, where people forget that the goal should be mitigating overall
project risk (via delivering functionality and so forth) and start to
believe that the goal is delivering 100\% code coverage. Writing tests
to cover every \texttt{get()} method is a fools' errand which increases
the overall \textbf{codebase complexity} for no real reduction in
\textbf{Feature Risk}.

Worse still is that having 100\% code coverage does not guarantee an
absence of bugs, or that the code will do what the users wanted it to
do. \textbf{Feature Risk} is always there.

\hypertarget{risks-mitigated}{%
\section{Risks Mitigated}\label{risks-mitigated}}

There are so many different types of testing and this guide is not meant
to be exhaustive. Instead, here is a table covering some of the main
types of testing and the risks they mitigate:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.27\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.67\columnwidth}\raggedright
Mitigation\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Boundary Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
System Integration TestingCI DeploymentUser Acceptance Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Dependency Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
Integration TestingSystem Integration Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Production Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
Performance Testing / Load TestingNon-Functional TestingDisaster
Recovery TestingSecurity estingSmoke / Sanity Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Software Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
Unit TestingComponent TestingEnd-To-End TestingFunctional Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Feature Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
Browser-Based TestingAccessibility TestingAcceptance Testing (UAT)Beta
Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Visibility Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
Usability TestingCorridor Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
\textbf{Complexity Risk}\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
Unit TestingAutomated Acceptance testingIntegration Testing\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{attendant-risks-5}{%
\section{Attendant Risks}\label{attendant-risks-5}}

Firstly, it can be easy to fool yourself with tests: just because your
tests pass does \emph{not} mean your code is perfect. Vigilance is
required against \textbf{Map And Territory Risk}:

\begin{itemize}
\tightlist
\item
  Do the tests explore the behaviour of the system the same way the
  users will?
\item
  Can you be sure you haven't written a ``null test'', one that passes
  when it should fail?
\item
  Have you covered the ``cracks'' between the different parts of the
  system? Just because all the \emph{components} of a bicycle are fine,
  it doesn't mean that the \emph{bike itself will work}.
\end{itemize}

Second, Testing is a double-edged sword. While it allows you to mitigate
various \textbf{Feature Risks}, by adding test-code to your project you
are necessarily increasing the \textbf{complexity}. Maintaining tests is
hard work, and if you're not careful, \emph{running} tests can take time
and slow down builds and add delay through \textbf{Process Risk}.

Third, if you are \textbf{exploring functionality} in order to flush out
requirements, understand user behaviour or figure out performance
characteristics, then there is \emph{no point in building tests} yet:
what you are doing is exploratory at best and the extra code will
\textbf{slow you down}.

For these reasons, focus on writing the \emph{smallest number of tests
that mitigates the risks}.

\hypertarget{see-also-1}{%
\section{See Also}\label{see-also-1}}

\href{https://www.amazon.co.uk/Risk-Driven-Agile-Testing-risk-based-effective-ebook/dp/B06XGL4CDL/ref=sr_1_1?ie=UTF8\&qid=1521908627\&sr=8-1\&keywords=risk+based+agile+testing}{Risk
Based Agile Testing} by Martin Ivison, which covers a lot of this ground
in much more detail.

\part{Methodologies}

\hypertarget{methodologies}{%
\chapter{Methodologies}\label{methodologies}}

Thinking is hard. And worrying about Risk constantly would be
\emph{exhausting}.

Life is too short to go around considering Risk Management over
everything you do.

Luckily, our brains do it for us automatically and subconsiously:
Sometimes a voice inside will cry out Wait! before we walk out into a
road or try to pick up a hot teapot.

\hypertarget{habit-and-experience}{%
\section{Habit and Experience}\label{habit-and-experience}}

These subconsious reactions are borne of two things: \textbf{habit} (we
drill our children from an early age in crossing the road to embed road
safety) and \textbf{experience} (after picking up lots of too-hot
kitchenware, you don't do it again).

In this section (on Methodology), we're going to focus on how
\textbf{habit} can help us short-cut the Risk Management process, whilst
in the next we'll look at \textbf{experience}.

When it sticks, a methodology embeds a set of practices in a team to
such an extent that they become \emph{habit}: the team following the
methodology from feature to feature or release to release without
question.

\hypertarget{a-pattern-language}{%
\section{A Pattern Language}\label{a-pattern-language}}

\begin{figure}
\centering
\includegraphics{images/pattern.png}
\caption{A Pattern Language}
\end{figure}

It stands to reason that if \textbf{all software is about risk
management}, then we can examine methodologies \emph{themselves} in
terms of how their practices mitigate risk, and change the balance of
risk on projects.

With that in mind, we are going to examine several methodologies, and
break them down into their key \emph{practices}. For each practice, we
will look at which \textbf{attendant risks} it mitigates, and what
\textbf{attendant risks} it incurs.

!Show similarity between pattern and practice

So \emph{Methodology} exists as a way

ceremony practices bureacratic overhead

a point of religion.

The questions we want to ask in this section are as follows:

-How do frameworks change the risk landscape?

What are the risks in choosing a framework?

How does choosing a framework (at all) modify our risk landscape?

How should we choose a framework, then?

Evolution of software

There are more methodologies than stars in the sky, and it's not useful
to look at all of them. Instead, we're going to pick a few
\emph{archetypes} and leave it at that.

So, let's start at the beginning then, with \textbf{Waterfall}.

\hypertarget{its-the-same-steps-but-its-sizing-those-steps}{%
\subsection{It's the same steps, but it's Sizing those
steps:}\label{its-the-same-steps-but-its-sizing-those-steps}}

Agile is per-feature delivery, Waterfall is a bunch of features.

But, a lot of the practices end up being the same.

\hypertarget{waterfall}{%
\chapter{Waterfall}\label{waterfall}}

\href{https://en.wikipedia.org/wiki/Waterfall_model}{Waterfall} is a
linear, stepwise approach to the processes involved in delivering a
software system, and it really represents a family of methodologies,
such as
\href{https://en.wikipedia.org/wiki/Rational_Unified_Process}{RUP} or
\href{https://en.wikipedia.org/wiki/Structured_systems_analysis_and_design_method}{SSADM}.

\hypertarget{major-practices}{%
\section{Major Practices}\label{major-practices}}

The specifics differ from one formulation to another, but generally
speaking the process looks something like this:

\begin{figure}
\centering
\includegraphics{images/methodology_waterfall.png}
\caption{Waterfall Methodology}
\end{figure}

As shown in the diagram above, the software process is broken into
distinct stages, usually including:

\begin{itemize}
\tightlist
\item
  \textbf{Requirements Capture}
\item
  \textbf{Design}
\item
  \textbf{Implementation}
\item
  \textbf{Verification}
\item
  \textbf{Delivery} and \textbf{Operations}
\item
  \textbf{Sign Offs} at each stage
\end{itemize}

\hypertarget{variations-4}{%
\subsection{Variations}\label{variations-4}}

\begin{itemize}
\tightlist
\item
  \textbf{Prototyping}: Picking a particularly high-risk part of the
  project (such as UI elements) and delivering it first.\\
\item
  \textbf{Business Case}: Adding a stage in the at the start of the
  project to perform some benefits calculations.
\item
  \textbf{Cycles}: Delivering in multiple, incremental stages.
\end{itemize}

\hypertarget{risks-mitigated-1}{%
\section{Risks Mitigated}\label{risks-mitigated-1}}

\hypertarget{cost-of-implementation}{%
\subsection{\texorpdfstring{1. \textbf{Cost Of
Implementation}}{1. Cost Of Implementation}}\label{cost-of-implementation}}

It's likely that the Waterfall-Style methodologies were inspired by the
construction industry, wherein we try to \textbf{Design Up Front} in
order to avoid the cost of re-work: once concrete is poured, it's
expensive to change it again, compared to the cost of updating the
design in a diagram.

Also, when Waterfall was originally conceived, automated testing
techniques were not well established. If you expect to perform a large
\textbf{manual testing cycle} for each release, then clearly, doing
fewer releases looks cheaper on paper.

But, while \emph{in principle}, Waterfall aims to \emph{contain} the
cost of implementation. However, in practice, because of
\textbf{Requirements Drift}, \textbf{Student Syndrome} and
\textbf{Complexity Risk}, the schedules get more inaccurate the larger
the project.

\hypertarget{lots-of-stakeholders}{%
\subsection{\texorpdfstring{2. \textbf{Lots Of
Stakeholders}}{2. Lots Of Stakeholders}}\label{lots-of-stakeholders}}

In any construction project, there are likely to be lots of stakeholders
- landowners, neighbours, government, clients and so on.

Waterfall tries to mitigate this risk by getting \textbf{Sign-Offs} as
it goes along.

Additionally, by putting in the work at the planning and design stage,
hopefully this means lots of staff can work together and not interfere
with each other when the time for construction comes.

\hypertarget{agency-risk-1}{%
\subsection{\texorpdfstring{4. \textbf{Agency
Risk}}{4. Agency Risk}}\label{agency-risk-1}}

Because of it's step-wise delivery and reduction in visibility risk,
Waterfall documentation can be used as the basis for \textbf{contracted
delivery}, and this is useful in situations where you are employing 3rd
parties or putting work to tender.

This is very different from the way \textbf{Agency Risk} is mitigated
in, say \textbf{Scrum}, which relies on the \textbf{On Site Customer} to
police the implementation team.

\hypertarget{bureaucratic-risk}{%
\subsection{\texorpdfstring{5. \textbf{Bureaucratic
Risk}}{5. Bureaucratic Risk}}\label{bureaucratic-risk}}

Where projects can get tied up in lots of red tape, a Waterfall process
can supply enough gravitas in the form of documentation and ceremony in
order to appease bureaucracy, in a way that \textbf{Lean} or
\textbf{Agile} methods do not.

Additionally, because a \textbf{plan} can be based on the
\textbf{Design}, you can include bureaucratically-onerous tasks in the
plan and work on these in parallel.

\hypertarget{attendant-risks-6}{%
\section{Attendant Risks}\label{attendant-risks-6}}

\hypertarget{complexity-risk-3}{%
\subsection{\texorpdfstring{1. \textbf{Complexity
Risk}}{1. Complexity Risk}}\label{complexity-risk-3}}

One of the biggest problems in sticking to a \textbf{Design}, rather
than letting the design evolve, is that you are not going to be
practicing \textbf{Refactoring} in order to keep down

\hypertarget{production-risk-1}{%
\subsection{\texorpdfstring{2. \textbf{Production
Risk}}{2. Production Risk}}\label{production-risk-1}}

The fewer different \textbf{phases or cycles} in your project, the fewer
times you will \textbf{Meet Reality}
